<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Roger-Lv's space</title><meta name="author" content="Roger-Lv"><meta name="copyright" content="Roger-Lv"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Send a flare and light the way.">
<meta property="og:type" content="website">
<meta property="og:title" content="Roger-Lv&#39;s space">
<meta property="og:url" content="http://example.com/page/6/index.html">
<meta property="og:site_name" content="Roger-Lv&#39;s space">
<meta property="og:description" content="Send a flare and light the way.">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/avatar.jpg">
<meta property="article:author" content="Roger-Lv">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/avatar.jpg"><script type="application/ld+json"></script><link rel="shortcut icon" href="/img/avatar.jpg"><link rel="canonical" href="http://example.com/page/6/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=5.4.2"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.2/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":-1,"unescape":true,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.12.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Roger-Lv\'s space',
  isHighlightShrink: false,
  isToc: false,
  pageType: 'home'
}</script><link rel="stylesheet" href="/css/font.css"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">149</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">128</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">41</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url(/img/jinx.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Roger-Lv's space</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div><!-- 添加搜索按钮 ↓--><span class="search-button"><i class="fas fa-search" aria-hidden="true"></i></span></div></nav><div id="site-info"><h1 id="site-title">Roger-Lv's space</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/Roger-Lv" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:1150568956@qq.com" target="_blank" title="Email"><i class="fas fa-envelope-open-text" style="color: #4a7dbe;"></i></a><a class="social-icon" href="https://www.linkedin.com/in/zhongrenjie-lv-5588a928a/" target="_blank" title="LinkedIn"><i class="iconfont icon-linkedin-fill"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts nc" id="recent-posts"><div class="recent-post-items"><div class="recent-post-item"><div class="post_cover left"><a href="/2025/08/18/2025-08-15-Camel%E6%A1%86%E6%9E%B6/" title="Camel框架"><img class="post-bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/camel.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Camel框架"></a></div><div class="recent-post-info"><a class="article-title" href="/2025/08/18/2025-08-15-Camel%E6%A1%86%E6%9E%B6/" title="Camel框架">Camel框架</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-08-17T16:00:00.000Z" title="发表于 2025-08-18 00:00:00">2025-08-18</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Agent/">Agent</a></span></div><div class="content">NeurIPS 2023｜AI Agents先行者CAMEL:第一个基于大模型的多智能体框架 转自：https://zhuanlan.zhihu.com/p/671093582 AI Agents是当下大模型领域备受关注的话题，用户可以引入多个扮演不同角色的LLM Agents参与到实际的任务中，Agents之间会进行竞争和协作等多种形式的动态交互，进而产生惊人的群体智能效果。本文介绍了来自KAUST研究团队的大模型心智交互CAMEL框架（“骆驼”），CAMEL框架是最早基于ChatGPT的autonomous agents知名项目，目前已被顶级人工智能会议NeurIPS 2023录用。  1777dbe9073c4bcd8ab59365481bcafc.png  论文题目： CAMEL: Communicative Agents for “Mind” Exploration of Large Scale Language Model Society 论文链接： https://ghli.org/camel.pdf 代码链接： https://github.com/camel-a...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2025/08/18/2025-08-18-%E6%9E%81%E7%AE%80-Megatron-LM-%E6%A8%A1%E5%9E%8B%E5%B9%B6%E8%A1%8C%E5%88%87%E5%88%86%E4%BB%8B%E7%BB%8D/" title="极简 Megatron-LM 模型并行切分介绍"><img class="post-bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/Megatron.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="极简 Megatron-LM 模型并行切分介绍"></a></div><div class="recent-post-info"><a class="article-title" href="/2025/08/18/2025-08-18-%E6%9E%81%E7%AE%80-Megatron-LM-%E6%A8%A1%E5%9E%8B%E5%B9%B6%E8%A1%8C%E5%88%87%E5%88%86%E4%BB%8B%E7%BB%8D/" title="极简 Megatron-LM 模型并行切分介绍">极简 Megatron-LM 模型并行切分介绍</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-08-17T16:00:00.000Z" title="发表于 2025-08-18 00:00:00">2025-08-18</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/AIInfra/">AIInfra</a></span></div><div class="content">极简 Megatron-LM 模型并行切分介绍 转自：https://zhuanlan.zhihu.com/p/498422407 在大模型流行的年代，我经常需要给同事解释 Megatron-LM 是怎么做的模型并行，自己也经常记不清从头推。而现有大多数的文章都是算法向或者历史向的，信息浓度比较低。为了节省大家的时间，在这里记录一下 Megatron-LM 的切分方式。由于只考虑切分，所以本文忽略 transformer 模型中的各种 elementwise 运算和 layernorm。 下文中，我们规定 b 为 batch size，s 为 sequence length，h 为 hidden size，n 为 num head，p 为切分数，用中括号表示 tensor 形状，例如 [b, s, h] 为常规的 transformer encoder 输入。这种表示方法参考了尤洋老师的 An Efficient 2D Method for Training Super-Large Deep Learning Models。 transformer encoder 结构 tran...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2025/08/17/2025-08-15-RAG/" title="多Agent"><img class="post-bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/LLM.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="多Agent"></a></div><div class="recent-post-info"><a class="article-title" href="/2025/08/17/2025-08-15-RAG/" title="多Agent">多Agent</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-08-16T16:00:00.000Z" title="发表于 2025-08-17 00:00:00">2025-08-17</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/RAG/">RAG</a></span></div><div class="content">多Agent https://www.zhihu.com/question/642650878/answer/1896282773486011813 https://zhuanlan.zhihu.com/p/1908922657027621854 多Agent系统，任务：https://zhuanlan.zhihu.com/p/1909200989090722209 AutoAgents是一个创新的框架，根据不同任务自适应地生成和协调多个专用代理来构建AI团队。AutoAgents通过动态生成多个所需代理并基于生成的专家代理为当前任务规划解决方案，将任务与角色之间的关系相结合。多个专门的代理相互协作以高效地完成任务。该框架还融入了观察者角色，反映指定计划和代理响应，并对其进行改进。该论文在各种基准测试上的实验证明，AutoAgents生成的解决方案比现有的多代理方法更连贯准确，为处理复杂任务提供了新的视角。 地址：https://http://arxiv.org/pdf/2309.17288 代码：https://http://github.com/LinkSoul-AI/Aut...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2025/08/15/2025-08-15-ray-accelerate-trainer-lightning-pytorch/" title="ray accelerate trainer lightning pytorch"><img class="post-bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/LLM.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ray accelerate trainer lightning pytorch"></a></div><div class="recent-post-info"><a class="article-title" href="/2025/08/15/2025-08-15-ray-accelerate-trainer-lightning-pytorch/" title="ray accelerate trainer lightning pytorch">ray accelerate trainer lightning pytorch</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-08-14T16:00:00.000Z" title="发表于 2025-08-15 00:00:00">2025-08-15</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/AIInfra/">AIInfra</a></span></div><div class="content">ray、accelerate、trainer、lightning、pytorch 转自：https://www.zhihu.com/question/1926849595331318550/answer/1928049512619968205 作者：CodeCrafter 链接：https://www.zhihu.com/question/1926849595331318550/answer/1939450608894608104 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 2025 年，纯 PyTorch 是基本功，你必须得会，而且要熟。 它是你的内力，是你理解一切上层框架的基础。 Hugging Face Trainer 是特定领域（尤其是 NLP）的“版本答案”。 如果你就是做微调、做推理，用它，省心省力，快速出活儿。 Lightning 和 Accelerate 是“效率增强器”。 帮你把 PyTorch 代码写得更规范、更工程化，让你从繁琐的样板代码里解放出来，专注于模型本身。 Ray… 这家伙是个“大杀器”，跟前面几个不是一个维度...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2025/08/15/2025-08-15-xpu_timer/" title="xpu_timer"><img class="post-bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/LLM.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="xpu_timer"></a></div><div class="recent-post-info"><a class="article-title" href="/2025/08/15/2025-08-15-xpu_timer/" title="xpu_timer">xpu_timer</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-08-14T16:00:00.000Z" title="发表于 2025-08-15 00:00:00">2025-08-15</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/AIInfra/">AIInfra</a></span></div><div class="content">xpu_timer 转自：https://cloud.tencent.com/developer/article/2418684 背景 随着大型模型的参数量从十亿量级跃升至万亿级别，其训练规模的急剧扩张不仅引发了集群成本的显著上涨，还对系统稳定性构成了挑战，尤其是机器故障的频发成为不可忽视的问题。对于大规模分布式训练任务而言，可观测性能力成为了排查故障、优化性能的关键所在。所以从事大型模型训练领域的技术人，都会不可避免地面临以下挑战：  训练过程中，性能可能会因网络、计算瓶颈等多种因素而不稳定，出现波动甚至衰退； 分布式训练是多个节点协同工作的，任一节点发生故障（无论是软件、硬件、网卡或 GPU 问题），整个训练流程均需暂停，严重影响训练效率，而且浪费宝贵的 GPU 资源。  但在实际的大模型训练过程中，这些问题是很难排查的，主要原因如下：  训练过程为同步操作，很难通过整体性能指标来排除此时哪些机器出现问题，一个机器慢可以拖慢整体训练速度； 训练性能变慢往往不是训练逻辑/框架的问题，通常为环境导致，如果没有训练相关的监控数据，打印 timeline 实际上也没有任何作用，并且同...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2025/08/14/2025-08-13-Qwen3%E6%8A%80%E6%9C%AF%E6%96%87%E6%A1%A3/" title="Qwen3技术报告解读"><img class="post-bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/Qwen.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Qwen3技术报告解读"></a></div><div class="recent-post-info"><a class="article-title" href="/2025/08/14/2025-08-13-Qwen3%E6%8A%80%E6%9C%AF%E6%96%87%E6%A1%A3/" title="Qwen3技术报告解读">Qwen3技术报告解读</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-08-13T16:00:00.000Z" title="发表于 2025-08-14 00:00:00">2025-08-14</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B/">大模型</a></span></div><div class="content">Qwen3技术报告解读 转自：https://zhuanlan.zhihu.com/p/1905926139756680880 模型架构 Qwen3系列，包括6个Dense模型，分别是Qwen3-0.6B、Qwen3-1.7B、Qwen3-4B、Qwen3-8B、Qwen3-14B和Qwen3-32B；2个MoE模型，分别是Qwen3-30B-A3B和Qwen3-235B-A22B。 Qwen3 Dense模型的架构与Qwen2.5相似，包括GQA、SwiGLU、RoPE以及RMSNorm with pre-normalization。此外，移除了Qwen2中使用的QKV偏置，并在注意力机制中引入了QK-Norm，以确保Qwen3的稳定训练。  Qwen3 MoE模型采用了细粒度专家分割，共有128个专家，激活8个专家。但与Qwen2.5-MoE不同，Qwen3-MoE去除了共享专家。同时，采用了全局批次负载平衡损失。  预训练 预训练数据共36T Tokens，包含119种语言和方言，涉及代码、STEM、推理任务、书籍、合成数据等。 其中，有部分数据是Qwen2.5-VL模型对...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2025/08/14/2025-08-14-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E6%8A%80%E6%9C%AF/" title="大模型蒸馏技术"><img class="post-bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/Distillation.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="大模型蒸馏技术"></a></div><div class="recent-post-info"><a class="article-title" href="/2025/08/14/2025-08-14-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E6%8A%80%E6%9C%AF/" title="大模型蒸馏技术">大模型蒸馏技术</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-08-13T16:00:00.000Z" title="发表于 2025-08-14 00:00:00">2025-08-14</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B/">大模型</a></span></div><div class="content">导读 在人工智能快速发展的今天，模型的规模越来越大，计算成本也越来越高，这对中小型开发者来说无疑是一个巨大的挑战：如何通过将大模型的知识和能力浓缩到更小、更轻量化的模型中，降低硬件要求，以更低的成本享受到先进的人工智能技术？  DeepSeek-R1及其API的开源标志着这一领域的重要突破。 对于中小型开发者而言，这意味着他们不再需要依赖庞大的计算资源就能实现高效、强大的人工智能应用。DeepSeek提供的开源蒸馏检查点（如基于Qwen2.5和Llama3系列的1.5B、7B、8B等参数规模）为开发者提供了丰富的选择空间，无论是初创公司还是个人项目，都可以根据自身需求灵活调用这些模型。   github 地址：https://github.com/deepseek-ai/DeepSeek-R1  这一技术不仅降低了人工智能的准入门槛，也为中小型开发者在资源有限的情况下实现创新提供了更多可能性。通过蒸馏模型，他们可以更专注于业务逻辑和应用场景的优化，而无需过多关注底层计算资源的限制。这无疑将推动人工智能技术在更广泛的领域中落地生根。  接下来，详细跟大家聊聊模型蒸馏。  一、为什么...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2025/08/14/2025-08-14-Qwen2.5%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E5%85%A5%E9%97%A8%E5%AE%9E%E6%88%98/" title="Qwen2.5大模型微调入门实战"><img class="post-bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/Qwen.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Qwen2.5大模型微调入门实战"></a></div><div class="recent-post-info"><a class="article-title" href="/2025/08/14/2025-08-14-Qwen2.5%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E5%85%A5%E9%97%A8%E5%AE%9E%E6%88%98/" title="Qwen2.5大模型微调入门实战">Qwen2.5大模型微调入门实战</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-08-13T16:00:00.000Z" title="发表于 2025-08-14 00:00:00">2025-08-14</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B/">大模型</a></span></div><div class="content">Qwen2.5大模型微调入门实战 知识点：什么是全参数微调？ 大模型全参数微调是指对预训练大模型的所有参数进行更新和优化，区别于部分参数微调和LoRA微调。 这种方法通过将整个模型权重（包括底层词嵌入、中间特征提取层和顶层任务适配层）在下游任务数据上进行梯度反向传播，使模型整体适应新任务的需求。相比仅微调部分参数，全参数微调能更充分地利用预训练模型的泛化能力，并针对特定任务进行深度适配，通常在数据差异较大或任务复杂度较高的场景下表现更优。  不过，全参数微调往往需要更高的计算资源和存储开销，且存在**过拟合风险**（尤其在小数据集上）。实际应用中常结合学习率调整、参数分组优化或正则化技术来缓解这些问题。 全参数微调多用于对模型表现性能要求较高的场景，例如专业领域知识问答或高精度文本生成。 1. 环境安装 本案例基于Python&gt;=3.8，请在您的计算机上安装好Python； 另外，您的计算机上至少要有一张英伟达/昇腾显卡（显存要求大概32GB左右可以跑）。 我们需要安装以下这几个Python库，在这之前，请确保你的环境内已安装了pytorch以及CUDA： 1234567s...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2025/08/14/2025-08-14-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%BB%8E%E8%BD%AF%E6%A0%87%E7%AD%BE%E5%88%B0%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6/" title="知识蒸馏技术原理详解:从软标签到模型压缩的实现机制"><img class="post-bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/soft.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="知识蒸馏技术原理详解:从软标签到模型压缩的实现机制"></a></div><div class="recent-post-info"><a class="article-title" href="/2025/08/14/2025-08-14-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%BB%8E%E8%BD%AF%E6%A0%87%E7%AD%BE%E5%88%B0%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6/" title="知识蒸馏技术原理详解:从软标签到模型压缩的实现机制">知识蒸馏技术原理详解:从软标签到模型压缩的实现机制</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-08-13T16:00:00.000Z" title="发表于 2025-08-14 00:00:00">2025-08-14</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B/">大模型</a></span></div><div class="content">知识蒸馏技术原理详解：从软标签到模型压缩的实现机制 **知识蒸馏**是一种通过性能与模型规模的权衡来实现模型压缩的技术。其核心思想是将较大规模模型（称为教师模型）中的知识迁移到规模较小的模型（称为学生模型）中。本文将深入探讨知识迁移的具体实现机制。  知识蒸馏原理 知识蒸馏的核心目标是实现从教师模型到学生模型的知识迁移。在实际应用中，无论是大规模语言模型（LLMs）还是其他类型的神经网络模型，都会通过softmax函数输出概率分布。  Softmax输出示例分析 考虑一个输出三类别概率的神经网络模型。假设教师模型输出以下logits值： 教师模型logits： [1.1, 0.2, 0.2] 经过softmax函数转换后得到： Softmax概率分布： [0.552, 0.224, 0.224] 此时，类别0获得最高概率，成为模型的预测输出。模型同时为类别1和类别2分配了较低的概率值。这种概率分布表明，尽管输入数据最可能属于类别0，但其特征表现出了与类别1和类别2的部分相关性。 低概率信息的利用价值 在传统分类任务中，由于最高概率（0.552）显著高于其他概率值（均为0.224）...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2025/08/13/2025-08-13-Shall-We-Pretrain-Autoregressive-Language-Models-with-Retrieval/" title="Shall We Pretrain Autoregressive Language Models with Retrieval"><img class="post-bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/LLM.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Shall We Pretrain Autoregressive Language Models with Retrieval"></a></div><div class="recent-post-info"><a class="article-title" href="/2025/08/13/2025-08-13-Shall-We-Pretrain-Autoregressive-Language-Models-with-Retrieval/" title="Shall We Pretrain Autoregressive Language Models with Retrieval">Shall We Pretrain Autoregressive Language Models with Retrieval</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-08-12T16:00:00.000Z" title="发表于 2025-08-13 00:00:00">2025-08-13</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B/">大模型</a></span></div><div class="content">Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study 解析论文《Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study》的主要内容 本文由 Boxin Wang 等人（主要来自 NVIDIA）撰写，旨在解决一个核心问题：在预训练自回归语言模型（如 GPT）时，是否应融入检索机制？ 通过全面研究检索增强模型 RETRO 及其变体 RETRO++，论文比较了 RETRO 与标准 GPT、微调阶段融入检索的 GPT（如 RAG）和推理阶段融入检索的 GPT（如 KNN-LM）的性能差异。研究基于大规模预训练（参数规模从 148M 到 9.5B，检索数据库包含 330B tokens），并覆盖文本生成质量(text generation quality)、下游任务准确性和毒性等多个维度。以下是详细解析，结构分为六个部分，确保内容逻辑清晰、层次丰富。  1...</div></div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/5/#content-inner"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/#content-inner">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/#content-inner">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/15/#content-inner">15</a><a class="extend next" rel="next" href="/page/7/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Roger-Lv</div><div class="author-info-description">Send a flare and light the way.</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">149</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">128</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">41</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Roger-Lv"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/Roger-Lv" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:1150568956@qq.com" target="_blank" title="Email"><i class="fas fa-envelope-open-text" style="color: #4a7dbe;"></i></a><a class="social-icon" href="https://www.linkedin.com/in/zhongrenjie-lv-5588a928a/" target="_blank" title="LinkedIn"><i class="iconfont icon-linkedin-fill"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">Welcome!</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/10/12/2025-10-12-Rust-just%E5%AE%89%E8%A3%85/" title="Rust-just安装"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/rust.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Rust-just安装"/></a><div class="content"><a class="title" href="/2025/10/12/2025-10-12-Rust-just%E5%AE%89%E8%A3%85/" title="Rust-just安装">Rust-just安装</a><time datetime="2025-10-11T16:00:00.000Z" title="发表于 2025-10-12 00:00:00">2025-10-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/30/2025-09-30-Langfuse-%E5%92%8C-ClickHouse-%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8/" title="Langfuse 和 ClickHouse 结合使用"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/tencent.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Langfuse 和 ClickHouse 结合使用"/></a><div class="content"><a class="title" href="/2025/09/30/2025-09-30-Langfuse-%E5%92%8C-ClickHouse-%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8/" title="Langfuse 和 ClickHouse 结合使用">Langfuse 和 ClickHouse 结合使用</a><time datetime="2025-09-29T16:00:00.000Z" title="发表于 2025-09-30 00:00:00">2025-09-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/24/2025-09-24-Intern-%E5%BF%AB%E9%80%9F-Landing+%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" title="Intern 快速 Landing+环境搭建"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/tencent.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Intern 快速 Landing+环境搭建"/></a><div class="content"><a class="title" href="/2025/09/24/2025-09-24-Intern-%E5%BF%AB%E9%80%9F-Landing+%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" title="Intern 快速 Landing+环境搭建">Intern 快速 Landing+环境搭建</a><time datetime="2025-09-23T16:00:00.000Z" title="发表于 2025-09-24 00:00:00">2025-09-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/20/2025-09-14-Autogen%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E4%BA%A4%E6%8E%A5/" title="Autogen多智能体交接"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/agent.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Autogen多智能体交接"/></a><div class="content"><a class="title" href="/2025/09/20/2025-09-14-Autogen%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E4%BA%A4%E6%8E%A5/" title="Autogen多智能体交接">Autogen多智能体交接</a><time datetime="2025-09-19T16:00:00.000Z" title="发表于 2025-09-20 00:00:00">2025-09-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/18/2025-09-17-GPU%E8%B5%84%E6%BA%90%E5%85%B1%E4%BA%AB%E6%8A%A2%E5%8D%A0/" title="GPU资源共享/抢占"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/k8s.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="GPU资源共享/抢占"/></a><div class="content"><a class="title" href="/2025/09/18/2025-09-17-GPU%E8%B5%84%E6%BA%90%E5%85%B1%E4%BA%AB%E6%8A%A2%E5%8D%A0/" title="GPU资源共享/抢占">GPU资源共享/抢占</a><time datetime="2025-09-17T16:00:00.000Z" title="发表于 2025-09-18 00:00:00">2025-09-18</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            <a class="card-more-btn" href="/categories/" title="查看更多">
      <i class="fas fa-angle-right"></i></a>
          </div>
          <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/AI-Infra/"><span class="card-category-list-name">AI Infra</span><span class="card-category-list-count">6</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/AIInfra/"><span class="card-category-list-name">AIInfra</span><span class="card-category-list-count">3</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Agent/"><span class="card-category-list-name">Agent</span><span class="card-category-list-count">21</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/CUDA/"><span class="card-category-list-name">CUDA</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Docker/"><span class="card-category-list-name">Docker</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Flowise/"><span class="card-category-list-name">Flowise</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Golang/"><span class="card-category-list-name">Golang</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/K8S/"><span class="card-category-list-name">K8S</span><span class="card-category-list-count">2</span></a></li>
          </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" style="font-size: 1.1em; color: #999">概率论</a> <a href="/tags/%E5%B9%B6%E5%8F%91/" style="font-size: 1.1em; color: #999">并发</a> <a href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/" style="font-size: 1.1em; color: #999">大模型微调</a> <a href="/tags/GFS/" style="font-size: 1.16em; color: #999b9e">GFS</a> <a href="/tags/KL%E6%95%A3%E5%BA%A6/" style="font-size: 1.1em; color: #999">KL散度</a> <a href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" style="font-size: 1.16em; color: #999b9e">动态规划</a> <a href="/tags/ResNet/" style="font-size: 1.1em; color: #999">ResNet</a> <a href="/tags/%E6%95%B0%E5%AD%97%E5%8C%96/" style="font-size: 1.1em; color: #999">数字化</a> <a href="/tags/LangGraph/" style="font-size: 1.21em; color: #999ea4">LangGraph</a> <a href="/tags/ElasticSearch/" style="font-size: 1.1em; color: #999">ElasticSearch</a> <a href="/tags/AutoGen/" style="font-size: 1.1em; color: #999">AutoGen</a> <a href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" style="font-size: 1.44em; color: #99a7ba">强化学习</a> <a href="/tags/WSL/" style="font-size: 1.1em; color: #999">WSL</a> <a href="/tags/AI%E4%BA%A7%E5%93%81/" style="font-size: 1.1em; color: #999">AI产品</a> <a href="/tags/memory/" style="font-size: 1.16em; color: #999b9e">memory</a> <a href="/tags/RL/" style="font-size: 1.33em; color: #99a2af">RL</a> <a href="/tags/Seq2Seq/" style="font-size: 1.1em; color: #999">Seq2Seq</a> <a href="/tags/Ollama/" style="font-size: 1.16em; color: #999b9e">Ollama</a> <a href="/tags/%E5%8F%8D%E5%B0%84/" style="font-size: 1.1em; color: #999">反射</a> <a href="/tags/Stream/" style="font-size: 1.1em; color: #999">Stream</a> <a href="/tags/SpringBoot/" style="font-size: 1.1em; color: #999">SpringBoot</a> <a href="/tags/RPC/" style="font-size: 1.1em; color: #999">RPC</a> <a href="/tags/%E5%AE%B9%E5%99%A8%E5%8C%96/" style="font-size: 1.21em; color: #999ea4">容器化</a> <a href="/tags/%E5%A4%8F%E4%BB%A4%E8%90%A5/" style="font-size: 1.1em; color: #999">夏令营</a> <a href="/tags/C/" style="font-size: 1.21em; color: #999ea4">C++</a> <a href="/tags/Agent/" style="font-size: 1.5em; color: #99a9bf">Agent</a> <a href="/tags/CNN/" style="font-size: 1.1em; color: #999">CNN</a> <a href="/tags/Longformer/" style="font-size: 1.1em; color: #999">Longformer</a> <a href="/tags/SRV6/" style="font-size: 1.1em; color: #999">SRV6</a> <a href="/tags/Transformer/" style="font-size: 1.1em; color: #999">Transformer</a> <a href="/tags/%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84/" style="font-size: 1.1em; color: #999">基础架构</a> <a href="/tags/%E5%90%8E%E7%AB%AF/" style="font-size: 1.39em; color: #99a4b4">后端</a> <a href="/tags/Megatron/" style="font-size: 1.16em; color: #999b9e">Megatron</a> <a href="/tags/SDN/" style="font-size: 1.1em; color: #999">SDN</a> <a href="/tags/%E7%BA%BF%E6%AE%B5%E6%A0%91/" style="font-size: 1.1em; color: #999">线段树</a> <a href="/tags/%E6%8E%A7%E5%88%B6%E9%9D%A2/" style="font-size: 1.1em; color: #999">控制面</a> <a href="/tags/linux/" style="font-size: 1.1em; color: #999">linux</a> <a href="/tags/MCP/" style="font-size: 1.27em; color: #99a0a9">MCP</a> <a href="/tags/%E8%B4%AA%E5%A9%AA%E8%A7%A3%E7%A0%81/" style="font-size: 1.1em; color: #999">贪婪解码</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 1.16em; color: #999b9e">深度学习</a></div></div><div class="card-widget card-archives">
    <div class="item-headline">
      <i class="fas fa-archive"></i>
      <span>归档</span>
      <a class="card-more-btn" href="/archives/"
            title="查看更多">
            <i class="fas fa-angle-right"></i>
          </a>
    </div>
  
    <ul class="card-archive-list">
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2025/10/">
            <span class="card-archive-list-date">
              十月 2025
            </span>
            <span class="card-archive-list-count">1</span>
          </a>
        </li>
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2025/09/">
            <span class="card-archive-list-date">
              九月 2025
            </span>
            <span class="card-archive-list-count">37</span>
          </a>
        </li>
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2025/08/">
            <span class="card-archive-list-date">
              八月 2025
            </span>
            <span class="card-archive-list-count">30</span>
          </a>
        </li>
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2025/07/">
            <span class="card-archive-list-date">
              七月 2025
            </span>
            <span class="card-archive-list-count">2</span>
          </a>
        </li>
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2025/06/">
            <span class="card-archive-list-date">
              六月 2025
            </span>
            <span class="card-archive-list-count">2</span>
          </a>
        </li>
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2025/02/">
            <span class="card-archive-list-date">
              二月 2025
            </span>
            <span class="card-archive-list-count">1</span>
          </a>
        </li>
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2024/10/">
            <span class="card-archive-list-date">
              十月 2024
            </span>
            <span class="card-archive-list-count">1</span>
          </a>
        </li>
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2024/09/">
            <span class="card-archive-list-date">
              九月 2024
            </span>
            <span class="card-archive-list-count">24</span>
          </a>
        </li>
      
    </ul>
  </div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站信息</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">149</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总浏览量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2025-10-24T03:28:37.650Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2024 - 2025 By Roger-Lv</span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.4.2"></script><script src="/js/main.js?v=5.4.2"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@19.1.3/dist/lazyload.iife.min.js"></script><div class="js-pjax"><script>window.typedJSFn = {
  init: str => {
    window.typed = new Typed('#subtitle', Object.assign({
      strings: str,
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50,
    }, null))
  },
  run: subtitleType => {
    if (true) {
      if (typeof Typed === 'function') {
        subtitleType()
      } else {
        btf.getScript('https://cdn.jsdelivr.net/npm/typed.js@2.1.0/dist/typed.umd.min.js').then(subtitleType)
      }
    } else {
      subtitleType()
    }
  },
  processSubtitle: (content, extraContents = []) => {
    if (true) {
      const sub = ["Under silent skies I hear the echo of your heart again.","Every tear you cry just drips away.","Won't you lift up the lights.","Come back to life.","You never thought you'd see the end.","So lift up the light won't you hold me tonight again.","Under silent skies."].slice()

      if (extraContents.length > 0) {
        sub.unshift(...extraContents)
      }

      if (typeof content === 'string') {
        sub.unshift(content)
      } else if (Array.isArray(content)) {
        sub.unshift(...content)
      }

      sub.length > 0 && typedJSFn.init(sub)
    } else {
      document.getElementById('subtitle').textContent = typeof content === 'string' ? content :
        (Array.isArray(content) && content.length > 0 ? content[0] : '')
    }
  }
}
btf.addGlobalFn('pjaxSendOnce', () => { typed.destroy() }, 'typedDestroy')
</script><script>function subtitleType () {
  typedJSFn.processSubtitle(["Under silent skies I hear the echo of your heart again.","Every tear you cry just drips away.","Won't you lift up the lights.","Come back to life.","You never thought you'd see the end.","So lift up the light won't you hold me tonight again.","Under silent skies."])
}
typedJSFn.run(subtitleType)</script><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid@11.8.0/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><div class="aplayer no-destroy" data-id="8674547170" data-server="netease" data-type="playlist" data-fixed="true" data-autoplay="true" data-lrcType="-1"> </div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.4/dist/fireworks.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.4/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.4/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=5.4.2"></script></div></div></body></html>