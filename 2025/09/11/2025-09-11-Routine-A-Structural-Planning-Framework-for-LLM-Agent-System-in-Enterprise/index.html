<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Routine:A Structural Planning Framework for LLM Agent System in Enterprise | Roger-Lv's space</title><meta name="author" content="Roger-Lv"><meta name="copyright" content="Roger-Lv"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Routine:A Structural Planning Framework for LLM Agent System in Enterprise 这篇论文的核心价值在于，它没有停留在“让大模型自己想”的层面，而是创造性地提供了一个“剧本”，从根本上解决了企业级Agent落地难的痛点。 我们将从问题根源、解决方案（Routine框架）、系统架构、训练方法、实验结果、核心洞见六个维度，层层递进地进">
<meta property="og:type" content="article">
<meta property="og:title" content="Routine:A Structural Planning Framework for LLM Agent System in Enterprise">
<meta property="og:url" content="http://example.com/2025/09/11/2025-09-11-Routine-A-Structural-Planning-Framework-for-LLM-Agent-System-in-Enterprise/index.html">
<meta property="og:site_name" content="Roger-Lv&#39;s space">
<meta property="og:description" content="Routine:A Structural Planning Framework for LLM Agent System in Enterprise 这篇论文的核心价值在于，它没有停留在“让大模型自己想”的层面，而是创造性地提供了一个“剧本”，从根本上解决了企业级Agent落地难的痛点。 我们将从问题根源、解决方案（Routine框架）、系统架构、训练方法、实验结果、核心洞见六个维度，层层递进地进">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/cover/agent.png">
<meta property="article:published_time" content="2025-09-10T16:00:00.000Z">
<meta property="article:modified_time" content="2025-09-11T03:29:42.328Z">
<meta property="article:author" content="Roger-Lv">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="Agent">
<meta property="article:tag" content="RL">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/cover/agent.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Routine:A Structural Planning Framework for LLM Agent System in Enterprise",
  "url": "http://example.com/2025/09/11/2025-09-11-Routine-A-Structural-Planning-Framework-for-LLM-Agent-System-in-Enterprise/",
  "image": "http://example.com/img/cover/agent.png",
  "datePublished": "2025-09-10T16:00:00.000Z",
  "dateModified": "2025-09-11T03:29:42.328Z",
  "author": [
    {
      "@type": "Person",
      "name": "Roger-Lv",
      "url": "http://example.com"
    }
  ]
}</script><link rel="shortcut icon" href="/img/avatar.jpg"><link rel="canonical" href="http://example.com/2025/09/11/2025-09-11-Routine-A-Structural-Planning-Framework-for-LLM-Agent-System-in-Enterprise/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=5.4.2"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.2/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":-1,"unescape":true,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.12.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Routine:A Structural Planning Framework for LLM Agent System in Enterprise',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/font.css"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">175</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">150</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">49</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/default_top_img.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Roger-Lv's space</span></a><a class="nav-page-title" href="/"><span class="site-name">Routine:A Structural Planning Framework for LLM Agent System in Enterprise</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div><!-- 添加搜索按钮 ↓--><span class="search-button"><i class="fas fa-search" aria-hidden="true"></i></span></div></nav><div id="post-info"><h1 class="post-title">Routine:A Structural Planning Framework for LLM Agent System in Enterprise</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-09-10T16:00:00.000Z" title="发表于 2025-09-11 00:00:00">2025-09-11</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-09-11T03:29:42.328Z" title="更新于 2025-09-11 11:29:42">2025-09-11</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Agent/">Agent</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="leancloud_visitors" id="/2025/09/11/2025-09-11-Routine-A-Structural-Planning-Framework-for-LLM-Agent-System-in-Enterprise/" data-flag-title="Routine:A Structural Planning Framework for LLM Agent System in Enterprise"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span class="leancloud-visitors-count"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1>Routine:A Structural Planning Framework for LLM Agent System in Enterprise</h1>
<p>这篇论文的核心价值在于，它没有停留在“让大模型自己想”的层面，而是创造性地提供了一个“剧本”，从根本上解决了企业级Agent落地难的痛点。</p>
<p>我们将从<strong>问题根源、解决方案（Routine框架）、系统架构、训练方法、实验结果、核心洞见</strong>六个维度，层层递进地进行深度剖析。</p>
<p>PS:在附录提供了prompt、routin的格式、多步工具调用的例子</p>
<hr>
<h3 id="一、-问题根源：为什么企业级Agent总是“掉链子”？"><strong>一、 问题根源：为什么企业级Agent总是“掉链子”？</strong></h3>
<p>论文开篇就犀利地指出了当前LLM Agent在企业环境中失败的三大根本原因：</p>
<ol>
<li>
<p><strong>“无知” (Lack of Domain-Specific Process Knowledge)</strong>：</p>
<ul>
<li>通用大模型（如GPT-4）是“通才”，但不是“专才”。它不了解企业内部错综复杂的业务流程。</li>
<li><strong>后果</strong>：模型在规划时会遗漏关键步骤。论文特别指出，最容易被忽略的是<strong>权限验证</strong>（permission verification）和<strong>模型生成</strong>（model generation）这类工具。例如，一个HR查询任务，模型可能直接去查员工薪资，而忘了先验证当前用户是否有权限查看该信息，导致安全漏洞或执行失败。</li>
</ul>
</li>
<li>
<p><strong>“工具说明书看不懂” (Insufficient Tool Descriptions)</strong>：</p>
<ul>
<li>企业内部的API或工具文档往往不完善、不标准，甚至存在歧义。</li>
<li><strong>后果</strong>：即使模型知道“该做什么”，也不知道“用哪个工具做”以及“怎么填参数”。这直接导致了工具调用的不稳定和高错误率。</li>
</ul>
</li>
<li>
<p><strong>“计划书写得乱七八糟” (Lack of Unified, Structured Format)</strong>：</p>
<ul>
<li>当前的规划模块输出的往往是自由格式的自然语言指令，比如：“嗯…先查一下用户信息，然后…哦对，还得看看他的部门，最后生成个报告。”</li>
<li><strong>后果</strong>：执行模块需要“猜”模型的意图。这种“猜”的过程充满了不确定性，导致<strong>规划与执行严重脱节</strong>。执行模块可能误解步骤、跳过步骤、或调用错误的工具。</li>
</ul>
</li>
</ol>
<p><strong>总结来说，企业级Agent的失败，不是因为模型不够“聪明”，而是因为缺乏一个清晰、稳定、可执行的“操作手册”。</strong></p>
<hr>
<h3 id="二、-解决方案：Routine——你的AI“操作剧本”"><strong>二、 解决方案：Routine——你的AI“操作剧本”</strong></h3>
<p>Routine是这篇论文的灵魂。它不是一个算法，而是一个<strong>结构化的、人类和AI都能理解的“剧本”格式</strong>。</p>
<h4 id="2-1-Routine的精密结构"><strong>2.1 Routine的精密结构</strong></h4>
<p>一个完整的Routine由多个<code>Step</code>（步骤）组成，每个步骤是一个原子化的操作单元。其核心组件如下：</p>
<table>
<thead>
<tr>
<th style="text-align:left">组件 (Component)</th>
<th style="text-align:left">作用与意义</th>
<th style="text-align:left">为什么重要</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>Step Number</strong> (步骤编号)</td>
<td style="text-align:left"><code>Step 1</code>, <code>Step 2</code>, <code>Branch 3-1 Step 1</code></td>
<td style="text-align:left"><strong>明确执行顺序</strong>。让执行模型知道“现在该做第几步”，是线性执行还是进入分支。这是实现“按部就班”的基础。</td>
</tr>
<tr>
<td style="text-align:left"><strong>Step Name</strong> (步骤名称)</td>
<td style="text-align:left"><code>Check User Permission</code>, <code>Fetch Employee Data</code></td>
<td style="text-align:left"><strong>功能摘要</strong>。让人和AI能快速理解这一步是干什么的，便于调试和维护。</td>
</tr>
<tr>
<td style="text-align:left"><strong>Step Description</strong> (步骤描述)</td>
<td style="text-align:left">“验证当前用户ID是否有权访问目标员工的薪资信息。”</td>
<td style="text-align:left"><strong>详细指令</strong>。告诉执行模型“具体要做什么”，包括执行条件和目标。这是自然语言指令的核心。</td>
</tr>
<tr>
<td style="text-align:left"><strong>Step Tool</strong> (步骤工具)</td>
<td style="text-align:left"><code>verify_user_permission</code>, <code>get_employee_salary</code></td>
<td style="text-align:left"><strong>强制指定工具</strong>。这是Routine最革命性的设计！它把“选择哪个工具”这个高难度、高错误率的任务，降级为“执行哪个指令”的简单任务，极大降低了执行模型的认知负担。</td>
</tr>
<tr>
<td style="text-align:left"><strong>Input/Output Description</strong> (输入/输出描述) (可选)</td>
<td style="text-align:left">“输入：当前用户ID，目标员工ID；输出：布尔值（True/False）”</td>
<td style="text-align:left"><strong>参数指南</strong>。帮助执行模型理解需要什么参数，以及上一步的输出是什么。对能力较弱的模型是巨大的帮助。</td>
</tr>
</tbody>
</table>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 例子</span><br><span class="line">&lt;routines&gt;</span><br><span class="line">Step 1. Get announcements: Download the latest employee handbook file from the company’s internal system, use the `fetch_latest_announcements` tool;</span><br><span class="line">Step 2. Download handbook: Obtain the company’s most recent official announcement for consistency check with the employee handbook, use the `download_file` tool;</span><br><span class="line">Step 3. Read PDF content: Use text parsing tools to extract all text content from the employee handbook PDF file, use the `read_pdf` tool;</span><br><span class="line">Step 4. Compare text differences: Compare the relevant content in the employee handbook with the company’s latest announcement word by word, using the `compare_texts` tool, and end the workflow;</span><br><span class="line">&lt;/routines&gt;</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>步骤编号 (Step Number)</th>
<th>步骤名称 (Step Name)</th>
<th>步骤描述 (Step Description)</th>
<th>指定工具 (Step Tool)</th>
<th>输入输出</th>
</tr>
</thead>
<tbody>
<tr>
<td>Step 1</td>
<td>Get announcements</td>
<td>从公司内部系统下载最新的员工手册文件。</td>
<td>fetch_latest_announcements</td>
<td></td>
</tr>
<tr>
<td>Step 2</td>
<td>Download handbook</td>
<td>获取公司最新的官方公告，以便与员工手册进行一致性检查。</td>
<td>download_file</td>
<td></td>
</tr>
<tr>
<td>Step 3</td>
<td>Read PDF content</td>
<td>使用文本解析工具从员工手册的PDF文件中提取所有文本内容。</td>
<td>read_pdf</td>
<td></td>
</tr>
<tr>
<td>Step 4</td>
<td>Compare text differences</td>
<td>逐字比较员工手册中的相关内容与公司最新公告，然后结束工作流。</td>
<td>compare_texts</td>
<td></td>
</tr>
</tbody>
</table>
<h4 id="2-2-支持分支：处理复杂业务逻辑"><strong>2.2 支持分支：处理复杂业务逻辑</strong></h4>
<p>企业流程往往不是一条直线，而是充满“如果…那么…”的判断。Routine通过精妙的命名规则支持分支逻辑：</p>
<ul>
<li><strong><code>Step X.&lt;Name&gt;</code></strong>: 主步骤，通常是条件判断。</li>
<li><strong><code>Branch X-n Step i.&lt;Name&gt;</code></strong>: 表示主步骤 <code>X</code> 的第 <code>n</code> 个分支中的第 <code>i</code> 个步骤。</li>
</ul>
<blockquote>
<p><strong>示例：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Step 3. Check User Role:</span><br><span class="line">• Branch 3-1 Step 1. If user is &#x27;Manager&#x27;, fetch team data using `get_team_info`.</span><br><span class="line">• Branch 3-2 Step 1. If user is &#x27;Employee&#x27;, fetch personal data using `get_personal_info`.</span><br><span class="line">Step 4. Generate Report: Compile data using `generate_report`, and terminate.</span><br></pre></td></tr></table></figure>
</blockquote>
<p>这种设计让Routine能够描述几乎任何复杂的业务流程，而执行模型只需根据上一步的结果，找到对应的分支继续执行即可。</p>
<h4 id="2-3-工作流程：从草稿到执行"><strong>2.3 工作流程：从草稿到执行</strong></h4>
<ol>
<li>
<p><strong>生成Routine (Planning Module)</strong>：</p>
<ul>
<li><strong>输入</strong>：领域专家提供一个简单的、非结构化的流程草稿（Draft），例如：“先验证权限，再查数据，最后生成报告。”</li>
<li><strong>处理</strong>：一个强大的规划模型（如GPT-4o）接收这个草稿和可用的工具列表，根据预设的Prompt模板，将其<strong>优化、细化、结构化</strong>，输出一个包含所有必要组件的完整Routine。</li>
<li><strong>输出</strong>：一个格式清晰、指令明确的“操作剧本”。</li>
</ul>
</li>
<li>
<p><strong>执行Routine (Execution Module)</strong>：</p>
<ul>
<li><strong>输入</strong>：将生成的Routine、当前对话历史、变量内存、工具列表等，通过一个<strong>标准化的系统提示（System Prompt）</strong> 传递给执行模型。</li>
<li><strong>处理</strong>：执行模型（可以是小模型）<strong>严格遵循</strong>Routine的指示，按步骤编号，调用指定的工具，并传递正确的参数。</li>
<li><strong>输出</strong>：每一步只输出一个标准的工具调用指令（JSON格式），最终一步调用一个专门的“总结工具”生成面向用户的自然语言回复。</li>
</ul>
</li>
</ol>
<p><strong>核心思想</strong>：将复杂的“开放式推理规划”问题，转化为简单的“封闭式指令跟随”问题。</p>
<hr>
<h3 id="三、-系统架构：四大模块的协同革命"><strong>三、 系统架构：四大模块的协同革命</strong></h3>
<p>为了支撑Routine的高效运行，论文对传统Agent架构的四大模块进行了颠覆性的重新设计：</p>
<h4 id="3-1-Planning-Module-规划模块-：从“思考者”变为“编剧”"><strong>3.1 Planning Module (规划模块)：从“思考者”变为“编剧”</strong></h4>
<ul>
<li><strong>核心任务</strong>：生成和优化Routine。</li>
<li><strong>关键创新</strong>：利用AI（GPT-4o）将专家草稿转化为高质量的结构化剧本。这大大降低了专家的工作量，使得大规模生成Routine成为可能。</li>
<li><strong>与传统区别</strong>：传统规划模块输出的是模糊的自然语言计划；Routine规划模块输出的是精确的、可执行的“代码”。</li>
</ul>
<h4 id="3-2-Execution-Module-执行模块-：从“全能王”变为“执行者”"><strong>3.2 Execution Module (执行模块)：从“全能王”变为“执行者”</strong></h4>
<ul>
<li><strong>核心任务</strong>：严格按照Routine的指示，一步步调用工具。</li>
<li><strong>关键创新</strong>：
<ul>
<li><strong>模型降级</strong>：执行模块不需要强大的推理能力，只需要优秀的“指令跟随”能力。因此，可以使用<strong>小规模、低成本的模型</strong>（如Qwen3-8B）。</li>
<li><strong>职责分离</strong>：执行模型<strong>不负责生成最终的自然语言回复</strong>，而是调用一个专门的“总结工具”。这避免了在同一个Prompt中混合“工具调用”和“文本生成”两种任务，导致模型混淆。</li>
</ul>
</li>
<li><strong>与传统区别</strong>：传统架构中，规划和执行通常由同一个大模型完成，成本高昂。Routine架构实现了“大模型规划，小模型执行”，大幅降低成本。</li>
</ul>
<h4 id="3-3-Tool-Module-工具模块-：标准化与解耦"><strong>3.3 Tool Module (工具模块)：标准化与解耦</strong></h4>
<ul>
<li><strong>核心任务</strong>：提供稳定、可靠的工具接口。</li>
<li><strong>关键创新</strong>：采用 <strong>MCP (Model Context Protocol) 服务器</strong>。
<ul>
<li>MCP以标准化协议定义每个工具的名称、参数类型和调用约束。</li>
<li>执行模块只需关心“调哪个工具”和“传什么参”，无需了解工具内部实现。</li>
</ul>
</li>
<li><strong>优势</strong>：实现了<strong>执行逻辑与工具层的彻底解耦</strong>。开发者可以轻松添加、修改或替换工具，而不会影响执行模块，系统可扩展性极强。</li>
</ul>
<h4 id="3-4-Memory-Module-记忆模块-：智能的“上下文管理器”"><strong>3.4 Memory Module (记忆模块)：智能的“上下文管理器”</strong></h4>
<p>为了解决长上下文带来的成本和错误问题，设计了两种记忆：</p>
<ul>
<li>
<p><strong>Procedure Memory (流程记忆)</strong>：</p>
<ul>
<li><strong>作用</strong>：存储所有预定义的Routine。</li>
<li><strong>机制</strong>：当用户提问时，系统通过语义相似度计算，<strong>只检索并加载最相关的1个Routine</strong>到上下文中。</li>
<li><strong>为什么</strong>：避免将所有Routine都塞进Prompt，造成信息过载和干扰，导致模型分心或选错流程。</li>
</ul>
</li>
<li>
<p><strong>Variable Memory (变量记忆)</strong>：</p>
<ul>
<li><strong>作用</strong>：优化多步调用中的参数传递。</li>
<li><strong>机制</strong>：如果某个工具返回的参数值过长（如一段长文本或复杂JSON），系统会将其存入临时变量（如 <code>memory_content</code>），后续步骤只需引用这个变量名。</li>
<li><strong>为什么</strong>：
<ol>
<li><strong>缓解上下文压力</strong>：避免长文本占用大量Token。</li>
<li><strong>减少语法错误</strong>：小模型在传递长文本时容易出错（如引号、括号不匹配），引用变量名则完全规避了这个问题。</li>
<li><strong>提高效率</strong>：变量传递比传递实际值更快、更稳定。</li>
</ol>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="四、-训练方法：让小模型“内化”专家知识"><strong>四、 训练方法：让小模型“内化”专家知识</strong></h3>
<p>论文不仅提出了框架，还提供了让模型更好地利用Routine的训练方案。</p>
<h4 id="4-1-通用Routine跟随训练-Common-Routine-following-Fine-tuning"><strong>4.1 通用Routine跟随训练 (Common Routine-following Fine-tuning)</strong></h4>
<ul>
<li><strong>目标</strong>：让模型学会“读懂”并“遵循”任何结构化的Routine。</li>
<li><strong>方法</strong>：
<ol>
<li>基于开源数据集（BUTTON），使用GPT-4o为8000个样本生成对应的结构化Routine。</li>
<li>经过数据清洗和过滤（移除自然语言总结、过滤过长或结构复杂的样本），得到4209条高质量训练数据。</li>
<li>用这些数据对Qwen等模型进行微调。</li>
</ol>
</li>
<li><strong>效果</strong>：显著提升了模型在<strong>有Routine引导</strong>情况下的表现（Qwen3-14B从83.3% → 88.2%），但对模型<strong>自主规划</strong>能力帮助不大，甚至略有下降。这证明了模型变得更“听话”，但也更依赖外部指令。</li>
</ul>
<h4 id="4-2-场景特定知识蒸馏-Scenario-Specific-Knowledge-Distillation"><strong>4.2 场景特定知识蒸馏 (Scenario-Specific Knowledge Distillation)</strong></h4>
<p>这是论文最惊艳的成果，它让小模型“偷师”大模型，把流程知识“学到骨子里”。</p>
<ul>
<li><strong>目标</strong>：让小模型即使<strong>没有Routine引导</strong>，也能像专家一样正确执行任务。</li>
<li><strong>方法</strong>：
<ol>
<li>在目标场景（如HR系统）中，使用GPT-4o（教师模型）配合Routine，为537个真实用户查询生成精确的、多步的工具调用轨迹（即“标准答案”）。</li>
<li>用这些“标准答案”去训练一个较小的“学生模型”（如Qwen3-14B）。</li>
</ol>
</li>
<li><strong>效果</strong>：
<ul>
<li><strong>无Routine时</strong>：学生模型的准确率从32.6% <strong>飙升至90.2%</strong>！这表明小模型通过蒸馏，成功将特定场景的流程知识“内化”到了自己的参数中。</li>
<li><strong>有Routine时</strong>：准确率进一步提升至<strong>95.5%</strong>，几乎追平了教师模型GPT-4o（96.3%）。</li>
</ul>
</li>
<li><strong>意义</strong>：这提供了一条“降本增效”的黄金路径——用大模型+Routine生成高质量数据，训练小模型，最终用小模型以极低成本实现接近大模型的性能。</li>
</ul>
<hr>
<h3 id="五、-实验结果：数据说话，Routine威力惊人"><strong>五、 实验结果：数据说话，Routine威力惊人</strong></h3>
<p>论文在真实的HR场景中进行了严谨评估，数据极具说服力。</p>
<h4 id="5-1-Routine的“神效”"><strong>5.1 Routine的“神效”</strong></h4>
<ul>
<li><strong>GPT-4o</strong>：从41.1% → 96.3% （提升55.2个百分点）</li>
<li><strong>Qwen3-14B</strong>：从32.6% → 83.3% （提升50.7个百分点）</li>
</ul>
<p><strong>结论</strong>：无论模型强弱，引入Routine都能带来<strong>质的飞跃</strong>。它有效弥补了模型在复杂规划和工具选择上的不足。</p>
<h4 id="5-2-消融实验：Routine的哪些部分最重要？"><strong>5.2 消融实验：Routine的哪些部分最重要？</strong></h4>
<ul>
<li>
<p><strong>明确指定工具名是“命脉”</strong>：</p>
<ul>
<li>如果Routine中不告诉模型用哪个工具，而是让它自己从描述中推断，几乎所有模型的准确率都会<strong>显著下降5%-15%</strong>。</li>
<li><strong>洞见</strong>：将“工具选择”这个高难度任务转化为“工具执行”这个低难度任务，是Routine成功的关键。</li>
</ul>
</li>
<li>
<p><strong>I/O参数描述是“锦上添花”</strong>：</p>
<ul>
<li>为步骤添加输入输出描述，对能力较弱的模型帮助很大（如GPT-3.5从52.7% → 61.1%），能减少参数错误。</li>
<li>对顶级模型（如GPT-4o）提升不明显（96.3% → 97.5%）。</li>
</ul>
</li>
<li>
<p><strong>AI优化 vs 人工标注</strong>：</p>
<ul>
<li>由AI（GPT-4o）优化的Routine，其效果已经非常接近人工专家标注的Routine。</li>
<li><strong>意义</strong>：为大规模、低成本地生成高质量Routine提供了可行路径。</li>
</ul>
</li>
<li>
<p><strong>记忆模块的“干扰”</strong>：</p>
<ul>
<li>给执行模型同时提供多个相似的Routine会引入干扰，导致准确率下降（如GPT-4o从96.3% → 76.6%）。</li>
<li><strong>洞见</strong>：“流程记忆”模块必须高精度，最好只提供最相关的一个Routine。</li>
</ul>
</li>
</ul>
<h4 id="5-3-分支逻辑的挑战"><strong>5.3 分支逻辑的挑战</strong></h4>
<ul>
<li>带有分支的Routine比线性Routine更难执行。</li>
<li>性能越差的模型，在遇到分支时准确率下降越明显。</li>
<li><strong>建议</strong>：对于复杂分支逻辑，应确保执行模型本身具备较强的推理能力，或对分支逻辑进行更细致的拆分和描述。</li>
</ul>
<hr>
<h3 id="六、-核心洞见与未来方向"><strong>六、 核心洞见与未来方向</strong></h3>
<h4 id="核心洞见总结"><strong>核心洞见总结</strong></h4>
<ol>
<li><strong>“计划先行”优于“边想边做”</strong>：为企业级Agent提供一个清晰、结构化的“剧本”（Routine），是提升其稳定性和准确性的最有效手段。</li>
<li><strong>“术业有专攻”</strong>：分离规划与执行模块，用大模型做“编剧”，用小模型做“演员”，能实现性能与成本的最佳平衡。</li>
<li><strong>“授人以鱼不如授人以渔”</strong>：通过基于Routine的知识蒸馏，可以让小模型“内化”领域知识，摆脱对显式计划的依赖，实现真正的“降本增效”。</li>
<li><strong>“细节决定成败”</strong>：在Routine中<strong>明确指定工具名</strong>是提升准确率的最关键因素。</li>
</ol>
<h4 id="未来工作"><strong>未来工作</strong></h4>
<ol>
<li><strong>引入强化学习 (RL)</strong>：让规划模型能通过试错自主学习生成更好的Routine，让执行模型能学习更优的工具调用策略，提升系统的自主适应能力。</li>
<li><strong>构建多智能体框架</strong>：用一个高级“协调Agent”通过Routine来管理多个专门的“执行Agent”，以处理更庞大、更复杂的业务流程。</li>
<li><strong>动态Routine生成</strong>：探索如何让系统根据实时数据和用户反馈，动态调整和优化Routine，而不是完全依赖预定义的流程。</li>
</ol>
<hr>
<p><strong>终极总结：</strong></p>
<blockquote>
<p>《Routine》这篇论文的伟大之处，在于它用一个极其简单却无比精妙的“结构化剧本”思想，一举击穿了阻碍企业级AI Agent落地的核心壁垒。它不追求让AI“更聪明”，而是追求让AI“更听话”、“更稳定”、“更便宜”。通过“大模型生成剧本，小模型严格执行，再用蒸馏让小模型自学成才”的三板斧，Routine框架将Agent的执行准确率从“不堪用”的30-40%，提升到了“可生产”的95%以上，为AI真正融入企业核心业务流程铺平了道路。这不仅是技术上的创新，更是工程思想上的胜利。</p>
</blockquote>
<h2 id="QA">QA</h2>
<h3 id="1-真实企业的数据集？">1. 真实企业的数据集？</h3>
<ul>
<li>合成数据为主，真实数据为辅。
<ul>
<li>通用Routine跟随数据集（让执行模型学会“读懂”并“严格遵守”任何结构化的Routine指令，提升<strong>其基础的指令跟随能力</strong>）
<ul>
<li>在论文中选用的是开源的数据集-&gt;用强大的规划模型去合成Routine-&gt;进行数据清洗和过滤，移除步骤过多的样本，移除自然语言总结，只保留user_query, tool_call, observation</li>
</ul>
</li>
<li>场景特定知识蒸馏数据集（让小模型“内化”特定业务场景的流程知识，即使没有显式的Routine引导，也能像专家一样准确执行）：
<ul>
<li>明确场景与工具：明确agent的业务场景（论文中的HR场景的子场景有7个），梳理并标准化所有的工具列表</li>
<li>专家编写routine草稿：让人工专家为每个子场景编写简单的、非结构化的draft步骤（不需要完美，只需要包含关键步骤）</li>
<li>AI优化Routine:AI基于此生成高质量routine。这样优化下来的效果已经非常接近人工专家标注。</li>
<li>设计用户查询模板：
<ul>
<li>为每个子场景设计5-6个<strong>用户查询模板</strong>。例如，HR场景下可以是：“帮我查一下[员工姓名]的薪资”或“[部门名称]这个月的考勤情况如何？”</li>
<li>用真实的员工姓名、部门名称等信息填充模板，生成大量多样化的用户查询。</li>
</ul>
</li>
<li><strong>教师模型生成“标准答案”</strong>：使用教师模型在有Routine引导下去生成多步调用轨迹（tool_call,observation）</li>
<li>得到一个高质量包含标准答案的数据集</li>
<li>数据增强：
<ul>
<li>使用<strong>LLM对用户查询进行改写</strong>，生成语义相同但表述不同的实体，增强模型的鲁棒性和泛化能力。</li>
</ul>
</li>
</ul>
</li>
<li>真实交互数据集（用户评估和迭代，比如RL）
<ul>
<li>上线测试：将前两种策略训练好的Agent部署到小范围真实业务场景中</li>
<li>收集日志：记录用户的真实提问，agent的每一步调用、工具返回结果、最终回复和用户的反馈</li>
<li>人工审核：对收集到的数据进行人工审核，标注出agent错误的案例及其失败原因</li>
<li><strong>构建评估集</strong>：从真实交互数据中筛选出有代表性的样本，构建一个专门的评估数据集（如论文中的200个样本），用于自动化评估（如使用BFCL框架）。</li>
<li><strong>适用场景</strong>：主要用于模型性能评估、错误分析和后续的针对性优化，不直接用于大规模训练。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="2-这里都是用的SFT去做的，为什么没用RL？">2.这里都是用的SFT去做的，为什么没用RL？</h3>
<p><strong>因为在企业级Agent落地的“冷启动”阶段，RL面临数据效率低、训练不稳定、成本高昂等核心挑战。相比之下，基于结构化“剧本”（Routine）的监督式微调（SFT）和知识蒸馏（Knowledge Distillation）是更务实、更高效、风险更低的首选方案。</strong></p>
<ul>
<li>
<p>以下是详细的原因分析：</p>
<p><strong>1. 冷启动难题：RL需要大量高质量的交互数据</strong></p>
<ul>
<li><strong>RL的运作机制</strong>：强化学习需要一个“环境”（Environment）来提供奖励信号（Reward）。在企业Agent场景中，这个“环境”就是真实用户或一个高保真的模拟器。模型通过不断尝试（Trial-and-Error），根据最终任务的成功与否（或中间步骤的奖励）来学习最优策略。</li>
<li>现实困境：
<ul>
<li><strong>初期Agent能力差</strong>：在项目启动时，Agent的自主规划能力非常弱（如论文所示，Qwen3-14B在无引导时准确率仅32.6%）。让它直接与真实用户交互，会产生大量失败、错误甚至有害的响应，严重影响用户体验和企业声誉。</li>
<li><strong>构建模拟器成本高</strong>：为复杂的企业流程（如HR、财务、供应链）构建一个能提供精确奖励信号的高保真模拟器，其工程复杂度和成本可能不亚于开发Agent本身。</li>
<li><strong>奖励函数设计难</strong>：如何为一个多步骤、涉及权限、数据查询、报告生成的复杂任务设计一个能精确衡量每一步好坏的奖励函数？这本身就是一个巨大的研究难题。</li>
</ul>
</li>
</ul>
<p><strong>相比之下，论文的方法优势明显</strong>：</p>
<ul>
<li>
<p><strong>数据生成安全高效</strong>：利用强大的教师模型（GPT-4o）+ 结构化Routine，可以<strong>离线、批量、安全地生成海量高质量的“标准答案”</strong>（即正确的工具调用序列），完全规避了与真实用户交互的风险。</p>
</li>
<li>
<p><strong>数据质量有保障</strong>：生成的数据是100%正确的（由教师模型保证），这为监督学习提供了完美的训练信号。</p>
</li>
</ul>
<p><strong>2. 训练稳定性与可预测性：SFT比RL更可靠</strong></p>
<ul>
<li><strong>RL的不稳定性</strong>：RL训练过程 notoriously 不稳定。策略的微小更新可能导致性能的剧烈波动，甚至“灾难性遗忘”。在企业环境中，这种不稳定性是不可接受的，因为系统需要稳定、可预测地运行。</li>
<li><strong>SFT的确定性</strong>：监督式微调是一个确定性的优化过程。给定一个输入（用户查询+Routine）和一个目标输出（正确的工具调用），模型通过最小化损失函数来学习。这个过程稳定、可复现，更容易调试和部署。</li>
</ul>
<p>论文通过Routine框架，将复杂的规划问题转化为简单的指令跟随问题，使得即使是小模型也能通过SFT获得极高的准确率（95.5%），这在RL中是难以想象的。</p>
<p><strong>3. 成本与效率：SFT是“短平快”的工程胜利</strong></p>
<ul>
<li><strong>RL的计算成本</strong>：RL通常需要大量的环境交互和策略迭代，计算成本极高。尤其是在多步骤任务中，探索空间巨大，收敛速度慢。</li>
<li><strong>SFT的高效性</strong>：论文的方案，特别是“场景特定知识蒸馏”，只需要用教师模型生成一次高质量数据集（537个样本），然后对小模型进行几轮SFT即可。整个过程<strong>计算成本低、周期短，非常适合企业快速迭代和部署</strong>。</li>
</ul>
<p>正如论文摘要所强调的，其目标是提供一个“<strong>practical and accessible approach</strong>”（实用且易于访问的方法），而RL在现阶段显然不符合这一目标。</p>
<p><strong>4. 作者的未来展望：RL是下一步，而非第一步</strong></p>
<p>论文作者并非否定RL的价值，相反，他们在<strong>第6节明确将RL列为未来的核心工作方向</strong>：</p>
<blockquote>
<p>“To address this challenge, incorporating RL-based agent frameworks into the workflow, including mechanisms for data distillation and reward modeling might be a possible solution. This approach aims to improve the Routine generation capability of the planning model as well as the tool invocation capability of the execution model. The combination of instruction fine-tuning for cold start and reinforcement learning has shown promising potential… and may emerge as a future paradigm…”</p>
</blockquote>
<p><strong>翻译与解读</strong>： 作者认为，当前基于SFT和蒸馏的方法，是解决“冷启动”（cold start）问题的最佳方案。它能快速让系统达到一个高准确率、高稳定性的基线水平。在此基础之上，再引入RL，才是更合理的发展路径。</p>
<p><strong>未来的RL可以用于</strong>：</p>
<ol>
<li><strong>优化规划模块</strong>：让规划模型（Planner）能通过RL自主学习生成更好的Routine，而不是完全依赖专家草稿和AI优化。</li>
<li><strong>优化执行模块</strong>：让执行模型（Executor）能在遵循Routine大框架的前提下，学习更优的工具调用策略或参数填充策略。</li>
<li><strong>构建奖励模型（Reward Modeling）</strong>：利用人类反馈或规则引擎，构建一个能自动评估Agent表现的奖励模型，为RL提供训练信号。</li>
</ol>
<h3 id="总结：务实的选择，明智的路径"><strong>总结：务实的选择，明智的路径</strong></h3>
<p>论文《Routine》没有选择RL，是经过深思熟虑后的<strong>工程最优解</strong>。它选择了一条“<strong>先立后破</strong>”的道路：</p>
<ol>
<li><strong>先立</strong>：用结构化Routine + SFT/蒸馏，快速构建一个高性能、高稳定、低成本的生产级Agent系统，解决企业最迫切的落地需求。</li>
<li><strong>后破</strong>：在系统稳定运行、积累了真实交互数据后，再引入RL进行精细化优化和自主能力提升，追求更高的智能水平。</li>
</ol>
<p>这是一种典型的“<strong>MVP（Minimum Viable Product）思维</strong>”，先用最简单有效的方法解决核心痛点，再逐步迭代升级。在充满不确定性的企业AI落地场景中，这种务实、稳健的策略，远比追求技术先进性但风险极高的RL方案要明智得多。</p>
</li>
</ul>
<p>但是由于我们这里使我们自己的网站的操作，是不是可以从优化奖励信号这一步去着手？</p>
<h3 id="3-评测这一步咋做的？">3. 评测这一步咋做的？</h3>
<p>论文《Routine》中的评测设计得非常严谨、系统且具有高度的自动化，其核心目标是<strong>精确衡量LLM Agent在企业级多步工具调用（multi-step tool calling）任务中的执行准确率</strong>，并深入分析错误来源。评测不是简单地看最终答案对不对，而是像“代码调试”一样，逐层解析模型输出的每一个工具调用指令。</p>
<p>以下是其评测方法的超详细解读：</p>
<hr>
<p><strong>一、 评测框架：基于BFCL的AST评估</strong></p>
<p>论文选择了开源的 <strong>Berkeley Function-Calling Leaderboard (BFCL)</strong> 作为核心评测框架，并主要使用其 <strong>Function-Calling (FC) 模式</strong> 和 <strong>抽象语法树 (Abstract Syntax Tree, AST) 评估方法</strong>。</p>
<h4 id="为什么选择BFCL？"><strong>为什么选择BFCL？</strong></h4>
<ul>
<li><strong>效率高</strong>：不依赖真实工具的响应速度，评测过程快速。</li>
<li><strong>精度高</strong>：能对模型输出的工具调用指令进行精确到“括号和逗号”的语法和语义分析。</li>
<li><strong>归因能力强</strong>：可以清晰地将错误分类，告诉开发者模型到底是在哪个环节出了问题。</li>
</ul>
<hr>
<p><strong>二、 评测流程：分层解析，逐级归因</strong></p>
<p>评测过程是一个<strong>层级化的错误检查流程</strong>，如论文图7所示。模型的输出会依次经过以下三道“关卡”：</p>
<ol>
<li>
<p><strong>结构正确性 (Structural Error)</strong></p>
<ul>
<li><strong>检查内容</strong>：模型输出的是否是一个<strong>语法正确的JSON对象</strong>。</li>
<li><strong>常见错误</strong>：
<ul>
<li>缺少大括号 <code>&#123;&#125;</code> 或方括号 <code>[]</code>。</li>
<li>引号 <code>&quot;</code> 不匹配或缺失。</li>
<li>逗号 <code>,</code> 遗漏或多余。</li>
<li>其他任何导致JSON无法被解析的语法错误。</li>
</ul>
</li>
<li><strong>重要性</strong>：这是最基础的关卡。如果结构错误，后续的工具和参数检查都无法进行。</li>
</ul>
</li>
<li>
<p><strong>工具选择正确性 (Tool Selection Error)</strong></p>
<ul>
<li><strong>前提</strong>：模型输出的JSON结构必须正确。</li>
<li><strong>检查内容</strong>：
<ul>
<li>模型是否调用了<strong>工具</strong>，而不是输出了自然语言。</li>
<li>调用的工具<strong>数量</strong>是否正确（例如，当前步骤只需调用一个工具，但模型调了两个）。</li>
<li>调用的工具<strong>名称</strong>是否正确，是否是工具列表中定义的工具，是否存在拼写错误或调用了不存在的工具。</li>
</ul>
</li>
<li><strong>重要性</strong>：论文发现，这是导致任务失败的<strong>最主要错误类型</strong>（占所有错误的85%以上）。Routine框架通过明确指定工具名，正是为了解决这个核心痛点。</li>
</ul>
</li>
<li>
<p><strong>参数正确性 (Parameter Error)</strong></p>
<ul>
<li><strong>前提</strong>：模型输出的JSON结构正确，且工具选择正确。</li>
<li><strong>检查内容</strong>（分为三个子类）：
<ul>
<li><strong>参数缺失 (Missing Key Parameters)</strong>：必需的参数没有提供。</li>
<li><strong>参数幻觉 (Parameter Hallucination)</strong>：提供了工具定义中<strong>不存在</strong>的参数。</li>
<li><strong>参数值错误 (Incorrect Parameter Values)</strong>：参数的<strong>数据类型</strong>或<strong>内容</strong>错误。</li>
</ul>
</li>
<li><strong>特殊处理 - 近似匹配 (Approximate Matching)</strong>：
<ul>
<li>对于<strong>自由文本参数</strong>（free text parameters），论文<strong>不采用严格的字符串完全匹配</strong>。</li>
<li><strong>原因</strong>：在企业场景中，参数值可能是很长的自然语言描述（如用户查询）。模型生成的描述与标准答案在措辞上可能有微小差异（如 “user need: query” vs “user need-query”），但这并不影响语义。</li>
<li><strong>方法</strong>：评测系统会检查参数的<strong>存在性、类型和关键语义</strong>，允许一定的措辞灵活性，避免因吹毛求疵的匹配而低估模型的核心能力。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="最终指标：整体准确率-Overall-Accuracy"><strong>最终指标：整体准确率 (Overall Accuracy)</strong></h4>
<p>一个样本只有在<strong>结构、工具、参数</strong>三个层面都完全正确，才被计为“正确”。这是最严格、最能反映模型端到端解决问题能力的指标。</p>
<hr>
<p><strong>三、 评测数据集的构建</strong></p>
<p>为了保证评测的公平性和有效性，论文专门构建了一个高质量的评测数据集。</p>
<ol>
<li><strong>数据来源</strong>：使用与训练数据相同的“知识蒸馏”方法，由GPT-4o在Routine引导下，为200个用户查询生成精确的、多步的工具调用轨迹（共1,148个独立步骤）。</li>
<li><strong>数据分解</strong>：
<ul>
<li>将每个完整的多步执行轨迹，<strong>分解为多个独立的单步测试样本</strong>。</li>
<li>每个测试样本包含：<strong>当前步骤之前的所有历史执行记录</strong> + <strong>当前步骤专属的系统提示</strong>。</li>
<li><strong>目的</strong>：模拟Agent在真实运行时的逐步执行过程，确保评测环境与生产环境完全一致。</li>
</ul>
</li>
<li><strong>上下文动态性</strong>：
<ul>
<li>由于论文的“变量记忆”（Variable Memory）机制，系统提示会随着执行步骤动态更新（例如，上一步的长输出被替换为 <code>memory_xxx</code>）。</li>
<li>评测系统会<strong>完整记录并还原每一步的系统提示状态</strong>，确保模型在评测时看到的上下文与其在真实交互中看到的完全相同。</li>
</ul>
</li>
<li><strong>防作弊设计</strong>：
<ul>
<li>在每个测试样本中，<strong>随机打乱工具列表的顺序</strong>。</li>
<li><strong>目的</strong>：防止模型通过记忆工具在列表中的“位置”来选择工具，强迫模型真正理解工具的功能和名称。</li>
</ul>
</li>
</ol>
<hr>
<p><strong>四、 评测场景设置</strong></p>
<p>为了全面评估Routine框架的效果，论文设置了三种不同的评测场景：</p>
<ol>
<li>
<p><strong>无Routine场景 (No-Routine Scenario / Baseline)</strong>：</p>
<ul>
<li>模型只收到用户查询，必须<strong>自主规划</strong>并完成所有工具调用。</li>
<li><strong>目的</strong>：评估模型的原始能力，作为性能基线。</li>
</ul>
</li>
<li>
<p><strong>有Routine场景（无分支）(Routine-Guided Scenario w/o Branches)</strong>：</p>
<ul>
<li>模型收到一个<strong>结构清晰、线性的Routine</strong>，其中明确指定了每一步的工具。</li>
<li><strong>目的</strong>：评估模型在简单、明确指令下的“指令跟随”能力。</li>
</ul>
</li>
<li>
<p><strong>有Routine场景（有分支）(Routine-Guided Scenario w/ Branches)</strong>：</p>
<ul>
<li>模型收到一个<strong>包含条件分支的复杂Routine</strong>。</li>
<li><strong>目的</strong>：评估模型在面对更复杂、非线性流程时的逻辑判断和执行稳定性。</li>
</ul>
</li>
</ol>
<hr>
<p><strong>五、 评测结果分析维度</strong></p>
<p>论文不仅报告了最终的准确率数字，还进行了深入的归因分析和消融实验：</p>
<ul>
<li><strong>错误分布分析</strong>：明确指出在无Routine时，<strong>85%的错误来自“工具选择”</strong>，证明了Routine通过指定工具名来解决核心痛点的有效性。</li>
<li><strong>模型能力对比</strong>：对比了GPT系列、Claude和Qwen系列等不同规模和能力的模型，验证了<strong>Routine对小模型的提升尤为显著</strong>。</li>
<li><strong>训练策略效果</strong>：对比了“通用Routine跟随训练”和**“场景特定知识蒸馏”两种微调策略的效果，证明了后者能让小模型“内化”知识**，在无Routine时也能达到接近GPT-4o的水平。</li>
<li><strong>组件消融实验</strong>：
<ul>
<li><strong>Routine组件</strong>：测试了“有无工具名”、“有无I/O参数描述”对准确率的影响，证明“明确指定工具名”是最关键的组件。</li>
<li><strong>Routine生成方式</strong>：对比了“人工标注”、“AI优化”、“用户草稿”的效果，证明<strong>AI优化是性价比极高的方案</strong>。</li>
<li><strong>Routine数量</strong>：测试了给模型提供1个、2个、3个或5个Routine时的准确率，证明了“流程记忆”模块需要高精度检索，最好只提供最相关的一个Routine，以避免干扰。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="总结：一套工业级的评测标准"><strong>总结：一套工业级的评测标准</strong></h3>
<p>论文的评测方法堪称企业级Agent评测的典范：</p>
<ul>
<li><strong>它不迷信“端到端准确率”</strong>，而是通过分层AST解析，精准定位问题。</li>
<li><strong>它不追求“理想化环境”</strong>，而是通过动态上下文和随机化工具列表，模拟真实世界的复杂性。</li>
<li><strong>它不仅“评模型”，更“评框架”</strong>，通过严谨的消融实验，验证了Routine中每一个设计决策的价值。</li>
</ul>
<p>这套方法为企业构建和优化自己的Agent系统提供了一套可复用的、科学的评估标准，是论文除Routine框架本身外的另一大宝贵贡献。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">Roger-Lv</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2025/09/11/2025-09-11-Routine-A-Structural-Planning-Framework-for-LLM-Agent-System-in-Enterprise/">http://example.com/2025/09/11/2025-09-11-Routine-A-Structural-Planning-Framework-for-LLM-Agent-System-in-Enterprise/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">Roger-Lv's space</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/LLM/">LLM</a><a class="post-meta__tags" href="/tags/Agent/">Agent</a><a class="post-meta__tags" href="/tags/RL/">RL</a></div><div class="post-share"><div class="social-share" data-image="/img/cover/agent.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.4/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.4/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/09/11/2025-09-11-Agent%E4%B8%ADmulti-hop-reasoning%E7%9A%84%E8%B7%B3%E6%95%B0%E5%A6%82%E4%BD%95%E6%8E%A7%E5%88%B6%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E6%97%A0%E9%99%90%E5%BE%AA%E7%8E%AF/" title="Agent中multi-hop reasoning的跳数如何控制?如何避免无限循环?"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/agent.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Agent中multi-hop reasoning的跳数如何控制?如何避免无限循环?</div></div><div class="info-2"><div class="info-item-1">Agent中multi-hop reasoning的跳数如何控制?如何避免无限循环? 在 Agent 系统中，multi-hop reasoning（多跳推理） 是指 Agent 通过多次调用工具、反思中间结果、逐步逼近最终答案的推理过程。例如：  用户问：“马斯克创办的公司中，哪家市值最高？” → 第一跳：查“马斯克创办了哪些公司？” → 得到 SpaceX、Tesla、xAI、Neuralink 等 → 第二跳：查“Tesla 当前市值？”、“SpaceX 估值？” → 比较得出 Tesla 市值最高 → 返回答案  这类推理能力是 Agent 智能性的体现，但若不加以控制，可能导致：  无限循环（如反复调用同一工具，无进展） 效率低下（跳数过多，响应慢） 资源浪费（API 调用超限、Token 耗尽） 错误累积（中间步骤出错导致最终答案错误）   一、如何控制跳数？ 1. ✅ 设置最大跳数（Max Hop Limit） 最直接有效的方法： 123456789101112MAX_HOPS = 5  # 或根据任务复杂度调整，如 3~8current_hop = 0while ...</div></div></div></a><a class="pagination-related" href="/2025/09/11/2025-09-11-GSPO-&amp;-Routing-Replay/" title="GSPO &amp; Routing Replay"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/GSPO.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">GSPO & Routing Replay</div></div><div class="info-2"><div class="info-item-1">GSPO &amp; Routing Replay 强化学习（RL）中用于大模型（尤其是MoE架构）的策略优化算法演进：GRPO → Routing Replay → GSPO。我们来系统梳理一下：  🧩 背景：GRPO 在 MoE 下的问题 什么是 GRPO？ GRPO（Generalized Reward Policy Optimization） 是一种广义的策略优化方法，旨在通过广义优势估计和策略梯度提升训练稳定性与样本效率，常用于语言模型的 RLHF（Reinforcement Learning from Human Feedback）阶段。 什么是 MoE？ MoE（Mixture of Experts） 是一种模型架构，通过“路由机制”动态选择部分专家（子网络）处理每个 token，从而在不显著增加计算量的前提下扩展模型容量。 GRPO 在 MoE 下的问题：   新旧策略的差异 新旧策略可能会激活不同的专家，产生结构性偏差，带来噪声。 当从 πθold 更新到 πθ 时，很有可能出现 Router 发生变化，导致新旧策略激活了不同的专家。 例如：  在 πθold...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/08/21/2025-08-21-Agentic-RL/" title="Agentic RL"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/AgenticRL.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-21</div><div class="info-item-2">Agentic RL</div></div><div class="info-2"><div class="info-item-1">转自：https://zhuanlan.zhihu.com/p/1913905349284591240 通过蒙特卡洛树搜索、过程监督与结果监督、强化学习来提高 LLM 的推理能力，从本质上来说，都是尽可能榨取 LLM 本身的能力，区别可能在于多次尝试、反馈信号、训练方法而已，这类方法可称之为“求诸内”。而由 scaling law 可知，模型的能力是有限的，那么该如何进一步提高LLM在具体问题上的表现呢？近期的答案是，类似 RAG，Multi-Agent 系统，让 LLM 学会使用工具，毕竟人与动物的关键区别也只是“能制造并使用工具”，这种方式则是“求诸外”。那么本篇就以此为中心，重点讨论以下问题：  Agentic LLM 的算法逻辑、具体方法与实际表现？ RL 如何训练 Agentic LLM，其与 tool using 的 SFT 的差异在哪？ Agentic RL 的工程化问题  一、Agentic RL 的算法设计 Agent 和 RL 都并非新鲜事物，而使用 RL 训练基于 LLM 的 agent 则是近期的研究的热点，那么，从算法角度来说，如何理解二者结合的动机、场...</div></div></div></a><a class="pagination-related" href="/2025/08/18/2025-08-15-Camel%E6%A1%86%E6%9E%B6/" title="Camel框架"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/camel.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-18</div><div class="info-item-2">Camel框架</div></div><div class="info-2"><div class="info-item-1">NeurIPS 2023｜AI Agents先行者CAMEL:第一个基于大模型的多智能体框架 转自：https://zhuanlan.zhihu.com/p/671093582 AI Agents是当下大模型领域备受关注的话题，用户可以引入多个扮演不同角色的LLM Agents参与到实际的任务中，Agents之间会进行竞争和协作等多种形式的动态交互，进而产生惊人的群体智能效果。本文介绍了来自KAUST研究团队的大模型心智交互CAMEL框架（“骆驼”），CAMEL框架是最早基于ChatGPT的autonomous agents知名项目，目前已被顶级人工智能会议NeurIPS 2023录用。  1777dbe9073c4bcd8ab59365481bcafc.png  论文题目： CAMEL: Communicative Agents for “Mind” Exploration of Large Scale Language Model Society 论文链接： https://ghli.org/camel.pdf 代码链接： https://github.com/camel-a...</div></div></div></a><a class="pagination-related" href="/2025/08/21/2025-08-21-%E4%B8%80%E8%A1%8C%E4%BB%A3%E7%A0%81%EF%BC%8C%E8%A7%A3%E9%94%81SFT%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B%E6%B7%B1%E5%BA%A6%E8%A7%A3%E8%AF%BBDFT%E5%A6%82%E4%BD%95%E5%AE%8C%E8%83%9C%E4%BC%A0%E7%BB%9F%E5%BE%AE%E8%B0%83/" title="一行代码，解锁SFT泛化能力:深度解读DFT如何完胜传统微调"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/DFT.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-21</div><div class="info-item-2">一行代码，解锁SFT泛化能力:深度解读DFT如何完胜传统微调</div></div><div class="info-2"><div class="info-item-1">一行代码，解锁SFT泛化能力：深度解读DFT如何完胜传统微调 转自：https://mp.weixin.qq.com/s/XXGxRk-p5LahtqdYNnbKaA 在大型语言模型 (LLM) 的世界里，如何让模型更好地理解并遵循人类的指令，即所谓的“对齐”，始终是核心议题。目前，主流的技术路线分为两条：监督微调（Supervised Fine-Tuning, SFT）和基于人类反馈的强化学习 （Reinforcement Learning from Human Feedback, RLHF）。 SFT 简单直接，就像教一个学生做题，直接给他看大量的“问题-标准答案”对，让他去模仿。 这种方法易于实现，能让模型快速学会特定任务的“套路”。然而，它的弊病也十分明显——模型容易“死记硬背”，学到的知识很“脆”，泛化能力差，遇到没见过的题型就可能“翻车”。 相比之下，RLHF 更像是请一位教练来指导学生。它不直接给出答案，而是对模型的不同回答给出评分（奖励），让模型在不断的尝试和反馈中，自己探索出更好的策略。但它的问题在于，训练过程极其复杂，需要耗费大量的计算资源，对超参数敏感，且依...</div></div></div></a><a class="pagination-related" href="/2025/08/21/2025-08-21-SFT%E4%B8%93%E6%94%BBPass@k%EF%BC%8CRL%E5%BC%BA%E5%8C%96Pass@1/" title="SFT专攻Pass@k，RL强化Pass@1?"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/RLVR.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-21</div><div class="info-item-2">SFT专攻Pass@k，RL强化Pass@1?</div></div><div class="info-2"><div class="info-item-1">深挖RLVR探索机制：SFT专攻Pass@k，RL强化Pass@1 转自：https://mp.weixin.qq.com/s/QSi580SJ2RFewyFirAe65A 先前的工作已经证明了 RLVR 在实践中的成功，但其背后的根本机制，特别是模型在训练过程中的探索行为，仍有待深入研究。来自中国人民大学高瓴人工智能学院的研究者们发表了一篇题为《From Trial-and-Error to Improvement: A Systematic Analysis of LLM Exploration Mechanisms in RLVR》的技术报告，系统性地研究了RLVR 中的探索机制。   论文题目：From Trial-and-Error to Improvement: A Systematic Analysis of LLM Exploration Mechanisms in RLVR 论文链接：https://arxiv.org/pdf/2508.07534  这篇报告结合了详尽的文献回顾和创新的实证分析，围绕探索空间塑造、熵与性能的相互作用以及强化学习性能优化这三个维度...</div></div></div></a><a class="pagination-related" href="/2025/08/21/2025-08-21-%E4%BD%BF%E7%94%A8-Flowise-%E6%9E%84%E5%BB%BA%E5%9F%BA%E4%BA%8E%E7%A7%81%E6%9C%89%E7%9F%A5%E8%AF%86%E5%BA%93%E7%9A%84%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D-Agent(%E5%9B%BE%E6%96%87%E6%95%99%E7%A8%8B)/" title="使用 Flowise 构建基于私有知识库的智能客服 Agent(图文教程)"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/Flowise.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-21</div><div class="info-item-2">使用 Flowise 构建基于私有知识库的智能客服 Agent(图文教程)</div></div><div class="info-2"><div class="info-item-1">使用 Flowise 构建基于私有知识库的智能客服 Agent（图文教程） https://blog.csdn.net/hejiahao_/article/details/147902607?fromshare=blogdetail&amp;sharetype=blogdetail&amp;sharerId=147902607&amp;sharerefer=PC&amp;sharesource=a1150568956&amp;sharefrom=from_link </div></div></div></a><a class="pagination-related" href="/2025/08/27/2025-08-27-InfiGUIAgent-A-Multimodal-Generalist-GUI-Agent-with-Native-Reasoning-and-Reflection/" title="InfiGUIAgent:A Multimodal Generalist GUI Agent with Native Reasoning and Reflection"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/InfiGUIAgent.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-27</div><div class="info-item-2">InfiGUIAgent:A Multimodal Generalist GUI Agent with Native Reasoning and Reflection</div></div><div class="info-2"><div class="info-item-1">InfiGUIAgent: A Multimodal Generalist GUI Agent with Native Reasoning and Reflection 2025-01-08｜ZJU, DLUT, Reallm Labs, ByteDance Inc, PolyU| 15 http://arxiv.org/abs/2501.04575v1 https://huggingface.co/papers/2501.04575 https://github.com/Reallm-Labs/InfiGUIAgent 研究背景与意义  在当今数字化时代，图形用户界面（GUI）智能体的应用愈发广泛，成为自动化任务的重要工具。现有的多模态大语言模型（MLLMs）为GUI智能体的智能化提供了基础，但其在多步骤推理和对文本注释的依赖上仍存在显著局限。本研究提出的InfiGUIAgent旨在解决这些挑战，强调了原生推理能力在提升GUI交互效率中的重要性，为自动化任务的执行提供了新的可能性。  当前挑战：现有的MLLM基础的GUI智能体在处理复杂操作时，往往受限于单步推理能力，无法有效利...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Roger-Lv</div><div class="author-info-description">Send a flare and light the way.</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">175</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">150</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">49</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Roger-Lv"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/Roger-Lv" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:1150568956@qq.com" target="_blank" title="Email"><i class="fas fa-envelope-open-text" style="color: #4a7dbe;"></i></a><a class="social-icon" href="https://www.linkedin.com/in/zhongrenjie-lv-5588a928a/" target="_blank" title="LinkedIn"><i class="iconfont icon-linkedin-fill"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">Welcome!</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">Routine:A Structural Planning Framework for LLM Agent System in Enterprise</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E3%80%81-%E9%97%AE%E9%A2%98%E6%A0%B9%E6%BA%90%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%81%E4%B8%9A%E7%BA%A7Agent%E6%80%BB%E6%98%AF%E2%80%9C%E6%8E%89%E9%93%BE%E5%AD%90%E2%80%9D%EF%BC%9F"><span class="toc-number">1.0.1.</span> <span class="toc-text">一、 问题根源：为什么企业级Agent总是“掉链子”？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E3%80%81-%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%9ARoutine%E2%80%94%E2%80%94%E4%BD%A0%E7%9A%84AI%E2%80%9C%E6%93%8D%E4%BD%9C%E5%89%A7%E6%9C%AC%E2%80%9D"><span class="toc-number">1.0.2.</span> <span class="toc-text">二、 解决方案：Routine——你的AI“操作剧本”</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-Routine%E7%9A%84%E7%B2%BE%E5%AF%86%E7%BB%93%E6%9E%84"><span class="toc-number">1.0.2.1.</span> <span class="toc-text">2.1 Routine的精密结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-%E6%94%AF%E6%8C%81%E5%88%86%E6%94%AF%EF%BC%9A%E5%A4%84%E7%90%86%E5%A4%8D%E6%9D%82%E4%B8%9A%E5%8A%A1%E9%80%BB%E8%BE%91"><span class="toc-number">1.0.2.2.</span> <span class="toc-text">2.2 支持分支：处理复杂业务逻辑</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%EF%BC%9A%E4%BB%8E%E8%8D%89%E7%A8%BF%E5%88%B0%E6%89%A7%E8%A1%8C"><span class="toc-number">1.0.2.3.</span> <span class="toc-text">2.3 工作流程：从草稿到执行</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E3%80%81-%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%EF%BC%9A%E5%9B%9B%E5%A4%A7%E6%A8%A1%E5%9D%97%E7%9A%84%E5%8D%8F%E5%90%8C%E9%9D%A9%E5%91%BD"><span class="toc-number">1.0.3.</span> <span class="toc-text">三、 系统架构：四大模块的协同革命</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-Planning-Module-%E8%A7%84%E5%88%92%E6%A8%A1%E5%9D%97-%EF%BC%9A%E4%BB%8E%E2%80%9C%E6%80%9D%E8%80%83%E8%80%85%E2%80%9D%E5%8F%98%E4%B8%BA%E2%80%9C%E7%BC%96%E5%89%A7%E2%80%9D"><span class="toc-number">1.0.3.1.</span> <span class="toc-text">3.1 Planning Module (规划模块)：从“思考者”变为“编剧”</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-Execution-Module-%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9D%97-%EF%BC%9A%E4%BB%8E%E2%80%9C%E5%85%A8%E8%83%BD%E7%8E%8B%E2%80%9D%E5%8F%98%E4%B8%BA%E2%80%9C%E6%89%A7%E8%A1%8C%E8%80%85%E2%80%9D"><span class="toc-number">1.0.3.2.</span> <span class="toc-text">3.2 Execution Module (执行模块)：从“全能王”变为“执行者”</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-Tool-Module-%E5%B7%A5%E5%85%B7%E6%A8%A1%E5%9D%97-%EF%BC%9A%E6%A0%87%E5%87%86%E5%8C%96%E4%B8%8E%E8%A7%A3%E8%80%A6"><span class="toc-number">1.0.3.3.</span> <span class="toc-text">3.3 Tool Module (工具模块)：标准化与解耦</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-Memory-Module-%E8%AE%B0%E5%BF%86%E6%A8%A1%E5%9D%97-%EF%BC%9A%E6%99%BA%E8%83%BD%E7%9A%84%E2%80%9C%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AE%A1%E7%90%86%E5%99%A8%E2%80%9D"><span class="toc-number">1.0.3.4.</span> <span class="toc-text">3.4 Memory Module (记忆模块)：智能的“上下文管理器”</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9B%E3%80%81-%E8%AE%AD%E7%BB%83%E6%96%B9%E6%B3%95%EF%BC%9A%E8%AE%A9%E5%B0%8F%E6%A8%A1%E5%9E%8B%E2%80%9C%E5%86%85%E5%8C%96%E2%80%9D%E4%B8%93%E5%AE%B6%E7%9F%A5%E8%AF%86"><span class="toc-number">1.0.4.</span> <span class="toc-text">四、 训练方法：让小模型“内化”专家知识</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-%E9%80%9A%E7%94%A8Routine%E8%B7%9F%E9%9A%8F%E8%AE%AD%E7%BB%83-Common-Routine-following-Fine-tuning"><span class="toc-number">1.0.4.1.</span> <span class="toc-text">4.1 通用Routine跟随训练 (Common Routine-following Fine-tuning)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-%E5%9C%BA%E6%99%AF%E7%89%B9%E5%AE%9A%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F-Scenario-Specific-Knowledge-Distillation"><span class="toc-number">1.0.4.2.</span> <span class="toc-text">4.2 场景特定知识蒸馏 (Scenario-Specific Knowledge Distillation)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%94%E3%80%81-%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C%EF%BC%9A%E6%95%B0%E6%8D%AE%E8%AF%B4%E8%AF%9D%EF%BC%8CRoutine%E5%A8%81%E5%8A%9B%E6%83%8A%E4%BA%BA"><span class="toc-number">1.0.5.</span> <span class="toc-text">五、 实验结果：数据说话，Routine威力惊人</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-Routine%E7%9A%84%E2%80%9C%E7%A5%9E%E6%95%88%E2%80%9D"><span class="toc-number">1.0.5.1.</span> <span class="toc-text">5.1 Routine的“神效”</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-%E6%B6%88%E8%9E%8D%E5%AE%9E%E9%AA%8C%EF%BC%9ARoutine%E7%9A%84%E5%93%AA%E4%BA%9B%E9%83%A8%E5%88%86%E6%9C%80%E9%87%8D%E8%A6%81%EF%BC%9F"><span class="toc-number">1.0.5.2.</span> <span class="toc-text">5.2 消融实验：Routine的哪些部分最重要？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-%E5%88%86%E6%94%AF%E9%80%BB%E8%BE%91%E7%9A%84%E6%8C%91%E6%88%98"><span class="toc-number">1.0.5.3.</span> <span class="toc-text">5.3 分支逻辑的挑战</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%AD%E3%80%81-%E6%A0%B8%E5%BF%83%E6%B4%9E%E8%A7%81%E4%B8%8E%E6%9C%AA%E6%9D%A5%E6%96%B9%E5%90%91"><span class="toc-number">1.0.6.</span> <span class="toc-text">六、 核心洞见与未来方向</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%B4%9E%E8%A7%81%E6%80%BB%E7%BB%93"><span class="toc-number">1.0.6.1.</span> <span class="toc-text">核心洞见总结</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%AA%E6%9D%A5%E5%B7%A5%E4%BD%9C"><span class="toc-number">1.0.6.2.</span> <span class="toc-text">未来工作</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#QA"><span class="toc-number">1.1.</span> <span class="toc-text">QA</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E7%9C%9F%E5%AE%9E%E4%BC%81%E4%B8%9A%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%9F"><span class="toc-number">1.1.1.</span> <span class="toc-text">1. 真实企业的数据集？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E8%BF%99%E9%87%8C%E9%83%BD%E6%98%AF%E7%94%A8%E7%9A%84SFT%E5%8E%BB%E5%81%9A%E7%9A%84%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E6%B2%A1%E7%94%A8RL%EF%BC%9F"><span class="toc-number">1.1.2.</span> <span class="toc-text">2.这里都是用的SFT去做的，为什么没用RL？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%EF%BC%9A%E5%8A%A1%E5%AE%9E%E7%9A%84%E9%80%89%E6%8B%A9%EF%BC%8C%E6%98%8E%E6%99%BA%E7%9A%84%E8%B7%AF%E5%BE%84"><span class="toc-number">1.1.3.</span> <span class="toc-text">总结：务实的选择，明智的路径</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E8%AF%84%E6%B5%8B%E8%BF%99%E4%B8%80%E6%AD%A5%E5%92%8B%E5%81%9A%E7%9A%84%EF%BC%9F"><span class="toc-number">1.1.4.</span> <span class="toc-text">3. 评测这一步咋做的？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%80%89%E6%8B%A9BFCL%EF%BC%9F"><span class="toc-number">1.1.4.1.</span> <span class="toc-text">为什么选择BFCL？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%80%E7%BB%88%E6%8C%87%E6%A0%87%EF%BC%9A%E6%95%B4%E4%BD%93%E5%87%86%E7%A1%AE%E7%8E%87-Overall-Accuracy"><span class="toc-number">1.1.4.2.</span> <span class="toc-text">最终指标：整体准确率 (Overall Accuracy)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%EF%BC%9A%E4%B8%80%E5%A5%97%E5%B7%A5%E4%B8%9A%E7%BA%A7%E7%9A%84%E8%AF%84%E6%B5%8B%E6%A0%87%E5%87%86"><span class="toc-number">1.1.5.</span> <span class="toc-text">总结：一套工业级的评测标准</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/12/23/2025-12-17-Anthropic-skils%E8%A7%A3%E8%AF%BB%E4%B8%8E%E5%AE%9E%E8%B7%B5/" title="Anthropic skils解读与实践"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/SKILL.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Anthropic skils解读与实践"/></a><div class="content"><a class="title" href="/2025/12/23/2025-12-17-Anthropic-skils%E8%A7%A3%E8%AF%BB%E4%B8%8E%E5%AE%9E%E8%B7%B5/" title="Anthropic skils解读与实践">Anthropic skils解读与实践</a><time datetime="2025-12-22T16:00:00.000Z" title="发表于 2025-12-23 00:00:00">2025-12-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/12/22/2025-12-22-LLM%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF%EF%BC%9AMC-TD-Q-Learning-DQN-PG-AC-TRPO-PPO-DPO-GRPO/" title="LLM强化学习算法演进之路：MC-&gt;TD-&gt;Q-Learning-&gt;DQN-&gt;PG-&gt;AC-&gt;TRPO-&gt;PPO-&gt;DPO-&gt;GRPO"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/pytorch.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="LLM强化学习算法演进之路：MC-&gt;TD-&gt;Q-Learning-&gt;DQN-&gt;PG-&gt;AC-&gt;TRPO-&gt;PPO-&gt;DPO-&gt;GRPO"/></a><div class="content"><a class="title" href="/2025/12/22/2025-12-22-LLM%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF%EF%BC%9AMC-TD-Q-Learning-DQN-PG-AC-TRPO-PPO-DPO-GRPO/" title="LLM强化学习算法演进之路：MC-&gt;TD-&gt;Q-Learning-&gt;DQN-&gt;PG-&gt;AC-&gt;TRPO-&gt;PPO-&gt;DPO-&gt;GRPO">LLM强化学习算法演进之路：MC-&gt;TD-&gt;Q-Learning-&gt;DQN-&gt;PG-&gt;AC-&gt;TRPO-&gt;PPO-&gt;DPO-&gt;GRPO</a><time datetime="2025-12-21T16:00:00.000Z" title="发表于 2025-12-22 00:00:00">2025-12-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/12/19/2025-12-19-pytorch%E5%AD%A6%E4%B9%A0/" title="pytorch学习"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/pytorch.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="pytorch学习"/></a><div class="content"><a class="title" href="/2025/12/19/2025-12-19-pytorch%E5%AD%A6%E4%B9%A0/" title="pytorch学习">pytorch学习</a><time datetime="2025-12-18T16:00:00.000Z" title="发表于 2025-12-19 00:00:00">2025-12-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/12/18/2025-12-18-WebDancer-Towards-Autonomous-Information-Seeking-Agency/" title="WebDancer:Towards Autonomous Information Seeking Agency"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/webdancer.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="WebDancer:Towards Autonomous Information Seeking Agency"/></a><div class="content"><a class="title" href="/2025/12/18/2025-12-18-WebDancer-Towards-Autonomous-Information-Seeking-Agency/" title="WebDancer:Towards Autonomous Information Seeking Agency">WebDancer:Towards Autonomous Information Seeking Agency</a><time datetime="2025-12-17T16:00:00.000Z" title="发表于 2025-12-18 00:00:00">2025-12-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/12/18/2025-12-17-TongSearch-QR-Reinforced-Query-Reasoning-for-Retrieval/" title="TongSearch-QR:Reinforced Query Reasoning for Retrieval"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover/tongsearch.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="TongSearch-QR:Reinforced Query Reasoning for Retrieval"/></a><div class="content"><a class="title" href="/2025/12/18/2025-12-17-TongSearch-QR-Reinforced-Query-Reasoning-for-Retrieval/" title="TongSearch-QR:Reinforced Query Reasoning for Retrieval">TongSearch-QR:Reinforced Query Reasoning for Retrieval</a><time datetime="2025-12-17T16:00:00.000Z" title="发表于 2025-12-18 00:00:00">2025-12-18</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2024 - 2025 By Roger-Lv</span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.4.2"></script><script src="/js/main.js?v=5.4.2"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@19.1.3/dist/lazyload.iife.min.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid@11.8.0/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const initValine = (el, path) => {
    if (isShuoshuo) {
      window.shuoshuoComment.destroyValine = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }

    const valineConfig = {
      el: '#vcomment',
      appId: 'smA3tZdRGodG2VgnMubBQjLm-gzGzoHsz',
      appKey: 'biCDxj0lSBtZTMie2kNIKErd',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      visitor: true,
      ...option,
      path: isShuoshuo ? path : (option && option.path) || window.location.pathname
    }

    new Valine(valineConfig)
  }

  const loadValine = async (el, path) => {
    if (typeof Valine === 'function') {
      initValine(el, path)
    } else {
      await btf.getScript('https://cdn.jsdelivr.net/npm/valine@1.5.3/dist/Valine.min.js')
      initValine(el, path)
    }
  }

  if (isShuoshuo) {
    'Valine' === 'Valine'
      ? window.shuoshuoComment = { loadComment: loadValine }
      : window.loadOtherComment = loadValine
    return
  }

  if ('Valine' === 'Valine' || !false) {
    if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
    else setTimeout(loadValine, 0)
  } else {
    window.loadOtherComment = loadValine
  }
})()</script></div><div class="aplayer no-destroy" data-id="8674547170" data-server="netease" data-type="playlist" data-fixed="true" data-autoplay="true" data-lrcType="-1"> </div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.4/dist/fireworks.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.4/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.4/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=5.4.2"></script></div></div></body></html>