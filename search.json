[{"title":"Java八股","url":"/2024/07/10/2024-06-24-Java%E5%85%AB%E8%82%A1/","content":"Java八股2024年 Java 面试八股文（20w字）_java八股文2023-CSDN博客\nSpring面试被问了几百遍的 IOC 和 AOP ，一篇文章带你搞清楚！！！_ioc和aop的原理面试-CSDN博客\nSentinelsentinel （史上最全）-CSDN博客\nGradle&amp;Mavengradle中的build script详解_gradle buildscript-CSDN博客\n[Gradle和Maven的区别-CSDN博客](https://blog.csdn.net/weixin_45626288/article/details/131973787?ops_request_misc=%7B%22request%5Fid%22%3A%22172024305816800185819613%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172024305816800185819613&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-131973787-null-null.142^v100^pc_search_result_base8&amp;utm_term=gradle maven&amp;spm&#x3D;1018.2226.3001.4187)\n线程池和锁面试+基础—–详细解读多线程（线程池、锁、死锁…）_多线程井发、死锁问题、线程池原理等-CSDN博客\nJava 多线程：彻底搞懂线程池_java线程池-CSDN博客\nNetty【硬核】肝了一月的Netty知识点-CSDN博客\n超详细Netty入门，看这篇就够了！_netty框架-CSDN博客\nJUnitJUnit详解-CSDN博客\nPytestPython测试框架之pytest详解_pytest框架详解-CSDN博客\nDockerdocker入门，这一篇就够了。-CSDN博客\n\ndocker run [可选参数] image 命令 #启动容器（无镜像会先下载镜像）#参数说明–name &#x3D; “Name”   容器名字-c   后面跟待完成的命令-d   以后台方式运行并且返回ID，启动守护进程式容器-i   使用交互方式运行容器，通常与t同时使用-t   为容器重新分配一个伪输入终端。也即启动交互式容器-p   指定容器端口    -p 容器端口:物理机端口  映射端口-P   随机指定端口-v   给容器挂载存储卷\n\nJVM[JAVA内存分配原理解析–栈、堆、常量池_堆,栈,常量池详解-CSDN博客](https://blog.csdn.net/gb702250823/article/details/92801716?ops_request_misc=%7B%22request%5Fid%22%3A%22171151029816800225558425%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=171151029816800225558425&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-92801716-null-null.142^v100^pc_search_result_base2&amp;utm_term=java 常量池 栈 堆&amp;spm&#x3D;1018.2226.3001.4187)\njava的垃圾回收(GC)详解_java gc-CSDN博客\nJava - 类加载器_java类加载器-CSDN博客\n","categories":["博客"],"tags":["Java","八股"]},{"title":"状压DP算法","url":"/2024/07/18/2024-06-24-%E7%8A%B6%E5%8E%8BDP%E7%AE%97%E6%B3%95/","content":"状压DP使用状压DP的原因我们知道状态压缩，顾名思义，就是需要考虑的状态非常多，我们如果用平常的思想去表示状态，那是非常不现实的，在时间和空间上都不允许，我们使用某种方法，以最小的代价表示某种状态。 那么，这通常是用进制来表示状态的，而选择几进制则根据要求使用的对象的点的状态有几种。一般来说，只有0和1，我们则是用二进制来表示，当然也有其他进制的题，在例题中会列举，需要我们灵活变通，主要谈二进制。\n那么如何用二进制表示状态呢？我们发现，二进制上是按位分的，那么我们每一位可以看成一个点，而点上的取值则为该点的状态或者选择。例如00001001这个状态则表示第一个点和第四个点状态为1，其余的点状态为0。所以按照这种思想，能抽象的表示出一个很复杂的状态，实现了时间和空间的优化。\n状压DP的适用条件状态压缩其实是有适用环境的：\n\n状态需要有一定的状态单元。 即一个状态应该是保存一个集合，其中的元素值对应着0或1，例如我们常见的棋盘，我们可以用0或1来表示棋子的放置状态。而整个集合即是一个01串，即二进制数，我们通常用十进制表示。那么我们再进行状态转移或者判断的时候，需要先将十进制转化为二进制，再将二进制转化为十进制。\n题目中限制的集合大小不会超过20。 这是最显著的特征，为什么呢？我们知道如果用二进制表示状态，那么集合大小为20的二进制状态有2^{20} - 1已经达到1e7的数量级了。\n具有动态规划的特性。 对于动态规划，一般都是要求最优化某个值，具有最优子结构的性质。同时也需要满足状态转移的特性，而不是前一个状态毫无关系的。\n\n适用环境总结：\n\n二进制\n集合&#x2F;状态大小受限（比如不会大于int类型能表示的最大数）\n满足动态规划特性\n\n状压DP的板子int n;int maxn = 1 &lt;&lt; n;//总状态数。//枚举已有的集合数。按照状态转移的顺序，一般从小编号到大编号。for(int i = 1; i &lt;= m; ++ i)&#123;    //枚举当前集合中的状态。    for(int j = 0; j &lt; maxn; ++ j)&#123;        //判断当前集合是否处于合法状态，通常我们需用一个数组提前处理好。如g数组;        if(当前状态是否合格)&#123;            for(int k = 0; k &lt; maxn; ++ k)&#123;                //枚举上一个集合的状态。                if(上一个集合的状态是否合格 + 上一个集合的状态和当前状态的集合是否产生了冲突)&#123;                    列写状态转移方程。                &#125;            &#125;        &#125;    &#125;&#125;\n\n例题 USACO06NOV Corn Fields G农场主John新买了一块长方形的新牧场，这块牧场被划分成M行N列(1 ≤ M ≤ 12; 1 ≤ N ≤ 12)，每一格都是一块正方形的土地。John打算在牧场上的某几格里种上美味的草，供他的奶牛们享用。\n遗憾的是，有些土地相当贫瘠，不能用来种草。并且，奶牛们喜欢独占一块草地的感觉，于是John不会选择两块相邻的土地，也就是说，没有哪两块草地有公共边。\nJohn想知道，如果不考虑草地的总块数，那么，一共有多少种种植方案可供他选择？（当然，把新牧场完全荒废也是一种方案）\n输入格式\n第一行：两个整数M和N，用空格隔开。\n第2到第M+1行：每行包含N个用空格隔开的整数，描述了每块土地的状态。第i+1行描述了第i行的土地，所有整数均为0或1，是1的话，表示这块土地足够肥沃，0则表示这块土地不适合种草。\n输出格式\n一个整数，即牧场分配总方案数除以100,000,000的余数。\n输入\n2 31 1 10 1 0\n\n输出\n9\n\n思路：\n我们先作出规定，定义n代表的是行，m代表的是列。那么牧场大小就是n × m。我们看到数据范围,n , m都特别小，同时所求为方案数，这很符合状压DP的适用条件。那么对于每一行，我们就可以看成一个未知集合，而集合的大小自然就是列m。对于每一个单元，其取值范围为0 , 1，而1代表放置奶牛，0代表不放置奶牛，所以我们自然可以用二进制表示，那么状态总数就是( 1 &lt; &lt; m ) − 1。 \n\n对于每一个状态，我们需要判断是否合格，而其中明确不能选择两块相邻的土地，在集合内，即相邻位不能全为1，所以我们可以预处理g数组，处理方式即为:g[i] &#x3D; !(i &amp; (i &lt;&lt; 1))（这里的i的取值从0到所有的状态）；\n同样，我们还应该知晓土地的状况，因为毕竟只有土地肥沃才可以放置奶牛，则我们可以通过一个st数组判断，集合与集合之间，我们也需要考虑相邻位不能全为1，所以在枚举上一个集合的状态也需要严格判断。\n对于状态定义，我们可以用f [ i ] [ j ]表示第i行且状态为j的方案数。\n对于状态转移，假设上一行状态为k，则状态转移方程为：f [ i ] [ j ] + &#x3D; f [ i − 1 ] [ k ]\n\n答案：\n#include &lt;bits/stdc++.h&gt;using namespace std;typedef long long ll;const int N = 10 + 5,M = 10 + 5;const int P = 1e8;int n,m;//n行m列的土地。int a[N][M],st[N];//a代表土地，st代表每一行的土地状况。bool g[1 &lt;&lt; N];//g得到所有状态中的合法状态。int f[N][1 &lt;&lt; N];//f[i][j]表示的则是第i行且状态为j的方案数，是由上一行转移过来的，所以我们定义上一行的状态为k。//则状态转移方程为f[i][j] += f[i - 1][k];//其中j和k必须满足条件。void solve()&#123;&#125;int main()&#123;    scanf(&quot;%d%d&quot;, &amp;n, &amp;m);    for(int i = 1; i &lt;= n; ++ i)&#123;        for(int j = 1; j &lt;= m; ++ j)&#123;            scanf(&quot;%d&quot;, &amp;a[i][j]);        &#125;    &#125;    //得到每一行的土地状况。    for(int i = 1; i &lt;= n; ++ i)&#123;        for(int j = 1; j &lt;= m; ++ j)&#123;            st[i] = (st[i] &lt;&lt; 1) + a[i][j];        &#125;    &#125;    //得到所有状态中的合法状态。    int maxn = 1 &lt;&lt; m;//总状态。    f[0][0] = 1;//初始化，这种也算一种。    for(int i = 0; i &lt; maxn; ++ i)&#123;        g[i] = !( i &amp; (i &lt;&lt; 1));//由于不能相邻，所以我们左移判断是否符合条件。     &#125;    for(int i = 1; i &lt;= n; ++ i)&#123;        //枚举每一行。        for(int j = 0; j &lt; maxn; ++ j)&#123;            //枚举每一行的状态，判断此状态是否符合条件。1.不能相邻。2.是全部状态的子集。            if(g[j] &amp;&amp; (j &amp; st[i]) == j)&#123;                //如果符合条件。则我们去判断上一行是否符合。                for(int k = 0; k &lt; maxn; ++ k)&#123;                    //枚举上一行状态。注意，这里我们无需判断上一行状态是否存在，因为不存在即为0.                    //只需要判断j和k是否存在相邻草地。                    if(!(j &amp; k))&#123;                        f[i][j] = (f[i][j] + f[i - 1][k]) % P;                    &#125;                &#125;            &#125;        &#125;    &#125;    int ans = 0;    for(int j = 0; j &lt; maxn; ++ j)&#123;        ans = (ans + f[n][j]) % P;    &#125;    printf(&quot;%d\\n&quot;, ans);    solve();    return 0;&#125;\n\n\n\n糖果【问题描述】糖果店的老板一共有 M 种口味的糖果出售。为了方便描述，我们将M种口味编号1~M。小明希望能品尝到所有口味的糖果。遗憾的是老板并不单独出售糖果，而是K颗一包整包出售。幸好糖果包装上注明了其中K颗糖果的口味，所以小明可以在买之前就知道每包内的糖果口味。给定N包糖果，请你计算小明最少买几包，就可以品尝到所有口味的糖果【输入格式】第一行包含三个整数 N、M 和 K。接下来 N 行每行 K个整数 T1,T2,….Tκ，代表一包糖果的口味。【输出格式】一个整数表示答案。如果小明无法品尝所有口味，输出-1。\npublic static void main(String[] args) &#123;\tScanner sc = new Scanner(System.in);    int n=sc.nextInt();    int m=sc.nextInt();    int k=sc.nextInt();    int[][] a = new int[n][k];    int[] sta = new int[n];    int[] dp = new int[1&lt;&lt;k];    Arrays.fill(dp, -1);    dp[0]=0;\t// 动规数组只有dp[0]为0，其余全部初始化-1    for(int i=1; i&lt;=n; i++)&#123;        for(int j=1; j&lt;=k; j++)&#123;            a[i][j] = sc.nextInt(); // 读取数据            /* 此处用sta[i]做了k次或赋值，解释如下。 */            /* 对于数据a[i][j]，意味第i个包裹中的第j块糖果的种类 */            /* 比如a[i][j]是第4类糖果，那么1&lt;&lt;(a[i][j]-1)的值为二进制的1000，也就是第四类糖果被选中。 */            /* 当sta[i]做了k次或赋值后，sta[i]的二进制上会有若干个1，表示第i个包裹中有哪些类别的糖果。 */            sta[i] |= 1 &lt;&lt; (a[i][j] - 1);           \t        &#125;        /* 这里说明一下dp数组的含义 */        /* dp[l] = k，表示要想获得l的二进制表示的所有糖果种类，至少要选取k个包裹。 */        /* 由于我们刚刚初始化sta数组，那么这里表示的含义就是对于每一个包裹，要想获得这个包裹里的所有糖果种类，需要1个包裹。 */        dp[sta[i]] = 1;    &#125;    /* 接下来就是动规得出答案了 */    for(int i=1; i&lt;=n; i++) &#123; // 依次考虑每一个包裹，获取包裹后会对dp有什么影响        for(int j=0; j&lt;(1&lt;&lt;m); j++) &#123; // 在考虑包裹i时，对所有已经存在的状态j都做分析，看包裹i是否对状态j有所影响            if (dp[j] == -1) continue; // 状态j不存在，考虑下一个            /* 分两种情况 */            /* 状态j存在，但拿到包裹i后，状态j|sta[i]不存在，更新之 */            /* 状态j存在，拿到包裹i后的状态也存在，但在状态j下拿到包裹i，比之前的代价更小，更新之 */            if (dp[j | sta[i]] == -1 || dp[j] + 1 &lt; dp[j|sta[i]]) &#123;                dp[j | sta[i]] = dp[j] + 1;            &#125;        &#125;    &#125;    System.out.println(dp[(1 &lt;&lt; m) - 1]); // 最后输出的是要拿到所有糖果种类需要的最少包裹数&#125;\n\n","categories":["博客"],"tags":["Java","C++","算法","数据结构","状态压缩","动态规划"]},{"title":"Rust异步编程","url":"/2024/07/09/2024-07-09-Rust%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/","content":"Rust异步编程let mut handles = Vec::new();for index in 1..=100 &#123;    let handle = tokio::spawn(        async_http_client.get(format!(&quot;www.example.com/items/&#123;&#125;&quot;, index))    );    handles.push(handle);&#125;for handle in handles &#123;    let result = handle.await;&#125;\n\n比较使用异步编写的示例与同步编写的相同示例 - 对于大量并发 Web 请求，异步版本比同步请求快约 60%\n","categories":["Rust"],"tags":["Rust"]},{"title":"Rust基础学习","url":"/2024/07/08/2024-07-08-Rust%E5%AD%A6%E4%B9%A0/","content":"Rust基础学习Learn Rust - Rust Programming Language (rust-lang.org)\n【一起学Rust】Rust介绍与开发环境搭建_rust开发-CSDN博客\n包管理工具：cargo\n命令行：\n\ncargo new [name]：创建一个新的Rust项目cargo build：构建项目cargo run：运行项目cargo test：运行测试cargo doc：生成文档cargo update：更新依赖项cargo clean：清除构建输出cargo publish：将软件包发布到crates.io上cargo install [package]: 安装指定软件包cargo uninstall [package]: 卸载指定软件包\n\nRust 全面指南：从基础到高级，一网打尽 Rust 的编程知识_rust语言-CSDN博客\n语法变量声明//定义变量可以使用let关键字，例如：let x = 10; //会被自动推断为i32类型let y: i32 = 20;//上述默认为不可变变量,若要可变变量需要加入mut关键字let mut z=30;z=40;//const关键字用于代表这是一个常亮，不能与mut关键字连用\n\n关键字关键字Rust 语言有一组保留的 关键字（keywords），就像大部分语言一样，它们只能由语言本身使用。记住，你不能使用这些关键字作为变量或函数的名称。大部分关键字有特殊的意义，你将在 Rust 程序中使用它们完成各种任务；一些关键字目前没有相应的功能，是为将来可能添加的功能保留的。可以在附录 A 中找到关键字的列表。\n目前正在使用的关键字如下关键字目前有对应其描述的功能。\nas - 强制类型转换，消除特定包含项的 trait 的歧义，或者对 use 语句中的项重命名async - 返回一个 Future 而不是阻塞当前线程await - 暂停执行直到 Future 的结果就绪break - 立刻退出循环const - 定义常量或不变裸指针（constant raw pointer）continue - 继续进入下一次循环迭代crate - 在模块路径中，代指 crate rootdyn - 动态分发 trait 对象else - 作为 if 和 if let 控制流结构的 fallbackenum - 定义一个枚举extern - 链接一个外部函数或变量false - 布尔字面值 falsefn - 定义一个函数或 函数指针类型 (function pointer type)for - 遍历一个迭代器或实现一个 trait 或者指定一个更高级的生命周期if - 基于条件表达式的结果分支impl - 实现自有或 trait 功能in - for 循环语法的一部分let - 绑定一个变量loop - 无条件循环match - 模式匹配mod - 定义一个模块move - 使闭包获取其所捕获项的所有权mut - 表示引用、裸指针或模式绑定的可变性pub - 表示结构体字段、impl 块或模块的公有可见性ref - 通过引用绑定return - 从函数中返回Self - 定义或实现 trait 的类型的类型别名self - 表示方法本身或当前模块static - 表示全局变量或在整个程序执行期间保持其生命周期struct - 定义一个结构体super - 表示当前模块的父模块trait - 定义一个 traittrue - 布尔字面值 truetype - 定义一个类型别名或关联类型union - 定义一个 union 并且是 union 声明中唯一用到的关键字unsafe - 表示不安全的代码、函数、trait 或实现use - 引入外部空间的符号where - 表示一个约束类型的从句while - 基于一个表达式的结果判断是否进行循环\n作用域由大括号控制\n&#123;    let a = 1;    println!(&quot;a = &#123;&#125;&quot;, a);&#125;\n\n数据类型\n元组(tuple)和数组(array)\n//元组fn main() &#123;    let tup=(100,&#x27;余&#x27;,true,10.1);&#125;\n\n元组是以()表示的，里面放入各个元素，且各个元素之间用,分隔\n由于rust可以自动推导出其类型，所以这里没有手动为其标注类型：\n//元组fn main() &#123;    let tup:(i32,char,bool,f64)=(100,&#x27;余&#x27;,true,10.1);    println!(&quot;&#123;&#125; &#123;&#125; &#123;&#125; &#123;&#125;&quot;,tup.0,)&#125;\n\n这里是手动标注类型\n还有数组也很常用，它的使用方法与元组还是有点差距的，其中最大的差别就是，数组中的所有元素的类型必须相同（而上面提到的元组各个元素类型可以不同）\nfn main() &#123;    let arr=[1,2,3,4,5,6,7,8];    println!(&quot;&#123;&#125; &#123;&#125; &#123;&#125; &#123;&#125;&quot;,arr[0],arr[1],arr[2],arr[3]);&#125;\n\n\n\n字符串分为String（可变）和&amp;str（不可变）\n//Stringlet mut s = String::new();s.push_str(&quot;hello&quot;);s.push_str(&quot;, world!&quot;);//&amp;strlet s = &quot;hello, world!&quot;;//转化let s = &quot;hello&quot;;let mut s2 = s.to_string();s2.push_str(&quot;, world!&quot;);\n\n可变数组Veclet mut v: Vec&lt;i32&gt; = Vec::new(); // 创建一个空向量(由于是可变的，要使用mut关键字)v.push(1); // 向向量中添加元素v.push(2);v.pop();//向量中弹出元素//insert,remove\n\nRust HashTable(Map)use std::collections::HashMap;//insertlet mut scores = HashMap::new();scores.insert(String::from(&quot;Alice&quot;), 100); //这里应该是将字符串字面量转化为String类scores.insert(String::from(&quot;Bob&quot;), 90);//getscores.get(&quot;Alice&quot;);//有序的map是BTreeMap，要求KEY类型是可以排序的\n\n逻辑判断//if elseif condition &#123;    // code block to execute if the condition is true&#125; else &#123;    // code block to execute if the condition is false&#125;if a&gt;0 &#123;        println!(&quot;a&gt;0&quot;);    &#125;else if  a==0&#123;        println!(&quot;a==0&quot;);    &#125;else&#123;        println!(&quot;a&lt;0&quot;);    &#125;//matchfn main() &#123;    //枚举    enum Direction &#123;        Up,        Down,        Left,        Right,    &#125;    let direction = Direction::Up;    match direction &#123;        Direction::Up =&gt; println!(&quot;You chose up&quot;), //在使用match语句的时候，对于每一种不同的情况进行匹配，如果匹配成功了之后，就执行这个=&gt;符号后面所对应的那些代码        Direction::Down =&gt; println!(&quot;You chose down&quot;),        Direction::Left =&gt; println!(&quot;You chose left&quot;),        Direction::Right =&gt; println!(&quot;You chose right&quot;),    &#125;&#125;\n\n循环//whilewhile condition &#123;    // code block to execute while the condition is true&#125;//forfor variable in iterable &#123;    // code block to execute for each value in the iterable&#125;for i in 10..20&#123;        println!(&quot;&#123;&#125;&quot;,i);    &#125;/*通过语法 10..20就可以自动生成一个10到20的范围对象，并将该对象中的值，依次赋值给for后面的变量名i，注意范围运算符 ..生成的范围对象是左闭右开的，具体来说，10..20 ，i只会等于10到19但是，10..=20则是10到20*///looploop &#123;    // code block to execute repeatedly until break is called&#125;\n\n\n函数一个最简单的函数长下面这样：\nfn simple()&#123;    &#125;\n\n通过关键字fn加一个函数名字，()与&#123;&#125;组成，除此之外什么都没有，同样，它也不能做任何事。\n为了能让这个函数干一些事情，我们就需要在函数体，也就是&#123;&#125;中写一些代码：\nfn simple()&#123;    println!(&quot;代码&quot;);    println!(&quot;code&quot;);    //.....&#125;\n\n但只是这样还不够，在没有任何输入的情况下，这个函数能做的事情基本就写死了：无论任何地方调用它，其结果都是一样的（调用随机数除外）。\n所以我们就需要函数参数，也就是从函数外部传入的变量，可以让函数内部来使用，参数写在()中。\nfn simple(i:i32,c:char,f:f64,b:bool)&#123;    println!(&quot;&#123;&#125; &#123;&#125; &#123;&#125; &#123;&#125;&quot;,i,c,f,b);&#125;//带有返回值的例子fn sum(a:i32,b:i32) -&gt; i32&#123; //-&gt;返回值类型    return a+b;&#125;fn main() &#123;    let s=sum(100,200);    println!(&quot;a+b=&#123;&#125;&quot;,s);&#125;\n\n\n\n\n\n结构Rust结构体讲解学习，以及impl结构体方法和结构体关联函数_rust struct impl-CSDN博客\nRust 里 struct 语句仅用来定义，不能声明实例，结尾不需要 ; 符号，而且每个字段定义之后用 , 分隔。\n结构中也没有方法，要有方法只能用impl去实现方法\nstruct Person &#123;    name: String,    age: u32 = 0,&#125;//创建实例let person = Person &#123;    name: String::from(&quot;Alice&quot;),    age: 30,&#125;;//访问字段 person.name//单元结构体:结构体可以只作为一种象征而无需任何成员：struct UnitStruct;\n\n结构体方法方法（Method）和函数（Function）类似，只不过它是用来操作结构体实例的。\n如果你学习过一些面向对象的语言，那你一定很清楚函数一般放在类定义里并在函数中用 this 表示所操作的实例。\nRust 语言不是面向对象的，从它所有权机制的创新可以看出这一点。但是面向对象的珍贵思想可以在 Rust 实现。\n结构体方法的第一个参数必须是 &amp;self，不需声明类型，因为 self 不是一种风格而是关键字。\n在调用结构体方法的时候不需要填写 self ，这是出于对使用方便性的考虑:\n//计算一个矩形的面积：struct Rectangle &#123;    width: u32,    height: u32,&#125;   impl Rectangle &#123;    fn area(&amp;self) -&gt; u32 &#123;        self.width * self.height    &#125;&#125; fn main() &#123;    let rect1 = Rectangle &#123; width: 30, height: 50 &#125;; //创建实例    println!(&quot;rect1&#x27;s area is &#123;&#125;&quot;, rect1.area());&#125;\n\n结构体关联函数之所以”结构体方法”不叫”结构体函数”是因为”函数”这个名字留给了这种函数：它在 impl 块中却没有 &amp;self 参数。\n这种函数不依赖实例，但是使用它需要声明是在哪个 impl 块中的。\n一直使用的 String::from 函数就是一个”关联函数”。\n#[derive(Debug)]struct Rectangle &#123;    width: u32,    height: u32,&#125; impl Rectangle &#123;    fn create(width: u32, height: u32) -&gt; Rectangle &#123;         Rectangle &#123; width, height &#125;    &#125;&#125; fn main() &#123;    let rect = Rectangle::create(30, 50); //调用的时候::    println!(&quot;&#123;:?&#125;&quot;, rect);&#125;\n\n枚举【Rust 基础篇】Rust 枚举类型_rust enum-CSDN博客\n接口（Trait）trait Fly &#123;    fn fly(&amp;self); //这个方法接收一个self参数，表示对实现这个trait的类型的引用&#125;//实例struct Bird &#123;&#125;impl Fly for Bird &#123;    fn fly(&amp;self) &#123;        println!(&quot;I can fly!&quot;);    &#125;&#125;let bird = Bird&#123;&#125;;bird.fly();\n\n注解Rust的注解是以#字符开头的特殊注释，可以为代码提供更多的语义信息或者修改编译器的行为。Rust注解通常放在代码的上方，用于注释某些特定的语法结构或者代码块。下面是一些常用的Rust注解：\n\n#[derive(Debug)]：这个注解用于标记一个结构体或者枚举，让编译器自动生成Debug trait的实现。这样，在调试时，我们可以使用{:?}格式化输出结构体或者枚举的内容，方便快捷。\n#[test]：这个注解用于标记一个测试函数，表示它是一个单元测试。测试框架可以通过这个注解自动识别测试函数并执行测试，方便我们编写和运行测试代码。\n#[allow(unused_variables)]：这个注解用于关闭编译器的未使用变量警告。如果我们定义了一个变量但是并没有使用它，编译器会发出警告，这个注解可以帮助我们屏蔽这个警告。\n#[cfg(target_os &#x3D; “windows”)]：这个注解用于根据不同的操作系统编译不同的代码。如果我们的代码需要在不同的操作系统上运行，就可以使用这个注解来指定特定的编译条件。\n#[no_mangle]：这个注解用于防止Rust编译器对函数名进行重命名，保留原始名称。如果我们的代码需要和其他语言交互，就需要使用这个注解来保证函数名的一致性。\n\n总之，Rust注解可以提供额外的信息，帮助编译器和开发者更好地理解和处理代码，同时也可以修改编译器的行为，以满足特定的需求。\nRust允许开发者自定义注解（Attribute），可以通过宏定义的方式实现。自定义注解可以为代码提供更多的语义信息，也可以修改编译器的行为，方便我们编写高效、优雅的代码。\n自定义注解的语法格式如下：\n#[my_attribute(arg1, arg2, ...)]fn my_function() &#123;    // code here&#125;//例子#[my_attribute(&quot;hello&quot;, 42)]fn my_function() &#123;    // code here&#125;定义了一个名为my_attribute的注解，它带有两个参数：一个字符串&quot;hello&quot;和一个整数42。我们可以在函数内部使用这个注解，例如对函数进行标记，表示它是一个特定类型的函数。\n\n模块Rust的模块系统是基于文件系统的组织方式。每个Rust文件都可以被视为一个模块，模块名与文件名相同。在一个模块中，可以使用mod关键字定义子模块，使用use关键字引用其他模块中的定义。\n例如，假设有如下结构的文件系统：\n\nsrc&#x2F;├── main.rs└── my_module&#x2F;    ├── mod.rs    ├── sub_module.rs    └── my_struct.rs\n\n在上述结构中，src目录是Rust项目的根目录，main.rs是项目的入口文件。my_module目录是一个模块，其下有三个文件：\nmod.rs：定义了my_module模块的公共接口。\nsub_module.rs：定义了my_module模块的子模块sub_module。\nmy_struct.rs：定义了my_module模块的一个结构体MyStruct。\n在mod.rs中，可以使用mod关键字定义子模块，例如：\nmod sub_module;pub struct MyStruct &#123;    pub field: i32,&#125;pub fn my_function() &#123;    println!(&quot;Hello from my_function!&quot;);&#125;\n\n在上述代码中，定义了一个名为MyStruct的结构体，还有一个名为my_function的函数。同时，使用mod关键字定义了一个名为sub_module的子模块。\n在sub_module.rs中，可以定义子模块sub_module中的内容，例如：\npub fn sub_function() &#123;    println!(&quot;Hello from sub_function!&quot;);&#125;\n\n在上述代码中，定义了一个名为sub_function的函数。\n在使用my_module模块中的定义时，需要使用use关键字引用它们，例如：\nuse crate::my_module::&#123;MyStruct, my_function&#125;;use crate::my_module::sub_module::sub_function;fn main() &#123;    let my_struct = MyStruct &#123; field: 42 &#125;;    my_function();    sub_function();&#125;\n\n在上述代码中，使用use关键字引用了MyStruct和my_function，以及sub_function。然后，可以在main函数中使用这些定义。\nRust Cargo.tomlRust使用 Cargo.toml 文件描述项目的元数据和依赖关系。下面是对 Cargo.toml 文件的详细讲解。\nCargo.toml 文件是一个 TOML（Tom’s Obvious, Minimal Language，即Tom的简洁明了语言）格式的文件，用于描述 Rust 项目的元数据和依赖关系。它通常位于项目的根目录下，与 src&#x2F; 目录同级。\n下面是一个示例：\n[package]name = &quot;myproject&quot;version = &quot;0.1.0&quot;authors = [&quot;Your Name &lt;you@example.com&gt;&quot;]edition = &quot;2018&quot;[dependencies]rand = &quot;0.7.0&quot;serde = &quot;1.0&quot;[lib]name = &quot;mylib&quot;path = &quot;src/mylib.rs&quot;[[bin]]name = &quot;mybin&quot;path = &quot;src/mybin.rs&quot;[[bin]]name = &quot;myotherbin&quot;path = &quot;src/myotherbin.rs&quot;[features]default = [&quot;myfeature1&quot;]myfeature1 = []myfeature2 = [][dependencies.mydependency]version = &quot;1.0&quot;features = [&quot;myfeature1&quot;][workspace]members = [    &quot;mylib&quot;,    &quot;mybin&quot;,    &quot;myotherbin&quot;,]\n\n[package] 表示包的元数据，包括包名、版本号、作者和 Rust 版本等信息。[dependencies] 表示包的依赖项，[lib] 表示库的配置，[[bin]] 表示可执行文件的配置，[features] 表示特性的配置，[dependencies.mydependency] 表示依赖的配置，[workspace] 表示工作空间的配置。\n引入单个本地模块的方法是，在项目根目录下创建一个名为 src/ 的文件夹，然后在该文件夹下创建 Rust 模块，例如：\n// src/mymodule.rspub fn myfunction() &#123;    println!(&quot;Hello, world!&quot;);&#125;\n\n然后，在 main.rs（或其他程序入口文件）中引入该模块：\n// src/main.rsmod mymodule;fn main() &#123;    mymodule::myfunction();&#125;\n\n引入多个本地模块也是类似的。假设在 src&#x2F; 目录下还有一个名为 myothermodule.rs 的 Rust 模块，可以这样写：\n// src/main.rsmod mymodule;mod myothermodule;fn main() &#123;    mymodule::myfunction();    myothermodule::myotherfunction();&#125;\n\n::的用法在Rust中，双冒号有几种用途，主要涉及到模块、类型、枚举变体或trait实现的引用。\n\n模块和类型的引用：::用于引用模块中的类型或函数。例如，String::from(&quot;hello&quot;)表示调用String类型中的from静态方法，用于创建一个新的字符串。\n\n枚举变体的引用：当需要引用枚举的某个变体时，也可以使用::。例如，如果有一个枚举Color，其中包含Red和Green两个变体，那么可以通过Color::Red和Color::Green来引用这些变体。\nenum Message &#123;    Hello(String),    Goodbye&#125;fn hello(message: Message) &#123;    match message &#123;        Message::Hello(s) =&gt; println!(&quot;Hello, &#123;&#125;&quot;, s),        Message::Goodbye =&gt; println!(&quot;Goodbye!&quot;),    &#125;&#125;\n\nTrait实现的引用：在Rust中，Trait可以定义一组方法，这些方法可以由实现该Trait的类型提供具体实现。使用::可以明确指定某个类型实现了某个Trait的具体方法。例如，如果有一个Trait Greeter，并且有一个类型Person实现了这个Trait，那么可以通过Person::greet(&amp;person)来调用这个方法，尽管这通常与具体的实例无关，更常见的是使用动态调度（如g.greet()），但在某些情况下，如需要明确类型和方法的关系时，这种语法是有用的。\ntrait Greeter &#123;    fn greet(&amp;self);&#125;struct Person;impl Greeter for Person &#123;    fn greet(&amp;self) &#123;        println!(&quot;Hello from Person!&quot;);    &#125;&#125;fn use_greeter(g: &amp;dyn Greeter) &#123;    g.greet();&#125;fn main() &#123;    let person = Person;    use_greeter(&amp;person as &amp;dyn Greeter); // 使用 as 关键字和 &amp;dyn 来创建一个 trait 对象&#125;\n\n\n\n在泛型实例化中指定类型参数：当你要创建一个泛型类型的实例并明确指定其类型参数时，可以使用 ::&lt;T&gt;。这在你不想依赖类型推断，或者类型推断不能正确工作时特别有用。\nlet vec = Vec::&lt;i32&gt;::new(); // 创建一个包含 i32 类型元素的 Vec 实例\n\n\n\n明确指定作用域：在某些情况下，::也用于明确指定作用域，尤其是在处理与命名空间相关的问题时。这有助于编译器理解你的意图，避免名称冲突。\n例子：\nuse std::io;fn print_something() &#123;    io::println!(&quot;Hello from io!&quot;); // 使用 std::io 模块中的 println 函数&#125;\n\nself和Selfself\nself 是一个代表类型实例（或者是类型的引用或者是值）的关键字，在 Rust 的方法中使用 self 可以引用当前类型的实例或者类型本身。\n具体来说，当我们定义一个方法时，使用 self 关键字作为方法的第一个参数可以让我们在调用该方法时直接访问类型实例本身\nstruct Point &#123;    x: f32,    y: f32,&#125; impl Point &#123;    fn distance(&amp;self, other: &amp;Point) -&gt; f32 &#123;        let dx = self.x - other.x;        let dy = self.y - other.y;        (dx * dx + dy * dy).sqrt()    &#125;&#125;\n\nSelf通常在 Rust 的 trait 和 associated function 中使用 Self 来指代实现该 trait 或调用该 associated function 的类型。\nstruct Point &#123;    x: f32,    y: f32,&#125; impl Point &#123;    //关联函数    fn origin() -&gt; Self &#123;        Point &#123; x: 0.0, y: 0.0 &#125;    &#125;&#125; fn main() &#123;    let p = Point::origin();&#125; \n\n\n\n所有权Rust核心功能之一（所有权）_rust 所有权-CSDN博客\n【Rust 基础篇】Rust 所有权详解_rust所有权和内存分析图解-CSDN博客\n引用和借用Rust - 引用和借用_rust 借用和引用-CSDN博客\n切片和数组rust中的数组和切片_rust 数组切片-CSDN博客\n常用库Rust常用库好的，以下是一些常用的 Rust 库及其常用方法的举例：\n\nstd 库\nprintln!(): 打印输出信息到控制台\nVec: 动态数组类型\nString: 可变字符串类型\nHashMap&lt;K, V&gt;: 哈希表类型\n\n\nserde 库\nserde_json::to_string(): 将 Rust 结构体序列化为 JSON 字符串\nserde_json::from_str(): 将 JSON 字符串反序列化为 Rust 结构体\nserde_yaml::to_string(): 将 Rust 结构体序列化为 YAML 字符串\nserde_yaml::from_str(): 将 YAML 字符串反序列化为 Rust 结构体\n\n\nactix 库\nactix_web::get(): 注册一个 GET 请求处理器\nactix_web::post(): 注册一个 POST 请求处理器\nactix_web::web::Json: 解析请求体中的 JSON 数据\n\n\ntokio 库\ntokio::net::TcpListener: 创建一个 TCP 监听器\ntokio::net::TcpStream: 创建一个 TCP 连接\ntokio::spawn(): 在异步任务池中启动一个新的异步任务\n\n\nreqwest 库\nreqwest::get(): 发送一个 GET 请求\nreqwest::post(): 发送一个 POST 请求\nreqwest::Client::new(): 创建一个 HTTP 客户端对象\n\n\nrusoto 库\nrusoto_s3::S3Client::new(): 创建一个 AWS S3 客户端对象\nrusoto_ec2::Ec2Client::new(): 创建一个 AWS EC2 客户端对象\nrusoto_lambda::LambdaClient::new(): 创建一个 AWS Lambda 客户端对象\n\n\ndiesel 库\ndiesel::prelude::*: 导入 Diesel 的预定义类型和函数\ndiesel::insert_into(): 插入一条新的记录\ndiesel::load(): 加载一组记录\n\n\nlog 库\nlog::info(): 记录一条信息级别的日志\nlog::error(): 记录一条错误级别的日志\nlog::warn(): 记录一条警告级别的日志\n\n\nrand 库\nrand::thread_rng(): 创建一个随机数生成器对象\nrand::Rng::gen_range(): 生成一个指定范围内的随机数\nrand::Rng::shuffle(): 随机打乱一个数组\n\n\nimage 库\nimage::open(): 打开一个图像文件\nimage::save(): 保存一个图像文件\nimage::DynamicImage::resize(): 调整图像尺寸大小\n\n\n\n","categories":["Rust"],"tags":["Rust"]},{"title":"Rust构建自己的第一个项目","url":"/2024/07/17/2024-07-17-Rust%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E9%A1%B9%E7%9B%AE/","content":"Rust构建自己的第一个项目几个核心命令：\ncargo new xxx：用于新建项目\ncargo build：用于在Cargo.toml中添加dependencies进行依赖的下载和编译\ncargo run：用于运行\n新建项目在目录下输入下列指令，例如要构建一个叫做hello-rust的项目\ncargo new hello-rust\n\n\nCargo 已经帮我们创建好默认项目了，还创建了个git的本地仓库，还有一些配置文件， src/main.rs 为编写应用代码的地方。\n运行项目使用cargo run命令运行\ncargo run\n\n\n可以看到会经历一个编译的过程后，打印出Hello,world！信息\n编写Hello-RustCargo.toml文件是一个管理项目配置的文件，包括项目依赖等相关配置\n添加配置在dependencies中：\n\n在命令行中运行：\ncargo build\n\n\n可以看到除了我们自定义添加的ferris-say版本的依赖，还会自动添加好依赖的依赖\n接下来就在 src/main.rs 中写入以下内容:\nuse ferris_says::say; // from the previous stepuse std::io::&#123;stdout, BufWriter&#125;;fn main() &#123;    let stdout = stdout();    let message = String::from(&quot;Hello fellow Rustaceans!&quot;);    let width = message.chars().count();    let mut writer = BufWriter::new(stdout.lock());    say(message.as_bytes(), width, &amp;mut writer).unwrap();&#125;\n\n再执行\ncargo run\n\n\n","categories":["Rust"],"tags":["Rust"]},{"title":"Redis常用操作","url":"/2024/07/29/2024-07-21-Redis%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/","content":"Redis常用操作\n\n\n数据类型\n操作\n键（key）位置\n值（value）位置\n示例\n\n\n\nString\nGET\n直接使用键名\n键对应的字符串值\nGET mykey\n\n\n\nSET\n直接使用键名\n要设置的字符串值\nSET mykey &quot;Hello World&quot;\n\n\n\nDEL\n直接使用键名\n无（操作是删除）\nDEL mykey\n\n\n\nINCR\n直接使用键名\n键的整数值（自动增加1）\nINCR mykey\n\n\n\nDECR\n直接使用键名\n键的整数值（自动减少1）\nDECR mykey\n\n\nHash\nHGET\n哈希名\n哈希字段名\nHGET myhash field1\n\n\n\nHSET\n哈希名\n哈希字段名和值\nHSET myhash field1 &quot;value1&quot;\n\n\n\nHDEL\n哈希名\n哈希字段名\nHDEL myhash field1\n\n\n\nHGETALL\n哈希名\n无（返回所有字段和值）\nHGETALL myhash\n\n\nList\nLPUSH\n列表名\n要推入的值\nLPUSH mylist &quot;item1&quot;\n\n\n\nRPUSH\n列表名\n要推入的值\nRPUSH mylist &quot;item1&quot;\n\n\n\nLPOP\n列表名\n无（操作是弹出）\nLPOP mylist\n\n\n\nRPOP\n列表名\n无（操作是弹出）\nRPOP mylist\n\n\n\nLRANGE\n列表名\n起始和结束索引\nLRANGE mylist 0 2\n\n\nSet\nSADD\n集合名\n要添加的元素\nSADD myset item1\n\n\n\nSREM\n集合名\n要删除的元素\nSREM myset item1\n\n\n\nSMEMBERS\n集合名\n无（返回所有元素）\nSMEMBERS myset\n\n\n\nSISMEMBER\n集合名和元素\n无（检查元素是否存在）\nSISMEMBER myset item1\n\n\nSorted Set\nZADD\n有序集合名\n成员和分数\nZADD myzset 3.0 item1\n\n\n\nZREM\n有序集合名\n要删除的成员\nZREM myzset item1\n\n\n\nZRANGE\n有序集合名\n起始和结束索引\nZRANGE myzset 0 2\n\n\n\nZREVRANGE\n有序集合名\n起始和结束索引\nZREVRANGE myzset 0 2\n\n\n\nZSCORE\n有序集合名\n成员名\nZSCORE myzset item1\n\n\n说明：\nString：简单的字符串键值对。\nHash：键值对集合，其中键是哈希名，值是字段名和字段值。\nList：有序集合，键是列表名，值是列表中的元素。\nSet：无序集合，键是集合名，值是集合中的元素。\nSorted Set：有序集合，键是有序集合名，值是成员和成员的分数。\n\n这些操作和示例可以帮助你理解如何在 Redis 中使用不同的数据类型进行基本操作。\n在 Redis 的上下文中，特别是在 Hash 数据类型的操作中，”field” 指的是哈希表中的字段名，它与 “value”（值）一起构成了哈希表中的一个键值对。Hash 类型在 Redis 中用于存储对象或者映射（map），其中每个对象或映射项由一个字段名和对应的值组成。\n以下是一些 Hash 数据类型的操作示例，以展示 “field” 的使用：\n\nHSET myhash username &quot;JohnDoe&quot;：在这个操作中，myhash 是哈希名（key），username 是字段名（field），&quot;JohnDoe&quot; 是与字段名相关联的值（value）。\n\nHGET myhash username：这里，myhash 是哈希名，username 是我们要获取的字段名。操作的目的是获取与 username 字段名关联的值。\n\nHDEL myhash username：在这个删除操作中，myhash 是哈希名，username 是要删除的字段名。\n\nHGETALL myhash：这个操作返回哈希 myhash 中所有的字段和值。返回的结果是一个列表，其中每个字段名和值交替出现。\n\n\n在 Hash 数据类型中，字段名（field）可以是字符串，而且一个哈希可以包含多个这样的字段和值对。这使得 Hash 成为存储具有多个属性的对象（如用户信息、配置设置等）的理想选择。\n","categories":["Redis"],"tags":["Redis","后端","微服务"]},{"title":"Rust中的错误处理","url":"/2024/07/18/2024-07-18-Rust%E4%B8%AD%E7%9A%84%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86/","content":"Rust中的错误处理如果你使用过其他编程语言，那么就会知道Rust中的错误处理是完全不同的方法。像Java,JS,Python等你常常会使用throw处理异常，以及return成功的值。但在Rust中，你会返回给调用者一个Result\nResult&lt;T, E&gt;是一个拥有两个值的枚举类型，其中Ok(T)用来返回成功值，Err(E)用来返回错误值\nenum Result&lt;T, E&gt; &#123;    Ok(T),    Err(E),&#125;\n\n返回错误而不是抛出错误,这是一种编程习惯的转变。所以如果你是Rust的初学者，可能刚开始学习起来觉得很麻烦，因为这需要你用去思考在不同的场景，应该使用什么样的方法去处理错误。\n在这篇博客中会有错误处理的一些范式，以及它们在Rust中是如何体现的：\n\n忽略错误\n直接结束程序\n使用默认值处理\n传递错误\n传递多个错误\n模式匹配Boxed错误\n使用库 or 应用\n创建自定义错误\n传递自定义错误\n模式匹配自定义错误\n\n忽略错误(unwrap())（如果出现错误会触发panic，让该线程退出）\n最简单的处理方法就是直接忽略这个错误，这听起来是不太好的想法，但是可以在以下情况使用：\n\n刚刚开始编写代码，不想浪费太多时间在错误处理上。\n坚定确信当前的情况下，错误一定不会发生。\n\nuse std::fs;fn main() &#123;    let content = fs::read_to_string(&quot;./Cargo.toml&quot;).unwrap();    println!(&quot;&#123;&#125;&quot;, content)&#125;\n\n即使知道文件会存在，但是编译器也无法知道。因此，使用unwrap()关键字让编译器信任，并返回其中的值。如果read_to_string()函数返回一个Ok()，unwrap将获取Ok()的内容并将其分配给content变量。如果它返回一个错误，那么程序会陷入panic这回让当前程序线程退出。\n\n需要注意的是在许多Rust示例代码中使用unwrap来跳过错误处理，但是这样做主要是为了方便，不应该在实际开发中使用。\n\n结束程序(expect())有些错误无法处理或从中恢复。在这些情况下，最好直接终止程序。 让使用与上面相同的例子——正在读取一个文件，肯定会看到它。想象一下，对于这个程序来说，这个文件绝对重要，没有它就无法正常工作。如果由于某种原因，该文件不存在，那么最好应该直接终止该程序。\n可以像之前一样使用unwrap或者使用expect，它和unwrap差不多，唯一不同的是添加了额外的错误信息。\nuse std::fs;fn main() &#123;  let content = fs::read_to_string(&quot;./Cargo.toml&quot;).expect(&quot;Can&#x27;t read Cargo.toml&quot;);  println!(&quot;&#123;&#125;&quot;, content)&#125;\n\n了解关于：panic!\n使用默认值(unwrap_or())在某些情况下，可以通过返回默认值来处理错误。\n例如正在编写一个服务器，它监听的端口可以使用环境变量进行配置。如果没有设置环境变量，则访问该值将导致错误。但可以通过返回默认值来轻松处理这个问题。\nuse std::env;fn main() &#123;  let port = env::var(&quot;PORT&quot;).unwrap_or(&quot;3000&quot;.to_string());  println!(&quot;&#123;&#125;&quot;, port);&#125;\n\n在这里，使用在这里，使用了一种称为unwrap_or的unwrap变体，它允许提供默认值。\n了解关于： unwrap_or_else, unwrap_or_default\n传递错误给调用者当没有足够的context来处理错误时，可以将错误冒泡（向上传播）到调用者函数。下面是一个精心设计的示例，它使用Web服务获取当前年份：\nuse std::collections::HashMap;fn main() &#123;  match get_current_date() &#123;    Ok(date) =&gt; println!(&quot;We&#x27;ve time travelled to &#123;&#125;!!&quot;, date),    Err(e) =&gt; eprintln!(&quot;Oh noes, we don&#x27;t know which era we&#x27;re in! :( \\n  &#123;&#125;&quot;, e),  &#125;&#125;fn get_current_date() -&gt; Result&lt;String, reqwest::Error&gt; &#123;  let url = &quot;https://postman-echo.com/time/object&quot;;  let result = reqwest::blocking::get(url);  let response = match result &#123;    Ok(res) =&gt; res,    Err(err) =&gt; return Err(err),  &#125;;  let body = response.json::&lt;HashMap&lt;String, i32&gt;&gt;();  let json = match body &#123;    Ok(json) =&gt; json,    Err(err) =&gt; return Err(err),  &#125;;  let date = json[&quot;years&quot;].to_string();  Ok(date)&#125;\n\n这块在get_current_date中有两个函数调用(get和json)会返回Result值。因为get_current_date并没有返回错误时要做什么的上下文，所以使用模式匹配将错误传回main.\n有时候在使用模式匹配去处理，多个嵌套的错误处理可能会让代码看起来非常混乱，所以可以引入?来重写上述代码.\nuse std::collections::HashMap;fn main() &#123;  match get_current_date() &#123;    Ok(date) =&gt; println!(&quot;We&#x27;ve time travelled to &#123;&#125;!!&quot;, date),    Err(e) =&gt; eprintln!(&quot;Oh noes, we don&#x27;t know which era we&#x27;re in! :( \\n  &#123;&#125;&quot;, e),  &#125;&#125;fn get_current_date() -&gt; Result&lt;String, reqwest::Error&gt; &#123;  let url = &quot;https://postman-echo.com/time/object&quot;;  let res = reqwest::blocking::get(url)?.json::&lt;HashMap&lt;String, i32&gt;&gt;()?;  let date = res[&quot;years&quot;].to_string();  Ok(date)&#125;\n\n这看起来简洁明了。其中?操作符类似于unwrap但是在遇到Error时并不会产生panic，而是会将错误返回给调用者函数。需要记住的一件事情是只有在函数返回Option和Result类型时才能使用?操作符。\nRust语言中Option和Result两种类型的使用_rust option result-CSDN博客\n注意Option和Result：\npub enum Option&lt;T&gt; &#123;    None,    Some(T),&#125;pub enum Result&lt;T, E&gt; &#123;    Ok(T),    Err(E),&#125;\n\n其中Option更多用于一个返回值不确定是否存在的情况下（可以理解为其他语言中的NULL）。\n而Result更多用于会出现错误进行捕捉的场景。\n所以会看到很多函数后面的返回值(可以return，也可以直接None&#x2F;Some&#x2F;Ok&#x2F;Err)是这样的，给出各自的例子：\n// 使用Option处理可能存在或不存在的值fn find_element_index(arr: &amp;[i32], target: i32) -&gt; Option&lt;usize&gt; &#123;    for (index, &amp;value) in arr.iter().enumerate() &#123;        if value == target &#123;            return Some(index);        &#125;    &#125;    None&#125;// 使用Result处理可能的错误情况fn divide(a: i32, b: i32) -&gt; Result&lt;i32, &amp;&#x27;static str&gt; &#123;    if b == 0 &#123;        Err(&quot;Cannot divide by zero&quot;) //这里会返回Result中的Err，内容是这个字符串字面量    &#125; else &#123;        Ok(a / b) //这里会返回Result中的Ok，内容就是实际除法得到的结果    &#125;&#125;/*这里 &amp;&#x27;static str 表示错误信息是一个指向程序生命周期为整个程序的字符串字面量的引用。使用 &amp;&#x27;static str 而不是 String 可以避免在堆上分配内存，从而提高效率。&amp;&#x27;static str 表示一个指向字符串字面量的引用，其生命周期是 &#x27;static。这意味着这个字符串字面量在程序的整个生命周期内都是有效的。为什么使用 &#x27;static 生命周期？避免动态内存分配：字符串字面量存储在程序的只读数据段中，使用 &#x27;static 生命周期可以避免在堆上为错误消息分配额外的内存。这在处理大量错误时尤其重要，因为它可以减少内存消耗。简化错误处理：使用静态字符串可以简化错误处理逻辑，因为编译器可以保证这些字符串在整个程序生命周期内都是有效的，无需担心生命周期问题。*/fn main() &#123;    let numbers = [1, 2, 3, 4, 5];        // 使用Option    let index = find_element_index(&amp;numbers, 3);    match index &#123;        Some(i) =&gt; println!(&quot;Element found at index: &#123;&#125;&quot;, i),        None =&gt; println!(&quot;Element not found&quot;),    &#125;    // 使用Result    match divide(10, 2) &#123;        Ok(result) =&gt; println!(&quot;Result of division: &#123;&#125;&quot;, result),        Err(error) =&gt; println!(&quot;Error: &#123;&#125;&quot;, error),    &#125;\tdivide(10,2).unwrap();\tdivide(10,2).expect(&quot;defined by yourself&quot;);&#125;\n\n\n\n传递多个错误给调用者在之前的例子中，get和json函数返回了一个reqwest::Error错误。但是如果已经有了一个在调用其他的函数时返回的错误类型，那么应该怎么处理呢？\n让通过返回格式化的日期而不是年份来扩展上一个示例：\n+ use chrono::NaiveDate;  use std::collections::HashMap;  fn main() &#123;    match get_current_date() &#123;      Ok(date) =&gt; println!(&quot;We&#x27;ve time travelled to &#123;&#125;!!&quot;, date),      Err(e) =&gt; eprintln!(&quot;Oh noes, we don&#x27;t know which era we&#x27;re in! :( \\n  &#123;&#125;&quot;, e),    &#125;  &#125;  fn get_current_date() -&gt; Result&lt;String, reqwest::Error&gt; &#123;    let url = &quot;https://postman-echo.com/time/object&quot;;    let res = reqwest::blocking::get(url)?.json::&lt;HashMap&lt;String, i32&gt;&gt;()?;-   let date = res[&quot;years&quot;].to_string();+   let formatted_date = format!(&quot;&#123;&#125;-&#123;&#125;-&#123;&#125;&quot;, res[&quot;years&quot;], res[&quot;months&quot;] + 1, res[&quot;date&quot;]);+   let parsed_date = NaiveDate::parse_from_str(formatted_date.as_str(), &quot;%Y-%m-%d&quot;)?;+   let date = parsed_date.format(&quot;%Y %B %d&quot;).to_string();    Ok(date)  &#125;\n\n上述的代码是不能编译的，由于parse_from_str返回了一个chrono::format::ParseError错误而不是reqwest::Error\n可以使用Box关键字来解决这个问题\n  use chrono::NaiveDate;  use std::collections::HashMap;  fn main() &#123;    match get_current_date() &#123;      Ok(date) =&gt; println!(&quot;We&#x27;ve time travelled to &#123;&#125;!!&quot;, date),      Err(e) =&gt; eprintln!(&quot;Oh noes, we don&#x27;t know which era we&#x27;re in! :( \\n  &#123;&#125;&quot;, e),    &#125;  &#125;- fn get_current_date() -&gt; Result&lt;String, reqwest::Error&gt; &#123;+ fn get_current_date() -&gt; Result&lt;String, Box&lt;dyn std::error::Error&gt;&gt; &#123;    let url = &quot;https://postman-echo.com/time/object&quot;;    let res = reqwest::blocking::get(url)?.json::&lt;HashMap&lt;String, i32&gt;&gt;()?;    let formatted_date = format!(&quot;&#123;&#125;-&#123;&#125;-&#123;&#125;&quot;, res[&quot;years&quot;], res[&quot;months&quot;] + 1, res[&quot;date&quot;]);    let parsed_date = NaiveDate::parse_from_str(formatted_date.as_str(), &quot;%Y-%m-%d&quot;)?;    let date = parsed_date.format(&quot;%Y %B %d&quot;).to_string();    Ok(date)  &#125;\n\n当想要发返回多个不同的错误时，返回一个特征对象 Box&lt;dyn std::error::Error&gt;是一种便利的处理方法。\n了解更多关于： anyhow, eyre\n模式匹配Boxed错误目前为止，只在main中打印错误，而不是真正地去处理它们。如果想处理和恢复Box错误，需要“downcast”它们：\n use chrono::NaiveDate;  use std::collections::HashMap;  fn main() &#123;    match get_current_date() &#123;      Ok(date) =&gt; println!(&quot;We&#x27;ve time travelled to &#123;&#125;!!&quot;, date),-     Err(e) =&gt; eprintln!(&quot;Oh noes, we don&#x27;t know which era we&#x27;re in! :( \\n  &#123;&#125;&quot;, e),+     Err(e) =&gt; &#123;+       eprintln!(&quot;Oh noes, we don&#x27;t know which era we&#x27;re in! :(&quot;);+       if let Some(err) = e.downcast_ref::&lt;reqwest::Error&gt;() &#123;+         eprintln!(&quot;Request Error: &#123;&#125;&quot;, err)+       &#125; else if let Some(err) = e.downcast_ref::&lt;chrono::format::ParseError&gt;() &#123;+         eprintln!(&quot;Parse Error: &#123;&#125;&quot;, err)+       &#125;+     &#125;    &#125;  &#125;  fn get_current_date() -&gt; Result&lt;String, Box&lt;dyn std::error::Error&gt;&gt; &#123;    let url = &quot;https://postman-echo.com/time/object&quot;;    let res = reqwest::blocking::get(url)?.json::&lt;HashMap&lt;String, i32&gt;&gt;()?;    let formatted_date = format!(&quot;&#123;&#125;-&#123;&#125;-&#123;&#125;&quot;, res[&quot;years&quot;], res[&quot;months&quot;] + 1, res[&quot;date&quot;]);    let parsed_date = NaiveDate::parse_from_str(formatted_date.as_str(), &quot;%Y-%m-%d&quot;)?;    let date = parsed_date.format(&quot;%Y %B %d&quot;).to_string();    Ok(date)  &#125;\n\n需要注意的是，必须知道get_current_date的实现细节（其中包含的不同错误），才能够在main中对其进行downcast。\n了解更多关于: downcast, downcast_mut\n库 vs 应用如前面所述，使用Box带来的问题是：如果想要处理底层错误，必须了解函数的实现细节。当以Box&lt; dyn std::error::Error&gt;形式返回某个内容时，具体的类型信息将会丢失。为了以不同方式处理不同的错误，需要将它们向下转换为某个具体类型，这种转换可能会在运行时失败。\n然而，脱离上下文，谈论好坏并不是很有用。一个很好的经验法则是思考当前正在编写的代码是一个“Application”还是“Library”：\nApplication应用\n您正在编写的代码将由最终用户使用。\n大多数由应用程序代码生成的错误不会被处理，而是记录或报告给用户。\n可以使用box错误。\n\nLibrary库\n您正在编写的代码将被其他代码使用。一个“库”可以是开源crate，内部library等。\n错误是库的API的一部分，因此库的使用者知道应该期望并从中恢复哪些错误。\n库中的错误通常由用户处理，因此它们需要结构化且易于执行exhaustive match\n如果您返回Box错误，那么库的使用者需要知道由代码、依赖项等创建的错误类型！\n可以返回自定义错误，而不是Box错误。\n\n创建自定义错误对于library代码，可以将所有错误转换为自定义的错误类型，并返回它，而不是使用特征对象box。在的例子中，目前由两个错误reqwest::Error和chrono::format::ParseError。可以将它们分别转换为MyCustomError::HttpError和MyCustomError::ParseError\n首先要创建一个enum来装的两个错误变量\n// error.rspub enum MyCustomError &#123;  HttpError,  ParseError,&#125;\n\nErrortrait规定实现必须Debug和Display traits:\n// error.rsuse std::fmt;#[derive(Debug)]pub enum MyCustomError &#123;  HttpError,  ParseError,&#125;impl std::error::Error for MyCustomError &#123;&#125;impl fmt::Display for MyCustomError &#123;  fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result &#123;    match self &#123;      MyCustomError::HttpError =&gt; write!(f, &quot;HTTP Error&quot;),      MyCustomError::ParseError =&gt; write!(f, &quot;Parse Error&quot;),    &#125;  &#125;&#125;\n\n就这样创建的自定义错误类型，这是一个非常简单的例子，但是没有包含太多关于错误的信息。但这应该足以作为创建更复杂、更现实的自定义错误的起点。下面是一些常见开发中的自定义错误处理的例子:ripgrep, reqwest, csv and serde_json\n还有: thiserror, snafu\n传递自定义错误看看使用自定义错误类型后对于之前程序的修改\n  // main.rs+ mod error;  use chrono::NaiveDate;+ use error::MyCustomError;  use std::collections::HashMap;  fn main() &#123;    // skipped, will get back later  &#125;- fn get_current_date() -&gt; Result&lt;String, Box&lt;dyn std::error::Error&gt;&gt; &#123;+ fn get_current_date() -&gt; Result&lt;String, MyCustomError&gt; &#123;    let url = &quot;https://postman-echo.com/time/object&quot;;-   let res = reqwest::blocking::get(url)?.json::&lt;HashMap&lt;String, i32&gt;&gt;()?;+   let res = reqwest::blocking::get(url)+     .map_err(|_| MyCustomError::HttpError)?+     .json::&lt;HashMap&lt;String, i32&gt;&gt;()+     .map_err(|_| MyCustomError::HttpError)?;    let formatted_date = format!(&quot;&#123;&#125;-&#123;&#125;-&#123;&#125;&quot;, res[&quot;years&quot;], res[&quot;months&quot;] + 1, res[&quot;date&quot;]);-   let parsed_date = NaiveDate::parse_from_str(formatted_date.as_str(), &quot;%Y-%m-%d&quot;)?;+   let parsed_date = NaiveDate::parse_from_str(formatted_date.as_str(), &quot;%Y-%m-%d&quot;)+     .map_err(|_| MyCustomError::ParseError)?;    let date = parsed_date.format(&quot;%Y %B %d&quot;).to_string();    Ok(date)  &#125;\n\n注意到使用了map_err将一个错误类型转换为另外的错误类型.\n但是可以看到太多的verbose作为结果，的函数充斥着太多map_err调用。可以实现From trait，这样就会完成自动错误类型转换。\n  // error.rs  use std::fmt;  #[derive(Debug)]  pub enum MyCustomError &#123;    HttpError,    ParseError,  &#125;  impl std::error::Error for MyCustomError &#123;&#125;  impl fmt::Display for MyCustomError &#123;    fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result &#123;      match self &#123;        MyCustomError::HttpError =&gt; write!(f, &quot;HTTP Error&quot;),        MyCustomError::ParseError =&gt; write!(f, &quot;Parse Error&quot;),      &#125;    &#125;  &#125;+ impl From&lt;reqwest::Error&gt; for MyCustomError &#123;+   fn from(_: reqwest::Error) -&gt; Self &#123;+     MyCustomError::HttpError+   &#125;+ &#125;+ impl From&lt;chrono::format::ParseError&gt; for MyCustomError &#123;+   fn from(_: chrono::format::ParseError) -&gt; Self &#123;+     MyCustomError::ParseError+   &#125;+ &#125; // main.rs  mod error;  use chrono::NaiveDate;  use error::MyCustomError;  use std::collections::HashMap;  fn main() &#123;    // skipped, will get back later  &#125;  fn get_current_date() -&gt; Result&lt;String, MyCustomError&gt; &#123;    let url = &quot;https://postman-echo.com/time/object&quot;;-   let res = reqwest::blocking::get(url)-     .map_err(|_| MyCustomError::HttpError)?-     .json::&lt;HashMap&lt;String, i32&gt;&gt;()-     .map_err(|_| MyCustomError::HttpError)?;+   let res = reqwest::blocking::get(url)?.json::&lt;HashMap&lt;String, i32&gt;&gt;()?;    let formatted_date = format!(&quot;&#123;&#125;-&#123;&#125;-&#123;&#125;&quot;, res[&quot;years&quot;], res[&quot;months&quot;] + 1, res[&quot;date&quot;]);-   let parsed_date = NaiveDate::parse_from_str(formatted_date.as_str(), &quot;%Y-%m-%d&quot;)-     .map_err(|_| MyCustomError::ParseError)?;+   let parsed_date = NaiveDate::parse_from_str(formatted_date.as_str(), &quot;%Y-%m-%d&quot;)?;    let date = parsed_date.format(&quot;%Y %B %d&quot;).to_string();    Ok(date)  &#125;\n\n在移除map_err后代码变得更加整洁了。\n然而,Fromtrait并不是一种能减少使用map_err的魔法。在上面的例子中，将类型转换从get_current_data函数内部移动到From&lt;X&gt; for MyCustomError实现.那么如果一个错误没有在MyCustomError出现过，就不能使用From trait，从而只能使用map_err\n模式匹配自定义错误一直忽略了main的变动，现在要看看如何去处理自定义错误类型的模式匹配问题。\n  // main.rs  mod error;  use chrono::NaiveDate;  use error::MyCustomError;  use std::collections::HashMap;  fn main() &#123;    match get_current_date() &#123;      Ok(date) =&gt; println!(&quot;We&#x27;ve time travelled to &#123;&#125;!!&quot;, date),      Err(e) =&gt; &#123;        eprintln!(&quot;Oh noes, we don&#x27;t know which era we&#x27;re in! :(&quot;);-       if let Some(err) = e.downcast_ref::&lt;reqwest::Error&gt;() &#123;-         eprintln!(&quot;Request Error: &#123;&#125;&quot;, err)-       &#125; else if let Some(err) = e.downcast_ref::&lt;chrono::format::ParseError&gt;() &#123;-         eprintln!(&quot;Parse Error: &#123;&#125;&quot;, err)-       &#125;+       match e &#123;+         MyCustomError::HttpError =&gt; eprintln!(&quot;Request Error: &#123;&#125;&quot;, e),+         MyCustomError::ParseError =&gt; eprintln!(&quot;Parse Error: &#123;&#125;&quot;, e),+       &#125;      &#125;    &#125;  &#125;  fn get_current_date() -&gt; Result&lt;String, MyCustomError&gt; &#123;    let url = &quot;https://postman-echo.com/time/object&quot;;    let res = reqwest::blocking::get(url)?.json::&lt;HashMap&lt;String, i32&gt;&gt;()?;    let formatted_date = format!(&quot;&#123;&#125;-&#123;&#125;-&#123;&#125;&quot;, res[&quot;years&quot;], res[&quot;months&quot;] + 1, res[&quot;date&quot;]);    let parsed_date = NaiveDate::parse_from_str(formatted_date.as_str(), &quot;%Y-%m-%d&quot;)?;    let date = parsed_date.format(&quot;%Y %B %d&quot;).to_string();    Ok(date)  &#125;\n\n请注意，与Boxed错误不同，实际上可以直接匹配MyCustomError enum中的变量。\n","categories":["Rust"],"tags":["Rust"]},{"title":"SQL刷题","url":"/2024/07/30/2024-07-30-SQL%E5%88%B7%E9%A2%98/","content":"SQL刷题数据库SQL查询语句的执行顺序是怎么样的？_sql查询顺序-CSDN博客\n注意where和having“Where”是一个约束声明，在查询数据库的结果返回之前对数据库中的查询条件进行约束，即在结果返回之前起作用，且where后面不能使用“聚合函数”；\n“Having”是一个过滤声明，所谓过滤是在查询数据库的结果返回之后进行过滤，即在结果返回之后起作用，并且having后面可以使用“聚合函数”。\n\n使用的角度：\n\nwhere后面之所以不能使用聚合函数是因为where的执行顺序在聚合函数之前，\n如下面这个sql语句：\nselect  sum(score) from student  group by student.sex where sum(student.age)&gt;100;\n\nhaving既然是对查出来的结果进行过滤，那么就不能对没有查出来的值使用having，\n如下面这个sql语句：\nselect  student.id,student.name from student having student.score &gt;90;\n\n\n\n在查询过程中聚合语句(sum,min,max,avg,count)要比having子句优先执行，而where子句在查询过程中执行优先级别优先于聚合语句(sum,min,max,avg,count)。简单说来：where子句：\nselect sum(num) as rmb from order where id&gt;10\n\n&#x2F;&#x2F;只有先查询出id大于10的记录才能进行聚合语句\n升序降序升序：asc(ascend)\n降序：desc(descend)\nUnion[sql语句中union的用法_sql union-CSDN博客](https://blog.csdn.net/weixin_42383680/article/details/119858753?ops_request_misc=%7B%22request%5Fid%22%3A%22172242275016800222833310%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172242275016800222833310&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-119858753-null-null.142^v100^pc_search_result_base8&amp;utm_term=SQL union&amp;spm&#x3D;1018.2226.3001.4187)\nunion联合的结果集不会有重复值，如果要有重复值，则使用union all\n union会自动压缩多个结果集合中重复的结果，使结果不会有重复行，union all 会将所有的结果共全部显示出来，不管是不是重复。\n union：会对两个结果集进行并集操作，不包括重复行，同时进行默认规则的排序。\n union all：对两个结果集进行并集操作，包括重复行，不会对结果进行排序。\ncount[SQL中COUNT()函数的用法_sqlcount函数的使用方法-CSDN博客](https://blog.csdn.net/fdggdg/article/details/118757777?ops_request_misc=%7B%22request%5Fid%22%3A%22172242334216800211564239%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172242334216800211564239&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-118757777-null-null.142^v100^pc_search_result_base8&amp;utm_term=sql count&amp;spm&#x3D;1018.2226.3001.4187)\n177. 第N高的薪水注意声明函数，变量，set的过程，limit的用法，distinct的用法。\n这里变量不能直接N-1带进去，必须重新声明一个变量。\nCREATE FUNCTION getNthHighestSalary(N INT) RETURNS INTBEGINDECLARE M INT;     SET M = N-1;   RETURN (      SELECT DISTINCT salary      FROM Employee      ORDER BY salary DESC      LIMIT M, 1  );END\n\n180.连续出现的数字select distinct l1.num as ConsecutiveNums from Logs l1,Logs l2,Logs l3where    l1.id=l2.id-1     and l1.num=l2.num    and l1.id=l3.id-2 and l1.num=l3.num\n\n602.好友申请②：谁有最多的好友# Write your MySQL query statement belowselect id,num from(select ids as id,count(ids) as num from(select requester_id as ids  from RequestAccepted union allselect accepter_id as ids  from RequestAccepted )as table1 group by ids)as table2order by num desc limit 0,1;\n\n","categories":["博客"],"tags":["SQL","MySQL"]},{"title":"后端微服务-programmer-club项目的设计与实现心得","url":"/2024/07/21/2024-07-21-%E5%90%8E%E7%AB%AF%E5%BE%AE%E6%9C%8D%E5%8A%A1-programmer-club%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E5%BF%83%E5%BE%97/","content":"后端微服务-programmer-club项目的设计与实现心得开发工具后端：IDEA\n前端：VSCode\n项目管理：git\n包依赖管理：Maven3.6.0\n数据库：Mysql5.7\n数据库连接池和监控库：Druid\n框架：Springboot 2.4.2\n数据库图形化：Navicat\n接口管理工具：APIPost7\nRedis桌面工具：RedisDesktop\n表建模：PDManager\n原型设计：axure8\n原型组件库: antdesign\n代码生成器：easycode（idea的plugin市场）\n一些插件：mybatis（类-&gt;dao-&gt;数据库），easycode（由数据库表生成相应代码）, preconditions（参数校验）\nnode.js\n阿里云脚手架用于组件&#x2F;版本的选择兼容，非常方便: start.aliyun.com\n架构设计传统项目[SpringMVC框架（详解）-CSDN博客](https://blog.csdn.net/H20031011/article/details/131511482?ops_request_misc=%7B%22request%5Fid%22%3A%22172145077916800222810035%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172145077916800222810035&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-131511482-null-null.142^v100^pc_search_result_base8&amp;utm_term=spring mvc架构&amp;spm&#x3D;1018.2226.3001.4187)\n一般的mvc：model，view，controller\nSpringMVC：controller(view+controller)，service（业务逻辑），dao（数据库）\n\n\n现有的架构DDD架构-CSDN博客\n[浅谈架构设计：MVC架构与DDD架构【开发实践】_ddd架构和mvc架构区别-CSDN博客](https://blog.csdn.net/qq_40656637/article/details/137344153?ops_request_misc=%7B%22request%5Fid%22%3A%22172145093416800184184571%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&amp;request_id=172145093416800184184571&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-1-137344153-null-null.142^v100^pc_search_result_base8&amp;utm_term=spring mvc架构和ddd架构&amp;spm&#x3D;1018.2226.3001.4187)\nddd 架构\n\n\n用户接口层（User Interface ）：负责向用户显示信息和解释用户指令（是DDD架构中的表现层）（表现层是视图层的超集，概念有所区别，知道最上层就是表现层即可）\n应用层（Application）：很“薄”的一层，理论上不应该有业务规则或逻辑，主要面向用例和流程相关的操作。在应用层协调多个服务和领域对象完成服务的组合和编排，协作完成业务操作。此外，应用层也是微服务之间交互的通道，它可以调用其它微服务的应用服务，完成微服务之间服务的组合和编排\n领域层（Domain）：是实现企业核心业务逻辑，通过各种校验手段保证业务的正确性。领域层主要体现领域模型的业务能力，它用来表达业务概念、业务状态和业务规则。领域层包含聚合根、实体、值对象、领域服务等领域模型中的领域对象\n基础层（Infrastructure）：贯穿所有层，为其它层提供通用的技术和基础服务，包括第三方工具、驱动、消息中间件、网关、文件、缓存以及数据库等\n个人理解：将service层拆分为了应用层和领域层。其中应用层关注于用例和流程，不涉及业务规则或逻辑，通过组合和编排下层的领域层来完成业务操作。而领域层用于封装具体的业务规则或逻辑，拆分出来的领域层不再和具体流程关联，实现了高内聚和低耦合，还提高了领域层的可复用性。用户接口层和基础层则为原来的视图层和dao层的扩展，新增了部分职责功能。\n\n\n\nAPI（对外接口层）：这一层负责定义对外提供的服务接口，通常用于与客户端或其他服务进行交互。\n\nController：在传统的MVC架构中，控制器用于处理用户的请求。在这里，它用于接收API层的请求，并将请求转换为应用层可以理解的格式。\n\nDTO（Data Transfer Object）：\n代表数据传输对象的意思\n是一种设计模式之间传输数据的软件应用系统，数据传输目标往往是数据访问对象从数据库中检索数据\n数据传输对象与数据交互对象或数据访问对象之间的差异是一个以不具任何行为除了存储和检索的数据（访问和存取器）\n简而言之，就是接口之间传递的数据封装\n表里面有十几个字段：id，name，gender（M&#x2F;F)，age……\n页面需要展示三个字段：name，gender(男&#x2F;女)，age\nDTO由此产生，一是能提高数据传输的速度(减少了传输字段)，二能隐藏后端表结构。\n\nBO（Business Object）：\n代表业务对象的意思，Bo就是把业务逻辑封装为一个对象（注意是逻辑，业务逻辑），这个对象可以包括一个或多个其它的对象。通过调用Dao方法，结合Po或Vo进行业务操作。\n形象描述为一个对象的形为和动作，当然也有涉及到基它对象的一些形为和动作。比如处理一个人的业务逻辑，该人会睡觉，吃饭，工作，上班等等行为，还有可能和别人发关系的行为，处理这样的业务逻辑时，我们就可以针对BO去处理。\n再比如投保人是一个PO，被保险人是一个PO，险种信息也是一个PO等等，他们组合起来就是一张保单的BO。\n\nPO&#x2F;DO: Persistent Object &#x2F; Data Object，持久对象 &#x2F; 数据对象。\n它跟持久层（通常是关系型数据库）的数据结构形成一一对应的映射关系，如果持久层是关系型数据库，那么，数据表中的每个字段（或若干个）就对应PO的一个（或若干个）属性。\n\nVO: View Object, 视图模型，展示层对象:\n对应页面显示（web页面&#x2F;移动端H5&#x2F;Native视图）的数据对象。\n\nApplication层（应用层）：这一层包含应用服务，它们协调领域对象来完成业务逻辑。它还包含一些业务逻辑的转换逻辑，如DTO到BO的转换。\n\nInterceptor：拦截器，用于在请求处理过程中进行一些前置或后置处理，例如日志记录、权限验证等。\n\nApplication-MQ（消费者）&#x2F; Application-Job：这指的是应用层中处理消息队列消息的组件，或者定时任务的处理。\n\nDomain层（领域层）：这是DDD中的核心层，包含业务逻辑和领域模型。领域层专注于业务规则和业务实体。\n\nService：领域服务，执行领域逻辑但不自然属于任何实体或值对象的操作。\n\nEntity&#x2F;PO（Persistent Object）：持久化对象，通常与数据库存储相关，代表数据库中的记录。\n\nMapper：数据访问对象，用于将领域对象映射到数据库表。\n\nInfra层（基础设施层）：提供技术实现，如数据库访问、消息传递、外部服务调用等。\n\nRPC：远程过程调用，用于服务之间的通信。\n\nMG（生产者）：指的是消息生成者，负责生成并发送消息到消息队列。\n\nStarter（启动层）：指的是服务启动时需要自动执行的代码或配置。\n\nAggressive（聚合层）：聚合层，将多个领域对象聚合成一个更大的业务实体。\n\nConfig：配置层，用于存储和访问配置信息。\n\nDict（字典）：指的是数据字典，用于存储一些固定的数据或映射关系。\n\nCommon（公共层）：包含整个应用中多个地方会用到的通用代码或工具。\n\nEnums：枚举，用于定义一组命名的常量。\n\nUtils：工具类，提供一些通用的辅助功能。\n\n\nreq-&gt;dto-&gt;do-&gt;bo-&gt;entity-&gt;po\n\n项目结构\n后端项目目录（backend）\nasyncTool: 包含异步处理工具或库，用于处理异步任务。\n\ndoc: 存放项目文档，如API文档、技术规范等。\n\njc-club-auth: 认证服务，负责用户认证和授权。\n\njc-club-circle: 可能与社区圈子或用户组相关功能。\n\njc-club-common-starter: 通用启动器或工具类，提供项目通用功能。\n\njc-club-gateway: 网关服务，负责请求路由、负载均衡等。\n\njc-club-gen: 代码生成工具，可能用于快速生成项目代码。\n\njc-club-interview: 面试相关功能，可能包含面试题库或模拟面试。\n\njc-club-oss: 对象存储服务，用于管理文件存储。\n\nminio安装部署及使用-CSDN博客\n\n\njc-club-practice: 实践项目或示例代码。\n\njc-club-subject: 主题或课程相关功能，可能用于教育或培训。\n\njc-club-wx: 微信相关功能，可能包含微信公众号接口或小程序支持。\n\n\n技术选型[Spring和Spring Boot之间的区别（小结）_spring和springboot的区别-CSDN博客](https://blog.csdn.net/mengxin_chen/article/details/116240326?ops_request_misc=%7B%22request%5Fid%22%3A%22172145220016800227442776%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172145220016800227442776&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-116240326-null-null.142^v100^pc_search_result_base8&amp;utm_term=spring和spring boot区别&amp;spm&#x3D;1018.2226.3001.4187)\n\nSpringBoot相关SpringBoot注解@Autowired用法详解-CSDN博客\n@RestController 注解_@restcontroller注解-CSDN博客\nMybatis:@Mapper注解-CSDN博客 给Dao用的\nmapstruct：[MAPSTRUCT(@Mapper用法)_org.mapstruct.mapper maven-CSDN博客](https://blog.csdn.net/qq_43459184/article/details/103372740?ops_request_misc=%7B%22request%5Fid%22%3A%22172259704016800180642299%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172259704016800180642299&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-103372740-null-null.142^v100^pc_search_result_base8&amp;utm_term=mapstruct @mapper&amp;spm&#x3D;1018.2226.3001.4187)\n详细分析Java中的@Service注解-CSDN博客\n[介绍@Component，@Bean，@service，@Autowire 和 @Resource等_@service @bean-CSDN博客](https://blog.csdn.net/weixin_38002126/article/details/122977500?ops_request_misc=%7B%22request%5Fid%22%3A%22172162091816800186516004%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172162091816800186516004&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-122977500-null-null.142^v100^pc_search_result_base8&amp;utm_term=@service和@component @bean @a&amp;spm&#x3D;1018.2226.3001.4187)\nSpringBoot ioc aop[深入理解Spring两大特性：IoC和AOP-CSDN博客](https://blog.csdn.net/dkbnull/article/details/87219562?ops_request_misc=%7B%22request%5Fid%22%3A%22172243396116800182129949%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172243396116800182129949&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-87219562-null-null.142^v100^pc_search_result_base8&amp;utm_term=SPRING BOOT AOP ioc&amp;spm&#x3D;1018.2226.3001.4187)\nAOP的连接点与切点区别，连接点，切点，切面的基础概念_aop连接点-CSDN博客\nSpring AOP术语：连接点和切点的区别。_切入点 连接点 区别-CSDN博客\nMybatis彻底搞懂MyBaits中#{}和${}的区别_mybatis #{}-CSDN博客\n[mybatis中resultMap的理解_result map-CSDN博客](https://blog.csdn.net/u012843873/article/details/80198185?ops_request_misc=%7B%22request%5Fid%22%3A%22172259150816800178584486%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172259150816800178584486&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~baidu_landing_v2~default-1-80198185-null-null.142^v100^pc_search_result_base8&amp;utm_term=mybatic resultmap&amp;spm&#x3D;1018.2226.3001.4187)\n【Mybatis】xml常用总结（持续更新）_mybatis xml-CSDN博客\n[SpringBoot+MyBatis项目Dao层最简单写法_springboot dao层怎么写-CSDN博客](https://blog.csdn.net/iiiliuyang/article/details/104162463?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=springboot dao.xml写法&amp;utm_medium&#x3D;distribute.pc_search_result.none-task-blog-2allsobaiduweb~default-2-104162463.142^v100^pc_search_result_base8&amp;spm&#x3D;1018.2226.3001.4187)\n[Spring Boot专栏六：在Dao.xml文件中写Mybatis语句_springboot dao xml-CSDN博客](https://blog.csdn.net/DTDanteDong/article/details/112606910?ops_request_misc=%7B%22request%5Fid%22%3A%22172243518216800222895850%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172243518216800222895850&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~baidu_landing_v2~default-1-112606910-null-null.142^v100^pc_search_result_base8&amp;utm_term=springboot dao.xml写法&amp;spm&#x3D;1018.2226.3001.4187)\n[Mybatis中动态Sql的if、for和foreach使用_mybatis foreach if open-CSDN博客](https://blog.csdn.net/wflsyf/article/details/112984282?ops_request_misc=%7B%22request%5Fid%22%3A%22172259182216800226531598%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172259182216800226531598&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-112984282-null-null.142^v100^pc_search_result_base8&amp;utm_term=mybatis if test foreach&amp;spm&#x3D;1018.2226.3001.4187)\ndao的接口放在mapper包下，在启动类前要加@MapperScan(“com.**.mapper”)，便于发现：blog.csdn.net&#x2F;zzxcvbnm19&#x2F;article&#x2F;details&#x2F;103275920?ops_request_misc&#x3D;%257B%2522request%255Fid%2522%253A%2522172259218016800226519050%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id&#x3D;172259218016800226519050&amp;biz_id&#x3D;0&amp;utm_medium&#x3D;distribute.pc_search_result.none-task-blog-2allfirst_rank_ecpm_v1~rank_v31_ecpm-1-103275920-null-null.142^v100^pc_search_result_base8&amp;utm_term&#x3D;mapperscan和dao&amp;spm&#x3D;1018.2226.3001.4187\n[spring和Mybatis中的拦截器_mybatis handlerinterceptor-CSDN博客](https://blog.csdn.net/qq_59612674/article/details/121027506?ops_request_misc=%7B%22request%5Fid%22%3A%22172388427716800178552460%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&amp;request_id=172388427716800178552460&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-2-121027506-null-null.142^v100^pc_search_result_base8&amp;utm_term=mybatis innovation&amp;spm&#x3D;1018.2226.3001.4187)\nJava相关Stream[讲透JAVA Stream的collect用法与原理，远比你想象的更强大_stream.collection-CSDN博客](https://blog.csdn.net/veezean/article/details/125857074?ops_request_misc=%7B%22request%5Fid%22%3A%22172258578116800227423214%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172258578116800227423214&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-125857074-null-null.142^v100^pc_search_result_base8&amp;utm_term=Java stream collect&amp;spm&#x3D;1018.2226.3001.4187)\n/** * 构建缓存key */public String buildKey(String... strObjs) &#123;    return Stream.of(strObjs).collect(Collectors.joining(CACHE_KEY_SEPARATOR));&#125;\n\n[Java–Stream流详解_java stream-CSDN博客](https://blog.csdn.net/MinggeQingchun/article/details/123184273?ops_request_misc=%7B%22request%5Fid%22%3A%22172258592916800182196501%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172258592916800182196501&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-123184273-null-null.142^v100^pc_search_result_base8&amp;utm_term=Java stream流&amp;spm&#x3D;1018.2226.3001.4187)\nstream的创建：\n\nStream.of(1,2,3,4)    （这里面的1,2,3,4其实是Array的类型）\nlist.stream()\n\n操作符\n\n中间操作符\nfilter：用于过滤 \nlist.stream().filter(number-&gt;number&gt;&#x3D;2).collect(Collectors.toList());\n\n\nmap：用于映射 \nlist.stream().(str-&gt;str+”-IT”).collect(Collectors.toList());\n\n\ndinstinct:  用于去重 \nnumbers.stream().filter(i -&gt; i % 2 &#x3D;&#x3D; 0).distinct().forEach(System.out::println);教你看懂System.out::println-CSDN博客\n\n\nsorted: 用于排序  \nstrings1.stream().sorted().collect(Collectors.toList());\n\n\n\n\n终端操作符\ncollect: 收集器，将流转换为其他形式 \nstrings.stream().collect(Collectors.toSet()); \nstrings.stream().collect(Collectors.toList());\n\n\nforEach:遍历流\nstrings.stream().forEach(s -&gt; out.println(s));\n\n\n\n\n\nLamda表达式Lambda表达式详解_lamda表达式-CSDN博客\n形如以下：\n\n(o1,o2) -&gt; Integer.compare(o1,o2)\n左边-&gt;右边\n\n\n-&gt; 被称为lambda操作符或箭头操作符\n左边：lambda形参列表（其实就是接口中的抽象方法的形参列表）\n右边：lambda体 （其实就是重写的抽象方法的方法体）\n\n线程池[java线程池（简单易懂）-CSDN博客](https://blog.csdn.net/qq_64680177/article/details/131445798?ops_request_misc=%7B%22request%5Fid%22%3A%22172277205216800186576272%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&amp;request_id=172277205216800186576272&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-2-131445798-null-null.142^v100^pc_search_result_base8&amp;utm_term=java线程池 简单易懂&amp;spm&#x3D;1018.2226.3001.4187)\nJava四种线程池newCachedThreadPool,newFixedThreadPool,newScheduledThreadPool,newSingle-CSDN博客\nJAVA线程池submit详解 ，execute和submit提交任务的区别_executor.submit-CSDN博客\n继承的ExecutorService接口\n\nnewCachedThreadPool（没有上限的线程池），如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。\n\nExecutorService cachedThreadPool = Executors.newCachedThreadPool();\ncachedThreadPool.execute(new Runnable()&#123;\n    @Override\n    public void run() &#123;\n        System.out.println(&quot;执行线程任务&quot;);\n&#125;)\n- **newFixdedThreadPool**（有上限的线程池），创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。  - ```    ExecutorService fixedThreadPool = Executors.newFixedThreadPool(3);    fixedThreadPool.execute(new Runnable()&#123;        @Override        public void run() &#123;            System.out.println(&quot;执行线程任务&quot;);    &#125;)\n\n\n\n\nnewScheduledThreadPool，创建一个定长线程池，支持定时及周期性任务执行。延迟执行示例代码如下：\n\nScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5);\nscheduledThreadPool.schedule(new Runnable() &#123;\n    @Override\n    public void run() &#123;\n        System.out.println(&quot;delay 3 seconds&quot;);\n    &#125;\n&#125;, 3, TimeUnit.SECONDS);//延迟三秒执行\n- **newSingleThreadExecutor**，创建一个**单线程化**的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。- **ThreadPoolExecutor**（自定义创建线程池）  - 它最长的构造方法有七个参数。    1. 核心线程数量——在线程池当中无论空闲多久都不会被删除的线程    2. 线程池当中最大的线程数量——线程池当中最大能创建的线程数量    3. 空闲时间（数值）——临时线程（线程池中出核心线程之外的线程）空闲了多久就会被淘汰的时间。    4. 空闲时间（单位）——临时线程空闲了多久就会被淘汰的时间单位，要用枚举类TimeUnit类作为参数    5. 阻塞队列——就是创建一个阻塞队列作为参数传入，就是当线程池当中线程数量已经达到了最大线程数量，允许多少个任务排队获取线程，其余的用参数七那个方案来处理。    6. 创建线程的方式——不是new一个线程，而是传入一个线程工厂（例如：Executors工具类中的defaultThreadFactory方法返回的就是一个线程工厂）    7. 要执行的任务过多时的解决方案——当等待队列中也排满时要怎么处理这些任务(任务拒绝策略)  - ```java        //代码实现       /**         * 之前用工具类进行创建，有好多参数不能自己设置         * 咱直接自己手动创建一个线程池，自己设置参数         * 参数一：核心线程数量                           不能小于0         * 参数二：最大线程数                             不能小于0，数值大于等于核心线程数量         * 参数三：空闲临时线程最大存活时间（数值）           不能小于0         * 参数四：空闲临时线程最大存活时间（单位）            用TimeUnit这个枚举类表示         * 参数五：任务队列，也就是一个堵塞队列               不能为null         * 参数六:创建线程的工厂                            不能为null         * 参数七：任务的拒绝策略                             不能为null         */     ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(            3,  // 核心线程数量            6,              //最大线程数            60,             //空闲临时线程最大存活时间（数值）            TimeUnit.SECONDS,//空闲临时线程最大存活时间（单位）            new ArrayBlockingQueue&lt;&gt;(3),//任务队列，也就是一个堵塞队列，也可以使用LinkedBlockingQueue这个阻塞队列            Executors.defaultThreadFactory(),//用线程池工具类Executors创建线程的工厂            new ThreadPoolExecutor.AbortPolicy()//任务的拒绝策略中其中一个，丢弃任务并抛出RejectedExecutionException            &#125;\n\n![image-20240804205131842.png](https://s2.loli.net/2024/08/04/fTsqWtGjBRbrVxS.png)\n\n\n\n\n\n锁Java中涉及到的锁_java的锁-CSDN博客\n可重入锁详解（什么是可重入）-CSDN博客\n浅谈synchronized、wait、notify和notifyAll_synchronized,wait,notify-CSDN博客\nJava中的锁升级_java 锁升级-CSDN博客\nSQL史上超强最常用SQL语句大全-CSDN博客\nmysql数据库–行级锁，间隙锁和临键锁详解 - 菜鸟的奋斗之路 - 博客园 (cnblogs.com)\n开发启示：日志是log4j+slf4j：最通俗易懂的 JAVA slf4j,log4j,log4j2,logback 关系与区别以及完整集成案例_slf4j log4j2-CSDN博客\ndruid用于控制数据库连接池等配置，可以生成公钥来对数据库密码加密\nnavicat连MySQL\neazycode是在利用idea与数据库连接后点击具体的表生成的相关的代码，template选择mapper.xml.vm, dao.java.vm, entity.java.vm, service.java.vm, serviceImpl.java.vm\nController层是访问的入口，其需要@RestController注解，可以将返回结果以正确的形式呈现；然后在每个接口(add,delete等)，使用@RestMapping注解，将正确的路由映射。\nDTO-&gt;BO的BO-&gt;实际类的转换的converter是接口+mapstruct的@Mapper实现的，要进行convert时记得在converter前加@Mapper ：[Mapstruct @Mapper @Mapping 使用介绍以及总结-CSDN博客](https://blog.csdn.net/weixin_44131922/article/details/126232977?ops_request_misc=%7B%22request%5Fid%22%3A%22172163217516800227461233%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&amp;request_id=172163217516800227461233&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-11-126232977-null-null.142^v100^pc_search_result_base8&amp;utm_term=@mapper convert&amp;spm&#x3D;1018.2226.3001.4187)\n\n用于各个对象实体间的相互转换，例如数据库底层实体 转为页面对象，Model 转为 DTO（data transfer object 数据转换实体）, DTO 转为其他中间对象， VO 等等，相关转换代码为编译时自动产生的新文件和代码。\nMapStruct会根据源对象和目标对象的属性名称进行自动映射。如果需要自定义映射逻辑，可以在接口中定义映射方法或使用配置文件。\n两个对象之间相同属性名的会被自动转换，指定特殊情况时需要通过注解在抽象方法上说明不同属性之间的转换。\n\ndomain层的接口和实现是具体的业务，会添加Service注解 ，会用到infra层的接口和实现，也会添加Service注解 \n到infra层的对数据库的实际访问是由dao+dao.xml实现的，在dao.xml中有具体的SQL语句\ncontroller-&gt;domain serviceImpl-&gt;infra serviceImpl\n在serviceImpl中，变量会使用@Resource注解\n微服务之间的调用：SpringCloud Feign实现微服务间的远程调用（黑马头条Day04）_feign 远程过程调用-CSDN博客\nEnableFeignClients详解-CSDN博客\n刷题模块对于题目模块（四种题目），共性的可以提出来，不同的就设置handler通过标志位进行判断题目类型（工厂+策略模式），进行处理，然后返回结果\n查询题目，分页查询：mysql基础 | 10.分页查询、联合查询_mysql分页语句-CSDN博客\nSQL拦截器自动翻译（mybatis提供的），用于打印展示infra层与数据库的交互，便于发现错误\n\nSqlStatementInterceptor 主要作用是监控MyBatis的SQL执行时间，并根据不同的执行时间记录不同级别的日志\nMybatisPlusAllSqlLog这个类实现了InnerInterceptor接口，它是MyBatis-Plus框架提供的一个内部拦截器接口，用于拦截SQL的执行。这个类有两个主要的重写方法：\n\nbeforeQuery: 在查询执行前调用，记录SQL信息。\nbeforeUpdate: 在更新执行前调用，记录SQL信息。\n\n\n\n彻底搞懂MyBaits中#{}和${}的区别_mybatis #{}-CSDN博客\n[mybatis中resultMap的理解_result map-CSDN博客](https://blog.csdn.net/u012843873/article/details/80198185?ops_request_misc=%7B%22request%5Fid%22%3A%22172259150816800178584486%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172259150816800178584486&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~baidu_landing_v2~default-1-80198185-null-null.142^v100^pc_search_result_base8&amp;utm_term=mybatic resultmap&amp;spm&#x3D;1018.2226.3001.4187)\n【Mybatis】xml常用总结（持续更新）_mybatis xml-CSDN博客\nminio模块：controller-&gt;service-&gt;adaper（阿里&#x2F;minio，适配器模式，不用工厂＋策略的是因为工厂+策略的传入的参数之类的差不多，所以用适配器）-&gt;具体操作。nacos 作为配置中心，可以实现动态配置，适用于比如动态数据源切换，动态切换 oss。这里要配合RefreshScope注解去使用，实现动态刷新（minio-&gt;ali）。\n参数校验Preconditions:checkNotNull&#x2F;checkArgument\n一文带你理解@RefreshScope注解实现动态刷新原理-CSDN博客\nnacos: 可通过**@Configuration**注解的Storage.java中的@Bean、@RefreshScope注解的storageService方法，在@Value注解拿到配置文件中的值时，会切换适配器的对应的StorageAdapter，拿到minio&#x2F;阿里云的oss服务。\n阿里云脚手架用于组件&#x2F;版本的选择兼容，非常方便: start.aliyun.com\n分类标签性能优化：【Java 8 新特性】Java CompletableFuture supplyAsync()详解_completablefuture.supplyasync-CSDN博客\n登录鉴权模块扫码微信-&gt;微信发送消息到服务器，校验签名确保来自微信（get）-&gt;服务器再把消息进行包装， 通过前缀+验证码（一个随机数）作为redis key，fromUserName(openId)作为value存到redis，并把包含验证码的消息发送到微信-&gt;用户验证码（微信）,从redis拿到openId（即用户名）-&gt;用satoken用openId进行登录，然后利用satoken返回一个token，后续登录就会带上这个token\n@Overridepublic SaTokenInfo doLogin(String validCode) &#123;    String loginKey = redisUtil.buildKey(LOGIN_PREFIX, validCode);    String openId = redisUtil.get(loginKey);    if (StringUtils.isBlank(openId)) &#123;        return null;    &#125;    AuthUserBO authUserBO = new AuthUserBO();    authUserBO.setUserName(openId);    this.register(authUserBO); //校验是否存在，存在直接返回，不存在就注册    StpUtil.login(openId);    SaTokenInfo tokenInfo = StpUtil.getTokenInfo();    return tokenInfo;&#125;\n\nSa-Token 功能一览\n全局异常拦截：继承ErrorWebExceptionHandler重写handle方法返回Mono类型（异步的），返回结果Result也封装和枚举了。\n深入学习ErrorWebExceptionHandler-CSDN博客\nFlux、Mono、Reactor 实战（史上最全）_reactor mono-CSDN博客\ngateway实现redis数据拉取：RedisTemplate-&gt;RedisConfig(重写序列化，@Bean创建RedisTemplate bean)-&gt;RedisUtil(封装对redis的操作，具体是用redistemplate来操作的)\n【Redis系列】RedisTemplate的使用与注意事项-CSDN博客\n为什么重写redistemplate?\n\n这里不重新他的一个序列化会造成一个乱码的问题，重写了RedisTemplate:\nobjectMapper-&gt;Jackson2jsonRedisSerializer-&gt;redisTemplate，注意@Bean注解返回重写RedisTemplate的方法\n\n\n\n[RedisTemplate 概述 与 操作 Redis 5 种数据类型、事务-CSDN博客](https://blog.csdn.net/wangmx1993328/article/details/103253479?ops_request_misc=%7B%22request%5Fid%22%3A%22172225212216800178583631%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172225212216800178583631&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~baidu_landing_v2~default-2-103253479-null-null.142^v100^pc_search_result_base8&amp;utm_term=redis template&amp;spm&#x3D;1018.2226.3001.4187)\nSpring date-redis中RedisTemplate的Jackson序列化设置_redistemplate序列化时date带有类型信息-CSDN博客\n[Redis 基本命令—— 超详细操作演示！！！_redis 操作-CSDN博客](https://blog.csdn.net/weixin_43412762/article/details/133934585?ops_request_misc=%7B%22request%5Fid%22%3A%22172225344516800227425617%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172225344516800227425617&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-133934585-null-null.142^v100^pc_search_result_base8&amp;utm_term=redis 操作&amp;spm&#x3D;1018.2226.3001.4187)\n用户&#x2F;角色&#x2F;用户角色关联用户注册时密码的加密：satoken实现的md5+salt，Hash散列\n进行用户角色关联用到redis和数据库时，使用了@Transactional注解：Spring——事务注解@Transactional【建议收藏】-CSDN博客\n权限开发与角色权限关联模块AuthPermissionDao.xml\n\ntype, show：这些列名使用了反引号，因为 type 和 show 是 MySQL 的保留字。在 SQL 中，保留字是具有特定意义的关键字，如果用作列名或表名，需要用反引号括起来，以避免语法错误。\n\n&lt;!--新增所有列--&gt;&lt;insert id=&quot;insert&quot; keyProperty=&quot;id&quot; useGeneratedKeys=&quot;true&quot;&gt;    insert into auth_permission(name, parent_id, `type`, menu_url, status, `show`, icon, permission_key, created_by, created_time, update_by, update_time, is_deleted)    values (#&#123;name&#125;, #&#123;parentId&#125;, #&#123;type&#125;, #&#123;menuUrl&#125;, #&#123;status&#125;, #&#123;show&#125;, #&#123;icon&#125;, #&#123;permissionKey&#125;, #&#123;createdBy&#125;, #&#123;createdTime&#125;, #&#123;updateBy&#125;, #&#123;updateTime&#125;, #&#123;isDeleted&#125;)&lt;/insert&gt;\n\n数据与缓存一致性问题辩证两个情况\n1、直接和缓存做交互，完全信任缓存\n2、和缓存做交互，如果缓存没有，则去和数据库查\n\n根据以上的流程没有问题，但是当数据变更的时候，如何把缓存变到最新，使我们下面要讨论的问题。\n\n更新了数据库，再更新缓存\n假设数据库更新成功，缓存更新失败，在缓存失效和过期的时候，读取到的都是老数据缓存。\n\n更新缓存，更新数据库\n缓存更新成功了，数据库更新失败，是不是读取的缓存的都是错误的。\n\n\n以上两种，全都不推荐。\n\n先删除缓存，再更新数据库\n有一定的使用量。即使数据库更新失败。缓存也可以会刷。\n存在的问题是什么？\n高并发情况下！！\n比如说有两个线程，一个是 A 线程，一个是 B 线程。\nA 线程把数据删了，正在更新数据库，这个时候 B 线程来了，发现缓存没了，又查数据，又放入缓存。缓存里面存的就一直是老数据了。\n\n\n延迟双删：:star:\n\n**延时是确保 **修改数据库 -&gt; 清空缓存前，其他事务的更改缓存操作已经执行完。redis缓存为什么要延时双删-CSDN博客\n\n扩展思路\n\n消息队列补偿\n删除失败的缓存，作为消息打入 mq，mq 消费者进行监听，再次进行重试刷缓存。\n\ncanal\n监听数据库的变化，做一个公共服务，专门来对接缓存刷新。优点业务解耦，避免业务太多冗余代码复杂度。\n\n\n登录模块内网穿透：natapp\n全流程：扫码微信-&gt;微信发送消息到服务器，校验签名确保来自微信（get）-&gt;服务器再把消息进行包装， 通过前缀+验证码（一个随机数）作为redis key，fromUserName(openId)作为value存到redis，并把包含验证码的消息发送到微信-&gt;用户验证码（微信）,从redis拿到openId（即用户名）-&gt;用satoken用openId进行登录，然后利用satoken返回一个token，后续登录就会带上这个token\n用户上下文打通全局拦截器：实现GlobalFilter接口Spring Cloud Gateway–全局过滤器(GlobalFilter)–作用&#x2F;使用_gateway globalfilter-CSDN博客\nLoginfilter(实现Globalfilter接口，通过filter拿到token，解析出loginId，然后传到后面的过滤链中)\n-&gt;LoginInterceptor(实现HandlerInterceptor，检验loginId是否存在且非空，如果存在，将其保存到自定义的线程局部变量上下文LoginContextHolder中，通过InheritableThreadLocal来实现)\n[ThreadLocal、InheritableThreadLocal、TransmittableThreadLocal-CSDN博客](https://blog.csdn.net/weixin_37862824/article/details/121177025?ops_request_misc=%7B%22request%5Fid%22%3A%22172344566516800186560849%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172344566516800186560849&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-121177025-null-null.142^v100^pc_search_result_base8&amp;utm_term=ThreadLocal inheritablethreadlocal&amp;spm&#x3D;1018.2226.3001.4187)\n[史上最全ThreadLocal 详解（一）-CSDN博客](https://blog.csdn.net/u010445301/article/details/111322569?ops_request_misc=%7B%22request%5Fid%22%3A%22172344571016800184113290%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172344571016800184113290&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-111322569-null-null.142^v100^pc_search_result_base8&amp;utm_term=ThreadLocal &amp;spm&#x3D;1018.2226.3001.4187)\nInheritableThreadLocal详解-CSDN博客\n跨微服务调用springMVC中拦截器执行时机和执行顺序分析_拦截器在什么时候执行-CSDN博客\n[SpringBoot常用拦截器（HandlerInterceptor，ClientHttpRequestInterceptor，RequestInterceptor）_springboot handlerinterceptor-CSDN博客](https://blog.csdn.net/weixin_41979002/article/details/124778961?ops_request_misc=%7B%22request%5Fid%22%3A%22172346204716800226593841%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172346204716800226593841&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-124778961-null-null.142^v100^pc_search_result_base8&amp;utm_term=HandlerInterceptor RequestInterceptor&amp;spm&#x3D;1018.2226.3001.4187)\n拦截器（HandlerInterceptor）-CSDN博客\n本地缓存caffiene &amp;&amp; guava\nCaffeine与Guava对比_caffeine guava 对比-CSDN博客\n全文检索ES:\n全称 elasticsearch。\n隶属于 elsastic stack。官网地址：https://www.elastic.co/cn/\n其中包含我们的 elasticsearch（存储、计算、搜索数据），kibana(数据可视化)，beats（数据抓取），logstash（数据抓取）。（ELK）。\nes 主要是对数据进行搜索，分析，倒排。他是一个开源的高扩展的分布式全文搜索引擎。近实时的搜索。扩展性高。处理 PB 级别的数据。\n为什么不用 mysql 做呢？\nes 的特点：\n1、搜索的数据对象大量的非结构化的文本\n2、倒排索引\n3、每个字段都可以被索引和搜索\n4、近实时分析，还可以做聚合，支持各种查询\nELasticsearch基本使用——基础篇_elasticsearch使用-CSDN博客\nElasticSearch从入门到精通，史上最全（持续更新，未完待续，每天一点点）_elasticsearch从入门到精通,史上最全-CSDN博客\nes与常规结构化数据数据库概念对照：\nindex-&gt;database\ntype-&gt;table\ndocument-&gt;row\nField-&gt;column\n[通过HTTP的方式操作ES-CSDN博客](https://blog.csdn.net/sss294438204/article/details/122884953?ops_request_misc=%7B%22request%5Fid%22%3A%22172355571716800211536069%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172355571716800211536069&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-122884953-null-null.142^v100^pc_search_result_base8&amp;utm_term=es http&amp;spm&#x3D;1018.2226.3001.4187)\nES集群客户端：hashmap+RestHighLevelClient，key为集群名，value为RestHighLevelClient，配置项-&gt;解析成HttpHost的list-&gt;通过HttpHost去创建RestHighLevelClient。根据RestHighLevelClient底层的API去使用。\nelasticsearch学习（七）：es客户端RestHighLevelClient-CSDN博客\n执行Elasticsearch搜索，支持复杂的查询条件、字段选择:ES构建queryBuilder条件查询_es querybuilder-CSDN博客\nJava中使用es条件构造器BoolQueryBuilder-CSDN博客 java中： 1. 构造请求的Builder（SearchSourceBuilder和BoolQueryBuilder）2. 给BoolQueryBuilder设置查询条件（MatchQueryBuilder，must&#x2F;should，minimumShouldMatch） 3. 将BoolQueryBuilder对象设置到SearchSourceBuilder对象中 4. 封装到SearchRequest中：searchRequest.source(searchSourceBuilder);5.  RestHighLevelClient利用SearchRequest进行查询\nJava学习笔记____ElasticSearch进阶(一)_searchhits-CSDN博客\n这个可以：ElasticSearch知识汇总 - 赟麟 - 博客园 (cnblogs.com)\nMybatis全文拦截器（createTime字段等）注意Field类\n[getsuperclass_Java类类getSuperClass（）方法及示例-CSDN博客](https://blog.csdn.net/cumt30111/article/details/107766525?ops_request_misc=%7B%22request%5Fid%22%3A%22172388481816800186530090%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&amp;request_id=172388481816800186530090&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-1-107766525-null-null.142^v100^pc_search_result_base8&amp;utm_term=Java 类 getSuperclass&amp;spm&#x3D;1018.2226.3001.4187)\n通过class获取到类，然后获取类的所有Fields：while循环调用getSuperClass去把所有的类的超类以及超类的超类给拿到fields。\n根据字段名称，进行对应的设置和sql操作\n排行榜常规mysql实现直接select语句实现就行\n通过redis的zset进行排列redis——Zset有序集合之reverseRangeWithScore函数使用_reverserangewithscores-CSDN博客\nxxljobXXL-JOB：定时任务框架的实战应用与调度方式详解-CSDN博客\nxxl-job学习笔记 | Roger-Lv’s space\n","categories":["后端"],"tags":["Java","后端","微服务"]},{"title":"Linux系统中卸载anaconda","url":"/2024/07/19/2024-07-19-Linux%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%8D%B8%E8%BD%BDanaconda/","content":"Linux系统中卸载anaconda要在Linux系统中卸载Anaconda，你需要执行一系列的命令。这里是一个通用的步骤指南：\n\n找到Anaconda安装脚本：在安装Anaconda时，它会在你的主目录中创建一个名为anaconda3的文件夹（默认情况下，如果你在安装时选择了不同的名称或位置，请确保使用正确的路径）。\n\n运行Anaconda卸载程序：Anaconda提供了一个卸载程序anaconda-clean，可以帮助你删除Anaconda的配置文件。在终端中运行以下命令：\nconda install anaconda-cleananaconda-clean --yes\n\n这个命令将删除Anaconda的配置文件，并且可以选择创建一个备份。使用–yes选项可以避免在删除每个项目时都要求确认。\n\n删除Anaconda安装目录：接下来，你需要手动删除Anaconda的安装目录。如果你的安装目录是默认的~&#x2F;anaconda3，你可以使用以下命令：\nrm -rf ~/anaconda3\n\n如果你的安装目录不是默认的，请确保使用正确的路径。\n\n编辑.bashrc或其他启动脚本：Anaconda安装过程中会在~&#x2F;.bashrc文件中添加初始化代码。你需要手动编辑这个文件并删除与Anaconda相关的行。你可以使用nano、vim或你喜欢的任何文本编辑器来做这件事。例如，如果你使用nano：\nnano ~/.bashrc\n\n然后找到并删除以下行（或类似内容）：\n# added by Anaconda3 installerexport PATH=&quot;/home/username/anaconda3/bin:$PATH&quot;\n\n保存并关闭文件。为了让这些更改生效，你需要重新加载.bashrc文件或重启你的终端：\nsource ~/.bashrc\n\n或者，如果你在图形界面中，你可以简单地关闭并重新打开你的终端窗口。\n\n检查并删除任何剩余的Anaconda文件：为了确保所有与Anaconda相关的文件都被删除，你可以使用find命令来搜索它们：\nfind ~ -type d -name &#x27;*anaconda*&#x27; -or -name &#x27;*conda*&#x27; -or -name &#x27;*miniconda*&#x27;\n\n然后你可以手动删除找到的任何相关目录。\n\n检查并更新环境变量：如果你在其他地方（如.profile或.bash_profile）添加了Anaconda到你的PATH环境变量，你需要更新这些文件并删除相关的行。\n\n\n按照这些步骤操作后，Anaconda应该已经从你的Linux系统中完全卸载。请记得在执行删除操作时要小心，确保不要错误地删除非Anaconda相关的文件或目录。\n","categories":["博客"],"tags":["Linux","anaconda"]},{"title":"SpringBoot Transactional和@Transaction","url":"/2024/07/31/2024-07-31-SpringBoot-Transactional%E5%92%8C@Transaction/","content":"SpringBoot Transactional和@TransactionTransactionTemplate 和 @Transactional 都是Spring框架提供用于事务管理的工具，但它们在使用方式和适用场景上存在一些区别：\n\n使用方式：\n\nTransactionTemplate 是一个Spring模板类，它提供了一种编程式事务管理的方法。使用 TransactionTemplate 时，你需要显式地编写代码来控制事务的开始、提交和回滚。\n@Transactional 是一个注解，它提供了声明式事务管理的方式。通过在方法或类上添加 @Transactional 注解，Spring 容器会在方法执行前后自动处理事务的开始和提交。如果方法执行过程中抛出异常，默认情况下事务将回滚。\n\n\n适用场景：\n\nTransactionTemplate 更适合于那些需要更细粒度控制事务的场景，例如，你可能需要在事务的某个阶段执行一些特定的操作，或者需要在事务中嵌套使用不同的事务管理器。\n@Transactional 更适合于大多数简单的用例，其中事务的边界清晰，并且不需要编程式的事务控制。\n\n\n侵入性：\n\n使用 TransactionTemplate 时，事务管理代码与业务逻辑代码混合在一起，可能会增加业务代码的复杂性。\n@Transactional 作为注解，与业务逻辑分离，保持了代码的清晰和解耦。\n\n\n可重用性：\n\nTransactionTemplate 可以实例化并在多个地方重用，为不同的业务逻辑提供事务管理。\n@Transactional 一旦定义，就可以很容易地应用到多个方法或整个类上，提高了代码的复用性。\n\n\n配置复杂性：\n\nTransactionTemplate 需要更多的配置和编码工作来设置事务参数，如隔离级别、传播行为等。\n@Transactional 可以通过简单的属性配置实现复杂的事务设置，如 propagation, isolation, timeout 等。\n\n\n错误处理：\n\n使用 TransactionTemplate 时，开发者需要自己管理事务的异常和错误处理。\n@Transactional 允许开发者通过注解的 rollbackFor 和 noRollbackFor 属性来指定哪些异常类型会触发事务回滚。\n\n\n与Spring的集成：\n\nTransactionTemplate 作为Spring框架的一部分，需要与Spring的ApplicationContext紧密集成。\n@Transactional 与Spring的AOP（面向切面编程）集成，利用代理机制来实现事务管理。\n\n\n\n总结来说，TransactionTemplate 提供了更细粒度的控制和灵活性，适合复杂的事务场景，而 @Transactional 提供了一种更简单、更声明式的方法来管理事务，适合大多数标准用例。在实际开发中，选择哪一种取决于具体需求和偏好。\n","categories":["后端"],"tags":["Java","SpringBoot","事务"]},{"title":"后端微服务-programmer-club项目的设计与实现","url":"/2024/07/10/2024-07-10-%E7%A8%8B%E5%BA%8F%E5%91%98%E7%A4%BE%E5%8C%BA%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/","content":"程序员社区项目\n开发模式前后端分离，后端负责所有的设计、接口的定义，后端先行，前端协同，通过接口文档，采用apifox的文档进行对接。\n敏捷开发，版本上线迭代，需求分析-&gt;功能设计-&gt;详细设计-&gt;编码实现。\n开发工具后端：IDEA\n前端：VSCode\n项目管理：giteazycode\n包依赖管理：Maven3.6.0\n数据库：Mysql5.7\n数据库连接池和监控库：Druid\n框架：Springboot 2.4.2\n数据库图形化：Navicat\n接口管理工具：APIPost7\nRedis桌面工具：RedisDesktop\n表建模：PDManager\n原型设计：axure8\n原型组件库: antdesign\n代码生成器：easycode（idea的plugin市场）\n一些插件：mybatis（类-&gt;dao-&gt;数据库），easycode（由数据库表生成相应代码）, preconditions（参数校验）\nnode.js\n架构设计传统项目[SpringMVC框架（详解）-CSDN博客](https://blog.csdn.net/H20031011/article/details/131511482?ops_request_misc=%7B%22request%5Fid%22%3A%22172145077916800222810035%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172145077916800222810035&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-131511482-null-null.142^v100^pc_search_result_base8&amp;utm_term=spring mvc架构&amp;spm&#x3D;1018.2226.3001.4187)\n一般的mvc：model，view，controller\nSpringMVC：controller(view+controller)，service（业务逻辑），dao（数据库）\n\n\n现有的架构DDD架构-CSDN博客\n[浅谈架构设计：MVC架构与DDD架构【开发实践】_ddd架构和mvc架构区别-CSDN博客](https://blog.csdn.net/qq_40656637/article/details/137344153?ops_request_misc=%7B%22request%5Fid%22%3A%22172145093416800184184571%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&amp;request_id=172145093416800184184571&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-1-137344153-null-null.142^v100^pc_search_result_base8&amp;utm_term=spring mvc架构和ddd架构&amp;spm&#x3D;1018.2226.3001.4187)\nddd 架构\n\n\n用户接口层（User Interface ）：负责向用户显示信息和解释用户指令（是DDD架构中的表现层）（表现层是视图层的超集，概念有所区别，知道最上层就是表现层即可）\n\n应用层（Application）：很“薄”的一层，理论上不应该有业务规则或逻辑，主要面向用例和流程相关的操作。在应用层协调多个服务和领域对象完成服务的组合和编排，协作完成业务操作。此外，应用层也是微服务之间交互的通道，它可以调用其它微服务的应用服务，完成微服务之间服务的组合和编排\n\n领域层（Domain）：是实现企业核心业务逻辑，通过各种校验手段保证业务的正确性。领域层主要体现领域模型的业务能力，它用来表达业务概念、业务状态和业务规则。领域层包含聚合根、实体、值对象、领域服务等领域模型中的领域对象\n\n基础层（Infrastructure）：贯穿所有层，为其它层提供通用的技术和基础服务，包括第三方工具、驱动、消息中间件、网关、文件、缓存以及数据库等\n\n个人理解：将service层拆分为了应用层和领域层。其中应用层关注于用例和流程，不涉及业务规则或逻辑，通过组合和编排下层的领域层来完成业务操作。而领域层用于封装具体的业务规则或逻辑，拆分出来的领域层不再和具体流程关联，实现了高内聚和低耦合，还提高了领域层的可复用性。用户接口层和基础层则为原来的视图层和dao层的扩展，新增了部分职责功能。\n\n\n例子：\n\n电子商务领域：\n实体：用户、产品、订单、支付记录。\n聚合：购物车、订单详情。\n领域服务：订单处理、库存管理、用户认证。\n\n\n交通物流领域：\n实体：司机、车辆、货物、运输任务。\n聚合：运输订单、车队管理。\n领域服务：路径规划、货物追踪、调度优化。\n\n\n\n\n\nAPI（对外接口层）：这一层负责定义对外提供的服务接口，通常用于与客户端或其他服务进行交互。\n\nController：在传统的MVC架构中，控制器用于处理用户的请求。在这里，它用于接收API层的请求，并将请求转换为应用层可以理解的格式。\n\nDTO（Data Transfer Object）：\n代表数据传输对象的意思\n是一种设计模式之间传输数据的软件应用系统，数据传输目标往往是数据访问对象从数据库中检索数据\n数据传输对象与数据交互对象或数据访问对象之间的差异是一个以不具任何行为除了存储和检索的数据（访问和存取器）\n简而言之，就是接口之间传递的数据封装\n表里面有十几个字段：id，name，gender（M&#x2F;F)，age……\n页面需要展示三个字段：name，gender(男&#x2F;女)，age\nDTO由此产生，一是能提高数据传输的速度(减少了传输字段)，二能隐藏后端表结构。\n\nBO（Business Object）：\n代表业务对象的意思，Bo就是把业务逻辑封装为一个对象（注意是逻辑，业务逻辑），这个对象可以包括一个或多个其它的对象。通过调用Dao方法，结合Po或Vo进行业务操作。\n形象描述为一个对象的形为和动作，当然也有涉及到基它对象的一些形为和动作。比如处理一个人的业务逻辑，该人会睡觉，吃饭，工作，上班等等行为，还有可能和别人发关系的行为，处理这样的业务逻辑时，我们就可以针对BO去处理。\n再比如投保人是一个PO，被保险人是一个PO，险种信息也是一个PO等等，他们组合起来就是一张保单的BO。\n\nPO&#x2F;DO: Persistent Object &#x2F; Data Object，持久对象 &#x2F; 数据对象。\n它跟持久层（通常是关系型数据库）的数据结构形成一一对应的映射关系，如果持久层是关系型数据库，那么，数据表中的每个字段（或若干个）就对应PO的一个（或若干个）属性。\n\nVO: View Object, 视图模型，展示层对象:\n对应页面显示（web页面&#x2F;移动端H5&#x2F;Native视图）的数据对象。\n\nApplication层（应用层）：这一层包含应用服务，它们协调领域对象来完成业务逻辑。它还包含一些业务逻辑的转换逻辑，如DTO到BO的转换。\n\nInterceptor：拦截器，用于在请求处理过程中进行一些前置或后置处理，例如日志记录、权限验证等。\n\nApplication-MQ（消费者）&#x2F; Application-Job：这指的是应用层中处理消息队列消息的组件，或者定时任务的处理。\n\nDomain层（领域层）：这是DDD中的核心层，包含业务逻辑和领域模型。领域层专注于业务规则和业务实体。\n\nService：领域服务，执行领域逻辑但不自然属于任何实体或值对象的操作。\n\nEntity&#x2F;PO（Persistent Object）：持久化对象，通常与数据库存储相关，代表数据库中的记录。\n\nMapper：数据访问对象，用于将领域对象映射到数据库表。\n\nInfra层（基础设施层）：提供技术实现，如数据库访问、消息传递、外部服务调用等。\n\nRPC：远程过程调用，用于服务之间的通信。\n\nMG（生产者）：指的是消息生成者，负责生成并发送消息到消息队列。\n\nStarter（启动层）：指的是服务启动时需要自动执行的代码或配置。\n\nAggressive（聚合层）：聚合层，将多个领域对象聚合成一个更大的业务实体。\n\nConfig：配置层，用于存储和访问配置信息。\n\nDict（字典）：指的是数据字典，用于存储一些固定的数据或映射关系。\n\nCommon（公共层）：包含整个应用中多个地方会用到的通用代码或工具。\n\nEnums：枚举，用于定义一组命名的常量。\n\nUtils：工具类，提供一些通用的辅助功能。\n\n\nreq-&gt;dto-&gt;do-&gt;bo-&gt;entity-&gt;po\n\n项目结构\n后端项目目录（backend）\nasyncTool: 包含异步处理工具或库，用于处理异步任务。\ndoc: 存放项目文档，如API文档、技术规范等。\njc-club-auth: 认证服务，负责用户认证和授权。\njc-club-circle: 可能与社区圈子或用户组相关功能。\njc-club-common-starter: 通用启动器或工具类，提供项目通用功能。\njc-club-gateway: 网关服务，负责请求路由、负载均衡等。\njc-club-gen: 代码生成工具，可能用于快速生成项目代码。\njc-club-interview: 面试相关功能，可能包含面试题库或模拟面试。\njc-club-oss: 对象存储服务，用于管理文件存储。\njc-club-practice: 实践项目或示例代码。\njc-club-subject: 主题或课程相关功能，可能用于教育或培训。\njc-club-wx: 微信相关功能，可能包含微信公众号接口或小程序支持。\n\n技术选型[Spring和Spring Boot之间的区别（小结）_spring和springboot的区别-CSDN博客](https://blog.csdn.net/mengxin_chen/article/details/116240326?ops_request_misc=%7B%22request%5Fid%22%3A%22172145220016800227442776%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172145220016800227442776&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-116240326-null-null.142^v100^pc_search_result_base8&amp;utm_term=spring和spring boot区别&amp;spm&#x3D;1018.2226.3001.4187)\n\n服务器中间件服务器采用的京东云 centos\nDocker安装yum install -y yum-utils device-mapper-persistent-data lvm2yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repoyum install docker-ce docker-ce-cli containerd.io -y systemctl start dockersystemctl enable dockerdocker version docker images\n\nDocker安装mysqldocker pull mysql:5.7 docker images mkdir -p /home/service/mysql/data mkdir -p /home/service/mysql/confcd /home/service/mysql/conftouch my.cnf\n\n将以下内容粘入:\n[mysqld]user=mysqlcharacter-set-server=utf8default_authentication_plugin=mysql_native_passworddefault-time_zone = &#x27;+8:00&#x27;[client]default-character-set=utf8[mysql]default-character-set=utf8\n\ndocker run -p 3306:3306 --name mysql -v /home/service/mysql/logs:/logs -v /home/service/mysql/data:/mysql_data -e MYSQL_ROOT_PASSWORD=Wing1Q2W#E -d mysql:5.7docker exec -it mysql bash mysql -uroot -p CREATE USER &#x27;admin&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;Wing1Q2W#E&#x27;;GRANT ALL ON *.* TO &#x27;admin&#x27;@&#x27;%&#x27;; flush privileges; \n\ndocker ps 查看启动状态。\nnavicat直接连接即可，云服务器需要开启防火墙。\nMaven配置国内源maven一定要放到Jenkins的数据挂载目录内，这样容器才能读到。参考开发工具选型里面的maaven包。\n在maven的conf的setting的mirrors里面进行配置，配置后，Jenkins下载包会非常的快。\n\n    alimaven\n    aliyun maven\n    http://maven.aliyun.com/nexus/content/groups/public/\n    central\n\n\nDocker安装Jenkins机器上要有 jdk，服务器可以执行如下命令安装\nyum install -y java-1.8.0-openjdk.x86_64\n\njenkins开始\ndocker search jenkinsdocker pull jenkins/jenkins:2.414.2docker run -d -u root -p 8080:8080 -p 50000:50000 -v /var/jenkins_home:/var/jenkins_home -v /etc/localtime:/etc/localtime --name jenkins jenkins/jenkins:2.414.2docker start jenkins\n\n\n这样就是启动成功了。然后通过8080端口进行访问。访问的过程会很慢等待一下。服务器内存最好大点，内存小的容易启动不起来。\n通过log来看一下密码:\ndocker logs 67166b666c76\n\n\n访问之后，输入上面的密码。\n点击继续后，选择 按照推荐安装插件。然后继续等待。\n\n界面如下：\n\n新建任务\n上面输入任务名称，下面选择构建自由风格\n\n选择源码管理，配置maven，注意：maven一定要放到Jenkins的数据挂载目录内，这样容器才能读到。\n\n配置ssh服务器\n\n\n设置密码即可。\n配置ssh分发\n\n配置shell脚本\ncp /var/jenkins_home/workspace/programmer-club-subject/programmer-club-subject/programmer-club-starter/target/programmer-club-starter.jar /var/jenkins_home/jar/#!/bin/bashAPP_NAME=programmer-club-starter.jarLOG_NAME=programmer-club-starter.logpid=`ps -ef | grep $APP_NAME | grep -v grep|awk &#x27;&#123;print $2&#125;&#x27;`function is_exist()&#123;pid=`ps -ef | grep $APP_NAME | grep -v grep|awk &#x27;&#123;print $2&#125;&#x27;`if [ -z $&#123;pid&#125; ]; thenString=&quot;notExist&quot;echo $StringelseString=&quot;exist&quot;echo $Stringfi&#125;str=$(is_exist)if [ $&#123;str&#125; = &quot;exist&quot; ]; thenecho &quot; 检测到已经启动的程序，pid 是 $&#123;pid&#125; &quot;kill -9 $pidelseecho &quot; 程序没有启动了 &quot;echo &quot;$&#123;APP_NAME&#125; is not running&quot;fistr=$(is_exist)if [ $&#123;str&#125; = &quot;exist&quot; ]; thenecho &quot;$&#123;APP_NAME&#125; 已经启动了. pid=$&#123;pid&#125; .&quot;elsesource /etc/profileBUILD_ID=dontKillMenohup java -Xms300m -Xmx300m -jar /var/jenkins_home/jar/$APP_NAME   &gt;$LOG_NAME 2&gt;&amp;1 &amp;echo &quot;程序已重新启动...&quot;fi\n\nyum安装JDKyum install -y java-1.8.0-openjdk.x86_64\n\nDocker安装minio，搭建自己的oss服务器docker search minio\n\n\ndocker pull minio/miniodocker run -p 9000:9000 -p 9090:9090 \\ --name minio \\ -d --restart=always \\ -e &quot;MINIO_ACCESS_KEY=minioadmin&quot; \\ -e &quot;MINIO_SECRET_KEY=minioadmin&quot; \\ -v /mydata/minio/data:/data \\ minio/minio server \\ /data --console-address &quot;:9090&quot; -address &quot;:9000&quot;\n\n启动后，访问机器ip+9090，进入minio的界面，输入用户名或密码后可以访问。\n\nDocker安装miniomc突破7天限制docker pull minio/mcdocker run -it --entrypoint=/bin/sh minio/mcmc config host add &lt;ALIAS&gt; &lt;YOUR-S3-ENDPOINT&gt; &lt;YOUR-ACCESS-KEY&gt; &lt;YOUR-SECRET-KEY&gt; [--api API-SIGNATURE]mc config host add minio http://xxx.xx.xx.xxx:9000 GrVCPXySKgGoJiGgXmtv 0xlqSI9GXvnBOtp0GwUj5OshKNBk9JgwoexotbVVmc ls miniomc anonymousmc anonymous set download minio/jichi\n\nDocker查看运行容器启动命令安装一个小工具 get_command_4_run_container\ndocker pull cucker/get_command_4_run_container# 以nacos为例子docker run --rm -v /var/run/docker.sock:/var/run/docker.sock cucker/get_command_4_run_container nacos\n\n看到如下的启动命令\ndocker run -d \\ --name nacos \\ --privileged \\ --cgroupns host \\ --env JVM_XMX=256m \\ --env MODE=standalone \\ --env JVM_XMS=256m \\ -p 8848:8848/tcp \\ -p 9848:9848/tcp \\ --restart=always \\ -w /home/nacos \\ nacos/nacos-server\n\nDocker安装nacosdocker search nacosdocker pull nacos/nacos-server\n\n镜像拉完之后，启动脚本\ndocker run -d \\  --name nacos \\  --privileged  \\  --cgroupns host \\  --env JVM_XMX=256m \\ --env MODE=standalone \\  --env JVM_XMS=256m \\  -p 8848:8848/tcp \\  -p 9848:9848/tcp \\  --restart=always \\  -w /home/nacos \\  nacos/nacos-server\n\n云服务器不要忘记打开防火墙端口。\n访问 ip 地址+8848 &#x2F;nacos 即可进入控制台\n\nnacos 的文档：https://nacos.io/zh-cn/docs/what-is-nacos.html\nnacos 的架构原理：https://developer.aliyun.com/ebook/36?spm=a2c6h.20345107.ebook-index.18.152c2984fsi5ST\nDocker安装Redisdocker search redisdocker pull redis\n\n拉下镜像之后，点击下面地址选择自己需要的 redis 版本的配置文件\nhttps://redis.io/docs/management/config/\n\n提前在服务器建立 &#x2F;data&#x2F;redis 文件夹，touch 文件redis.conf，也可以上面的直接复制\nredis.conf\nprotected-mode yesport 6379tcp-backlog 511timeout 0tcp-keepalive 300daemonize nopidfile /var/run/redis_6379.pidloglevel noticelogfile &quot;&quot;databases 16always-show-logo noset-proc-title yesproc-title-template &quot;&#123;title&#125; &#123;listen-addr&#125; &#123;server-mode&#125;&quot;locale-collate &quot;&quot;...\n\n\n\n启动命令docker run -p 6379:6379 --name redis -v /data/redis/redis.conf:/etc/redis/redis.conf  -v /data/redis/data:/data -d redis redis-server /etc/redis/redis.conf --appendonly yes\n\n-p 6379:6379:把容器内的6379端口映射到宿主机6379端口 \n-v &#x2F;data&#x2F;redis&#x2F;redis.conf:&#x2F;etc&#x2F;redis&#x2F;redis.conf：把宿主机配置好的redis.conf放到容器内的这个位置中 \n-v &#x2F;data&#x2F;redis&#x2F;data:&#x2F;data：把redis持久化的数据在宿主机内显示，做数据备份\nredis-server &#x2F;etc&#x2F;redis&#x2F;redis.conf：这个是关键配置，让redis不是无配置启动，而是按照这个redis.conf的配置启动 \n–appendonly yes：redis启动后数据持久化\n工具：Redis Desktop Manager\nIDEA连接redis可以直接下载 plugin 的 redis 插件\nDocker安装esyum install -y yum-utils device-mapper-persistent-data lvm2docker search elasticsearchdocker pull elasticsearch:7.3.1docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot;  -e ES_JAVA_OPTS=&quot;-Xms1024m -Xmx1024m&quot; 3d3aa92f641f\n\n启动成功之后，访问http://xxx.xx.xx.xxx:9200/\n\n看到这个就证明成功了！\n插件：es-head\ndocker安装xxl-jobdocker search xxl-jobdocker pull xuxueli/xxl-job-admin:2.4.0docker run  -d \\        -p 8088:8088\\        -v /tool/xxl-job/logs:/data/applogs \\        -v /tool/xxl-job/application.properties:/xxl-job/xxl-job-admin/src/main/resources/application.properties \\        -e PARAMS=&quot;--server.port=8088\\        --spring.datasource.url=jdbc:mysql://xxx.xx.xx.xxx:3306/xxl_job?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;serverTimezone=Asia/Shanghai \\        --spring.datasource.username=root \\        --spring.datasource.password=Wing1Q2W#E&quot; \\        --name xxl-job-admin  \\xuxueli/xxl-job-admin:2.4.0\n\nrocketmq安装官网地址：https://rocketmq.apache.org/\n安装包上传到 linux 的&#x2F;soft 文件夹，没有此文件夹，先创建，不过在 es 的时候已经创建过了。\n\nyum install unzip  可以解压zip包的依赖unzip rocketmq-all-4.8.0-bin-release.zipcd rocketmq-all-4.8.0-bin-releasecd binvim runserver.sh将其中的xmx，xms等进行修改256m，弄小一点，让服务器用vim runbroker.sh同理修改其中的xmx，xms等进行修改256m，弄小一点，让服务器用nohup sh mqnamesrv &amp;tail -f ~/logs/rocketmqlogs/namesrv.log\n\n启动broker\nexport NAMESRV_ADDR=localhost:9876nohup sh mqbroker -n localhost:9876 &amp;tail -f ~/logs/rocketmqlogs/broker.log\n\n发送消息\nsh tools.sh org.apache.rocketmq.example.quickstart.Producersh tools.sh org.apache.rocketmq.example.quickstart.Consumer\n\n如果发送消息报错，建立文件夹\ncd ~/storemkdir commitlog cd commitlogmkdir consumequeue\n\n关闭\nsh bin/mqshutdown brokersh bin/mqshutdown namesrv\n\n安装控制台\n\n更改端口和配置文件。\nnohup java -Xms300m -Xmx300m -jar rocketmq-console.jar &gt; console.log &amp;\n\n\n第一部分数据库表数据库表建模JSON刷题模块\n\nSQL\nDROP TABLE IF EXISTS `subject_radio`;CREATE TABLE `subject_radio`(    `id`             bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#x27;主键&#x27;,    `subject_id`     bigint(20) DEFAULT NULL COMMENT &#x27;题目id&#x27;,    `option_type`    tinyint(4) DEFAULT NULL COMMENT &#x27;a,b,c,d&#x27;,    `option_content` varchar(128) DEFAULT NULL COMMENT &#x27;选项内容&#x27;,    `is_correct`     tinyint(2) DEFAULT NULL COMMENT &#x27;是否正确&#x27;,    `created_by`     varchar(32)  DEFAULT NULL COMMENT &#x27;创建人&#x27;,    `created_time`   datetime     DEFAULT NULL COMMENT &#x27;创建时间&#x27;,    `update_by`      varchar(32)  DEFAULT NULL COMMENT &#x27;修改人&#x27;,    `update_time`    datetime     DEFAULT NULL COMMENT &#x27;修改时间&#x27;,    `is_deleted`     int(11) DEFAULT &#x27;0&#x27;,    PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&#x27;单选题信息表&#x27;;DROP TABLE IF EXISTS `subject_multiple`;CREATE TABLE `subject_multiple`(    `id`             bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#x27;主键&#x27;,    `subject_id`     bigint(20) DEFAULT NULL COMMENT &#x27;题目id&#x27;,    `option_type`    bigint(4) DEFAULT NULL COMMENT &#x27;选项类型&#x27;,    `option_content` varchar(64) DEFAULT NULL COMMENT &#x27;选项内容&#x27;,    `is_correct`     tinyint(2) DEFAULT NULL COMMENT &#x27;是否正确&#x27;,    `created_by`     varchar(32) DEFAULT NULL COMMENT &#x27;创建人&#x27;,    `created_time`   datetime    DEFAULT NULL COMMENT &#x27;创建时间&#x27;,    `update_by`      varchar(32) DEFAULT NULL COMMENT &#x27;更新人&#x27;,    `update_time`    datetime    DEFAULT NULL COMMENT &#x27;更新时间&#x27;,    `is_deleted`     int(11) DEFAULT &#x27;0&#x27;,    PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&#x27;多选题信息表&#x27;;DROP TABLE IF EXISTS `subject_mapping`;CREATE TABLE `subject_mapping`(    `id`           bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#x27;主键&#x27;,    `subject_id`   bigint(20) DEFAULT NULL COMMENT &#x27;题目id&#x27;,    `category_id`  bigint(20) DEFAULT NULL COMMENT &#x27;分类id&#x27;,    `label_id`     bigint(20) DEFAULT NULL COMMENT &#x27;标签id&#x27;,    `created_by`   varchar(32) DEFAULT NULL COMMENT &#x27;创建人&#x27;,    `created_time` datetime    DEFAULT NULL COMMENT &#x27;创建时间&#x27;,    `update_by`    varchar(32) DEFAULT NULL COMMENT &#x27;修改人&#x27;,    `update_time`  datetime    DEFAULT NULL COMMENT &#x27;修改时间&#x27;,    `is_deleted`   int(11) DEFAULT &#x27;0&#x27;,    PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=536 DEFAULT CHARSET=utf8 COMMENT=&#x27;题目分类关系表&#x27;;DROP TABLE IF EXISTS `subject_liked`;CREATE TABLE `subject_liked`(    `id`           bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#x27;主键&#x27;,    `subject_id`   bigint(20) DEFAULT NULL COMMENT &#x27;题目id&#x27;,    `like_user_id` varchar(32) COLLATE utf8mb4_bin DEFAULT NULL COMMENT &#x27;点赞人id&#x27;,    `status`       int(11) DEFAULT NULL COMMENT &#x27;点赞状态 1点赞 0不点赞&#x27;,    `created_by`   varchar(32) CHARACTER SET utf8  DEFAULT NULL COMMENT &#x27;创建人&#x27;,    `created_time` datetime                        DEFAULT NULL COMMENT &#x27;创建时间&#x27;,    `update_by`    varchar(32) CHARACTER SET utf8  DEFAULT NULL COMMENT &#x27;修改人&#x27;,    `update_time`  datetime                        DEFAULT NULL COMMENT &#x27;修改时间&#x27;,    `is_deleted`   int(11) DEFAULT &#x27;0&#x27;,    PRIMARY KEY (`id`),    UNIQUE KEY `uniq_like` (`subject_id`,`like_user_id`) USING BTREE COMMENT &#x27;点赞唯一索引&#x27;) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin COMMENT=&#x27;题目点赞表&#x27;;DROP TABLE IF EXISTS `subject_label`;CREATE TABLE `subject_label`(    `id`           bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#x27;主键&#x27;,    `label_name`   varchar(32) DEFAULT NULL COMMENT &#x27;标签分类&#x27;,    `sort_num`     int(11) DEFAULT NULL COMMENT &#x27;排序&#x27;,    `category_id`  varchar(50) DEFAULT NULL,    `created_by`   varchar(32) DEFAULT NULL COMMENT &#x27;创建人&#x27;,    `created_time` datetime    DEFAULT NULL COMMENT &#x27;创建时间&#x27;,    `update_by`    varchar(32) DEFAULT NULL COMMENT &#x27;更新人&#x27;,    `update_time`  datetime    DEFAULT NULL COMMENT &#x27;更新时间&#x27;,    `is_deleted`   int(11) DEFAULT &#x27;0&#x27;,    PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=64 DEFAULT CHARSET=utf8 COMMENT=&#x27;题目标签表&#x27;;DROP TABLE IF EXISTS `subject_judge`;CREATE TABLE `subject_judge`(    `id`           bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#x27;主键&#x27;,    `subject_id`   bigint(20) DEFAULT NULL COMMENT &#x27;题目id&#x27;,    `is_correct`   tinyint(2) DEFAULT NULL COMMENT &#x27;是否正确&#x27;,    `created_by`   varchar(32) DEFAULT NULL COMMENT &#x27;创建人&#x27;,    `created_time` datetime    DEFAULT NULL COMMENT &#x27;创建时间&#x27;,    `update_by`    varchar(32) DEFAULT NULL COMMENT &#x27;更新人&#x27;,    `update_time`  datetime    DEFAULT NULL COMMENT &#x27;更新时间&#x27;,    `is_deleted`   int(11) DEFAULT &#x27;0&#x27;,    PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&#x27;判断题&#x27;;DROP TABLE IF EXISTS `subject_info`;CREATE TABLE `subject_info`(    `id`                bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#x27;主键&#x27;,    `subject_name`      varchar(128) DEFAULT NULL COMMENT &#x27;题目名称&#x27;,    `subject_difficult` tinyint(4) DEFAULT NULL COMMENT &#x27;题目难度&#x27;,    `settle_name`       varchar(32)  DEFAULT NULL COMMENT &#x27;出题人名&#x27;,    `subject_type`      tinyint(4) DEFAULT NULL COMMENT &#x27;题目类型 1单选 2多选 3判断 4简答&#x27;,    `subject_score`     tinyint(4) DEFAULT NULL COMMENT &#x27;题目分数&#x27;,    `subject_parse`     varchar(512) DEFAULT NULL COMMENT &#x27;题目解析&#x27;,    `created_by`        varchar(32)  DEFAULT NULL COMMENT &#x27;创建人&#x27;,    `created_time`      datetime     DEFAULT NULL COMMENT &#x27;创建时间&#x27;,    `update_by`         varchar(32)  DEFAULT NULL COMMENT &#x27;修改人&#x27;,    `update_time`       datetime     DEFAULT NULL COMMENT &#x27;修改时间&#x27;,    `is_deleted`        int(11) DEFAULT &#x27;0&#x27;,    PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=327 DEFAULT CHARSET=utf8 COMMENT=&#x27;题目信息表&#x27;;DROP TABLE IF EXISTS `subject_category`;CREATE TABLE `subject_category`(    `id`            bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#x27;主键&#x27;,    `category_name` varchar(16) DEFAULT NULL COMMENT &#x27;分类名称&#x27;,    `category_type` tinyint(2) DEFAULT NULL COMMENT &#x27;分类类型&#x27;,    `image_url`     varchar(64) DEFAULT NULL COMMENT &#x27;图标连接&#x27;,    `parent_id`     bigint(20) DEFAULT NULL COMMENT &#x27;父级id&#x27;,    `created_by`    varchar(32) DEFAULT NULL COMMENT &#x27;创建人&#x27;,    `created_time`  datetime    DEFAULT NULL COMMENT &#x27;创建时间&#x27;,    `update_by`     varchar(32) DEFAULT NULL COMMENT &#x27;更新人&#x27;,    `update_time`   datetime    DEFAULT NULL COMMENT &#x27;更新时间&#x27;,    `is_deleted`    tinyint(1) DEFAULT &#x27;0&#x27; COMMENT &#x27;是否删除 0: 未删除 1: 已删除&#x27;,    PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=12 DEFAULT CHARSET=utf8 COMMENT=&#x27;题目分类&#x27;;DROP TABLE IF EXISTS `subject_brief`;CREATE TABLE `subject_brief`(    `id`             bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#x27;主键&#x27;,    `subject_id`     int(20) DEFAULT NULL COMMENT &#x27;题目id&#x27;,    `subject_answer` text COMMENT &#x27;题目答案&#x27;,    `created_by`     varchar(32) DEFAULT NULL COMMENT &#x27;创建人&#x27;,    `created_time`   datetime    DEFAULT NULL COMMENT &#x27;创建时间&#x27;,    `update_by`      varchar(32) DEFAULT NULL COMMENT &#x27;更新人&#x27;,    `update_time`    datetime    DEFAULT NULL COMMENT &#x27;更新时间&#x27;,    `is_deleted`     int(11) DEFAULT &#x27;0&#x27;,    PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=280 DEFAULT CHARSET=utf8 COMMENT=&#x27;简答题&#x27;;\n\n\n\n刷题模块数据模型\n\n鉴权模块\n1.刷题模块（微服务模块）\nstarter类是用于放置整个项目的启动类的\n产品功能模块\n研发功能模块拆分\n原型设计axrue+antdesign的组件库\n刷题首页\n题目详情\n分类模块\n分类的概念是面试题的大类。其中我们有两种概念：\n\n一种是岗位分类，例如后端，前端，测试。\n一种是岗位下细分的分类，比如后端下细分，框架，并发，集合等等。\n\n新增分类正常的业务逻辑，保证新增后，可以正常的插入数据库即可。\n修改分类crud\n删除分类crud\n首页的分类可以扩展做成做成缓存，不易变的数据，直接从redis查缓存。\n缓存预热这种，启动项目之后，扔进去。\n目前做成串行化的，二期可以优化，由前端先查询岗位大类，然后再根据大类查询小类。\n标签详细设计标签的概念是分类下的细分。标签是通用性的，独立的个体，与分类不进行强耦合，和题目相关。标签和分类是公用的，多个分类可以对应同一个标签。\n新增标签crud 直接看代码\n修改标签crud\n删除标签crud\n标签查询根据分类去查询标签，要通过题目信息的关联表来进行查询。详细看代码\n以上功能涉及到 subject_label 表\n\n题目模块\n题目分为单选，多选，判断，简单，四种数据类型，在设计数据的时候，拆分成了题目的主表和其他对应的表来做。\n新增题目注意：采取工厂+策略的模式去做扩展，现在有四种题型，未来无论加多少种，都可以不用动主流程。\n后期会结合es 做题目的查重。为搜索做准备。\n修改题目crud\n删除题目要注意删除主表的同时，也把其他的细分的数据表进行同步的处理。\n题目列表难度不大，就是个简单的分页的查询，分类、标签，难度这些其实都是入参的场景。\n查标签，难度啊，出题人啊，等等，这些就直接查，不做join。\n题目的详情也做一下工厂+策略吧\n此功能涉及如下数据表\n\n刷题模块代码的实现（jc-club-subject）application层的SubjectController（应用层初探&amp;SpringMVC集成）在jc-club-subject中的jc-club-application-controller中的controller模块下面建立SubjectController.java\npackage com.jingdianjichi.subject.application.controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * 刷题controller */@RestController@RequestMapping(&quot;/subject&quot;)public class SubjectController &#123;    @GetMapping(&quot;/test&quot;)    public String test()&#123;    \treturn &quot;hello world&quot;;    &#125; &#125;\n\n这里给出的测试代码如上。\n在jc-club-subject中的jc-club-starter包中有SubjectApplication.java作为启动类,并且需要修改pom.xml中的内容，让启动类能够访问到jc-club-application-controller中的代码内容。\n//jc-club-starter的pom.xml,在starter中关于启动的配置是写在resources中的application.yml文件中的，包裹数据库连接,redis等等&lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;            &lt;version&gt;2.4.2&lt;/version&gt;            &lt;exclusions&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;                    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;/exclusion&gt;            &lt;/exclusions&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;            &lt;artifactId&gt;jc-club-application-controller&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;&lt;/dependencies&gt;\n\n//SubjectApplication.java 启动类package com.jingdianjichi.subject;import org.mybatis.spring.annotation.MapperScan;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.openfeign.EnableFeignClients;import org.springframework.context.annotation.ComponentScan;/** * 刷题微服务启动类 * * @author: ChickenWing * @date: 2023/10/1 */@SpringBootApplication@ComponentScan(&quot;com.jingdianjichi&quot;)@MapperScan(&quot;com.jingdianjichi.**.mapper&quot;)@EnableFeignClients(basePackages = &quot;com.jingdianjichi&quot;)public class SubjectApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(SubjectApplication.class);    &#125;&#125;\n\n记得maven install\nmysql,druid,mybatis集成(infrastructure层)彻底搞懂MyBaits中#{}和${}的区别_mybatis #{}-CSDN博客\n在jc-club-subject中的jc-club-infra包中\n//pom.xml &lt;dependencies&gt;        &lt;!-- jdbcStarter --&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;            &lt;version&gt;2.4.2&lt;/version&gt;        &lt;/dependency&gt;        &lt;!-- druid连接池 --&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;            &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt;            &lt;version&gt;1.1.22&lt;/version&gt;        &lt;/dependency&gt;        &lt;!-- mysql --&gt;        &lt;dependency&gt;            &lt;groupId&gt;mysql&lt;/groupId&gt;            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;            &lt;version&gt;8.0.22&lt;/version&gt;        &lt;/dependency&gt;        &lt;!-- mybatisplus --&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.baomidou&lt;/groupId&gt;            &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;            &lt;version&gt;3.4.0&lt;/version&gt;        &lt;/dependency&gt;&lt;/dependencies&gt;\n\n做subject_category这个模块\n用IDEA自带是数据库工具去连上MySQL\n\n联上数据库后，右键category表，然后Eazycode，选择目录，放在jc-club-infra包下的basic目录中，template选择mapper.xml.vm, dao.java.vm, entity.java.vm, service.java.vm, serviceImpl.java.vm(下面两张图是项目结束后完整的截图，这里就涉及到了mybatis)\n\n\nhttps://blog.csdn.net/quest101/article/details/105624322?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172154711316800226546866%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=172154711316800226546866&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-1-105624322-null-null.142\n[mybatis-plus关于@Mapper、@Repository、@MapperScan、xml文件的相关问题_mybatisplus repository-CSDN博客](https://blog.csdn.net/qq_41428418/article/details/132575881?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=mapperscan resulttype&#x3D;&amp;utm_medium&#x3D;distribute.pc_search_result.none-task-blog-2allsobaiduweb~default-1-132575881.142^v100^pc_search_result_base8&amp;spm&#x3D;1018.2226.3001.4187)\n继续在jc-club-starter模块的pom.xml中引入当前的jc-club-infra模块\n//jc-club-starter的pom.xml&lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;            &lt;version&gt;2.4.2&lt;/version&gt;            &lt;exclusions&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;                    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;/exclusion&gt;            &lt;/exclusions&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;            &lt;artifactId&gt;jc-club-application-controller&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;    \t&lt;dependency&gt;            &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;            &lt;artifactId&gt;jc-club-infra&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;&lt;/dependencies&gt;\n\n在jc-club-subject中的jc-club-starter中的resources中的application.yml中，定义了服务器和数据源的配置：\nserver:  port:3000spring:  datasource:    username: root    password: 123456    driver-class-name: com.mysql.cj.jdbc.Driver    url: jdbc:mysql://localhost:3306/jc-club?serverTimezone=Asia/Shanghai&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=true    type: com.alibaba.druid.pool.DruidDataSource    druid:      initial-size: 20      min-idle: 20      max-active: 100      max-wait: 60000      stat-view-servlet:        enabled: true        url-pattern: /druid/*        login-username: admin        login-password: 123456      filter:        stat:          enabled: true          slow-sql-millis: 2000          log-slow-sql: true        wall:          enabled: true\n\n\nserver: 定义了服务器的配置。\n\nport: 指定了服务器运行的端口号，这里是 3000。\n\n\nspring: 包含了Spring框架的配置。\n\ndatasource: 定义了数据源的配置，用于数据库连接。\nusername: 数据库的用户名，这里是 root。\npassword: 数据库的密码，这里是 123456。\ndriver-class-name: MySQL数据库驱动的类名。\nurl: 数据库的连接URL，包括数据库地址、端口、数据库名以及一些连接参数。这里的URL表明连接到本地的MySQL服务器上的 jc-club 数据库，并且指定了时区、字符编码和SSL的使用。\ntype: 指定了数据源的类型，这里使用的是阿里巴巴的Druid连接池。\ndruid: Druid连接池的特定配置。\ninitial-size: 连接池的初始大小，这里是 20。\nmin-idle: 连接池中最小的空闲连接数，这里是 20。\nmax-active: 连接池中最大的活动连接数，这里是 100。\nmax-wait: 连接池中获取连接的最大等待时间（毫秒），这里是 60000 毫秒（即60秒）。\nstat-view-servlet: 用于Druid的监控页面。\nenabled: 是否启用监控页面，这里是 true。\nurl-pattern: 监控页面的URL模式。\nlogin-username: 监控页面的登录用户名。\nlogin-password: 监控页面的登录密码。\n\n\nfilter: 定义了Druid的过滤器配置。\nstat: 用于统计的过滤器。\nenabled: 是否启用统计过滤器，这里是 true。\nslow-sql-millis: 执行时间超过多少毫秒的SQL被认为是慢查询，这里是 2000 毫秒。\nlog-slow-sql: 是否记录慢查询的日志，这里是 true。\n\n\nwall: 用于防火墙的过滤器，用于防止SQL注入。\nenabled: 是否启用防火墙过滤器，这里是 true。\n\n\n\n\n\n\n\n\n\n\n\n在jc-club-subject中的jc-club-application-controller中的pom.xml中引入jc-club-infra模块\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;    &lt;parent&gt;        &lt;artifactId&gt;jc-club-application&lt;/artifactId&gt;        &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/parent&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;artifactId&gt;jc-club-application-controller&lt;/artifactId&gt;    &lt;properties&gt;        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;        &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;            &lt;version&gt;2.4.2&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;            &lt;artifactId&gt;jc-club-infra&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;&lt;/project&gt;\n\n在jc-club-subject中的jc-club-application-controller中的SubjectController.java中新增一段对数据库的测试代码\npackage com.jingdianjichi.subject.application.controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * 刷题controller */@RestController@RequestMapping(&quot;/subject&quot;)public class SubjectController &#123;    @GetMapping(&quot;/test&quot;)    public String test()&#123;        SubjectCategory subjectCategory = subjectCategoryService.queryById(1L);        return subjectCategory;    &#125; &#125;\n\n测试成功\n\n基于druid配置文件加密（infra中的工具类）在jc-club-subject中的jc-club-infra/basic中新建一个utils包，建一个用于数据库加密的DruidEncrypUtil.java\npackage com.jingdianjichi.subject.infra.basic.utils;import com.alibaba.druid.filter.config.ConfigTools;import java.security.NoSuchAlgorithmException;import java.security.NoSuchProviderException;public class DruidEncryptUtil &#123;    private static String publicKey;    private static String privateKey;    static &#123;        try &#123;            String[] keyPair = ConfigTools.genKeyPair(512);            privateKey = keyPair[0]; //私钥            System.out.println(&quot;privateKey:&quot; + privateKey);            publicKey = keyPair[1]; //公钥            System.out.println(&quot;publicKey:&quot; + publicKey);        &#125; catch (NoSuchAlgorithmException e) &#123;            e.printStackTrace();        &#125; catch (NoSuchProviderException e) &#123;            e.printStackTrace();        &#125;    &#125;\t//加密    public static String encrypt(String plainText) throws Exception &#123;        String encrypt = ConfigTools.encrypt(privateKey, plainText);        System.out.println(&quot;encrypt:&quot; + encrypt);        return encrypt;    &#125;\t//解密    public static String decrypt(String encryptText) throws Exception &#123;        String decrypt = ConfigTools.decrypt(publicKey, encryptText);        System.out.println(&quot;decrypt:&quot; + decrypt);        return decrypt;    &#125;    public static void main(String[] args) throws Exception &#123;        String encrypt = encrypt(&quot;123456&quot;);        System.out.println(&quot;encrypt:&quot; + encrypt);    &#125;&#125;\n\n生成的公私钥和加密的密码\n\n在jc-club-subject中的jc-club-starter中修改application.yml，在password、config和publicKey处进行修改:\n\nconfig: 配置过滤器，这里启用了配置过滤器。\n\nconnectionProperties: 连接属性，这里配置了解密配置，config.decrypt=true 表示开启解密功能，config.decrypt.key=$&#123;publicKey&#125; 表示使用配置的公钥属性进行解密。\n\npublicKey: 定义了一个公钥，用于与 connectionProperties 中的 config.decrypt.key 配合，进行数据库密码的解密。\n\n\nserver:  port:3000spring:  datasource:    username: root    password: Me2Tw8jJlEU2C3ghYkBPPfauoyYKXOnb7iTsOHbISHU/mC1ol9OUvU3O9klxv1o5UEv49mErTSawnrw4zsG+5g==    driver-class-name: com.mysql.cj.jdbc.Driver    url: jdbc:mysql://localhost:3306/jc-club?serverTimezone=Asia/Shanghai&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=true    type: com.alibaba.druid.pool.DruidDataSource    druid:      initial-size: 20      min-idle: 20      max-active: 100      max-wait: 60000      connectionProperties: config.decrypt=true;config.decrypt.key=$&#123;publicKey&#125;;      stat-view-servlet:        enabled: true        url-pattern: /druid/*        login-username: admin        login-password: 123456      filter:        stat:          enabled: true          slow-sql-millis: 2000          log-slow-sql: true        wall:          enabled: true        config:          enabled: true publicKey: MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAIKZoTIyh/UEThK6nHOmxVlsSYM6o5qTle39c8NilMUjIln2P3bll86R0asiMLU2p2S81RRfARjIO1im8dNBvS8CAwEAAQ==\n\n现在数据库可以通过加密后的密码连上了\n分层架构业务开发所有接口如图所示：\n\n题目分类(SubjectCategoryController.java)这部分内容中，SujectCategoryController作为对题目类型涉及到get、post增删改查的入口，其中包含都在jc-club-application-controller中的SubjectCategoryServiceImpl和SubjectCategoryDomainServiceImpl。该controller通过jc-club-application-convert组件中SubjectCategoryDTOConverter的将DTO-&gt;BO&#x2F;BO-&gt;DTO，再利用SubjectCategoryDomainServiceImpl组件的add方法，其中涉及到jc-club-domain-convert组件中的SubjectCategoryConverter将BO-&gt;Category，在通过SubjectCategoryServiceImpl调用infra层的SubjectCategoryConverter将Category类转化为DAO。\nMapStruct转换器常见问题及其使用方式_@inheritinverseconfiguration-CSDN博客\n这里的convert的实现是利用@Mapper注解到converter类的\nMapStruct使用详解-CSDN博客\nimport org.mapstruct.Mapper;@Mapperpublic interface SubjectCategoryDTOConverter &#123;    SubjectCategoryDTOConverter INSTANCE = Mappers.getMapper(SubjectCategoryDTOConverter.class);    List&lt;SubjectCategoryDTO&gt; convertBoToCategoryDTOList(List&lt;SubjectCategoryBO&gt; subjectCategoryDTO);    SubjectCategoryBO convertDtoToCategoryBO(SubjectCategoryDTO subjectCategoryDTO);    SubjectCategoryDTO convertBoToCategoryDTO(SubjectCategoryBO subjectCategoryBO);&#125;\n\n\n新增分类（POST: /subject/category/add）\n请求body:\n&#123;\t&quot;categoryName&quot;:&quot;后端&quot;，\t&quot;categoryType&quot;:1,\t&quot;parentId&quot;:0,\t&quot;imgUrl&quot;:&quot;http://image/123&quot;&#125;\n\n响应成功示例：\n&#123;\t&quot;code&quot;:200,\t&quot;message&quot;:&quot;新增成功&quot;,\t&quot;data&quot;:true,\t&quot;reqUuid&quot;:&quot;123123123.123123.123123&quot;,\t&quot;success&quot;:true&#125;\n\n新增jc-club-common包：\n\nLombok是一个Java库，它通过注解的方式提供了一系列可以简化Java代码的工具，比如自动生成getter、setter、toString等方法。\n\nMapStruct是一个代码生成器，用于将Java方法的输入参数映射到输出参数，通常用于DTO（数据传输对象）和Entity（实体）之间的映射。\nDTO数据传输对象详解_dto撖寡情-CSDN博客\n\nmapstruct-processor，是MapStruct的注解处理器部分，用于在编译时生成映射代码。\n\n\n//pom.xml 注意lombok放在mapstruct前面是为了能够正常的拿到数据。如果项目中使用了lombok，那么需要在编译器指定他们的执行顺序，因为mapstrut底层是靠set/get赋值的，所以需要lombok先编译。&lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;            &lt;artifactId&gt;lombok&lt;/artifactId&gt;            &lt;version&gt;1.18.16&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.mapstruct&lt;/groupId&gt;            &lt;artifactId&gt;mapstruct&lt;/artifactId&gt;            &lt;version&gt;1.4.2.Final&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.mapstruct&lt;/groupId&gt;            &lt;artifactId&gt;mapstruct-processor&lt;/artifactId&gt;            &lt;version&gt;1.4.2.Final&lt;/version&gt;        &lt;/dependency&gt;&lt;/dependencies&gt;\n\njc-club-infra中的entity下的SubjectCategory.java\npackage com.jingdianjichi.subject.infra.basic.entity;import lombok.Data;import java.util.Date;import java.io.Serializable;/** * 题目分类(SubjectCategory)实体类 */@Data //导入了Lombok库中的@Data注解。@Data是一个便利的注解，它为类自动生成getter和setter方法、equals()、hashCode()和toString()方法。public class SubjectCategory implements Serializable &#123; //序列化    /**     * 主键     */    private Long id;    /**     * 分类名称     */    private String categoryName;    /**     * 分类类型     */    private Integer categoryType;    /**     * 图标连接     */    private String imageUrl;    /**     * 父级id     */    private Long parentId;    /**     * 创建人     */    private String createdBy;    /**     * 创建时间     */    private Date createdTime;    /**     * 更新人     */    private String updateBy;    /**     * 更新时间     */    private Date updateTime;    /**     * 逻辑删除 0未删除 1已删除     */    private Integer isDeleted;&#125;\n\njc-club-infra中的mapper下的SubjectCategoryDao.java\npackage com.jingdianjichi.subject.infra.basic.mapper;import com.jingdianjichi.subject.infra.basic.entity.SubjectCategory;import org.apache.ibatis.annotations.Param;import java.util.List;/** * 题目分类(SubjectCategory)表数据库访问层 */public interface SubjectCategoryDao &#123;    /**     * 通过ID查询单条数据     *     * @param id 主键     * @return 实例对象     */    SubjectCategory queryById(Long id);    /**     * 统计总行数     *     * @param subjectCategory 查询条件     * @return 总行数     */    long count(SubjectCategory subjectCategory);    /**     * 新增数据     *     * @param subjectCategory 实例对象     * @return 影响行数     */    int insert(SubjectCategory subjectCategory);    /**     * 批量新增数据（MyBatis原生foreach方法）     *     * @param entities List&lt;SubjectCategory&gt; 实例对象列表     * @return 影响行数     */    int insertBatch(@Param(&quot;entities&quot;) List&lt;SubjectCategory&gt; entities);    /**     * 批量新增或按主键更新数据（MyBatis原生foreach方法）     *     * @param entities List&lt;SubjectCategory&gt; 实例对象列表     * @return 影响行数     * @throws org.springframework.jdbc.BadSqlGrammarException 入参是空List的时候会抛SQL语句错误的异常，请自行校验入参     */    int insertOrUpdateBatch(@Param(&quot;entities&quot;) List&lt;SubjectCategory&gt; entities);    /**     * 修改数据     *     * @param subjectCategory 实例对象     * @return 影响行数     */    int update(SubjectCategory subjectCategory);    /**     * 通过主键删除数据     *     * @param id 主键     * @return 影响行数     */    int deleteById(Long id);    List&lt;SubjectCategory&gt; queryCategory(SubjectCategory subjectCategory);    Integer querySubjectCount(Long id);&#125;\n\njc-club-infra中的service下的SubjectCategoryServiceImpl.java\npackage com.jingdianjichi.subject.infra.basic.service.impl;import com.alibaba.fastjson.JSON;import com.jingdianjichi.subject.infra.basic.entity.SubjectCategory;import com.jingdianjichi.subject.infra.basic.mapper.SubjectCategoryDao;import com.jingdianjichi.subject.infra.basic.service.SubjectCategoryService;import lombok.extern.slf4j.Slf4j;import org.springframework.stereotype.Service;import javax.annotation.Resource;import java.util.List;/** * 题目分类(SubjectCategory)表服务实现类 */@Service(&quot;subjectCategoryService&quot;) //Spring注解，用于声明这个类是一个服务组件，并且可以通过subjectCategoryService这个名称获取到这个服务的实例。@Slf4j //Lombok注解，自动为类生成一个日志对象(log)，使用SLF4J日志框架。public class SubjectCategoryServiceImpl implements SubjectCategoryService &#123;    @Resource //Spring注解，用于自动装配(注入)SubjectCategoryDao类型的bean到subjectCategoryDao字段。    private SubjectCategoryDao subjectCategoryDao;    /**     * 新增数据     *     * @param subjectCategory 实例对象     * @return 实例对象     */    @Override    public SubjectCategory insert(SubjectCategory subjectCategory) &#123;        if(log.isInfoEnabled())&#123;            log.info(&quot;SubjectCategoryController.add.subjectCategory:&#123;&#125;&quot;                    , JSON.toJSONString(subjectCategory));        &#125;        this.subjectCategoryDao.insert(subjectCategory);        return subjectCategory;    &#125;    @Override    public SubjectCategory queryById(Long id) &#123;        return this.subjectCategoryDao.queryById(id);    &#125;    /**     * 修改数据     *     * @param subjectCategory 实例对象     * @return 实例对象     */    @Override    public int update(SubjectCategory subjectCategory) &#123;        return this.subjectCategoryDao.update(subjectCategory);    &#125;    /**     * 通过主键删除数据     *     * @param id 主键     * @return 是否成功     */    @Override    public boolean deleteById(Long id) &#123;        return this.subjectCategoryDao.deleteById(id) &gt; 0;    &#125;    @Override    public List&lt;SubjectCategory&gt; queryCategory(SubjectCategory subjectCategory) &#123;        return this.subjectCategoryDao.queryCategory(subjectCategory);    &#125;    @Override    public Integer querySubjectCount(Long id) &#123;        return this.subjectCategoryDao.querySubjectCount(id);    &#125;&#125;\n\njc-club-domain中的pom.xml引入infra模块，便于jc-club-domain中的service/impl下的SubjectCategoryDomainServiceImpl.java来引用\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;    &lt;parent&gt;        &lt;artifactId&gt;jc-club-subject&lt;/artifactId&gt;        &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/parent&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;artifactId&gt;jc-club-domain&lt;/artifactId&gt;    &lt;build&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;                &lt;configuration&gt;                    &lt;source&gt;8&lt;/source&gt;                    &lt;target&gt;8&lt;/target&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;            &lt;artifactId&gt;jc-club-infra&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;&lt;/project&gt;\n\njc-club-domain中的entity下的SubjectCategoryBO.java\npackage com.jingdianjichi.subject.domain.entity;import lombok.Data;import java.io.Serializable;import java.util.Date;import java.util.List;/** * 题目分类(SubjectCategory)实体类 * * @author makejava * @since 2023-10-01 21:49:59 */@Datapublic class SubjectCategoryBO implements Serializable &#123;    /**     * 主键     */    private Long id;    /**     * 分类名称     */    private String categoryName;    /**     * 分类类型     */    private Integer categoryType;    /**     * 图标连接     */    private String imageUrl;    /**     * 父级id     */    private Long parentId;    /**     * 数量     */    private Integer count;    /**     * 标签bo数量     */    private List&lt;SubjectLabelBO&gt; labelBOList;&#125;\n\njc-club-domain中的service下的SubjectCategoryDomainService.java\npackage com.jingdianjichi.subject.domain.service;import com.jingdianjichi.subject.domain.entity.SubjectCategoryBO;import java.util.List;public interface SubjectCategoryDomainService &#123;    /**     * 新增分类     */    void add(SubjectCategoryBO subjectCategoryBO);    /**     * 查询岗位大类     */    List&lt;SubjectCategoryBO&gt; queryCategory(SubjectCategoryBO subjectCategoryBO);    /**     * 更新分类     */    Boolean update(SubjectCategoryBO subjectCategoryBO);    /**     * 删除分类     */    Boolean delete(SubjectCategoryBO subjectCategoryBO);    /**     * 查询分类及标签     */    List&lt;SubjectCategoryBO&gt; queryCategoryAndLabel(SubjectCategoryBO subjectCategoryBO);&#125;\n\n怎么将BO转为Category呢？这里需要在jc-club-domain中的convert包设置SubjectCategoryConverter.java，用到mapstruct。\n//SubjectCategoryConverter.javapackage com.jingdianjichi.subject.domain.convert;import com.jingdianjichi.subject.domain.entity.SubjectCategoryBO;import com.jingdianjichi.subject.infra.basic.entity.SubjectCategory;import org.mapstruct.Mapper;import org.mapstruct.factory.Mappers;import java.util.List;@Mapperpublic interface SubjectCategoryConverter &#123;    SubjectCategoryConverter INSTANCE = Mappers.getMapper(SubjectCategoryConverter.class);    SubjectCategory convertBoToCategory(SubjectCategoryBO subjectCategoryBO);    List&lt;SubjectCategoryBO&gt; convertBoToCategory(List&lt;SubjectCategory&gt; categoryList);&#125;//此时`jc-club-domain`中的`service`下的`SubjectCategoryDomainServiceImpl.java`就可以调用这个了package com.jingdianjichi.subject.domain.service.impl;@Servicepublic class SubjectCategoryDomainServiceImpl implements SubjectCategoryDomainService &#123;    @Resource    private SubjectCategoryService subjectCategoryService;    public void add(SubjectCategoryBO subjectCategoryBO) &#123;        SubjectCategory subjectCategory = SubjectCategoryConverter.INSTANCE                .convertBoToCategory(subjectCategoryBO); //BO-&gt;SujectCategory        subjectCategory.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());        subjectCategoryService.insert(subjectCategory);    &#125;&#125;\n\n在jc-club-subject中的jc-club-application-controller的pom.xml中新增jc-club-domain，目的是在创建SubjectCategoryController时能正常引入。\n//pom.xml&lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;            &lt;version&gt;2.4.2&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;            &lt;artifactId&gt;jc-club-infra&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;            &lt;artifactId&gt;jc-club-domain&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;&lt;/dependencies&gt;\n\n在jc-club-subject中的jc-club-application-controller的SubjectCategoryController.java。这里会涉及到在jc-club-application-dto模块下的从BO到DTO的转换。\n//SubjectCategoryDTO.java BO-&gt;DTOpackage com.jingdianjichi.subject.application.dto;import lombok.Data;import java.io.Serializable;import java.util.List;/** * 题目分类 * * @author: ChickenWing * @date: 2023/10/3 */@Datapublic class SubjectCategoryDTO implements Serializable &#123;    /**     * 主键     */    private Long id;    /**     * 分类名称     */    private String categoryName;    /**     * 分类类型     */    private Integer categoryType;    /**     * 图标连接     */    private String imageUrl;    /**     * 父级id     */    private Long parentId;    /**     * 数量     */    private Integer count;    /**     * 标签信息     */    private List&lt;SubjectLabelDTO&gt; labelDTOList;&#125;//SubjectCategoryDTOConverter.javapackage com.jingdianjichi.subject.application.convert;import com.jingdianjichi.subject.application.dto.SubjectCategoryDTO;import com.jingdianjichi.subject.domain.entity.SubjectCategoryBO;import com.jingdianjichi.subject.infra.basic.entity.SubjectCategory;import org.mapstruct.Mapper;import org.mapstruct.factory.Mappers;import java.util.List;/** * 题目分类dto转换器 */@Mapperpublic interface SubjectCategoryDTOConverter &#123;    SubjectCategoryDTOConverter INSTANCE = Mappers.getMapper(SubjectCategoryDTOConverter.class);    List&lt;SubjectCategoryDTO&gt; convertBoToCategoryDTOList(List&lt;SubjectCategoryBO&gt; subjectCategoryDTO);    SubjectCategoryBO convertDtoToCategoryBO(SubjectCategoryDTO subjectCategoryDTO);    SubjectCategoryDTO convertBoToCategoryDTO(SubjectCategoryBO subjectCategoryBO);&#125;\n\n//SubjectCategoryController.java@RestController@RequestMapping(&quot;/subject/category&quot;)@Slf4jpublic class SubjectCategoryController &#123;    @Resource    private SubjectCategoryDomainService subjectCategoryDomainService;        @GetMapping(&quot;/add&quot;)    public Result&lt;Boolean&gt; add(@RequestBody SubjectCategoryDTO subjectCategoryDTO) &#123;        try&#123;            SubjectCategoryBO subjectCategoryBO=SubjectCategoryDTOConverter.INSTANCE.convertDtoToBO(subjectCategoryDTO);            subjectDomainService.add(subjectCategoryBO);            return Result.ok(true);        &#125;catch(Exception e)&#123;            return Result.fail(false); //这里的返回结果在jc-club-common中的entity模块设计一个Result类来统一返回        &#125;    &#125;&#125;\n\n由于会涉及到结果返回：\n//jc-club-common/entity Result.javapackage com.jingdianjichi.subject.common.entity;import com.jingdianjichi.subject.common.enums.ResultCodeEnum;import lombok.Data;@Datapublic class Result&lt;T&gt; &#123;    private Boolean success;    private Integer code;    private String message;    private T data;    public static Result ok()&#123;        Result result = new Result();        result.setSuccess(true);        result.setCode(ResultCodeEnum.SUCCESS.getCode());        result.setMessage(ResultCodeEnum.SUCCESS.getDesc());        return result;    &#125;    public static &lt;T&gt; Result ok(T data)&#123;        Result result = new Result();        result.setSuccess(true);        result.setCode(ResultCodeEnum.SUCCESS.getCode());        result.setMessage(ResultCodeEnum.SUCCESS.getDesc());        result.setData(data);        return result;    &#125;    public static Result fail()&#123;        Result result = new Result();        result.setSuccess(false);        result.setCode(ResultCodeEnum.FAIL.getCode());        result.setMessage(ResultCodeEnum.FAIL.getDesc());        return result;    &#125;    public static &lt;T&gt; Result fail(T data)&#123;        Result result = new Result();        result.setSuccess(false);        result.setCode(ResultCodeEnum.FAIL.getCode());        result.setMessage(ResultCodeEnum.FAIL.getDesc());        result.setData(data);        return result;    &#125;&#125;//jc-club-common/enums ResultCodeEnum.javapackage com.jingdianjichi.subject.common.enums;import lombok.Getter;@Getterpublic enum ResultCodeEnum &#123;    SUCCESS(200,&quot;成功&quot;),    FAIL(500,&quot;失败&quot;);    public int code;    public String desc;    ResultCodeEnum(int code,String desc)&#123;        this.code = code;        this.desc = desc;    &#125;    public static ResultCodeEnum getByCode(int codeVal)&#123;        for(ResultCodeEnum resultCodeEnum : ResultCodeEnum.values())&#123;            if(resultCodeEnum.code == codeVal)&#123;                return resultCodeEnum;            &#125;        &#125;        return null;    &#125;&#125;\n\n增加日志lo4j2和fastjson在jc-club-common中：\n//pom.xml&lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;            &lt;artifactId&gt;lombok&lt;/artifactId&gt;            &lt;version&gt;1.18.16&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.mapstruct&lt;/groupId&gt;            &lt;artifactId&gt;mapstruct&lt;/artifactId&gt;            &lt;version&gt;1.4.2.Final&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.mapstruct&lt;/groupId&gt;            &lt;artifactId&gt;mapstruct-processor&lt;/artifactId&gt;            &lt;version&gt;1.4.2.Final&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;            &lt;version&gt;2.4.2&lt;/version&gt;        &lt;/dependency&gt;   \t\t&lt;dependency&gt;            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;            &lt;artifactId&gt;fastjson&lt;/artifactId&gt;            &lt;version&gt;1.2.24&lt;/version&gt;        &lt;/dependency&gt;&lt;/dependencies&gt;\n\n对应的SubjectCategoryController.java和SubjectCategoryDomainServiceImpl.java\n//SubjectCategoryController.java@RestController@RequestMapping(&quot;/subject/category&quot;)@Slf4jpublic class SubjectCategoryController &#123;    @Resource    private SubjectCategoryDomainService subjectCategoryDomainService;        @GetMapping(&quot;/add&quot;)    public Result&lt;Boolean&gt; add(@RequestBody SubjectCategoryDTO subjectCategoryDTO) &#123;        try&#123;        \tif (log.isInfoEnabled()) &#123;                log.info(&quot;SubjectCategoryController.add.dto:&#123;&#125;&quot;, JSON.toJSONString(subjectCategoryDTO));            &#125;            /*这里log.isInfoEnabled()的作用是如果不加log.isDebugEnabled()等进行预先判断，当系统loglevel设置高于Debug或Info或Trace时，虽然系统不会答应出这些级别的日志，但是每次还是会拼接参数字符串/序列化，影响系统的性能。*/            SubjectCategoryBO subjectCategoryBO=SubjectCategoryDTOConverter.INSTANCE.convertDtoToBO(subjectCategoryDTO);            subjectDomainService.add(subjectCategoryBO);            return Result.ok(true);        &#125;catch(Exception e)&#123;            return Result.fail(false); //这里的返回结果在jc-club-common中的entity模块设计一个Result类来统一返回        &#125;    &#125;&#125;//SubjectCategoryDomainServiceImpl.javapackage com.jingdianjichi.subject.domain.service.impl;@Service@Slf4jpublic class SubjectCategoryDomainServiceImpl implements SubjectCategoryDomainService &#123;    @Resource    private SubjectCategoryService subjectCategoryService;    public void add(SubjectCategoryBO subjectCategoryBO) &#123;        if (log.isInfoEnabled()) &#123;            log.info(&quot;SubjectCategoryController.add.bo:&#123;&#125;&quot;, JSON.toJSONString(subjectCategoryBO));        &#125;        SubjectCategory subjectCategory = SubjectCategoryConverter.INSTANCE                .convertBoToCategory(subjectCategoryBO); //BO-&gt;SujectCategory        subjectCategory.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());        subjectCategoryService.insert(subjectCategory);    &#125;&#125;\n\npreconditions参数校验：\n回到SubjectCategoryController.java，进行参数校验，在pom.xml中添加guava（注意参数校验放在controller）\n//jc-club-common/pom.xml&lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;            &lt;artifactId&gt;lombok&lt;/artifactId&gt;            &lt;version&gt;1.18.16&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.mapstruct&lt;/groupId&gt;            &lt;artifactId&gt;mapstruct&lt;/artifactId&gt;            &lt;version&gt;1.4.2.Final&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.mapstruct&lt;/groupId&gt;            &lt;artifactId&gt;mapstruct-processor&lt;/artifactId&gt;            &lt;version&gt;1.4.2.Final&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;            &lt;version&gt;2.4.2&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;            &lt;artifactId&gt;fastjson&lt;/artifactId&gt;            &lt;version&gt;1.2.24&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.google.guava&lt;/groupId&gt;            &lt;artifactId&gt;guava&lt;/artifactId&gt;            &lt;version&gt;19.0&lt;/version&gt;        &lt;/dependency&gt;&lt;/dependencies&gt;\n\n//SubjectCategoryController.java@PostMapping(&quot;/add&quot;)    public Result&lt;Boolean&gt; add(@RequestBody SubjectCategoryDTO subjectCategoryDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;SubjectCategoryController.add.dto:&#123;&#125;&quot;, JSON.toJSONString(subjectCategoryDTO));            &#125;            Preconditions.checkNotNull(subjectCategoryDTO.getCategoryType(), &quot;分类类型不能为空&quot;);            Preconditions.checkArgument(!StringUtils.isBlank(subjectCategoryDTO.getCategoryName()), &quot;分类名称不能为空&quot;);            Preconditions.checkNotNull(subjectCategoryDTO.getParentId(), &quot;分类父级id不能为空&quot;);            SubjectCategoryBO subjectCategoryBO = SubjectCategoryDTOConverter.INSTANCE.convertDtoToCategoryBO(subjectCategoryDTO);            subjectCategoryDomainService.add(subjectCategoryBO);            return Result.ok(true);        &#125; catch (Exception e) &#123;            log.error(&quot;SubjectCategoryController.add.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;新增分类失败&quot;);        &#125;    &#125;\n\n刷题模块接口定义\n新增分类\n更新分类\n查询分类\n查询大类下分类\n查询分类及标签（二期优化）\n删除分类\n\n\n分类-&gt;标签\n基本的-&gt;二次优化\n数据库-&gt;缓存优化\n\n新增分类：POST：&#x2F;subject&#x2F;category&#x2F;add\n请求体：\n&#123;    &quot;categoryName&quot;: &quot;缓存&quot;,    &quot;parentId&quot;: 0,    &quot;categoryType&quot;: 1,    &quot;imageUrl&quot;: &quot;https://image/category.icon&quot;&#125;\n\n响应成功示例：\n&#123;\t&quot;success&quot;: true,\t&quot;code&quot;: 200,\t&quot;message&quot;: &quot;成功&quot;,\t&quot;data&quot;: true&#125;\n\n查询分类：POST：&#x2F;subject&#x2F;category&#x2F;queryPrimaryCategory\n请求体：\n&#123;    &quot;categoryType&quot;: 1&#125;\n\n响应示例：\n&#123;\t&quot;success&quot;: true,\t&quot;code&quot;: 200,\t&quot;message&quot;: &quot;成功&quot;,\t&quot;data&quot;: [\t\t&#123;\t\t\t&quot;id&quot;: 1,\t\t\t&quot;categoryName&quot;: &quot;后端&quot;,\t\t\t&quot;categoryType&quot;: 1,\t\t\t&quot;imageUrl&quot;: &quot;https://image/category.icon&quot;,\t\t\t&quot;parentId&quot;: 0,\t\t\t&quot;count&quot;: 65\t\t&#125;\t]&#125;\n\n查询大类下分类：POST：&#x2F;subject&#x2F;category&#x2F;queryCategoryByPrimary\n请求体：\n&#123;    &quot;parentId&quot;: 1,    &quot;categoryType&quot;: 2&#125;\n\n响应示例：\n&#123;\t&quot;success&quot;: true,\t&quot;code&quot;: 200,\t&quot;message&quot;: &quot;成功&quot;,\t&quot;data&quot;: [\t\t&#123;\t\t\t&quot;id&quot;: 4,\t\t\t&quot;categoryName&quot;: &quot;框架&quot;,\t\t\t&quot;categoryType&quot;: 2,\t\t\t&quot;imageUrl&quot;: &quot;http://image/123&quot;,\t\t\t&quot;parentId&quot;: 1\t\t&#125;,\t\t&#123;\t\t\t&quot;id&quot;: 5,\t\t\t&quot;categoryName&quot;: &quot;并发&quot;,\t\t\t&quot;categoryType&quot;: 2,\t\t\t&quot;imageUrl&quot;: &quot;http://image/123&quot;,\t\t\t&quot;parentId&quot;: 1\t\t&#125;,\t\t&#123;\t\t\t&quot;id&quot;: 6,\t\t\t&quot;categoryName&quot;: &quot;jvm&quot;,\t\t\t&quot;categoryType&quot;: 2,\t\t\t&quot;imageUrl&quot;: &quot;http://image/123&quot;,\t\t\t&quot;parentId&quot;: 1\t\t&#125;\t]&#125;\n\n查询分类及标签（二期优化）\n请求体：\n&#123;\t&quot;id&quot;: 1&#125;\n\n响应示例：\n&#123;\t&quot;success&quot;: true,\t&quot;code&quot;: 200,\t&quot;message&quot;: &quot;成功&quot;,\t&quot;data&quot;: [\t\t&#123;\t\t\t&quot;id&quot;: 2,\t\t\t&quot;categoryName&quot;: &quot;缓存&quot;,\t\t\t&quot;categoryType&quot;: 2,\t\t\t&quot;imageUrl&quot;: &quot;https://image/category.icon&quot;,\t\t\t&quot;parentId&quot;: 1,\t\t\t&quot;labelDTOList&quot;: [\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 1,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;Redis&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;,\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 8,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;集群&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;,\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 23,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;实际应用&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;,\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 34,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;多线程&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;,\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 44,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;数据一致性&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;,\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 46,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;分布式&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;,\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 47,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;持久化&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;,\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 49,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;事务&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;\t\t\t]\t\t&#125;,\t\t&#123;\t\t\t&quot;id&quot;: 3,\t\t\t&quot;categoryName&quot;: &quot;数据库&quot;,\t\t\t&quot;categoryType&quot;: 2,\t\t\t&quot;imageUrl&quot;: &quot;https://image/category.icon&quot;,\t\t\t&quot;parentId&quot;: 1,\t\t\t&quot;labelDTOList&quot;: [\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 2,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;进程&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;,\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 4,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;Mysql&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;,\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 16,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;索引&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;,\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 23,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;实际应用&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;,\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 33,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;存储引擎&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;,\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 44,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;数据一致性&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;,\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 49,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;事务&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;\t\t\t]\t\t&#125;,\t\t&#123;\t\t\t&quot;id&quot;: 4,\t\t\t&quot;categoryName&quot;: &quot;JavaSE&quot;,\t\t\t&quot;categoryType&quot;: 2,\t\t\t&quot;imageUrl&quot;: &quot;https://image/category.icon&quot;,\t\t\t&quot;parentId&quot;: 1,\t\t\t&quot;labelDTOList&quot;: [\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 15,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;基础&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;\t\t\t]\t\t&#125;,\t\t&#123;\t\t\t&quot;id&quot;: 5,\t\t\t&quot;categoryName&quot;: &quot;框架&quot;,\t\t\t&quot;categoryType&quot;: 2,\t\t\t&quot;imageUrl&quot;: &quot;https://image/category.icon&quot;,\t\t\t&quot;parentId&quot;: 1,\t\t\t&quot;labelDTOList&quot;: [\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 38,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;Spring&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;,\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 62,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;SpringBoot&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;\t\t\t]\t\t&#125;,\t\t&#123;\t\t\t&quot;id&quot;: 6,\t\t\t&quot;categoryName&quot;: &quot;消息队列&quot;,\t\t\t&quot;categoryType&quot;: 2,\t\t\t&quot;imageUrl&quot;: &quot;https://image/category.icon&quot;,\t\t\t&quot;parentId&quot;: 1,\t\t\t&quot;labelDTOList&quot;: [\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 15,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;基础&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;,\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 23,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;实际应用&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;\t\t\t]\t\t&#125;,\t\t&#123;\t\t\t&quot;id&quot;: 7,\t\t\t&quot;categoryName&quot;: &quot;代码管理工具&quot;,\t\t\t&quot;categoryType&quot;: 2,\t\t\t&quot;imageUrl&quot;: &quot;https://image/category.icon&quot;,\t\t\t&quot;parentId&quot;: 1,\t\t\t&quot;labelDTOList&quot;: [\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 25,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;Git&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;\t\t\t]\t\t&#125;,\t\t&#123;\t\t\t&quot;id&quot;: 9,\t\t\t&quot;categoryName&quot;: &quot;网络&quot;,\t\t\t&quot;categoryType&quot;: 2,\t\t\t&quot;imageUrl&quot;: &quot;https://image/category.icon&quot;,\t\t\t&quot;parentId&quot;: 1,\t\t\t&quot;labelDTOList&quot;: [\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 15,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;基础&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;\t\t\t]\t\t&#125;,\t\t&#123;\t\t\t&quot;id&quot;: 10,\t\t\t&quot;categoryName&quot;: &quot;操作系统&quot;,\t\t\t&quot;categoryType&quot;: 2,\t\t\t&quot;imageUrl&quot;: &quot;https://image/category.icon&quot;,\t\t\t&quot;parentId&quot;: 1,\t\t\t&quot;labelDTOList&quot;: [\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 15,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;基础&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;\t\t\t]\t\t&#125;,\t\t&#123;\t\t\t&quot;id&quot;: 11,\t\t\t&quot;categoryName&quot;: &quot;最佳实践&quot;,\t\t\t&quot;categoryType&quot;: 2,\t\t\t&quot;imageUrl&quot;: &quot;https://image/category.icon&quot;,\t\t\t&quot;parentId&quot;: 1,\t\t\t&quot;labelDTOList&quot;: [\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 23,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;实际应用&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;,\t\t\t\t&#123;\t\t\t\t\t&quot;id&quot;: 53,\t\t\t\t\t&quot;categoryId&quot;: 1,\t\t\t\t\t&quot;labelName&quot;: &quot;Jvm&quot;,\t\t\t\t\t&quot;sortNum&quot;: 1\t\t\t\t&#125;\t\t\t]\t\t&#125;\t]&#125;\n\n这里优化后的其实是把大分类-&gt;小分类-&gt;标签全都查完了，是用的多线程去实现的\n数据查完之后，再通过遍历然后利用某些规则，前端就能很轻松的查到了\n\n删除分类\n请求体:\n&#123;    &quot;id&quot;: 3&#125;\n\n响应示例：\n&#123;\t&quot;success&quot;: true,\t&quot;code&quot;: 200,\t&quot;message&quot;: &quot;成功&quot;,\t&quot;data&quot;: true&#125;\n\n更新分类\n请求体:\n&#123;    &quot;id&quot;: 3,    &quot;categoryName&quot;: &quot;Spring&quot;,    &quot;categoryType&quot;: 2,    &quot;parentId&quot;: 3,    &quot;imageUrl&quot;: &quot;http://image/123&quot;&#125;\n\n响应示例：\n&#123;\t&quot;success&quot;: true,\t&quot;code&quot;: 200,\t&quot;message&quot;: &quot;成功&quot;,\t&quot;data&quot;: true&#125;\n\n题目列表及详情接口定义\n涉及到难度，创建时间，题目，点赞收藏评论，创建人\n分页查询\n\n查询题目列表（POST:&#x2F;subject&#x2F;category&#x2F;querySubjectList）\n请求体：\n&#123;\t&quot;pageIndex&quot;:1,\t&quot;pageSize&quot;:10,\t&quot;labelId&quot;:2,\t&quot;categoryId&quot;:1,    &quot;difficulty&quot;:1&#125;\n\n响应示例：\n&#123;\t&quot;code&quot;:200,\t&quot;message&quot;:&quot;查询成功&quot;,    &quot;data&quot;:&#123;        &quot;total&quot;:100,        &quot;totalPage&quot;:20,        &quot;pageList&quot;:[            &#123;                &quot;subjectName&quot;:&quot;SpringBoot的自动装配原理是什么?&quot;,                &quot;subjectId&quot;:1,                &quot;difficulty&quot;:1,                &quot;labelNames&quot;:[                    &quot;并发&quot;,                    &quot;集合&quot;                ]            &#125;        ]    &#125;，    &quot;reqUuid&quot;：&quot;1231231223&quot;,    &quot;success&quot;：true&#125;\n\n分类接口开发//SubjectCategoryController.java/**     * 查询岗位大类     */    @PostMapping(&quot;/queryPrimaryCategory&quot;)    public Result&lt;List&lt;SubjectCategoryDTO&gt;&gt; queryPrimaryCategory(@RequestBody SubjectCategoryDTO subjectCategoryDTO) &#123;        try &#123;            SubjectCategoryBO subjectCategoryBO = SubjectCategoryDTOConverter.INSTANCE.                    convertDtoToCategoryBO(subjectCategoryDTO);            List&lt;SubjectCategoryBO&gt; subjectCategoryBOList = subjectCategoryDomainService.queryCategory(subjectCategoryBO);            List&lt;SubjectCategoryDTO&gt; subjectCategoryDTOList = SubjectCategoryDTOConverter.INSTANCE.                    convertBoToCategoryDTOList(subjectCategoryBOList);            return Result.ok(subjectCategoryDTOList);        &#125; catch (Exception e) &#123;            log.error(&quot;SubjectCategoryController.queryPrimaryCategory.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;查询失败&quot;);        &#125;    &#125;//domain包里 SubjectCategoryDomainService.javapublic interface SubjectCategoryDomainService &#123;    /**     * 新增分类     */    void add(SubjectCategoryBO subjectCategoryBO);    /**     * 查询岗位大类     */    List&lt;SubjectCategoryBO&gt; queryCategory(SubjectCategoryBO subjectCategoryBO);    &#125;//domain包里 SubjectCategoryDomainServiceImpl.java @Override    public List&lt;SubjectCategoryBO&gt; queryCategory(SubjectCategoryBO subjectCategoryBO) &#123;        SubjectCategory subjectCategory = SubjectCategoryConverter.INSTANCE                .convertBoToCategory(subjectCategoryBO);        subjectCategory.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());        List&lt;SubjectCategory&gt; subjectCategoryList = subjectCategoryService.queryCategory(subjectCategory);        List&lt;SubjectCategoryBO&gt; boList = SubjectCategoryConverter.INSTANCE                .convertBoToCategory(subjectCategoryList);        if (log.isInfoEnabled()) &#123;            log.info(&quot;SubjectCategoryController.queryPrimaryCategory.boList:&#123;&#125;&quot;,                    JSON.toJSONString(boList));        &#125;        boList.forEach(bo -&gt; &#123;            Integer subjectCount = subjectCategoryService.querySubjectCount(bo.getId());            bo.setCount(subjectCount);        &#125;);        return boList;    &#125;\n\ncontroller:用converter DTO-&gt;BO\ndomainservice: converter bo-&gt;category，用service带着category去查,用Dao去查（dao的接口+dao.xml,mapperscan能扫描到）数据库，返回List\ncontroller:用converter bolist-&gt;dtolist\n返回dtolist，用Result封装一下，查出来了\n关于为什么能够用Result返回用postman可以查到，其实用了@RestController标识：[SpringBoot以及集成组件注解大全详解（一）——lomback &amp;&amp; JPA_@componentscan是复合注解吗-CSDN博客](https://blog.csdn.net/qq_42133100/article/details/89084518?ops_request_misc=%7B%22request%5Fid%22%3A%22172154818816800186530805%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&amp;request_id=172154818816800186530805&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-1-89084518-null-null.142^v100^pc_search_result_base8&amp;utm_term=lomback中@data RestController&amp;spm&#x3D;1018.2226.3001.4187)\n[【MyBatis】Dao接口和Dao.xml文件如何建立连接-CSDN博客](https://blog.csdn.net/weixin_45156425/article/details/120956070?ops_request_misc=%7B%22request%5Fid%22%3A%22172154533316800207082850%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&amp;request_id=172154533316800207082850&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-1-120956070-null-null.142^v100^pc_search_result_base8&amp;utm_term=mybatis和dao xml&amp;spm&#x3D;1018.2226.3001.4187)\n\n根据大类查询二级分类\n//更新SubjectCategoryDomainService.javapublic interface SubjectCategoryDomainService &#123;    /**     * 新增分类     */    void add(SubjectCategoryBO subjectCategoryBO);    /**     * 查询岗位大类     */    List&lt;SubjectCategoryBO&gt; queryCategory(SubjectCategoryBO subjectCategoryBO);&#125;//SubjectCategoryController.java/**     * 根据分类id查二级分类     */    @PostMapping(&quot;/queryCategoryByPrimary&quot;)    public Result&lt;List&lt;SubjectCategoryDTO&gt;&gt; queryCategoryByPrimary(@RequestBody SubjectCategoryDTO subjectCategoryDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;SubjectCategoryController.queryCategoryByPrimary.dto:&#123;&#125;&quot;                        , JSON.toJSONString(subjectCategoryDTO));            &#125;            Preconditions.checkNotNull(subjectCategoryDTO.getParentId(), &quot;分类id不能为空&quot;);            SubjectCategoryBO subjectCategoryBO = SubjectCategoryDTOConverter.INSTANCE.                    convertDtoToCategoryBO(subjectCategoryDTO);            List&lt;SubjectCategoryBO&gt; subjectCategoryBOList = subjectCategoryDomainService.queryCategory(subjectCategoryBO);            List&lt;SubjectCategoryDTO&gt; subjectCategoryDTOList = SubjectCategoryDTOConverter.INSTANCE.                    convertBoToCategoryDTOList(subjectCategoryBOList);            return Result.ok(subjectCategoryDTOList);        &#125; catch (Exception e) &#123;            log.error(&quot;SubjectCategoryController.queryPrimaryCategory.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;查询失败&quot;);        &#125;    &#125;\n\n更新分类\n/**     * 更新分类     */    @PostMapping(&quot;/update&quot;)    public Result&lt;Boolean&gt; update(@RequestBody SubjectCategoryDTO subjectCategoryDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;SubjectCategoryController.update.dto:&#123;&#125;&quot;, JSON.toJSONString(subjectCategoryDTO));            &#125;            SubjectCategoryBO subjectCategoryBO = SubjectCategoryDTOConverter.INSTANCE.                    convertDtoToCategoryBO(subjectCategoryDTO);            Boolean result = subjectCategoryDomainService.update(subjectCategoryBO);            return Result.ok(result);        &#125; catch (Exception e) &#123;            log.error(&quot;SubjectCategoryController.update.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;更新分类失败&quot;);        &#125;    &#125;//SubjectCategoryDomainServiceBoolean update(SubjectCategoryBO subjectCategoryBO);//SubjectCategoryDomainServiceImpl@Override    public Boolean update(SubjectCategoryBO subjectCategoryBO) &#123;        SubjectCategory subjectCategory = SubjectCategoryConverter.INSTANCE                .convertBoToCategory(subjectCategoryBO);        int count = subjectCategoryService.update(subjectCategory);        return count &gt; 0;    &#125;//SubjectCategoryServiceint update(SubjectCategory subjectCategory);//SubjectCategoryServiceImpl@Override    public int update(SubjectCategory subjectCategory) &#123;        return this.subjectCategoryDao.update(subjectCategory);    &#125;//SubjectCategoryDaoint update(SubjectCategory subjectCategory);//接下来就是通过SubjectCategoryD.xml和mybatis组件去进行数据库的操作\n\n删除分类\n/**     * 删除分类     */    @PostMapping(&quot;/delete&quot;)    public Result&lt;Boolean&gt; delete(@RequestBody SubjectCategoryDTO subjectCategoryDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;SubjectCategoryController.delete.dto:&#123;&#125;&quot;, JSON.toJSONString(subjectCategoryDTO));            &#125;            SubjectCategoryBO subjectCategoryBO = SubjectCategoryDTOConverter.INSTANCE.                    convertDtoToCategoryBO(subjectCategoryDTO);            Boolean result = subjectCategoryDomainService.delete(subjectCategoryBO);            return Result.ok(result);        &#125; catch (Exception e) &#123;            log.error(&quot;SubjectCategoryController.delete.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;删除分类失败&quot;);        &#125;    &#125;//SubjectCategoryDomainServiceBoolean delete(SubjectCategoryBO subjectCategoryBO);//SubjectCategoryDomainServiceImpl@Override    public Boolean delete(SubjectCategoryBO subjectCategoryBO) &#123;        SubjectCategory subjectCategory = SubjectCategoryConverter.INSTANCE                .convertBoToCategory(subjectCategoryBO);        subjectCategory.setIsDeleted(IsDeletedFlagEnum.DELETED.getCode()); //设置已经删除字段        int count = subjectCategoryService.update(subjectCategory);        return count &gt; 0;    &#125;//IsDeletedFlagEnum 在common包下的enum中@Getterpublic enum IsDeletedFlagEnum &#123;    DELETED(1,&quot;已删除&quot;),    UN_DELETED(0,&quot;未删除&quot;);    public int code;    public String desc;    IsDeletedFlagEnum(int code, String desc)&#123;        this.code = code;        this.desc = desc;    &#125;    public static IsDeletedFlagEnum getByCode(int codeVal)&#123;        for(IsDeletedFlagEnum resultCodeEnum : IsDeletedFlagEnum.values())&#123;            if(resultCodeEnum.code == codeVal)&#123;                return resultCodeEnum;            &#125;        &#125;        return null;    &#125;&#125;//SubjectCategoryServiceboolean deleteById(Long id);//SubjectCategoryServiceImpl@Override    public boolean deleteById(Long id) &#123;        return this.subjectCategoryDao.deleteById(id) &gt; 0;    &#125;//SubjectCategoryDaoint deleteById(Long id);//接下来就是通过SubjectCategoryD.xml和mybatis组件去进行数据库的操作\n\n题目标签接口定义\n新增标签\n请求体：\n&#123;    &quot;labelName&quot;: &quot;SpringMVC&quot;,    &quot;categoryId&quot;:1,    &quot;sortNum&quot;: 1&#125;\n\n响应示例：\n&#123;\t&quot;success&quot;: true,\t&quot;code&quot;: 200,\t&quot;message&quot;: &quot;成功&quot;,\t&quot;data&quot;: true&#125;\n\n更新标签\n请求体：\n&#123;    &quot;id&quot;: 1,    &quot;labelName&quot;: &quot;Spring&quot;,    &quot;sortNum&quot;: 10&#125;\n\n响应示例：\n&#123;\t&quot;success&quot;: true,\t&quot;code&quot;: 200,\t&quot;message&quot;: &quot;成功&quot;,\t&quot;data&quot;: true&#125;\n\n删除标签\n请求体：\n&#123;    &quot;id&quot;: 1&#125;\n\n响应示例：\n&#123;\t&quot;success&quot;: true,\t&quot;code&quot;: 200,\t&quot;message&quot;: &quot;成功&quot;,\t&quot;data&quot;: true&#125;\n\n根据分类查询标签\n请求体：\n&#123;    &quot;categoryId&quot;: 1&#125;\n\n响应示例：\n&#123;\t&quot;success&quot;: true,\t&quot;code&quot;: 200,\t&quot;message&quot;: &quot;成功&quot;,\t&quot;data&quot;: [\t\t&#123;\t\t\t&quot;id&quot;: 2,\t\t\t&quot;categoryId&quot;: 4,\t\t\t&quot;labelName&quot;: &quot;SpringBoot&quot;,\t\t\t&quot;sortNum&quot;: 0\t\t&#125;,\t\t&#123;\t\t\t&quot;id&quot;: 3,\t\t\t&quot;categoryId&quot;: 4,\t\t\t&quot;labelName&quot;: &quot;SpringMVC&quot;,\t\t\t&quot;sortNum&quot;: 1\t\t&#125;\t]&#125;\n\n标签基础模块开发//SubjectLabelControllerpublic class SubjectLabelController &#123;    @Resource    private SubjectLabelDomainService subjectLabelDomainService;    /**     * 新增标签     */    @PostMapping(&quot;/add&quot;)    public Result&lt;Boolean&gt; add(@RequestBody SubjectLabelDTO subjectLabelDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;SubjectLabelController.add.dto:&#123;&#125;&quot;, JSON.toJSONString(subjectLabelDTO));            &#125;            Preconditions.checkArgument(!StringUtils.isBlank(subjectLabelDTO.getLabelName()),                    &quot;标签名称不能为空&quot;);            SubjectLabelBO subjectLabelBO = SubjectLabelDTOConverter.INSTANCE.convertDtoToLabelBO(subjectLabelDTO);            Boolean result = subjectLabelDomainService.add(subjectLabelBO);            return Result.ok(result);        &#125; catch (Exception e) &#123;            log.error(&quot;SubjectLabelController.add.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;新增标签失败&quot;);        &#125;    &#125;    /**     * 更新标签     */    @PostMapping(&quot;/update&quot;)    public Result&lt;Boolean&gt; update(@RequestBody SubjectLabelDTO subjectLabelDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;SubjectLabelController.update.dto:&#123;&#125;&quot;, JSON.toJSONString(subjectLabelDTO));            &#125;            Preconditions.checkNotNull(subjectLabelDTO.getId(), &quot;标签id不能为空&quot;);            SubjectLabelBO subjectLabelBO = SubjectLabelDTOConverter.INSTANCE.convertDtoToLabelBO(subjectLabelDTO);            Boolean result = subjectLabelDomainService.update(subjectLabelBO);            return Result.ok(result);        &#125; catch (Exception e) &#123;            log.error(&quot;SubjectLabelController.update.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;更新标签失败&quot;);        &#125;    &#125;    /**     * 删除标签     */    @PostMapping(&quot;/delete&quot;)    public Result&lt;Boolean&gt; delete(@RequestBody SubjectLabelDTO subjectLabelDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;SubjectLabelController.delete.dto:&#123;&#125;&quot;, JSON.toJSONString(subjectLabelDTO));            &#125;            Preconditions.checkNotNull(subjectLabelDTO.getId(), &quot;标签id不能为空&quot;);            SubjectLabelBO subjectLabelBO = SubjectLabelDTOConverter.INSTANCE.convertDtoToLabelBO(subjectLabelDTO);            Boolean result = subjectLabelDomainService.delete(subjectLabelBO);            return Result.ok(result);        &#125; catch (Exception e) &#123;            log.error(&quot;SubjectLabelController.delete.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;删除标签失败&quot;);        &#125;    &#125;    /**     * 查询分类下标签     */    @PostMapping(&quot;/queryLabelByCategoryId&quot;)    public Result&lt;List&lt;SubjectLabelDTO&gt;&gt; queryLabelByCategoryId(@RequestBody SubjectLabelDTO subjectLabelDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;SubjectLabelController.queryLabelByCategoryId.dto:&#123;&#125;&quot;,                        JSON.toJSONString(subjectLabelDTO));            &#125;            Preconditions.checkNotNull(subjectLabelDTO.getCategoryId(), &quot;分类id不能为空&quot;);            SubjectLabelBO subjectLabelBO = SubjectLabelDTOConverter.INSTANCE.convertDtoToLabelBO(subjectLabelDTO);            List&lt;SubjectLabelBO&gt; resultList = subjectLabelDomainService.queryLabelByCategoryId(subjectLabelBO);            List&lt;SubjectLabelDTO&gt; subjectLabelDTOS = SubjectLabelDTOConverter.INSTANCE.convertBOToLabelDTOList(resultList);            return Result.ok(subjectLabelDTOS);        &#125; catch (Exception e) &#123;            log.error(&quot;SubjectLabelController.queryLabelByCategoryId.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;查询分类下标签失败&quot;);        &#125;    &#125;&#125;\n\n//SubjectLabelDTOConverter@Mapperpublic interface SubjectLabelDTOConverter &#123;    SubjectLabelDTOConverter INSTANCE = Mappers.getMapper(SubjectLabelDTOConverter.class);    SubjectLabelBO convertDtoToLabelBO(SubjectLabelDTO subjectLabelDTO);    List&lt;SubjectLabelDTO&gt; convertBOToLabelDTOList(List&lt;SubjectLabelBO&gt; boList);&#125;//SubjectLabelConverter@Mapperpublic interface SubjectLabelConverter &#123;    SubjectLabelConverter INSTANCE = Mappers.getMapper(SubjectLabelConverter.class);    SubjectLabel convertBoToLabel(SubjectLabelBO subjectLabelBO);    List&lt;SubjectLabelBO&gt; convertLabelToBoList(List&lt;SubjectLabel&gt; subjectLabelList);&#125;//SubjectLabelDTO@Datapublic class SubjectLabelDTO implements Serializable &#123;    /**     * 主键     */    private Long id;        /**     * 分类id     */    private Long categoryId;        /**     * 标签分类     */    private String labelName;    /**     * 排序     */    private Integer sortNum;&#125;//SubjectLabelBO@Datapublic class SubjectLabelBO implements Serializable &#123;    /**     * 主键     */    private Long id;    /**     * 标签分类     */    private String labelName;    /**     * 排序     */    private Integer sortNum;    /**     * 分类id     */    private Long categoryId;&#125;\n\n//SubjectLabelDomainServicepublic interface SubjectLabelDomainService &#123;    /**     * 新增标签     */    Boolean add(SubjectLabelBO subjectLabelBO);    /**     * 更新标签     */    Boolean update(SubjectLabelBO subjectLabelBO);    /**     * 删除标签     */    Boolean delete(SubjectLabelBO subjectLabelBO);    /**     * 查询分类下标签     */    List&lt;SubjectLabelBO&gt; queryLabelByCategoryId(SubjectLabelBO subjectLabelBO);&#125;//SubjectLabelDomainServiceImpl@Service@Slf4jpublic class SubjectLabelDomainServiceImpl implements SubjectLabelDomainService &#123;    @Resource    private SubjectLabelService subjectLabelService;    @Resource    private SubjectMappingService subjectMappingService;    @Resource    private SubjectCategoryService subjectCategoryService;    @Override    public Boolean add(SubjectLabelBO subjectLabelBO) &#123;        if (log.isInfoEnabled()) &#123;            log.info(&quot;SubjectLabelDomainServiceImpl.add.bo:&#123;&#125;&quot;, JSON.toJSONString(subjectLabelBO));        &#125;        SubjectLabel subjectLabel = SubjectLabelConverter.INSTANCE                .convertBoToLabel(subjectLabelBO);        subjectLabel.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());        int count = subjectLabelService.insert(subjectLabel);        return count &gt; 0;    &#125;    @Override    public Boolean update(SubjectLabelBO subjectLabelBO) &#123;        if (log.isInfoEnabled()) &#123;            log.info(&quot;SubjectLabelDomainServiceImpl.update.bo:&#123;&#125;&quot;, JSON.toJSONString(subjectLabelBO));        &#125;        SubjectLabel subjectLabel = SubjectLabelConverter.INSTANCE                .convertBoToLabel(subjectLabelBO);        int count = subjectLabelService.update(subjectLabel);        return count &gt; 0;    &#125;    @Override    public Boolean delete(SubjectLabelBO subjectLabelBO) &#123;        if (log.isInfoEnabled()) &#123;            log.info(&quot;SubjectLabelDomainServiceImpl.update.bo:&#123;&#125;&quot;, JSON.toJSONString(subjectLabelBO));        &#125;        SubjectLabel subjectLabel = SubjectLabelConverter.INSTANCE                .convertBoToLabel(subjectLabelBO);        subjectLabel.setIsDeleted(IsDeletedFlagEnum.DELETED.getCode());        int count = subjectLabelService.update(subjectLabel);        return count &gt; 0;    &#125;    @Override    public List&lt;SubjectLabelBO&gt; queryLabelByCategoryId(SubjectLabelBO subjectLabelBO) &#123;        //如果当前分类是1级分类，则查询所有标签        SubjectCategory subjectCategory = subjectCategoryService.queryById(subjectLabelBO.getCategoryId());        if(CategoryTypeEnum.PRIMARY.getCode() == subjectCategory.getCategoryType())&#123;            SubjectLabel subjectLabel = new SubjectLabel();            subjectLabel.setCategoryId(subjectLabelBO.getCategoryId());            List&lt;SubjectLabel&gt; labelList = subjectLabelService.queryByCondition(subjectLabel);            List&lt;SubjectLabelBO&gt; labelResultList = SubjectLabelConverter.INSTANCE.convertLabelToBoList(labelList);            return labelResultList;        &#125;        Long categoryId = subjectLabelBO.getCategoryId();        SubjectMapping subjectMapping = new SubjectMapping();        subjectMapping.setCategoryId(categoryId);        subjectMapping.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());        List&lt;SubjectMapping&gt; mappingList = subjectMappingService.queryLabelId(subjectMapping);        if (CollectionUtils.isEmpty(mappingList)) &#123;            return Collections.emptyList();        &#125;        //将mappingList转换为一个流（Stream）,使用map操作对流中的每个元素（SubjectMapping对象）应用一个函数,使用collect操作将流中的元素汇总或归纳到一个新的集合中        List&lt;Long&gt; labelIdList = mappingList.stream().map(SubjectMapping::getLabelId).collect(Collectors.toList());        List&lt;SubjectLabel&gt; labelList = subjectLabelService.batchQueryById(labelIdList);        List&lt;SubjectLabelBO&gt; boList = new LinkedList&lt;&gt;();        labelList.forEach(label -&gt; &#123; //lamda表达式            SubjectLabelBO bo = new SubjectLabelBO();            bo.setId(label.getId());            bo.setLabelName(label.getLabelName());            bo.setCategoryId(categoryId);            bo.setSortNum(label.getSortNum());            boList.add(bo);        &#125;);        return boList;    &#125;&#125;//SubjectMappingServicepublic interface SubjectMappingService &#123;    /**     * 通过ID查询单条数据     *     * @return 实例对象     */    SubjectMapping queryById(int id);    /**     * 新增数据     *     * @param subjectMapping 实例对象     * @return 实例对象     */    SubjectMapping insert(SubjectMapping subjectMapping);    /**     * 修改数据     *     * @param subjectMapping 实例对象     * @return 实例对象     */    int update(SubjectMapping subjectMapping);    /**     * 通过主键删除数据     *     * @return 是否成功     */    boolean deleteById(int id);    /**     * 查询标签id     */    List&lt;SubjectMapping&gt; queryLabelId(SubjectMapping subjectMapping);    /**     * 批量插入     */    void batchInsert(List&lt;SubjectMapping&gt; mappingList);&#125;//SubjectMappingServiceImpl@Service(&quot;subjectMappingService&quot;)public class SubjectMappingServiceImpl implements SubjectMappingService &#123;    @Resource    private SubjectMappingDao subjectMappingDao;    /**     * 通过ID查询单条数据     *     * @return 实例对象     */    @Override    public SubjectMapping queryById(int id) &#123;        return this.subjectMappingDao.queryById(id);    &#125;    /**     * 新增数据     *     * @param subjectMapping 实例对象     * @return 实例对象     */    @Override    public SubjectMapping insert(SubjectMapping subjectMapping) &#123;        this.subjectMappingDao.insert(subjectMapping);        return subjectMapping;    &#125;    /**     * 修改数据     *     * @param subjectMapping 实例对象     * @return 实例对象     */    @Override    public int update(SubjectMapping subjectMapping) &#123;        return this.subjectMappingDao.update(subjectMapping);    &#125;    /**     * 通过主键删除数据     *     * @return 是否成功     */    @Override    public boolean deleteById(int id) &#123;        return this.subjectMappingDao.deleteById(id) &gt; 0;    &#125;    @Override    public List&lt;SubjectMapping&gt; queryLabelId(SubjectMapping subjectMapping) &#123;        return this.subjectMappingDao.queryDistinctLabelId(subjectMapping);    &#125;    @Override    public void batchInsert(List&lt;SubjectMapping&gt; mappingList) &#123;        this.subjectMappingDao.insertBatch(mappingList);    &#125;&#125;\n\n标签业务改动将一级分类和标签联系起来\n\nSubjectLabelDao.xml\n\ndomain层也跟着改\n题目模块接口定义\n新增单选题目\n请求体：\n&#123;    &quot;subjectName&quot;: &quot;SpringBoot自动装配原理是什么？&quot;,    &quot;subjectDifficult&quot;: 1,    &quot;subjectType&quot;: 1,    &quot;subjectScore&quot;: 2,    &quot;subjectParse&quot;: &quot;题目解析&quot;,    &quot;categoryIds&quot;: [        4,        5    ],    &quot;labelIds&quot;: [        2,        3    ],    &quot;optionList&quot;: [        &#123;            &quot;optionType&quot;: 1,            &quot;optionContent&quot;: &quot;自动的&quot;,            &quot;isCorrect&quot;: 1        &#125;,        &#123;            &quot;optionType&quot;: 2,            &quot;optionContent&quot;: &quot;其实是用配置文件&quot;,            &quot;isCorrect&quot;: 0        &#125;    ]&#125;\n\n响应成功示例：\n&#123;\t&quot;success&quot;: true,\t&quot;code&quot;: 200,\t&quot;message&quot;: &quot;成功&quot;,\t&quot;data&quot;: true&#125;\n\n新增多选题目\n请求体：\n&#123;    &quot;subjectName&quot;: &quot;SpringBoot自动装配原理是什么？&quot;,    &quot;subjectDifficult&quot;: 1,    &quot;subjectType&quot;: 2,    &quot;subjectScore&quot;: 2,    &quot;subjectParse&quot;: &quot;题目解析&quot;,    &quot;categoryIds&quot;: [        4,        5    ],    &quot;labelIds&quot;: [        2,        3    ],    &quot;optionList&quot;: [        &#123;            &quot;optionType&quot;: 1,            &quot;optionContent&quot;: &quot;自动的&quot;,            &quot;isCorrect&quot;: 1        &#125;,        &#123;            &quot;optionType&quot;: 2,            &quot;optionContent&quot;: &quot;其实是用配置文件&quot;,            &quot;isCorrect&quot;: 1        &#125;    ]&#125;\n\n响应成功示例：\n&#123;\t&quot;success&quot;: true,\t&quot;code&quot;: 200,\t&quot;message&quot;: &quot;成功&quot;,\t&quot;data&quot;: true&#125;\n\n新增判断题目\n请求体：\n&#123;    &quot;subjectName&quot;: &quot;SpringBoot自动装配原理是什么？&quot;,    &quot;subjectDifficult&quot;: 1,    &quot;subjectType&quot;: 3,    &quot;subjectScore&quot;: 2,    &quot;subjectParse&quot;: &quot;题目解析&quot;,    &quot;categoryIds&quot;: [        4,        5    ],    &quot;labelIds&quot;: [        2,        3    ],    &quot;optionList&quot;: [        &#123;            &quot;isCorrect&quot;: 1        &#125;    ]&#125;\n\n响应成功示例：\n&#123;\t&quot;success&quot;: true,\t&quot;code&quot;: 200,\t&quot;message&quot;: &quot;成功&quot;,\t&quot;data&quot;: true&#125;\n\n新增简答题目\n请求体：\n&#123;    &quot;subjectName&quot;: &quot;Mysql是个什么东西？&quot;,    &quot;subjectDifficult&quot;: 1,    &quot;subjectType&quot;: 4,    &quot;subjectScore&quot;: 2,    &quot;subjectParse&quot;: &quot;题目解析2&quot;,    &quot;subjectAnswer&quot;: &quot;Mysql是个数据库&quot;,    &quot;categoryIds&quot;: [        5    ],    &quot;labelIds&quot;: [        11    ]&#125;\n\n响应示例：\n&#123;\t&quot;success&quot;: true,\t&quot;code&quot;: 200,\t&quot;message&quot;: &quot;成功&quot;,\t&quot;data&quot;: true&#125;\n\n查询题目列表\n请求体：\n&#123;    &quot;pageNo&quot;: 2,    &quot;pageSize&quot;: 10,    &quot;labelId&quot;: 1,    &quot;categoryId&quot;: 2,    &quot;subjectDifficult&quot;: 1&#125;\n\n响应示例：\n&#123;\t&quot;success&quot;: true,\t&quot;code&quot;: 200,\t&quot;message&quot;: &quot;成功&quot;,\t&quot;data&quot;: &#123;\t\t&quot;pageNo&quot;: 1,\t\t&quot;pageSize&quot;: 20,\t\t&quot;total&quot;: 1,\t\t&quot;totalPages&quot;: 1,\t\t&quot;result&quot;: [\t\t\t&#123;\t\t\t\t&quot;pageNo&quot;: 1,\t\t\t\t&quot;pageSize&quot;: 20,\t\t\t\t&quot;id&quot;: 9,\t\t\t\t&quot;subjectName&quot;: &quot;SpringBoot自动装配原理是什么？&quot;,\t\t\t\t&quot;subjectDifficult&quot;: 1,\t\t\t\t&quot;subjectType&quot;: 4,\t\t\t\t&quot;subjectScore&quot;: 2,\t\t\t\t&quot;subjectParse&quot;: &quot;题目解析&quot;\t\t\t&#125;\t\t],\t\t&quot;start&quot;: 1,\t\t&quot;end&quot;: 20\t&#125;&#125;\n\n查询题目列表\n请求体：\n&#123;    &quot;pageNo&quot;: 2,    &quot;pageSize&quot;: 10,    &quot;labelId&quot;: 1,    &quot;categoryId&quot;: 2,    &quot;subjectDifficult&quot;: 1&#125;\n\n响应示例：\n&#123;\t&quot;success&quot;: true,\t&quot;code&quot;: 200,\t&quot;message&quot;: &quot;成功&quot;,\t&quot;data&quot;: &#123;\t\t&quot;pageNo&quot;: 1,\t\t&quot;pageSize&quot;: 20,\t\t&quot;total&quot;: 1,\t\t&quot;totalPages&quot;: 1,\t\t&quot;result&quot;: [\t\t\t&#123;\t\t\t\t&quot;pageNo&quot;: 1,\t\t\t\t&quot;pageSize&quot;: 20,\t\t\t\t&quot;id&quot;: 9,\t\t\t\t&quot;subjectName&quot;: &quot;SpringBoot自动装配原理是什么？&quot;,\t\t\t\t&quot;subjectDifficult&quot;: 1,\t\t\t\t&quot;subjectType&quot;: 4,\t\t\t\t&quot;subjectScore&quot;: 2,\t\t\t\t&quot;subjectParse&quot;: &quot;题目解析&quot;\t\t\t&#125;\t\t],\t\t&quot;start&quot;: 1,\t\t&quot;end&quot;: 20\t&#125;&#125;\n\n查询题目详情\n请求体：\n&#123;    &quot;id&quot;: 100&#125;\n\n响应体：\n&#123;\t&quot;success&quot;: true,\t&quot;code&quot;: 200,\t&quot;message&quot;: &quot;成功&quot;,\t&quot;data&quot;: &#123;\t\t&quot;pageNo&quot;: 1,\t\t&quot;pageSize&quot;: 20,\t\t&quot;id&quot;: 9,\t\t&quot;subjectName&quot;: &quot;SpringBoot自动装配原理是什么？&quot;,\t\t&quot;subjectDifficult&quot;: 1,\t\t&quot;subjectType&quot;: 4,\t\t&quot;subjectScore&quot;: 2,\t\t&quot;subjectParse&quot;: &quot;题目解析&quot;,\t\t&quot;subjectAnswer&quot;: &quot;题目答案&quot;,\t\t&quot;labelName&quot;: [\t\t\t&quot;SpringBoot&quot;,\t\t\t&quot;SpringMVC&quot;\t\t]\t&#125;&#125;\n\n题目模块接口开发题目模块接口开发是程序员社区项目中用于管理题目信息的核心部分。它涉及一系列接口，用于实现题目的新增、查询、更新和删除等操作。这些接口包括但不限于：\n\n新增单选、多选、判断和简答题目的接口，允许用户提交题目名称、难度、类型、分数、解析、所属分类和标签等信息。\n查询题目列表的接口，支持分页查询，并可根据分类、标签、难度等条件进行筛选。\n查询题目详情的接口，通过题目ID获取详细信息，包括题目类型、内容、选项、正确答案和解析等。\n\n代码层面，题目模块接口开发使用了Spring Boot框架来构建RESTful API，并采用了DTO（Data Transfer Object）和BO（Business Object）模式来分离数据传输和业务逻辑。通过MapStruct库实现了DTO与BO之间的自动转换，以简化代码并减少重复性工作。此外，服务层（Service）和数据访问层（DAO）的分离确保了业务逻辑的清晰和数据访问的高效性。\n在实现上，题目模块接口利用了Lombok库来自动生成getter、setter等方法，以及使用Spring框架的注解如@RestController和@RequestMapping来简化路由配置。日志记录采用SLF4J与Log4j2，确保了日志的灵活性和可配置性。此外，通过使用Spring的事务管理@Transactional，保证了数据操作的原子性和一致性。\n整体而言，题目模块接口开发为程序员社区项目提供了一个稳定、可扩展且易于维护的后端服务，以支持题目内容的管理与展示。\n//SubjectInfoBO@Datapublic class SubjectInfoBO extends PageInfo implements Serializable &#123;    /**     * 主键     */    private Long id;    /**     * 题目名称     */    private String subjectName;    /**     * 题目难度     */    private Integer subjectDifficult;    /**     * 出题人名     */    private String settleName;    /**     * 题目类型 1单选 2多选 3判断 4简答     */    private Integer subjectType;    /**     * 题目分数     */    private Integer subjectScore;    /**     * 题目解析     */    private String subjectParse;    /**     * 题目答案     */    private String subjectAnswer;    /**     * 分类id     */    private List&lt;Integer&gt; categoryIds;    /**     * 标签id     */    private List&lt;Integer&gt; labelIds;    /**     * 标签name     */    private List&lt;String&gt; labelName;    /**     * 答案选项     */    private List&lt;SubjectAnswerBO&gt; optionList;    private Long categoryId;    private Long labelId;    private String keyWord;    /**     * 创建人昵称     */    private String createUser;    /**     * 创建人头像     */    private String createUserAvatar;    /**     * 题目数量     */    private Integer subjectCount;    /**     * 是否被当前用户点赞     */    private Boolean liked;    /**     * 当前题目点赞的数量     */    private Integer likedCount;    /**     * 下一题     */    private Long nextSubjectId;    /**     * 上一题     */    private Long lastSubjectId;&#125;//PageResult@Datapublic class PageResult&lt;T&gt; implements Serializable &#123;    private Integer pageNo = 1;    private Integer pageSize = 20;    private Integer total = 0;    private Integer totalPages = 0;    private List&lt;T&gt; result = Collections.emptyList();    private Integer start = 1;    private Integer end = 0;    public void setRecords(List&lt;T&gt; result) &#123;        this.result = result;        if (result != null &amp;&amp; result.size() &gt; 0) &#123;            setTotal(result.size());        &#125;    &#125;    public void setTotal(Integer total) &#123;        this.total = total;        if (this.pageSize &gt; 0) &#123;            this.totalPages = (total / this.pageSize) + (total % this.pageSize == 0 ? 0 : 1);        &#125; else &#123;            this.totalPages = 0;        &#125;        this.start = (this.pageSize &gt; 0 ? (this.pageNo - 1) * this.pageSize : 0) + 1;        this.end = (this.start - 1 + this.pageSize * (this.pageNo &gt; 0 ? 1 : 0));    &#125;    public void setPageSize(Integer pageSize) &#123;        this.pageSize = pageSize;    &#125;    public void setPageNo(Integer pageNo) &#123;        this.pageNo = pageNo;    &#125;&#125;//PageInfo@Datapublic class PageInfo implements Serializable &#123;    private Integer pageNo = 1;    private Integer pageSize = 20;    public Integer getPageNo() &#123;        if (pageNo == null || pageNo &lt; 1) &#123;            return 1;        &#125;        return pageNo;    &#125;    public Integer getPageSize() &#123;        if (pageSize == null || pageSize &lt; 1 || pageSize &gt; Integer.MAX_VALUE) &#123;            return 20;        &#125;        return pageSize;    &#125;&#125;//SubjectAnswerBO@Datapublic class SubjectAnswerBO implements Serializable &#123;    /**     * 答案选项标识     */    private Integer optionType;    /**     * 答案     */    private String optionContent;    /**     * 是否正确     */    private Integer isCorrect;&#125;//SubjectAnswerDTO@Datapublic class SubjectAnswerDTO implements Serializable &#123;    /**     * 答案选项标识     */    private Integer optionType;    /**     * 答案     */    private String optionContent;    /**     * 是否正确     */    private Integer isCorrect;&#125;//SubjectOptionBO@Datapublic class SubjectOptionBO implements Serializable &#123;    /**     * 题目答案     */    private String subjectAnswer;    /**     * 答案选项     */    private List&lt;SubjectAnswerBO&gt; optionList;&#125;\n\n//SubjectInfo@Datapublic class SubjectInfo implements Serializable &#123;    private static final long serialVersionUID = -71318372165220898L;    /**     * 主键     */    private Long id;    /**     * 题目名称     */    private String subjectName;    /**     * 题目难度     */    private Integer subjectDifficult;    /**     * 出题人名     */    private String settleName;    /**     * 题目类型 1单选 2多选 3判断 4简答     */    private Integer subjectType;    /**     * 题目分数     */    private Integer subjectScore;    /**     * 题目解析     */    private String subjectParse;    /**     * 创建人     */    private String createdBy;    /**     * 创建时间     */    private Date createdTime;    /**     * 修改人     */    private String updateBy;    /**     * 修改时间     */    private Date updateTime;        private Integer isDeleted;    private Integer subjectCount;&#125;\n\n//SubjectInfoDTO@Datapublic class SubjectInfoDTO extends PageInfo implements Serializable &#123;    /**     * 主键     */    private Long id;    /**     * 题目名称     */    private String subjectName;    /**     * 题目难度     */    private Integer subjectDifficult;    /**     * 出题人名     */    private String settleName;    /**     * 题目类型 1单选 2多选 3判断 4简答     */    private Integer subjectType;    /**     * 题目分数     */    private Integer subjectScore;    /**     * 题目解析     */    private String subjectParse;    /**     * 题目答案     */    private String subjectAnswer;    /**     * 分类id     */    private List&lt;Integer&gt; categoryIds;    /**     * 标签id     */    private List&lt;Integer&gt; labelIds;    /**     * 答案选项     */    private List&lt;SubjectAnswerDTO&gt; optionList;    /**     * 标签name     */    private List&lt;String&gt; labelName;    private Long categoryId;    private Long labelId;    private String keyWord;    /**     * 创建人昵称     */    private String createUser;    /**     * 创建人头像     */    private String createUserAvatar;    /**     * 题目数量     */    private Integer subjectCount;    /**     * 是否被当前用户点赞     */    private Boolean liked;    /**     * 当前题目点赞的数量     */    private Integer likedCount;    /**     * 下一题     */    private Long nextSubjectId;    /**     * 上一题     */    private Long lastSubjectId;&#125;//SubjectTypeHandlerpublic interface SubjectTypeHandler &#123;    /**     * 枚举身份的识别     */    SubjectInfoTypeEnum getHandlerType();    /**     * 实际的题目的插入     */    void add(SubjectInfoBO subjectInfoBO);    /**     * 实际的题目的插入     */    SubjectOptionBO query(int subjectId);&#125;//BriefTypeHandler@Componentpublic class BriefTypeHandler implements SubjectTypeHandler&#123;    @Resource    private SubjectBriefService subjectBriefService;        @Override    public SubjectInfoTypeEnum getHandlerType() &#123;        return SubjectInfoTypeEnum.BRIEF;    &#125;    @Override    public void add(SubjectInfoBO subjectInfoBO) &#123;        SubjectBrief subjectBrief = BriefSubjectConverter.INSTANCE.convertBoToEntity(subjectInfoBO);        subjectBrief.setSubjectId(subjectInfoBO.getId().intValue());        subjectBrief.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());        subjectBriefService.insert(subjectBrief);    &#125;    @Override    public SubjectOptionBO query(int subjectId) &#123;        SubjectBrief subjectBrief = new SubjectBrief();        subjectBrief.setSubjectId(subjectId);        SubjectBrief result = subjectBriefService.queryByCondition(subjectBrief);        SubjectOptionBO subjectOptionBO = new SubjectOptionBO();        subjectOptionBO.setSubjectAnswer(result.getSubjectAnswer());        return subjectOptionBO;    &#125;&#125;//JudgeTypeHandler@Componentpublic class JudgeTypeHandler implements SubjectTypeHandler&#123;    @Resource    private SubjectJudgeService subjectJudgeService;        @Override    public SubjectInfoTypeEnum getHandlerType() &#123;        return SubjectInfoTypeEnum.JUDGE;    &#125;    @Override    public void add(SubjectInfoBO subjectInfoBO) &#123;        //判断题目的插入        SubjectJudge subjectJudge = new SubjectJudge();        SubjectAnswerBO subjectAnswerBO = subjectInfoBO.getOptionList().get(0);        subjectJudge.setSubjectId(subjectInfoBO.getId());        subjectJudge.setIsCorrect(subjectAnswerBO.getIsCorrect());        subjectJudge.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());        subjectJudgeService.insert(subjectJudge);    &#125;    @Override    public SubjectOptionBO query(int subjectId) &#123;        SubjectJudge subjectJudge = new SubjectJudge();        subjectJudge.setSubjectId(Long.valueOf(subjectId));        List&lt;SubjectJudge&gt; result = subjectJudgeService.queryByCondition(subjectJudge);        List&lt;SubjectAnswerBO&gt; subjectAnswerBOList = JudgeSubjectConverter.INSTANCE.convertEntityToBoList(result);        SubjectOptionBO subjectOptionBO = new SubjectOptionBO();        subjectOptionBO.setOptionList(subjectAnswerBOList);        return subjectOptionBO;    &#125;&#125;//MultipleTypeHandler@Componentpublic class MultipleTypeHandler implements SubjectTypeHandler&#123;    @Resource    private SubjectMultipleService subjectMultipleService;        @Override    public SubjectInfoTypeEnum getHandlerType() &#123;        return SubjectInfoTypeEnum.MULTIPLE;    &#125;    @Override    public void add(SubjectInfoBO subjectInfoBO) &#123;        //多选题目的插入        List&lt;SubjectMultiple&gt; subjectMultipleList = new LinkedList&lt;&gt;();        subjectInfoBO.getOptionList().forEach(option -&gt; &#123;            SubjectMultiple subjectMultiple = MultipleSubjectConverter.INSTANCE.convertBoToEntity(option);            subjectMultiple.setSubjectId(subjectInfoBO.getId());            subjectMultiple.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());            subjectMultipleList.add(subjectMultiple);        &#125;);        subjectMultipleService.batchInsert(subjectMultipleList);    &#125;    @Override    public SubjectOptionBO query(int subjectId) &#123;        SubjectMultiple subjectMultiple = new SubjectMultiple();        subjectMultiple.setSubjectId(Long.valueOf(subjectId));        List&lt;SubjectMultiple&gt; result = subjectMultipleService.queryByCondition(subjectMultiple);        List&lt;SubjectAnswerBO&gt; subjectAnswerBOList = MultipleSubjectConverter.INSTANCE.convertEntityToBoList(result);        SubjectOptionBO subjectOptionBO = new SubjectOptionBO();        subjectOptionBO.setOptionList(subjectAnswerBOList);        return subjectOptionBO;    &#125;&#125;//RadioTypeHandler@Componentpublic class RadioTypeHandler implements SubjectTypeHandler &#123;    @Resource    private SubjectRadioService subjectRadioService;    @Override    public SubjectInfoTypeEnum getHandlerType() &#123;        return SubjectInfoTypeEnum.RADIO;    &#125;    @Override    public void add(SubjectInfoBO subjectInfoBO) &#123;        //单选题目的插入        List&lt;SubjectRadio&gt; subjectRadioList = new LinkedList&lt;&gt;();        subjectInfoBO.getOptionList().forEach(option -&gt; &#123;            SubjectRadio subjectRadio = RadioSubjectConverter.INSTANCE.convertBoToEntity(option);            subjectRadio.setSubjectId(subjectInfoBO.getId());            subjectRadio.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());            subjectRadioList.add(subjectRadio);        &#125;);        subjectRadioService.batchInsert(subjectRadioList);    &#125;    @Override    public SubjectOptionBO query(int subjectId) &#123;        SubjectRadio subjectRadio = new SubjectRadio();        subjectRadio.setSubjectId(Long.valueOf(subjectId));        List&lt;SubjectRadio&gt; result = subjectRadioService.queryByCondition(subjectRadio);        List&lt;SubjectAnswerBO&gt; subjectAnswerBOList = RadioSubjectConverter.INSTANCE.convertEntityToBoList(result);        SubjectOptionBO subjectOptionBO = new SubjectOptionBO();        subjectOptionBO.setOptionList(subjectAnswerBOList);        return subjectOptionBO;    &#125;&#125;\n\n//SubjectController@RestController@Slf4j@RequestMapping(&quot;/subject&quot;)public class SubjectController &#123;    @Resource    private SubjectInfoDomainService subjectInfoDomainService;    @Resource    private RocketMQTemplate rocketMQTemplate;    /**     * 新增题目     */    @PostMapping(&quot;/add&quot;)    public Result&lt;Boolean&gt; add(@RequestBody SubjectInfoDTO subjectInfoDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;SubjectController.add.dto:&#123;&#125;&quot;, JSON.toJSONString(subjectInfoDTO));            &#125;            Preconditions.checkArgument(!StringUtils.isBlank(subjectInfoDTO.getSubjectName()),                    &quot;题目名称不能为空&quot;);            Preconditions.checkNotNull(subjectInfoDTO.getSubjectDifficult(), &quot;题目难度不能为空&quot;);            Preconditions.checkNotNull(subjectInfoDTO.getSubjectType(), &quot;题目类型不能为空&quot;);            Preconditions.checkNotNull(subjectInfoDTO.getSubjectScore(), &quot;题目分数不能为空&quot;);            Preconditions.checkArgument(!CollectionUtils.isEmpty(subjectInfoDTO.getCategoryIds())                    , &quot;分类id不能为空&quot;);            Preconditions.checkArgument(!CollectionUtils.isEmpty(subjectInfoDTO.getLabelIds())                    , &quot;标签id不能为空&quot;);            SubjectInfoBO subjectInfoBO = SubjectInfoDTOConverter.INSTANCE.convertDTOToBO(subjectInfoDTO); //转为BO            List&lt;SubjectAnswerBO&gt; subjectAnswerBOS =                    SubjectAnswerDTOConverter.INSTANCE.convertListDTOToBO(subjectInfoDTO.getOptionList()); //单独添加回答            subjectInfoBO.setOptionList(subjectAnswerBOS);            subjectInfoDomainService.add(subjectInfoBO);            return Result.ok(true);        &#125; catch (Exception e) &#123;            log.error(&quot;SubjectCategoryController.add.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;新增题目失败&quot;);        &#125;    &#125;    /**     * 查询题目列表     */    @PostMapping(&quot;/getSubjectPage&quot;)    public Result&lt;PageResult&lt;SubjectInfoDTO&gt;&gt; getSubjectPage(@RequestBody SubjectInfoDTO subjectInfoDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;SubjectController.getSubjectPage.dto:&#123;&#125;&quot;, JSON.toJSONString(subjectInfoDTO));            &#125;            Preconditions.checkNotNull(subjectInfoDTO.getCategoryId(), &quot;分类id不能为空&quot;);            Preconditions.checkNotNull(subjectInfoDTO.getLabelId(), &quot;标签id不能为空&quot;);            SubjectInfoBO subjectInfoBO = SubjectInfoDTOConverter.INSTANCE.convertDTOToBO(subjectInfoDTO);            subjectInfoBO.setPageNo(subjectInfoDTO.getPageNo()); //页码            subjectInfoBO.setPageSize(subjectInfoDTO.getPageSize()); //大小            PageResult&lt;SubjectInfoBO&gt; boPageResult = subjectInfoDomainService.getSubjectPage(subjectInfoBO);            return Result.ok(boPageResult);        &#125; catch (Exception e) &#123;            log.error(&quot;SubjectCategoryController.add.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;分页查询题目失败&quot;);        &#125;    &#125;    /**     * 查询题目信息     */    @PostMapping(&quot;/querySubjectInfo&quot;)    public Result&lt;SubjectInfoDTO&gt; querySubjectInfo(@RequestBody SubjectInfoDTO subjectInfoDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;SubjectController.querySubjectInfo.dto:&#123;&#125;&quot;, JSON.toJSONString(subjectInfoDTO));            &#125;            Preconditions.checkNotNull(subjectInfoDTO.getId(), &quot;题目id不能为空&quot;);            SubjectInfoBO subjectInfoBO = SubjectInfoDTOConverter.INSTANCE.convertDTOToBO(subjectInfoDTO);            SubjectInfoBO boResult = subjectInfoDomainService.querySubjectInfo(subjectInfoBO);            SubjectInfoDTO dto = SubjectInfoDTOConverter.INSTANCE.convertBOToDTO(boResult);            return Result.ok(dto);        &#125; catch (Exception e) &#123;            log.error(&quot;SubjectCategoryController.add.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;查询题目详情失败&quot;);        &#125;    &#125;    /**     * 全文检索     */    @PostMapping(&quot;/getSubjectPageBySearch&quot;)    public Result&lt;PageResult&lt;SubjectInfoEs&gt;&gt; getSubjectPageBySearch(@RequestBody SubjectInfoDTO subjectInfoDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;SubjectController.getSubjectPageBySearch.dto:&#123;&#125;&quot;, JSON.toJSONString(subjectInfoDTO));            &#125;            Preconditions.checkArgument(StringUtils.isNotBlank(subjectInfoDTO.getKeyWord()), &quot;关键词不能为空&quot;);            SubjectInfoBO subjectInfoBO = SubjectInfoDTOConverter.INSTANCE.convertDTOToBO(subjectInfoDTO);            subjectInfoBO.setPageNo(subjectInfoDTO.getPageNo());            subjectInfoBO.setPageSize(subjectInfoDTO.getPageSize());            PageResult&lt;SubjectInfoEs&gt; boPageResult = subjectInfoDomainService.getSubjectPageBySearch(subjectInfoBO);            return Result.ok(boPageResult);        &#125; catch (Exception e) &#123;            log.error(&quot;SubjectCategoryController.getSubjectPageBySearch.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;全文检索失败&quot;);        &#125;    &#125;    /**     * 获取题目贡献榜     */    @PostMapping(&quot;/getContributeList&quot;)    public Result&lt;List&lt;SubjectInfoDTO&gt;&gt; getContributeList() &#123;        try &#123;            List&lt;SubjectInfoBO&gt; boList = subjectInfoDomainService.getContributeList();            List&lt;SubjectInfoDTO&gt; dtoList = SubjectInfoDTOConverter.INSTANCE.convertBOToDTOList(boList);            return Result.ok(dtoList);        &#125; catch (Exception e) &#123;            log.error(&quot;SubjectCategoryController.getContributeList.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;获取贡献榜失败&quot;);        &#125;    &#125;    /**     * 测试mq发送     */    @PostMapping(&quot;/pushMessage&quot;)    public Result&lt;Boolean&gt; pushMessage(@Param(&quot;id&quot;) int id) &#123;        rocketMQTemplate.convertAndSend(&quot;test-topic&quot;, &quot;早上好&quot; + id);        return Result.ok(true);    &#125;&#125;\n\n//SubjectInfoDTOConverter@Mapperpublic interface SubjectInfoDTOConverter &#123;    SubjectInfoDTOConverter INSTANCE = Mappers.getMapper(SubjectInfoDTOConverter.class);    SubjectInfoBO convertDTOToBO(SubjectInfoDTO subjectInfoDTO);    SubjectInfoDTO convertBOToDTO(SubjectInfoBO subjectInfoBO);    List&lt;SubjectInfoDTO&gt; convertBOToDTOList(List&lt;SubjectInfoBO&gt; subjectInfoBO);&#125;//SubjectAnswerDTOConverter@Mapperpublic interface SubjectAnswerDTOConverter &#123;    SubjectAnswerDTOConverter INSTANCE = Mappers.getMapper(SubjectAnswerDTOConverter.class);    SubjectAnswerBO convertDTOToBO(SubjectAnswerDTO subjectAnswerDTO);    List&lt;SubjectAnswerBO&gt; convertListDTOToBO(List&lt;SubjectAnswerDTO&gt; dtoList);&#125;//SubjectInfoConverter@Mapperpublic interface SubjectInfoConverter &#123;    SubjectInfoConverter INSTANCE = Mappers.getMapper(SubjectInfoConverter.class);    SubjectInfo convertBoToInfo(SubjectInfoBO subjectInfoBO);    SubjectInfoBO convertOptionToBo(SubjectOptionBO subjectOptionBO);    SubjectInfoBO convertOptionAndInfoToBo(SubjectOptionBO subjectOptionBO,SubjectInfo subjectInfo);    List&lt;SubjectInfoBO&gt; convertListInfoToBO(List&lt;SubjectInfo&gt; subjectInfoList);&#125;\n\n//SubjectInfoDomainServicepublic interface SubjectInfoDomainService &#123;    /**     * 新增题目     */    void add(SubjectInfoBO subjectInfoBO);    /**     * 分页查询     */    PageResult&lt;SubjectInfoBO&gt; getSubjectPage(SubjectInfoBO subjectInfoBO);    /**     * 查询题目信息     */    SubjectInfoBO querySubjectInfo(SubjectInfoBO subjectInfoBO);    /**     * 全文检索     */    PageResult&lt;SubjectInfoEs&gt; getSubjectPageBySearch(SubjectInfoBO subjectInfoBO);    List&lt;SubjectInfoBO&gt; getContributeList();&#125;\n\n@Service@Slf4jpublic class SubjectInfoDomainServiceImpl implements SubjectInfoDomainService &#123;    @Resource    private SubjectInfoService subjectInfoService;    @Resource    private SubjectMappingService subjectMappingService;    @Resource    private SubjectLabelService subjectLabelService;    @Resource    private SubjectTypeHandlerFactory subjectTypeHandlerFactory;    @Resource    private SubjectEsService subjectEsService;    @Resource    private SubjectLikedDomainService subjectLikedDomainService;    @Resource    private UserRpc userRpc;    @Resource    private RedisUtil redisUtil;    private static final String RANK_KEY = &quot;subject_rank&quot;;    @Override    @Transactional(rollbackFor = Exception.class)    public void add(SubjectInfoBO subjectInfoBO) &#123;        if (log.isInfoEnabled()) &#123;            log.info(&quot;SubjectInfoDomainServiceImpl.add.bo:&#123;&#125;&quot;, JSON.toJSONString(subjectInfoBO));        &#125;        SubjectInfo subjectInfo = SubjectInfoConverter.INSTANCE.convertBoToInfo(subjectInfoBO);        subjectInfo.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());        subjectInfoService.insert(subjectInfo);        SubjectTypeHandler handler = subjectTypeHandlerFactory.getHandler(subjectInfo.getSubjectType()); //题目类型关系工厂        subjectInfoBO.setId(subjectInfo.getId());        handler.add(subjectInfoBO);        List&lt;Integer&gt; categoryIds = subjectInfoBO.getCategoryIds();        List&lt;Integer&gt; labelIds = subjectInfoBO.getLabelIds();        List&lt;SubjectMapping&gt; mappingList = new LinkedList&lt;&gt;();        categoryIds.forEach(categoryId -&gt; &#123; //category和label多对多的关系            labelIds.forEach(labelId -&gt; &#123;                SubjectMapping subjectMapping = new SubjectMapping();                subjectMapping.setSubjectId(subjectInfo.getId());                subjectMapping.setCategoryId(Long.valueOf(categoryId));                subjectMapping.setLabelId(Long.valueOf(labelId));                subjectMapping.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());                mappingList.add(subjectMapping);            &#125;);        &#125;);        subjectMappingService.batchInsert(mappingList);        //同步到es        SubjectInfoEs subjectInfoEs = new SubjectInfoEs();        subjectInfoEs.setDocId(new IdWorkerUtil(1, 1, 1).nextId());        subjectInfoEs.setSubjectId(subjectInfo.getId());        subjectInfoEs.setSubjectAnswer(subjectInfoBO.getSubjectAnswer());        subjectInfoEs.setCreateTime(new Date().getTime());        subjectInfoEs.setCreateUser(&quot;Roger&quot;);        subjectInfoEs.setSubjectName(subjectInfo.getSubjectName());        subjectInfoEs.setSubjectType(subjectInfo.getSubjectType());        subjectEsService.insert(subjectInfoEs);        //redis放入zadd计入排行榜        redisUtil.addScore(RANK_KEY, LoginUtil.getLoginId(), 1);    &#125;//实现了分页查询逻辑，并且将查询到的数据和相关的标签信息封装到业务对象中，最后包装成一个分页结果返回。    @Override    public PageResult&lt;SubjectInfoBO&gt; getSubjectPage(SubjectInfoBO subjectInfoBO) &#123;        PageResult&lt;SubjectInfoBO&gt; pageResult = new PageResult&lt;&gt;();        pageResult.setPageNo(subjectInfoBO.getPageNo());        pageResult.setPageSize(subjectInfoBO.getPageSize());        int start = (subjectInfoBO.getPageNo() - 1) * subjectInfoBO.getPageSize();        SubjectInfo subjectInfo = SubjectInfoConverter.INSTANCE.convertBoToInfo(subjectInfoBO);        int count = subjectInfoService.countByCondition(subjectInfo, subjectInfoBO.getCategoryId()                , subjectInfoBO.getLabelId()); //根据条件查询满足要求的题目总数。        if (count == 0) &#123;            return pageResult;        &#125;        List&lt;SubjectInfo&gt; subjectInfoList = subjectInfoService.queryPage(subjectInfo, subjectInfoBO.getCategoryId()                , subjectInfoBO.getLabelId(), start, subjectInfoBO.getPageSize());        List&lt;SubjectInfoBO&gt; subjectInfoBOS = SubjectInfoConverter.INSTANCE.convertListInfoToBO(subjectInfoList);        subjectInfoBOS.forEach(info -&gt; &#123;            SubjectMapping subjectMapping = new SubjectMapping();            subjectMapping.setSubjectId(info.getId());            List&lt;SubjectMapping&gt; mappingList = subjectMappingService.queryLabelId(subjectMapping);            List&lt;Long&gt; labelIds = mappingList.stream().map(SubjectMapping::getLabelId).collect(Collectors.toList());            List&lt;SubjectLabel&gt; labelList = subjectLabelService.batchQueryById(labelIds);            List&lt;String&gt; labelNames = labelList.stream().map(SubjectLabel::getLabelName).collect(Collectors.toList());            info.setLabelName(labelNames);        &#125;);        pageResult.setRecords(subjectInfoBOS);        pageResult.setTotal(count);        return pageResult;    &#125;    @Override    public SubjectInfoBO querySubjectInfo(SubjectInfoBO subjectInfoBO) &#123;        SubjectInfo subjectInfo = subjectInfoService.queryById(subjectInfoBO.getId());        SubjectTypeHandler handler = subjectTypeHandlerFactory.getHandler(subjectInfo.getSubjectType());        SubjectOptionBO optionBO = handler.query(subjectInfo.getId().intValue());        SubjectInfoBO bo = SubjectInfoConverter.INSTANCE.convertOptionAndInfoToBo(optionBO, subjectInfo);        SubjectMapping subjectMapping = new SubjectMapping();        subjectMapping.setSubjectId(subjectInfo.getId());        subjectMapping.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());        List&lt;SubjectMapping&gt; mappingList = subjectMappingService.queryLabelId(subjectMapping);        List&lt;Long&gt; labelIdList = mappingList.stream().map(SubjectMapping::getLabelId).collect(Collectors.toList());        List&lt;SubjectLabel&gt; labelList = subjectLabelService.batchQueryById(labelIdList);        List&lt;String&gt; labelNameList = labelList.stream().map(SubjectLabel::getLabelName).collect(Collectors.toList());        bo.setLabelName(labelNameList);        bo.setLiked(subjectLikedDomainService.isLiked(subjectInfoBO.getId().toString(), LoginUtil.getLoginId()));        bo.setLikedCount(subjectLikedDomainService.getLikedCount(subjectInfoBO.getId().toString()));        assembleSubjectCursor(subjectInfoBO, bo);        return bo;    &#125;    private void assembleSubjectCursor(SubjectInfoBO subjectInfoBO, SubjectInfoBO bo) &#123;        Long categoryId = subjectInfoBO.getCategoryId();        Long labelId = subjectInfoBO.getLabelId();        Long subjectId = subjectInfoBO.getId();        if (Objects.isNull(categoryId) || Objects.isNull(labelId)) &#123;            return;        &#125;        Long nextSubjectId = subjectInfoService.querySubjectIdCursor(subjectId, categoryId, labelId, 1);        bo.setNextSubjectId(nextSubjectId);        Long lastSubjectId = subjectInfoService.querySubjectIdCursor(subjectId, categoryId, labelId, 0);        bo.setLastSubjectId(lastSubjectId);    &#125;    @Override    public PageResult&lt;SubjectInfoEs&gt; getSubjectPageBySearch(SubjectInfoBO subjectInfoBO) &#123;        SubjectInfoEs subjectInfoEs = new SubjectInfoEs();        subjectInfoEs.setPageNo(subjectInfoBO.getPageNo());        subjectInfoEs.setPageSize(subjectInfoBO.getPageSize());        subjectInfoEs.setKeyWord(subjectInfoBO.getKeyWord());        return subjectEsService.querySubjectList(subjectInfoEs);    &#125;    @Override    public List&lt;SubjectInfoBO&gt; getContributeList() &#123;        Set&lt;ZSetOperations.TypedTuple&lt;String&gt;&gt; typedTuples = redisUtil.rankWithScore(RANK_KEY, 0, 5);        if (log.isInfoEnabled()) &#123;            log.info(&quot;getContributeList.typedTuples:&#123;&#125;&quot;, JSON.toJSONString(typedTuples));        &#125;        if (CollectionUtils.isEmpty(typedTuples)) &#123;            return Collections.emptyList();        &#125;        List&lt;SubjectInfoBO&gt; boList = new LinkedList&lt;&gt;();        typedTuples.forEach((rank -&gt; &#123;            SubjectInfoBO subjectInfoBO = new SubjectInfoBO();            subjectInfoBO.setSubjectCount(rank.getScore().intValue());            UserInfo userInfo = userRpc.getUserInfo(rank.getValue());            subjectInfoBO.setCreateUser(userInfo.getNickName());            subjectInfoBO.setCreateUserAvatar(userInfo.getAvatar());            boList.add(subjectInfoBO);        &#125;));        return boList;    &#125;&#125;\n\n@Service(&quot;subjectInfoService&quot;)public class SubjectInfoServiceImpl implements SubjectInfoService &#123;    @Resource    private SubjectInfoDao subjectInfoDao;    /**     * 通过ID查询单条数据     *     * @param id 主键     * @return 实例对象     */    @Override    public SubjectInfo queryById(Long id) &#123;        return this.subjectInfoDao.queryById(id);    &#125;    /**     * 新增数据     *     * @param subjectInfo 实例对象     * @return 实例对象     */    @Override    public SubjectInfo insert(SubjectInfo subjectInfo) &#123;        this.subjectInfoDao.insert(subjectInfo);        return subjectInfo;    &#125;    /**     * 修改数据     *     * @param subjectInfo 实例对象     * @return 实例对象     */    @Override    public SubjectInfo update(SubjectInfo subjectInfo) &#123;        this.subjectInfoDao.update(subjectInfo);        return this.queryById(subjectInfo.getId());    &#125;    /**     * 通过主键删除数据     *     * @param id 主键     * @return 是否成功     */    @Override    public boolean deleteById(Long id) &#123;        return this.subjectInfoDao.deleteById(id) &gt; 0;    &#125;    @Override    public int countByCondition(SubjectInfo subjectInfo, Long categoryId, Long labelId) &#123;        return this.subjectInfoDao.countByCondition(subjectInfo, categoryId, labelId);    &#125;    @Override    public List&lt;SubjectInfo&gt; queryPage(SubjectInfo subjectInfo, Long categoryId, Long labelId, int start, Integer pageSize) &#123;        return this.subjectInfoDao.queryPage(subjectInfo, categoryId, labelId, start, pageSize);    &#125;    @Override    public List&lt;SubjectInfo&gt; getContributeCount() &#123;        return this.subjectInfoDao.getContributeCount();    &#125;    @Override    public Long querySubjectIdCursor(Long subjectId, Long categoryId, Long labelId, int cursor) &#123;        return this.subjectInfoDao.querySubjectIdCursor(subjectId, categoryId, labelId, cursor);    &#125;&#125;\n\npublic interface SubjectInfoService &#123;    /**     * 通过ID查询单条数据     *     * @param id 主键     * @return 实例对象     */    SubjectInfo queryById(Long id);    /**     * 新增数据     *     * @param subjectInfo 实例对象     * @return 实例对象     */    SubjectInfo insert(SubjectInfo subjectInfo);    /**     * 修改数据     *     * @param subjectInfo 实例对象     * @return 实例对象     */    SubjectInfo update(SubjectInfo subjectInfo);    /**     * 通过主键删除数据     *     * @param id 主键     * @return 是否成功     */    boolean deleteById(Long id);    int countByCondition(SubjectInfo subjectInfo, Long categoryId, Long labelId);    List&lt;SubjectInfo&gt; queryPage(SubjectInfo subjectInfo, Long categoryId, Long labelId, int start, Integer pageSize);    List&lt;SubjectInfo&gt; getContributeCount();    Long querySubjectIdCursor(Long subjectId, Long categoryId, Long labelId, int cursor);&#125;\n\npublic interface SubjectInfoDao &#123;    /**     * 通过ID查询单条数据     *     * @param id 主键     * @return 实例对象     */    SubjectInfo queryById(Long id);    /**     * 查询指定行数据     *     * @param subjectInfo 查询条件     * @return 对象列表     */    List&lt;SubjectInfo&gt; queryAllByLimit(SubjectInfo subjectInfo);    /**     * 统计总行数     *     * @param subjectInfo 查询条件     * @return 总行数     */    long count(SubjectInfo subjectInfo);    /**     * 新增数据     *     * @param subjectInfo 实例对象     * @return 影响行数     */    int insert(SubjectInfo subjectInfo);    /**     * 批量新增数据（MyBatis原生foreach方法）     *     * @param entities List&lt;SubjectInfo&gt; 实例对象列表     * @return 影响行数     */    int insertBatch(@Param(&quot;entities&quot;) List&lt;SubjectInfo&gt; entities);    /**     * 批量新增或按主键更新数据（MyBatis原生foreach方法）     *     * @param entities List&lt;SubjectInfo&gt; 实例对象列表     * @return 影响行数     * @throws org.springframework.jdbc.BadSqlGrammarException 入参是空List的时候会抛SQL语句错误的异常，请自行校验入参     */    int insertOrUpdateBatch(@Param(&quot;entities&quot;) List&lt;SubjectInfo&gt; entities);    /**     * 修改数据     *     * @param subjectInfo 实例对象     * @return 影响行数     */    int update(SubjectInfo subjectInfo);    /**     * 通过主键删除数据     *     * @param id 主键     * @return 影响行数     */    int deleteById(Long id);    int countByCondition(@Param(&quot;subjectInfo&quot;) SubjectInfo subjectInfo,                         @Param(&quot;categoryId&quot;) Long categoryId,                         @Param(&quot;labelId&quot;) Long labelId);    List&lt;SubjectInfo&gt; queryPage(@Param(&quot;subjectInfo&quot;) SubjectInfo subjectInfo,                                @Param(&quot;categoryId&quot;) Long categoryId,                                @Param(&quot;labelId&quot;) Long labelId,                                @Param(&quot;start&quot;) int start,                                @Param(&quot;pageSize&quot;) Integer pageSize);    List&lt;SubjectInfo&gt; getContributeCount();    Long querySubjectIdCursor(@Param(&quot;subjectId&quot;) Long subjectId,                              @Param(&quot;categoryId&quot;) Long categoryId,                              @Param(&quot;labelId&quot;) Long labelId,                              @Param(&quot;cursor&quot;) int cursor);&#125;\n\nJacksonConverter（对于返回值的处理）\npackage com.jingdianjichi.subject.application.config;import com.fasterxml.jackson.annotation.JsonInclude;import com.fasterxml.jackson.databind.ObjectMapper;import com.fasterxml.jackson.databind.SerializationFeature;import com.jingdianjichi.subject.application.interceptor.LoginInterceptor;import org.springframework.context.annotation.Configuration;import org.springframework.http.converter.HttpMessageConverter;import org.springframework.http.converter.json.MappingJackson2HttpMessageConverter;import org.springframework.web.servlet.config.annotation.InterceptorRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport;import java.util.List;/** * mvc的全局处理 * * @author: ChickenWing * @date: 2023/10/7 */@Configurationpublic class GlobalConfig extends WebMvcConfigurationSupport &#123;    @Override    protected void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123;        super.configureMessageConverters(converters);        converters.add(mappingJackson2HttpMessageConverter());    &#125;    @Override    protected void addInterceptors(InterceptorRegistry registry) &#123;        registry.addInterceptor(new LoginInterceptor())                .addPathPatterns(&quot;/**&quot;);    &#125;    /**     * 自定义mappingJackson2HttpMessageConverter     * 目前实现：空值忽略，空字段可返回     */    private MappingJackson2HttpMessageConverter mappingJackson2HttpMessageConverter() &#123;        ObjectMapper objectMapper = new ObjectMapper();        objectMapper.configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false); //这行代码配置ObjectMapper，使其在序列化时不会因空Bean而失败。        objectMapper.setSerializationInclusion(JsonInclude.Include.NON_NULL); //这行代码设置序列化时只包含非空的字段。（即返回的json结果中不会含有值为Null的字段）        return new MappingJackson2HttpMessageConverter(objectMapper);    &#125;&#125;\n\nSQL拦截器自动翻译（mybatis提供的）\nSqlStatementInterceptor 主要作用是监控MyBatis的SQL执行时间，并根据不同的执行时间记录不同级别的日志\nMybatisPlusAllSqlLog这个类实现了InnerInterceptor接口，它是MyBatis-Plus框架提供的一个内部拦截器接口，用于拦截SQL的执行。这个类有两个主要的重写方法：\n\nbeforeQuery: 在查询执行前调用，记录SQL信息。\nbeforeUpdate: 在更新执行前调用，记录SQL信息。\n\n//SqlStatementInterceptor 主要作用是监控MyBatis的SQL执行时间，并根据不同的执行时间记录不同级别的日志package com.jingdianjichi.subject.infra.config;import org.apache.ibatis.cache.CacheKey;import org.apache.ibatis.executor.Executor;import org.apache.ibatis.mapping.BoundSql;import org.apache.ibatis.mapping.MappedStatement;import org.apache.ibatis.plugin.*;import org.apache.ibatis.session.ResultHandler;import org.apache.ibatis.session.RowBounds;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.Properties;@Intercepts(&#123;        @Signature(type = Executor.class, method = &quot;update&quot;, args = &#123;MappedStatement.class,                Object.class&#125;),        @Signature(type = Executor.class, method = &quot;query&quot;, args = &#123;MappedStatement.class,                Object.class, RowBounds.class, ResultHandler.class, CacheKey.class, BoundSql.class&#125;)&#125;)public class SqlStatementInterceptor implements Interceptor &#123;    public static final Logger log = LoggerFactory.getLogger(&quot;sys-sql&quot;);    @Override    public Object intercept(Invocation invocation) throws Throwable &#123;        long startTime = System.currentTimeMillis();        try &#123;            return invocation.proceed();        &#125; finally &#123;            long timeConsuming = System.currentTimeMillis() - startTime;            log.info(&quot;执行SQL:&#123;&#125;ms&quot;, timeConsuming);            if (timeConsuming &gt; 999 &amp;&amp; timeConsuming &lt; 5000) &#123;                log.info(&quot;执行SQL大于1s:&#123;&#125;ms&quot;, timeConsuming);            &#125; else if (timeConsuming &gt;= 5000 &amp;&amp; timeConsuming &lt; 10000) &#123;                log.info(&quot;执行SQL大于5s:&#123;&#125;ms&quot;, timeConsuming);            &#125; else if (timeConsuming &gt;= 10000) &#123;                log.info(&quot;执行SQL大于10s:&#123;&#125;ms&quot;, timeConsuming);            &#125;        &#125;    &#125;    @Override    public Object plugin(Object target) &#123;        return Plugin.wrap(target, this);    &#125;    @Override    public void setProperties(Properties properties) &#123;    &#125;&#125;//MybatisPlusAllSqlLogpublic class MybatisPlusAllSqlLog implements InnerInterceptor &#123;    public static final Logger log = LoggerFactory.getLogger(&quot;sys-sql&quot;);    @Override    public void beforeQuery(Executor executor, MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123;        logInfo(boundSql, ms, parameter);    &#125;    @Override    public void beforeUpdate(Executor executor, MappedStatement ms, Object parameter) throws SQLException &#123;        BoundSql boundSql = ms.getBoundSql(parameter);        logInfo(boundSql, ms, parameter);    &#125;    private static void logInfo(BoundSql boundSql, MappedStatement ms, Object parameter) &#123;        try &#123;            log.info(&quot;parameter = &quot; + parameter);            // 获取到节点的id,即sql语句的id            String sqlId = ms.getId();            log.info(&quot;sqlId = &quot; + sqlId);            // 获取节点的配置            Configuration configuration = ms.getConfiguration();            // 获取到最终的sql语句            String sql = getSql(configuration, boundSql, sqlId);            log.info(&quot;完整的sql:&#123;&#125;&quot;, sql);        &#125; catch (Exception e) &#123;            log.error(&quot;异常:&#123;&#125;&quot;, e.getLocalizedMessage(), e);        &#125;    &#125;    // 封装了一下sql语句，使得结果返回完整xml路径下的sql语句节点id + sql语句    public static String getSql(Configuration configuration, BoundSql boundSql, String sqlId) &#123;        return sqlId + &quot;:&quot; + showSql(configuration, boundSql);    &#125;    // 进行？的替换    public static String showSql(Configuration configuration, BoundSql boundSql) &#123;        // 获取参数        Object parameterObject = boundSql.getParameterObject();        List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings();        // sql语句中多个空格都用一个空格代替        String sql = boundSql.getSql().replaceAll(&quot;[\\\\s]+&quot;, &quot; &quot;);        if (!CollectionUtils.isEmpty(parameterMappings) &amp;&amp; parameterObject != null) &#123;            // 获取类型处理器注册器，类型处理器的功能是进行java类型和数据库类型的转换            TypeHandlerRegistry typeHandlerRegistry = configuration.getTypeHandlerRegistry();            // 如果根据parameterObject.getClass(）可以找到对应的类型，则替换            if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) &#123;                sql = sql.replaceFirst(&quot;\\\\?&quot;,                        Matcher.quoteReplacement(getParameterValue(parameterObject)));            &#125; else &#123;                // MetaObject主要是封装了originalObject对象，提供了get和set的方法用于获取和设置originalObject的属性值,主要支持对JavaBean、Collection、Map三种类型对象的操作                MetaObject metaObject = configuration.newMetaObject(parameterObject);                for (ParameterMapping parameterMapping : parameterMappings) &#123;                    String propertyName = parameterMapping.getProperty();                    if (metaObject.hasGetter(propertyName)) &#123;                        Object obj = metaObject.getValue(propertyName);                        sql = sql.replaceFirst(&quot;\\\\?&quot;,                                Matcher.quoteReplacement(getParameterValue(obj)));                    &#125; else if (boundSql.hasAdditionalParameter(propertyName)) &#123;                        // 该分支是动态sql                        Object obj = boundSql.getAdditionalParameter(propertyName);                        sql = sql.replaceFirst(&quot;\\\\?&quot;,                                Matcher.quoteReplacement(getParameterValue(obj)));                    &#125; else &#123;                        // 打印出缺失，提醒该参数缺失并防止错位                        sql = sql.replaceFirst(&quot;\\\\?&quot;, &quot;缺失&quot;);                    &#125;                &#125;            &#125;        &#125;        return sql;    &#125;    // 如果参数是String，则添加单引号， 如果是日期，则转换为时间格式器并加单引号； 对参数是null和不是null的情况作了处理    private static String getParameterValue(Object obj) &#123;        String value;        if (obj instanceof String) &#123;            value = &quot;&#x27;&quot; + obj.toString() + &quot;&#x27;&quot;;        &#125; else if (obj instanceof Date) &#123;            DateFormat formatter = DateFormat.getDateTimeInstance(DateFormat.DEFAULT,                    DateFormat.DEFAULT, Locale.CHINA);            value = &quot;&#x27;&quot; + formatter.format(new Date()) + &quot;&#x27;&quot;;        &#125; else &#123;            if (obj != null) &#123;                value = obj.toString();            &#125; else &#123;                value = &quot;&quot;;            &#125;        &#125;        return value;    &#125;&#125;\n\n部署传统部署形式在starter模块的pom.xml中\n//配置的版本等内容&lt;properties&gt;        &lt;maven.compiler.source&gt;8&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;8&lt;/maven.compiler.target&gt;        &lt;java.version&gt;1.8&lt;/java.version&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;        &lt;spring-boot.version&gt;2.4.2&lt;/spring-boot.version&gt;        &lt;spring-cloud-alibaba.version&gt;2021.1&lt;/spring-cloud-alibaba.version&gt;        &lt;spring-cloud.version&gt;2020.0.6&lt;/spring-cloud.version&gt;&lt;/properties&gt;....//打包的名字&lt;build&gt;        &lt;finalName&gt;$&#123;project.artifactId&#125;&lt;/finalName&gt;        &lt;!--打包成jar包时的名字--&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;                &lt;version&gt;2.3.0.RELEASE&lt;/version&gt;                &lt;executions&gt;                    &lt;execution&gt;                        &lt;goals&gt;                            &lt;goal&gt;repackage&lt;/goal&gt;                        &lt;/goals&gt;                    &lt;/execution&gt;                &lt;/executions&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;&lt;/build&gt;\n\n打包好Jar包,复制到服务器上,java -jar运行即可\n但是这样还是比较复杂\nCI&#x2F;CD jenkins自动打包集成和部署docker search jenkinsdocker pull jenkins/jenkins:ltsdocker run -d -u root -p 8080:8080 -p 50000:50000 -v /var/jenkins_home:/var/jenkins_home -v /etc/localtime:/etc/localtime --name jenkins jenkins/jenkins:ltsdocker ps -a\n\n然后配置一些密码，maven，拉一些包，配置pom.xml，配置路径，就可以打包好，写一个shell脚本然后运行就行了\n[shell脚本语言(超全超详细)-CSDN博客](https://blog.csdn.net/weixin_43288201/article/details/105643692?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=shell 脚本 ^&amp;utm_medium&#x3D;distribute.pc_search_result.none-task-blog-2allsobaiduweb~default-5-105643692.142^v100^pc_search_result_base8&amp;spm&#x3D;1018.2226.3001.4187)\ncp /var/jenkins_home/workspace/programmer-club-subject/programmer-club-subject/programmer-club-starter/target/programmer-club-starter.jar /var/jenkins_home/jar/#!/bin/bashAPP_NAME=programmer-club-starter.jarLOG_NAME=programmer-club-starter.logpid=`ps -ef | grep $APP_NAME | grep -v grep|awk &#x27;&#123;print $2&#125;&#x27;`function is_exist()&#123;pid=`ps -ef | grep $APP_NAME | grep -v grep|awk &#x27;&#123;print $2&#125;&#x27;`if [ -z $&#123;pid&#125; ]; thenString=&quot;notExist&quot;echo $StringelseString=&quot;exist&quot;echo $Stringfi&#125;str=$(is_exist)if [ $&#123;str&#125; = &quot;exist&quot; ]; thenecho &quot; 检测到已经启动的程序，pid 是 $&#123;pid&#125; &quot;kill -9 $pidelseecho &quot; 程序没有启动了 &quot;echo &quot;$&#123;APP_NAME&#125; is not running&quot;fistr=$(is_exist)if [ $&#123;str&#125; = &quot;exist&quot; ]; thenecho &quot;$&#123;APP_NAME&#125; 已经启动了. pid=$&#123;pid&#125; .&quot;elsesource /etc/profileBUILD_ID=dontKillMenohup java -Xms300m -Xmx300m -jar /var/jenkins_home/jar/$APP_NAME   &gt;$LOG_NAME 2&gt;&amp;1 &amp;echo &quot;程序已重新启动...&quot;fi\n\n这个脚本中获取PID的命令：\n\nps -ef：这个命令列出了当前系统上所有正在运行的进程。-e选项表示显示所有进程，-f选项表示显示完整格式。\ngrep $APP_NAME：grep命令用于搜索包含指定文本的行。在这里，它搜索包含APP_NAME变量值（即programmer-club-starter.jar）的行。\ngrep -v grep：这个命令用于排除包含grep本身的行，-v选项表示显示不包含匹配文本的行。\nawk &#39;&#123;print $2&#125;&#39;：awk是一个强大的文本处理工具。在这里，它用于打印每行的第二个字段，即进程ID（PID）。在Unix&#x2F;Linux系统中，ps -ef命令的输出中，PID通常位于第二列。\n\n2. OSS模块(jc-club-oss)\nOSS模块设计\n注意：考虑 oss 的扩展性和切换性。\n目前对接的 minio，要考虑，如果作为公共的 oss 服务，如何切换到其他的阿里云 oss 或者对接京东云的 oss。作为基础的 oss 服务，切换等等动作，不应该要求业务方进行改造，以及对切换有感知。\n\nminio模块开发controller-&gt;service-&gt;adaper（阿里&#x2F;minio，适配器模式，不用工厂＋策略的是因为工厂+策略的传入的参数之类的差不多，所以用适配器）-&gt;具体操作\nminio安装部署及使用-CSDN博客\npom.xml\n &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;            &lt;exclusions&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;                    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;/exclusion&gt;            &lt;/exclusions&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;io.minio&lt;/groupId&gt;            &lt;artifactId&gt;minio&lt;/artifactId&gt;            &lt;version&gt;8.2.0&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;            &lt;artifactId&gt;lombok&lt;/artifactId&gt;            &lt;version&gt;1.18.16&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;            &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; //spingcloud的nacos        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;            &lt;artifactId&gt;spring-cloud-starter-bootstrap&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;            &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;        &lt;/dependency&gt;&lt;/dependencies&gt;\n\n//application.ymlserver:  port: 4000minio:  url: http://117.72.14.166:9000  accessKey: minioadmin  secretKey: minioadminstorage:  service:  \ttype:  \t\tminio /*- `server.port: 4000`：这行配置指定了应用程序运行的端口号为4000。- `minio`部分：配置了MinIO服务的相关属性。  - `url`：MinIO服务的URL地址，这里是`http://117.72.14.166:9000`。  - `accessKey`和`secretKey`：访问MinIO服务的密钥和私钥，这里都设置为`minioadmin`。- `storage.service.type.minio`：指定存储服务的类型为MinIO。 */\n\nMiniocofig.java\npackage com.jingdianjichi.oss.config;import io.minio.MinioClient;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * minio配置管理 * * @author: ChickenWing * @date: 2023/10/11 */@Configurationpublic class MinioConfig &#123;    /**     * minioUrl     */    @Value(&quot;$&#123;minio.url&#125;&quot;)    private String url;    /**     * minio账户     */    @Value(&quot;$&#123;minio.accessKey&#125;&quot;)    private String accessKey;    /**     * minio密码     */    @Value(&quot;$&#123;minio.secretKey&#125;&quot;)    private String secretKey;    /**     * 构造minioClient     */    @Bean    public MinioClient getMinioClient() &#123;        return MinioClient.builder().endpoint(url).credentials(accessKey, secretKey).build();    &#125;&#125;\n\nMinioUtil.java\npackage com.jingdianjichi.oss.util;import com.jingdianjichi.oss.entity.FileInfo;import io.minio.*;import io.minio.errors.*;import io.minio.http.Method;import io.minio.messages.Bucket;import io.minio.messages.Item;import org.springframework.stereotype.Component;import javax.annotation.Resource;import java.io.IOException;import java.io.InputStream;import java.security.InvalidKeyException;import java.security.NoSuchAlgorithmException;import java.util.LinkedList;import java.util.List;import java.util.stream.Collectors;/** * minio文件操作工具 * * @author: ChickenWing * @date: 2023/10/11 */@Componentpublic class MinioUtil &#123;    @Resource    private MinioClient minioClient;    /**     * 创建bucket桶     */    public void createBucket(String bucket) throws Exception &#123;        boolean exists = minioClient.bucketExists(BucketExistsArgs.builder().bucket(bucket).build());        if (!exists) &#123;            minioClient.makeBucket(MakeBucketArgs.builder().bucket(bucket).build());        &#125;    &#125;    /**     * 上传文件     */    public void uploadFile(InputStream inputStream, String bucket, String objectName) throws Exception &#123;        minioClient.putObject(PutObjectArgs.builder().bucket(bucket).object(objectName)                .stream(inputStream, -1, 5242889L).build());    &#125;    /**     * 列出所有桶     */    public List&lt;String&gt; getAllBucket() throws Exception &#123;        List&lt;Bucket&gt; buckets = minioClient.listBuckets();        return buckets.stream().map(Bucket::name).collect(Collectors.toList());    &#125;    /**     * 列出当前桶及文件     */    public List&lt;FileInfo&gt; getAllFile(String bucket) throws Exception &#123;        Iterable&lt;Result&lt;Item&gt;&gt; results = minioClient.listObjects(                ListObjectsArgs.builder().bucket(bucket).build());        List&lt;FileInfo&gt; fileInfoList = new LinkedList&lt;&gt;();        for (Result&lt;Item&gt; result : results) &#123;            FileInfo fileInfo = new FileInfo();            Item item = result.get();            fileInfo.setFileName(item.objectName());            fileInfo.setDirectoryFlag(item.isDir());            fileInfo.setEtag(item.etag());            fileInfoList.add(fileInfo);        &#125;        return fileInfoList;    &#125;    /**     * 下载文件     */    public InputStream downLoad(String bucket, String objectName) throws Exception &#123;        return minioClient.getObject(                GetObjectArgs.builder().bucket(bucket).object(objectName).build()        );    &#125;    /**     * 删除桶     */    public void deleteBucket(String bucket) throws Exception &#123;        minioClient.removeBucket(                RemoveBucketArgs.builder().bucket(bucket).build()        );    &#125;    /**     * 删除文件     */    public void deleteObject(String bucket, String objectName) throws Exception &#123;        minioClient.removeObject(                RemoveObjectArgs.builder().bucket(bucket).object(objectName).build()        );    &#125;    /**     * 获取文件url     */    public String getPreviewFileUrl(String bucketName, String objectName) throws Exception&#123;            GetPresignedObjectUrlArgs args = GetPresignedObjectUrlArgs.builder()                    .method(Method.GET)                    .bucket(bucketName).object(objectName).build();            return minioClient.getPresignedObjectUrl(args);    &#125;&#125;\n\nFileInfo.java\npublic class FileInfo &#123;    private String fileName;    private Boolean directoryFlag;    private String etag;    public String getFileName() &#123;        return fileName;    &#125;    public void setFileName(String fileName) &#123;        this.fileName = fileName;    &#125;    public Boolean getDirectoryFlag() &#123;        return directoryFlag;    &#125;    public void setDirectoryFlag(Boolean directoryFlag) &#123;        this.directoryFlag = directoryFlag;    &#125;    public String getEtag() &#123;        return etag;    &#125;    public void setEtag(String etag) &#123;        this.etag = etag;    &#125;&#125;\n\nFileController.java\n@RestControllerpublic class FileController &#123;    @Resource    private FileService fileService;    @RequestMapping(&quot;/testGetAllBuckets&quot;)    public String testGetAllBuckets() throws Exception &#123;        List&lt;String&gt; allBucket = fileService.getAllBucket();        return allBucket.get(0);    &#125;    @RequestMapping(&quot;/getUrl&quot;)    public String getUrl(String bucketName, String objectName) throws Exception &#123;        return fileService.getUrl(bucketName, objectName);    &#125;    /**     * 上传文件     */    @RequestMapping(&quot;/upload&quot;)    public Result upload(MultipartFile uploadFile, String bucket, String objectName) throws Exception &#123;        String url = fileService.uploadFile(uploadFile, bucket, objectName);        return Result.ok(url);    &#125;&#125;\n\nfileService.java\n@Servicepublic class FileService &#123;    private final StorageAdapter storageAdapter;    public FileService(StorageAdapter storageAdapter) &#123;        this.storageAdapter = storageAdapter;    &#125;    /**     * 列出所有桶     */    public List&lt;String&gt; getAllBucket() &#123;        return storageAdapter.getAllBucket();    &#125;    /**     * 获取文件路径     */    public String getUrl(String bucketName,String objectName) &#123;        return storageAdapter.getUrl(bucketName,objectName);    &#125;    /**     * 上传文件     */    public String uploadFile(MultipartFile uploadFile, String bucket, String objectName)&#123;        storageAdapter.uploadFile(uploadFile,bucket,objectName);        objectName = objectName + &quot;/&quot; + uploadFile.getOriginalFilename();        return storageAdapter.getUrl(bucket, objectName);    &#125;&#125;\n\nStorageConfig.java\n@Configuration@RefreshScope //实现nacos动态的配置刷新public class StorageConfig &#123;    @Value(&quot;$&#123;storage.service.type&#125;&quot;)  //这里的注解是从pom.xml中去读的    private String storageType;    @Bean    @RefreshScope //实现nacos动态的配置刷新    public StorageAdapter storageService() &#123;        if (&quot;minio&quot;.equals(storageType)) &#123;            return new MinioStorageAdapter();        &#125; else if (&quot;aliyun&quot;.equals(storageType)) &#123;            return new AliStorageAdapter();        &#125; else &#123;            throw new IllegalArgumentException(&quot;未找到对应的文件存储处理器&quot;);        &#125;    &#125;&#125;\n\nStorageAdapter.java\npublic interface StorageAdapter &#123;    /**     * 创建bucket桶     */    void createBucket(String bucket);    /**     * 上传文件     */    void uploadFile(MultipartFile uploadFile, String bucket, String objectName);    /**     * 列出所有桶     */    List&lt;String&gt; getAllBucket();    /**     * 列出当前桶及文件     */    List&lt;FileInfo&gt; getAllFile(String bucket);    /**     * 下载文件     */    InputStream downLoad(String bucket, String objectName);    /**     * 删除桶     */    void deleteBucket(String bucket);    /**     * 删除文件     */    void deleteObject(String bucket, String objectName);    String getUrl(String bucket, String objectName);&#125;\n\nMinioStorageAdapter.java\npackage com.jingdianjichi.oss.adapter;import com.jingdianjichi.oss.entity.FileInfo;import com.jingdianjichi.oss.util.MinioUtil;import lombok.SneakyThrows;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.multipart.MultipartFile;import javax.annotation.Resource;import java.io.InputStream;import java.util.List;/** * minioIO存储适配器 */public class MinioStorageAdapter implements StorageAdapter &#123;    @Resource    private MinioUtil minioUtil;    /**     * minioUrl     */    @Value(&quot;$&#123;minio.url&#125;&quot;)    private String url;    @Override    @SneakyThrows    public void createBucket(String bucket) &#123;        minioUtil.createBucket(bucket);    &#125;    @Override    @SneakyThrows    public void uploadFile(MultipartFile uploadFile, String bucket, String objectName) &#123;        minioUtil.createBucket(bucket);        if (objectName != null) &#123;            minioUtil.uploadFile(uploadFile.getInputStream(), bucket, objectName + &quot;/&quot; + uploadFile.getOriginalFilename());        &#125; else &#123;            minioUtil.uploadFile(uploadFile.getInputStream(), bucket, uploadFile.getOriginalFilename());        &#125;    &#125;    @Override    @SneakyThrows    public List&lt;String&gt; getAllBucket() &#123;        return minioUtil.getAllBucket();    &#125;    @Override    @SneakyThrows    public List&lt;FileInfo&gt; getAllFile(String bucket) &#123;        return minioUtil.getAllFile(bucket);    &#125;    @Override    @SneakyThrows    public InputStream downLoad(String bucket, String objectName) &#123;        return minioUtil.downLoad(bucket, objectName);    &#125;    @Override    @SneakyThrows    public void deleteBucket(String bucket) &#123;        minioUtil.deleteBucket(bucket);    &#125;    @Override    @SneakyThrows    public void deleteObject(String bucket, String objectName) &#123;        minioUtil.deleteObject(bucket, objectName);    &#125;    @Override    @SneakyThrows    public String getUrl(String bucket, String objectName) &#123;        return url + &quot;/&quot; + bucket + &quot;/&quot; + objectName;    &#125;&#125;\n\n这里相当于做了个适配器，这里用的是minio的，如果要用阿里的服务就要切到另一套了\npackage com.jingdianjichi.oss.adapter;import com.jingdianjichi.oss.entity.FileInfo;import org.springframework.web.multipart.MultipartFile;import java.io.InputStream;import java.util.LinkedList;import java.util.List;/** * 阿里云oss适配器 */public class AliStorageAdapter implements StorageAdapter &#123;    @Override    public void createBucket(String bucket) &#123;    &#125;    @Override    public void uploadFile(MultipartFile uploadFile, String bucket, String objectName) &#123;    &#125;    @Override    public List&lt;String&gt; getAllBucket() &#123;        List&lt;String&gt; bucketNameList = new LinkedList&lt;&gt;();        bucketNameList.add(&quot;aliyun&quot;);        return bucketNameList;    &#125;    @Override    public List&lt;FileInfo&gt; getAllFile(String bucket) &#123;        return null;    &#125;    @Override    public InputStream downLoad(String bucket, String objectName) &#123;        return null;    &#125;    @Override    public void deleteBucket(String bucket) &#123;    &#125;    @Override    public void deleteObject(String bucket, String objectName) &#123;    &#125;    @Override    public String getUrl(String bucket, String objectName) &#123;        return null;    &#125;&#125;\n\n\n\nOSS模块配合nacos实现动态切换nacos 作为配置中心，可以实现动态配置，适用于比如动态数据源切换，动态切换 oss。\n这里要配合RefreshScope注解去使用，实现动态刷新（minio-&gt;ali）。\n一文带你理解@RefreshScope注解实现动态刷新原理-CSDN博客\n集成naocs动态配置配置\n\njc-club-oss&#x2F;pom.xml\n&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;        &lt;exclusions&gt;            &lt;exclusion&gt;                &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;/exclusion&gt;        &lt;/exclusions&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;io.minio&lt;/groupId&gt;        &lt;artifactId&gt;minio&lt;/artifactId&gt;        &lt;version&gt;8.2.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;        &lt;artifactId&gt;lombok&lt;/artifactId&gt;        &lt;version&gt;1.18.16&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-bootstrap&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\njc-club-oss&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;jingdianjichi&#x2F;oss&#x2F;controller&#x2F;FileController.java\n public class FileController&#123; \t@Resource    private FileService fileService;    @NacosValue(value = &quot;$&#123;storage.service.type&#125;&quot;, autoRefreshed = true)    private String storageType;    @RequestMapping(&quot;/testGetAllBuckets&quot;)    public String testGetAllBuckets() throws Exception &#123;        List&lt;String&gt; allBucket = fileService.getAllBucket();        return allBucket.get(0);    &#125;    @RequestMapping(&quot;/testNacos&quot;)    public String testNacos() throws Exception &#123;        return storageType;    &#125;&#125;\n\njc-club-oss&#x2F;src&#x2F;main&#x2F;resources&#x2F;bootstrap.yml\nspring:  application:    name: jc-club-oss-dev  profiles:    active: dev  cloud:    nacos:      config:        server-addr: 117.72.14.166:8848        prefix: $&#123;spring.application.name&#125;        group: DEFAULT_GROUP        namespace:        file-extension: yaml      discovery:        enabled: true        server-addr: 117.72.14.166:8848/*Spring 应用名称：application.name: jc-club-oss-dev：定义了Spring应用的名称为jc-club-oss-dev。激活的配置文件：profiles.active: dev：指定了激活的配置文件为dev，这意味着在启动时会加载application-dev.yaml或application-dev.properties等配置文件。Nacos 配置：cloud.nacos.config.server-addr: 117.72.14.166:8848：定义了Nacos配置服务器的地址，这里是117.72.14.166:8848。cloud.nacos.config.prefix: $&#123;spring.application.name&#125;：定义了配置的前缀，这里使用了$&#123;spring.application.name&#125;，即应用名称作为前缀。cloud.nacos.config.group: DEFAULT_GROUP：定义了配置的分组，这里是DEFAULT_GROUP。cloud.nacos.config.namespace：这里没有指定具体的命名空间，通常用于区分不同环境的配置。cloud.nacos.config.file-extension: yaml：指定了配置文件的扩展名，这里是yaml。Nacos 服务发现：cloud.nacos.discovery.enabled: true：启用了Nacos的服务发现功能。cloud.nacos.discovery.server-addr: 117.72.14.166:8848：定义了Nacos服务发现服务器的地址，与配置服务器地址一致。配置的作用配置管理：通过Nacos配置中心，应用可以动态地读取和更新配置，而不需要重启应用。这对于微服务架构中的配置管理非常有用。服务发现：通过Nacos服务注册中心，应用可以注册自身服务并发现其他服务，从而实现服务间的调用。使用场景在微服务架构中，使用Nacos进行配置管理和服务发现可以提高系统的可维护性和可扩展性。动态配置更新：应用可以根据Nacos配置中心的配置变化自动更新其配置，而不需要人工干预。*/\n\n通过在nacos界面修改：\nstorage:\tservice:\t\ttype: minio/aliyun\n\n即可通过**@Configuration**注解的Storage.java中的@Bean、@RefreshScope注解的storageService方法会创建适配器的对应的StorageAdapter，拿到minio&#x2F;阿里云的oss服务。\n@Configuration注解使用详解【记录】-CSDN博客\nSpring 常用注解@Configuration，@Bean，@Component，@Service，@Controller，@Repository，@Entity的区分与学习_@entity @repository 区别-CSDN博客\n3. 登录鉴权模块\n\n技术选型Sa-Token 是一个轻量级 Java 权限认证框架，主要解决：登录认证、权限认证、单点登录、OAuth2.0、分布式Session会话、微服务网关鉴权 等一系列权限相关问题。\nSa-Token 旨在以简单、优雅的方式完成系统的权限认证部分，以登录认证为例，你只需要：\n// 会话登录，参数填登录人的账号id StpUtil.login(10001);\n\n无需实现任何接口，无需创建任何配置文件，只需要这一句静态代码的调用，便可以完成会话登录认证。\n如果一个接口需要登录后才能访问，我们只需调用以下代码：\n// 校验当前客户端是否已经登录，如果未登录则抛出 `NotLoginException` 异常StpUtil.checkLogin();\n\n在 Sa-Token 中，大多数功能都可以一行代码解决：\n踢人下线：\n// 将账号id为 10077 的会话踢下线 StpUtil.kickout(10077);复制到剪贴板错误复制成功\n\n权限认证：\n// 注解鉴权：只有具备 `user:add` 权限的会话才可以进入方法@SaCheckPermission(&quot;user:add&quot;)public String insert(SysUser user) &#123;    // ...     return &quot;用户增加&quot;;&#125;\n\n路由拦截鉴权：\n// 根据路由划分模块，不同模块不同鉴权 registry.addInterceptor(new SaInterceptor(handler -&gt; &#123;    SaRouter.match(&quot;/user/**&quot;, r -&gt; StpUtil.checkPermission(&quot;user&quot;));    SaRouter.match(&quot;/admin/**&quot;, r -&gt; StpUtil.checkPermission(&quot;admin&quot;));    SaRouter.match(&quot;/goods/**&quot;, r -&gt; StpUtil.checkPermission(&quot;goods&quot;));    SaRouter.match(&quot;/orders/**&quot;, r -&gt; StpUtil.checkPermission(&quot;orders&quot;));    SaRouter.match(&quot;/notice/**&quot;, r -&gt; StpUtil.checkPermission(&quot;notice&quot;));    // 更多模块... &#125;)).addPathPatterns(&quot;/**&quot;);9\n\n当你受够 Shiro、SpringSecurity 等框架的三拜九叩之后，你就会明白，相对于这些传统老牌框架，Sa-Token 的 API 设计是多么的简单、优雅！\nSa-Token 功能一览\nSa-Token 目前主要五大功能模块：登录认证、权限认证、单点登录、OAuth2.0、微服务鉴权。\n\n登录认证 —— 单端登录、多端登录、同端互斥登录、七天内免登录。\n权限认证 —— 权限认证、角色认证、会话二级认证。\n踢人下线 —— 根据账号id踢人下线、根据Token值踢人下线。\n注解式鉴权 —— 优雅的将鉴权与业务代码分离。\n路由拦截式鉴权 —— 根据路由拦截鉴权，可适配 restful 模式。\nSession会话 —— 全端共享Session,单端独享Session,自定义Session,方便的存取值。\n持久层扩展 —— 可集成 Redis，重启数据不丢失。\n前后台分离 —— APP、小程序等不支持 Cookie 的终端也可以轻松鉴权。\nToken风格定制 —— 内置六种 Token 风格，还可：自定义 Token 生成策略。\n记住我模式 —— 适配 [记住我] 模式，重启浏览器免验证。\n二级认证 —— 在已登录的基础上再次认证，保证安全性。\n模拟他人账号 —— 实时操作任意用户状态数据。\n临时身份切换 —— 将会话身份临时切换为其它账号。\n同端互斥登录 —— 像QQ一样手机电脑同时在线，但是两个手机上互斥登录。\n账号封禁 —— 登录封禁、按照业务分类封禁、按照处罚阶梯封禁。\n密码加密 —— 提供基础加密算法，可快速 MD5、SHA1、SHA256、AES 加密。\n会话查询 —— 提供方便灵活的会话查询接口。\nHttp Basic认证 —— 一行代码接入 Http Basic、Digest 认证。\n全局侦听器 —— 在用户登陆、注销、被踢下线等关键性操作时进行一些AOP操作。\n全局过滤器 —— 方便的处理跨域，全局设置安全响应头等操作。\n多账号体系认证 —— 一个系统多套账号分开鉴权（比如商城的 User 表和 Admin 表）\n单点登录 —— 内置三种单点登录模式：同域、跨域、同Redis、跨Redis、前后端分离等架构都可以搞定。\n单点注销 —— 任意子系统内发起注销，即可全端下线。\nOAuth2.0认证 —— 轻松搭建 OAuth2.0 服务，支持openid模式 。\n分布式会话 —— 提供共享数据中心分布式会话方案。\n微服务网关鉴权 —— 适配Gateway、ShenYu、Zuul等常见网关的路由拦截认证。\nRPC调用鉴权 —— 网关转发鉴权，RPC调用鉴权，让服务调用不再裸奔\n临时Token认证 —— 解决短时间的 Token 授权问题。\n独立Redis —— 将权限缓存与业务缓存分离。\nQuick快速登录认证 —— 为项目零代码注入一个登录页面。\n标签方言 —— 提供 Thymeleaf 标签方言集成包，提供 beetl 集成示例。\njwt集成 —— 提供三种模式的 jwt 集成方案，提供 token 扩展参数能力。\nRPC调用状态传递 —— 提供 dubbo、grpc 等集成包，在RPC调用时登录状态不丢失。\n参数签名 —— 提供跨系统API调用签名校验模块，防参数篡改，防请求重放。\n自动续签 —— 提供两种Token过期策略，灵活搭配使用，还可自动续签。\n开箱即用 —— 提供SpringMVC、WebFlux、Solon 等常见框架集成包，开箱即用。\n最新技术栈 —— 适配最新技术栈：支持 SpringBoot 3.x，jdk 17。\n\n功能结构图：\n\n鉴权设计-RBAC模型RBAC 模型（role-based access control）\n非常成熟的安全的模型概念，基于角色帮助我们把授权和用户的访问控制来做结合。\nUser（用户）用户就是指我们的系统使用者。\nPerMission（权限）用户我们对系统的操作，访问哪些东西，可以操作写入操作等等。实际的例子，比如新增题目。\nRole（角色）我们去把一组的权限，去做集合，就得到了角色。\n核心思想其实就是把角色和权限做关联，实现整体的一个灵活访问，提高我们的系统的安全性和管理型。基于这个模型，我们的开发速度还有粒度的粗细也都是十分好控制的。\n优点：\n灵活，安全，简化管理。\n三种RBAC模型：\n\nRBAC-0 模型\n用户和角色是一个多对多的关系，角色和权限也是一个多对多关系。\n\nRBAC-1 模型\n多了一个继承的概念。\n比如一个业务部门，经理，主管，营业员。主管的权限肯定不能大于经理，营业员不能大于主管。\n子角色的范围一定会小于父角色。\n\nRBAC-2 模型\n角色互斥，基数约束，先决条件等等。\n\n角色互斥：同一个用户，不能被分配到复制的角色，比如说，你是一个采购，那你就不能分配销售。\n基数约束：一个角色分配的用户数量是有限的。比如有一个公司的架构师，最多只能有三个。\n先决条件：你想获得架构师的角色，那你必然得先是一个资深工程师的角色。\n\n\n\n权限：\n\n他的含义其实是非常广泛的，可以是菜单，页面，字段，数据。\n菜单权限\n页面权限\n字段权限\n数据权限\n操作权限\n\n\n\n用户组：\n\n平台的用户基数非常大，角色也非常的多，如果说我给每个用户都操作一下角色，就非常的麻烦。\n抽象一层组的概念，把同类的用户，放在一起，直接拥有相同的权限。\n非常有益于减少工作量，一些管理方面也非常合适。用户组抽象到实际中，其实就是部门啊，科室啊。\n\n鉴权数据模型设计\n-- ------------------------------ Table structure for auth_permission-- ----------------------------DROP TABLE IF EXISTS `auth_permission`;CREATE TABLE `auth_permission`(    `id`             bigint(20) NOT NULL AUTO_INCREMENT,    `name`           varchar(64)  DEFAULT NULL COMMENT &#x27;权限名称&#x27;,    `parent_id`      bigint(20) DEFAULT NULL COMMENT &#x27;父id&#x27;,    `type`           tinyint(4) DEFAULT NULL COMMENT &#x27;权限类型 0菜单 1操作&#x27;,    `menu_url`       varchar(255) DEFAULT NULL COMMENT &#x27;菜单路由&#x27;,    `status`         tinyint(2) DEFAULT NULL COMMENT &#x27;状态 0启用 1禁用&#x27;,    `show`           tinyint(2) DEFAULT NULL COMMENT &#x27;展示状态 0展示 1隐藏&#x27;,    `icon`           varchar(128) DEFAULT NULL COMMENT &#x27;图标&#x27;,    `permission_key` varchar(64)  DEFAULT NULL COMMENT &#x27;权限唯一标识&#x27;,    `created_by`     varchar(32)  DEFAULT NULL COMMENT &#x27;创建人&#x27;,    `created_time`   datetime     DEFAULT NULL COMMENT &#x27;创建时间&#x27;,    `update_by`      varchar(32)  DEFAULT NULL COMMENT &#x27;更新人&#x27;,    `update_time`    datetime     DEFAULT NULL COMMENT &#x27;更新时间&#x27;,    `is_deleted`     int(11) DEFAULT &#x27;0&#x27; COMMENT &#x27;是否被删除 0为删除 1已删除&#x27;,    PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;-- ------------------------------ Records of auth_permission-- ----------------------------INSERT INTO `auth_permission`VALUES (&#x27;1&#x27;, &#x27;新增题目&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;ladiwd/www&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;http://1.png&#x27;, &#x27;subject:add1&#x27;, &#x27;oYA4HtwGJEsLio6pGrhx5Hzv9XD0&#x27;,        &#x27;2024-02-28 03:20:38&#x27;, &#x27;&#x27;, &#x27;2023-11-12 16:17:12&#x27;, &#x27;0&#x27;);-- ------------------------------ Table structure for auth_role-- ----------------------------DROP TABLE IF EXISTS `auth_role`;CREATE TABLE `auth_role`(    `id`           bigint(20) NOT NULL AUTO_INCREMENT,    `role_name`    varchar(32) DEFAULT NULL COMMENT &#x27;角色名称&#x27;,    `role_key`     varchar(64) DEFAULT NULL COMMENT &#x27;角色唯一标识&#x27;,    `created_by`   varchar(32) DEFAULT NULL COMMENT &#x27;创建人&#x27;,    `created_time` datetime    DEFAULT NULL COMMENT &#x27;创建时间&#x27;,    `update_by`    varchar(32) DEFAULT NULL COMMENT &#x27;更新人&#x27;,    `update_time`  datetime    DEFAULT NULL COMMENT &#x27;更新时间&#x27;,    `is_deleted`   int(11) DEFAULT &#x27;0&#x27; COMMENT &#x27;是否被删除 0未删除 1已删除&#x27;,    PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8;-- ------------------------------ Records of auth_role-- ----------------------------INSERT INTO `auth_role`VALUES (&#x27;1&#x27;, &#x27;管理员&#x27;, &#x27;admin_user&#x27;, &#x27;oYA4HtwGJEsLio6pGrhx5Hzv9XD0&#x27;, &#x27;2024-02-28 03:20:44&#x27;, &#x27;&#x27;, &#x27;2023-11-12 16:16:07&#x27;,        &#x27;0&#x27;);INSERT INTO `auth_role`VALUES (&#x27;2&#x27;, &#x27;普通用户&#x27;, &#x27;normal_user&#x27;, &#x27;oYA4HtwGJEsLio6pGrhx5Hzv9XD0&#x27;, &#x27;2024-02-28 03:20:44&#x27;, &#x27;&#x27;, &#x27;2023-11-12 16:16:10&#x27;,        &#x27;0&#x27;);-- ------------------------------ Table structure for auth_role_permission-- ----------------------------DROP TABLE IF EXISTS `auth_role_permission`;CREATE TABLE `auth_role_permission`(    `id`            bigint(20) NOT NULL AUTO_INCREMENT,    `role_id`       bigint(20) DEFAULT NULL COMMENT &#x27;角色id&#x27;,    `permission_id` bigint(20) DEFAULT NULL COMMENT &#x27;权限id&#x27;,    `created_by`    varchar(32) DEFAULT NULL COMMENT &#x27;创建人&#x27;,    `created_time`  datetime    DEFAULT NULL COMMENT &#x27;创建时间&#x27;,    `update_by`     varchar(32) DEFAULT NULL COMMENT &#x27;更新人&#x27;,    `update_time`   datetime    DEFAULT NULL COMMENT &#x27;更新时间&#x27;,    `is_deleted`    int(11) DEFAULT &#x27;0&#x27;,    PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8 COMMENT=&#x27;角色权限关联表&#x27;;-- ------------------------------ Records of auth_role_permission-- ------------------------------ ------------------------------ Table structure for auth_user-- ----------------------------DROP TABLE IF EXISTS `auth_user`;CREATE TABLE `auth_user`(    `id`           bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#x27;主键&#x27;,    `user_name`    varchar(32)  DEFAULT NULL COMMENT &#x27;用户名称/账号&#x27;,    `nick_name`    varchar(32)  DEFAULT NULL COMMENT &#x27;昵称&#x27;,    `email`        varchar(32)  DEFAULT NULL COMMENT &#x27;邮箱&#x27;,    `phone`        varchar(32)  DEFAULT NULL COMMENT &#x27;手机号&#x27;,    `password`     varchar(64)  DEFAULT NULL COMMENT &#x27;密码&#x27;,    `sex`          tinyint(2) DEFAULT NULL COMMENT &#x27;性别&#x27;,    `avatar`       varchar(255) DEFAULT NULL COMMENT &#x27;头像&#x27;,    `status`       tinyint(2) DEFAULT NULL COMMENT &#x27;状态 0启用 1禁用&#x27;,    `introduce`    varchar(255) DEFAULT NULL COMMENT &#x27;个人介绍&#x27;,    `ext_json`     varchar(255) DEFAULT NULL COMMENT &#x27;特殊字段&#x27;,    `created_by`   varchar(32)  DEFAULT NULL COMMENT &#x27;创建人&#x27;,    `created_time` datetime     DEFAULT NULL COMMENT &#x27;创建时间&#x27;,    `update_by`    varchar(32)  DEFAULT NULL COMMENT &#x27;更新人&#x27;,    `update_time`  datetime     DEFAULT NULL COMMENT &#x27;更新时间&#x27;,    `is_deleted`   int(11) DEFAULT &#x27;0&#x27; COMMENT &#x27;是否被删除 0未删除 1已删除&#x27;,    PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&#x27;用户信息表&#x27;;-- ------------------------------ Records of auth_user-- ------------------------------ ------------------------------ Table structure for auth_user_role-- ----------------------------DROP TABLE IF EXISTS `auth_user_role`;CREATE TABLE `auth_user_role`(    `id`           bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#x27;主键&#x27;,    `user_id`      bigint(20) DEFAULT NULL COMMENT &#x27;用户id&#x27;,    `role_id`      bigint(20) DEFAULT NULL COMMENT &#x27;角色id&#x27;,    `created_by`   varchar(32) DEFAULT NULL COMMENT &#x27;创建人&#x27;,    `created_time` datetime    DEFAULT NULL COMMENT &#x27;创建时间&#x27;,    `update_by`    varchar(32) DEFAULT NULL COMMENT &#x27;更新人&#x27;,    `update_time`  datetime    DEFAULT NULL COMMENT &#x27;更新时间&#x27;,    `is_deleted`   int(11) DEFAULT &#x27;0&#x27;,    PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&#x27;用户角色表&#x27;;\n\n\n\n鉴权架构设计jc-club-auth：这个服务承载了我们所有的基础数据源。他不管鉴权，只管数据相关的持久化操作以及业务操作，提供出各种各样的权限相关的接口。\nnacos：将 auth 服务以及 subject 服务都注册到上面。内部进行调用，不对外暴露。通过 nacos 实现我们的服务发现。\ngateway（网关）：网关层会对外提供服务，内部实现路由，鉴权。整体我们采取 token 的方式来与前端进行交互。由网关来决定当前用户是否可以操作到后面的业务逻辑。\n\n鉴权、路由等处理都由网关来做。\n鉴权功能设计\n用户基础模块 \n\n新增用户\n修改用户\n删除用户\n用户启用\n用户禁用\n用户密码加密\n\n\n角色基础模块 \n\n新增角色\n修改角色\n删除角色\n角色与用户的关联\n\n\n权限基础模块 \n\n新增权限\n\n修改权限\n\n删除权限\n\n权限禁用与启用\n\n权限的展示与隐藏\n\n权限与角色关联\n\n\n\n登录注册模块 \n\n注册用户与验证\n\n\n短信的方式，通过向手机号发送验证码，来实现用户的验证并登录（考虑的成本是短信的费用）\n\n邮箱的注册登录。\n用户注册的时候，留一个邮箱，我们往邮箱里通过邮箱服务器发送一个链接，用户点击之后，实现一个激活，激活成功之后就完成了注册。（0 成本，坏处这种发送的邮件很容易进垃圾箱）\n\n个人公众号模式（个人开发者无公司的，比较适合使用，0 成本）\n用户登录的时候，弹出我们的这个公众号的码。扫码后，用户输入我们提示的验证码。可以随机比如说 nadbuge，通过我们的公众号对接的回调。能拿到一定的信息，用户的 openId。进而记录用户的信息\n\n企业的服务号（必须要有营业执照，自己玩的不上线的话，也可以用测试号）\n好处就是不仅打通了各种回调，而且还能拿到用户的信息。\n\n\n\n登录功能\n\n  传统的 pc 形式，都是登录之后，写入 cookie。前端再次请求的时候，带着 cookie 一个身份识别就可以完成认证。\n  坏处是什么？小程序呀，app 呀，其实是没有 cookie 这个概念的。\n  单点登录(SSO)详解——超详细-CSDN博客\n  为了更好的扩展，我们就直接选择 token的模式。token 放入 header 来实现用户身份的识别与鉴权。\n\n踢人下线\n\n  发现风险用户，可以通过后台直接把用户踢掉，禁止其再访问，token 也可以直接置为失效的形式。\n\n集成 redis （保存token）\n\n  如果说我们选择了 token，然后不做 token 的保存，服务重启呀，分布式微服务啊，数据是无法共享并且会产生丢失问题，所以用 redis 来存储一些信息，实现共享。\n\n自定义我们的 token 风格和前缀 \n比如正常的 token 可能是 uuid，我们可以选择其他形式。\n然后就是 token 的前端的传递，也可以去定义前缀，固定前缀才生效。\n\n记住我\n\n\n  当我们去勾选记住我的时候，下次登录就自动实现了。\n  前后端分离，没有 token 的时候，必然会产生无法实现的问题，我们就选择在前端的 localstorage 来做。\n\n网关统一鉴权 \n校验权限，校验用户的角色等等的东西，就放在网关里面统一去做。\n不放在网关，导致每个微服务，全要引入的鉴权的框架，不断的去写重复的代码。\n数据的权限获取产生问题：\n\n网关直接对接数据库，实现查询。\nredis 中获取数据，获取不到的时候还是要像第一种一样去数据库里查。\nredis 中获取缓存，没有的话，从 auth 服务里面获取相关的信息。\n直接从 redis 读取。\n\n\n\nauth模块配置jc-club-auth-application/pom.xml\n&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; //用于 Spring Cloud 项目中，通过 Feign 客户端简化 HTTP 客户端的调用。        &lt;version&gt;3.0.7&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-loadbalancer&lt;/artifactId&gt; //用于 Spring Cloud 项目中，提供客户端负载均衡功能。        &lt;version&gt;3.0.6&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;        &lt;artifactId&gt;lombok&lt;/artifactId&gt; //自动生成 getter、setter、构造函数等。        &lt;version&gt;1.18.16&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\njc-club-auth-application-controller/pom.xml\n&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;        &lt;version&gt;2.4.2&lt;/version&gt;    &lt;/dependency&gt;    &lt;!-- sa-token 依赖--&gt;    &lt;dependency&gt;        &lt;groupId&gt;cn.dev33&lt;/groupId&gt;        &lt;artifactId&gt;sa-token-spring-boot-starter&lt;/artifactId&gt;        &lt;version&gt;1.37.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;        &lt;artifactId&gt;jc-club-auth-domain&lt;/artifactId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;        &lt;artifactId&gt;jc-club-auth-api&lt;/artifactId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\njc-club-auth-starter/pom.xml\n&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;        &lt;version&gt;2.4.2&lt;/version&gt;        &lt;exclusions&gt;            &lt;exclusion&gt;                &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;/exclusion&gt;        &lt;/exclusions&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;        &lt;artifactId&gt;jc-club-auth-infra&lt;/artifactId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;        &lt;artifactId&gt;jc-club-auth-application-controller&lt;/artifactId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; //nacos    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-bootstrap&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\njc-club-auth-domain/pom.xml\n&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;        &lt;artifactId&gt;jc-club-auth-infra&lt;/artifactId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;        &lt;artifactId&gt;jc-club-auth-common&lt;/artifactId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;        &lt;artifactId&gt;jackson-core&lt;/artifactId&gt;        &lt;version&gt;2.12.7&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;        &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;        &lt;version&gt;2.12.7&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;        &lt;artifactId&gt;gson&lt;/artifactId&gt;        &lt;version&gt;2.8.6&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\njc-club-auth-infra/pom.xml\n&lt;dependencies&gt;    &lt;!-- jdbcStarter --&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;        &lt;version&gt;2.4.2&lt;/version&gt;    &lt;/dependency&gt;    &lt;!-- druid连接池 --&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba&lt;/groupId&gt;        &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt;        &lt;version&gt;1.1.22&lt;/version&gt;    &lt;/dependency&gt;    &lt;!-- mysql --&gt;    &lt;dependency&gt;        &lt;groupId&gt;mysql&lt;/groupId&gt;        &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;        &lt;version&gt;8.0.22&lt;/version&gt;    &lt;/dependency&gt;    &lt;!-- mybatisplus --&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.baomidou&lt;/groupId&gt;        &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;        &lt;version&gt;3.4.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;        &lt;artifactId&gt;jc-club-auth-common&lt;/artifactId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\n登录(详情在用户模块)注意openid就是username\nSa-token\n前后端分离 (sa-token.cc)\n在auth模块中的UserController.java中实现\njc-club-auth: UserController\n@RequestMapping(&quot;doLogin&quot;)public Result&lt;SaTokenInfo&gt; doLogin(@RequestParam(&quot;validCode&quot;) String validCode) &#123;    try &#123;        Preconditions.checkArgument(!StringUtils.isBlank(validCode), &quot;验证码不能为空!&quot;);        return Result.ok(authUserDomainService.doLogin(validCode));    &#125; catch (Exception e) &#123;        log.error(&quot;UserController.doLogin.error:&#123;&#125;&quot;, e.getMessage(), e);        return Result.fail(&quot;用户登录失败&quot;);    &#125;&#125;\n\njc-club-auth:AuthUserDomainServiceImpl\n@Overridepublic SaTokenInfo doLogin(String validCode) &#123;    String loginKey = redisUtil.buildKey(LOGIN_PREFIX, validCode);    String openId = redisUtil.get(loginKey);    if (StringUtils.isBlank(openId)) &#123;        return null;    &#125;    AuthUserBO authUserBO = new AuthUserBO();    authUserBO.setUserName(openId);    this.register(authUserBO);    StpUtil.login(openId);    SaTokenInfo tokenInfo = StpUtil.getTokenInfo();    return tokenInfo;&#125;\n\n微服务注册到nacos阿里云脚手架用于组件&#x2F;版本的选择兼容，非常方便: start.aliyun.com\noss服务-&gt;nacos\npom.xml\n&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; //构建 Web 应用程序所需的 Spring MVC 和 Tomcat。        &lt;exclusions&gt;            &lt;exclusion&gt;                &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; //不会包含默认的日志框架                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;/exclusion&gt;        &lt;/exclusions&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;io.minio&lt;/groupId&gt; //用于与 Minio 对象存储服务进行交互的客户端库。        &lt;artifactId&gt;minio&lt;/artifactId&gt;        &lt;version&gt;8.2.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; //        &lt;artifactId&gt;lombok&lt;/artifactId&gt; //减少样板代码，自动生成 getter、setter 等。        &lt;version&gt;1.18.16&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; //用于集成 Nacos 配置中心，提供配置管理功能。    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt; //替换默认的日志框架，使用 Log4j2 作为日志记录器。    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-bootstrap&lt;/artifactId&gt; //用于 Spring Cloud 应用的引导类，帮助应用启动时加载配置(bootstrap.yaml)。    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; //用于集成 Nacos 服务发现，提供服务注册与发现功能。    &lt;/dependency&gt;&lt;/dependencies&gt;\n\n这里要用到bootstrap.yaml去在nacos中注册:\nspring:  application:    name: jc-club-oss-dev  profiles:    active: dev  cloud:    nacos:      config:        server-addr: 117.72.14.166:8848        prefix: $&#123;spring.application.name&#125;        group: DEFAULT_GROUP        namespace:        file-extension: yaml      discovery:        enabled: true        server-addr: 117.72.14.166:8848 //部署有nacos的云服务器的地址\n\n启动程序就注册上去了\n（gateway-&gt;nacos）Spring Cloud Gateway搭建及路由配置pom.xml\n&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;io.minio&lt;/groupId&gt;        &lt;artifactId&gt;minio&lt;/artifactId&gt;        &lt;version&gt;8.2.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;        &lt;artifactId&gt;lombok&lt;/artifactId&gt;        &lt;version&gt;1.18.16&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-bootstrap&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-loadbalancer&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\nbootstrap.yaml\nspring:  application:    name: jc-club-gateway-dev  profiles:    active: dev  cloud:    nacos:      config:        server-addr: 117.72.14.166:8848        prefix: $&#123;spring.application.name&#125;        group: DEFAULT_GROUP        namespace:        file-extension: yaml      discovery:        enabled: true        server-addr: 117.72.14.166:8848\n\napplication.yaml，用于路由转发\nserver:  port: 5000spring:  cloud:    gateway:      routes:        - id: oss          uri: lb://jc-club-oss-dev //使用 lb:// 前缀表示这是一个负载均衡器的调用。jc-club-oss-dev 是服务名，Spring Cloud Gateway 将通过服务发现找到对应的实例。          predicates:            - Path=/oss/** //路由匹配条件          filters:            - StripPrefix=1 //过滤器用于从请求路径中去除前缀。        - id: auth          uri: lb://jc-club-auth-dev          predicates:            - Path=/auth/**          filters:            - StripPrefix=1        - id: subject          uri: lb://jc-club-subject-dev          predicates:            - Path=/subject/**          filters:            - StripPrefix=1\n\n运行及注册到nacos中，并且可以通过网关进行路由转发到对应的微服务上。\n鉴权+刷题-&gt;nacosauth:\nstarter/pom.xml\n&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;        &lt;version&gt;2.4.2&lt;/version&gt;        &lt;exclusions&gt;            &lt;exclusion&gt;                &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;/exclusion&gt;        &lt;/exclusions&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;        &lt;artifactId&gt;jc-club-auth-infra&lt;/artifactId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;        &lt;artifactId&gt;jc-club-auth-application-controller&lt;/artifactId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-bootstrap&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\nbootstrap.yaml\nspring:  application:    name: jc-club-gateway-dev  profiles:    active: dev  cloud:    nacos:      config:        server-addr: 117.72.14.166:8848        prefix: $&#123;spring.application.name&#125;        group: DEFAULT_GROUP        namespace:        file-extension: yaml      discovery:        enabled: true        server-addr: 117.72.14.166:8848\n\nsubject：\nstarter/pom.xml\n&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;        &lt;version&gt;2.4.2&lt;/version&gt;        &lt;exclusions&gt;            &lt;exclusion&gt;                &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;/exclusion&gt;        &lt;/exclusions&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;        &lt;artifactId&gt;jc-club-application-controller&lt;/artifactId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;        &lt;artifactId&gt;jc-club-application-mq&lt;/artifactId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;        &lt;artifactId&gt;jc-club-infra&lt;/artifactId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-bootstrap&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\nbootstrap.yaml\nspring:  application:    name: jc-club-subject-dev  profiles:    active: dev  cloud:    nacos:      config:        server-addr: 117.72.14.166:8848        prefix: $&#123;spring.application.name&#125;        group: DEFAULT_GROUP        namespace:        file-extension: yaml      discovery:        enabled: true        server-addr: 117.72.14.166:8848\n\nSa-Token集成Redis集成 Redis (sa-token.cc)\nredis.io&#x2F;docs&#x2F;management&#x2F;config\ngateway网关（sa-token）基于redis实现分布式会话鉴权gateway 集成 redis 及 refactor 鉴权\npom文件写入\n&lt;dependencies&gt;  &lt;!-- 省略了之前的部分，下面的是新增的 --&gt;    &lt;!-- Sa-Token 权限认证（Reactor响应式集成）, 在线文档：https://sa-token.cc --&gt;    &lt;dependency&gt;        &lt;groupId&gt;cn.dev33&lt;/groupId&gt;        &lt;artifactId&gt;sa-token-reactor-spring-boot-starter&lt;/artifactId&gt;        &lt;version&gt;1.37.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;!-- Sa-Token 整合 Redis （使用 jackson 序列化方式） --&gt;    &lt;dependency&gt;        &lt;groupId&gt;cn.dev33&lt;/groupId&gt;        &lt;artifactId&gt;sa-token-redis-jackson&lt;/artifactId&gt;        &lt;version&gt;1.37.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;        &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;        &lt;artifactId&gt;gson&lt;/artifactId&gt;        &lt;version&gt;2.8.6&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\ngateway的applicaiton.yaml,修改网关配置文件\nserver:  port: 5000spring:  cloud:    gateway:      routes:        - id: oss          uri: lb://jc-club-oss-dev          predicates:            - Path=/oss/**          filters:            - StripPrefix=1        - id: auth          uri: lb://jc-club-auth-dev          predicates:            - Path=/auth/**          filters:            - StripPrefix=1        - id: subject          uri: lb://jc-club-subject-dev          predicates:            - Path=/subject/**          filters:            - StripPrefix=1        - id: practice          uri: lb://jc-club-practice-dev          predicates:            - Path=/practice/**          filters:            - StripPrefix=1        - id: circle          uri: lb://jc-club-circle          predicates:            - Path=/circle/**          filters:            - StripPrefix=1        - id: interview          uri: lb://jc-club-interview          predicates:            - Path=/interview/**          filters:            - StripPrefix=1  redis:    # Redis数据库索引（默认为0）    database: 1    # Redis服务器地址    host: 117.72.14.166    # Redis服务器连接端口    port: 6379    # Redis服务器连接密码（默认为空）    password: jichi1234    # 连接超时时间    timeout: 2s    lettuce:      pool:        # 连接池最大连接数        max-active: 200        # 连接池最大阻塞等待时间（使用负值表示没有限制）        max-wait: -1ms        # 连接池中的最大空闲连接        max-idle: 10        # 连接池中的最小空闲连接        min-idle: 0sa-token:  # token 名称（同时也是 cookie 名称）  token-name: satoken  # token 有效期（单位：秒） 默认30天，-1 代表永久有效  timeout: 2592000  # token 最低活跃频率（单位：秒），如果 token 超过此时间没有访问系统就会被冻结，默认-1 代表不限制，永不冻结  active-timeout: -1  # 是否允许同一账号多地同时登录 （为 true 时允许一起登录, 为 false 时新登录挤掉旧登录）  is-concurrent: true  # 在多人登录同一账号时，是否共用一个 token （为 true 时所有登录共用一个 token, 为 false 时每次登录新建一个 token）  is-share: true  # token 风格（默认可取值：uuid、simple-uuid、random-32、random-64、random-128、tik）  token-style: random-32  # 是否输出操作日志  is-log: true  token-prefix: jichi\n\njc-club-auth-starter/application.yaml\n server:  port: 3011spring:  datasource:    username: root    password: qvQP7MBvSkbyGzLzlRaPp9swmOmkqdVkVgBNPQF7pMlImathGYopQcWR2CuZMZAkL1xrDHwut9Hbr2TZ4qmr2Q==    driver-class-name: com.mysql.cj.jdbc.Driver    url: jdbc:mysql://117.72.14.166:3306/jc-club?serverTimezone=Asia/Shanghai&amp;useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false    type: com.alibaba.druid.pool.DruidDataSource    druid:      initial-size: 20      min-idle: 20      connectionProperties: config.decrypt=true;config.decrypt.key=$&#123;publicKey&#125;;      max-active: 100      max-wait: 60000      stat-view-servlet:        enabled: true        url-pattern: /druid/*        login-username: admin        login-password: 123456      filter:        stat:          enabled: true          slow-sql-millis: 2000          log-slow-sql: true        wall:          enabled: true        config:          enabled: true  redis:    # Redis数据库索引（默认为0）    database: 1    # Redis服务器地址    host: 117.72.14.166    # Redis服务器连接端口    port: 6379    # Redis服务器连接密码（默认为空）    password: jichi1234    # 连接超时时间    timeout: 2s    lettuce: #lettuce连接池      pool:        # 连接池最大连接数        max-active: 200        # 连接池最大阻塞等待时间（使用负值表示没有限制）        max-wait: -1ms        # 连接池中的最大空闲连接        max-idle: 10        # 连接池中的最小空闲连接        min-idle: 0publicKey: MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAMJzo9TiSuOGAMR2Zma25lWdtR1oxq6RcZYnWE9vcYLNKxUOkBlvSfMrbS25KtlJi+hIzikfCoyTDB0VI5gB3Q8CAwEAAQ==logging:  config: classpath:log4j2-spring.xmlsa-token:  # token 名称（同时也是 cookie 名称）  token-name: satoken  # token 有效期（单位：秒） 默认30天，-1 代表永久有效  timeout: 2592000  # token 最低活跃频率（单位：秒），如果 token 超过此时间没有访问系统就会被冻结，默认-1 代表不限制，永不冻结  active-timeout: -1  # 是否允许同一账号多地同时登录 （为 true 时允许一起登录, 为 false 时新登录挤掉旧登录）  is-concurrent: true  # 在多人登录同一账号时，是否共用一个 token （为 true 时所有登录共用一个 token, 为 false 时每次登录新建一个 token）  is-share: true  # token 风格（默认可取值：uuid、simple-uuid、random-32、random-64、random-128、tik）  token-style: random-32  # 是否输出操作日志  is-log: true  token-prefix: jichi\n\n网关自定义权限接口扩展 \n@Componentpublic class StpInterfaceImpl implements StpInterface &#123;    @Resource    private RedisUtil redisUtil;    private String authPermissionPrefix = &quot;auth.permission&quot;;    private String authRolePrefix = &quot;auth.role&quot;;    @Override    public List&lt;String&gt; getPermissionList(Object loginId, String loginType) &#123;        return getAuth(loginId.toString(), authPermissionPrefix);    &#125;    @Override    public List&lt;String&gt; getRoleList(Object loginId, String loginType) &#123;        return getAuth(loginId.toString(), authRolePrefix);    &#125; &#125;\n\njc-club-gateway:SaTokenConfigure，satoken配置。\n这个配置类的主要作用是：\n\n拦截所有请求。\n根据请求的路径，执行不同的权限校验逻辑，确保只有具有相应权限的用户才能访问特定的资源。\n\n@Configurationpublic class SaTokenConfigure &#123;    @Bean    public SaReactorFilter getSaReactorFilter() &#123;        return new SaReactorFilter()                // 拦截地址                .addInclude(&quot;/**&quot;)                // 鉴权方法：每次访问进入                .setAuth(obj -&gt; &#123;                    System.out.println(&quot;-------- 前端访问path：&quot; + SaHolder.getRequest().getRequestPath());                    // 登录校验 -- 拦截所有路由，并排除/user/doLogin 用于开放登录                    SaRouter.match(&quot;/auth/**&quot;, &quot;/auth/user/doLogin&quot;, r -&gt; StpUtil.checkRole(&quot;admin&quot;));                    SaRouter.match(&quot;/oss/**&quot;, r -&gt; StpUtil.checkLogin());                    SaRouter.match(&quot;/subject/subject/add&quot;, r -&gt; StpUtil.checkPermission(&quot;subject:add&quot;));                    SaRouter.match(&quot;/subject/**&quot;, r -&gt; StpUtil.checkLogin());                &#125;)                ;    &#125;&#125;\n\n网关全局异常处理（sa-token mono）Sa-token 提供的示例，适用于单体项目的全局异常捕获。我们选择了微服务架构，则就要变为通过网关来进行全局异常的处理，我们希望，权限发生异常的时候，可以统一做 401 的返回，前端进行跳转登录。\n\nGatewayExceptionHandler.java\n这个全局异常处理器的主要作用是：\n\n捕获并处理网关中的异常。\n根据异常类型返回不同的状态码和消息。\n将异常信息序列化为 JSON 格式，并设置正确的 Content-Type 发送回客户端。\n\n深入学习ErrorWebExceptionHandler-CSDN博客\nFlux、Mono、Reactor 实战（史上最全）_reactor mono-CSDN博客\n[响应式编程二Mono，Flux简单介绍_flux mono-CSDN博客](https://blog.csdn.net/lsdstone/article/details/134983206?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=mono java响应式&amp;utm_medium&#x3D;distribute.pc_search_result.none-task-blog-2allsobaiduweb~default-2-134983206.142^v100^pc_search_result_base8&amp;spm&#x3D;1018.2226.3001.4187)\n@Componentpublic class GatewayExceptionHandler implements ErrorWebExceptionHandler &#123;    private ObjectMapper objectMapper = new ObjectMapper(); //创建了一个ObjectMapper实例，用于将Java对象转换为JSON格式。    @Override    public Mono&lt;Void&gt; handle(ServerWebExchange serverWebExchange, Throwable throwable) &#123; //处理异常的方法，返回一个Mono&lt;Void&gt;类型，表示异步操作的完成。        ServerHttpRequest request = serverWebExchange.getRequest();        ServerHttpResponse response = serverWebExchange.getResponse();        Integer code = 200;        String message = &quot;&quot;;        if (throwable instanceof SaTokenException) &#123;            code = 401;            message = &quot;用户无权限&quot;;            throwable.printStackTrace();        &#125; else &#123;            code = 500;            message = &quot;系统繁忙&quot;;            throwable.printStackTrace();        &#125;        Result result = Result.fail(code, message);        response.getHeaders().setContentType(MediaType.APPLICATION_JSON);        return response.writeWith(Mono.fromSupplier(() -&gt; &#123;            /*使用response.writeWith方法，结合Mono.fromSupplier来异步写入响应体。在Mono.fromSupplier中：使用objectMapper.writeValueAsBytes(result)将Result对象序列化为JSON格式的字节数组。使用DataBufferFactory.wrap(bytes)将字节数组包装成数据缓冲区，以便写入响应体*/            DataBufferFactory dataBufferFactory = response.bufferFactory();            byte[] bytes = null;            try &#123;                bytes = objectMapper.writeValueAsBytes(result); //json格式字节数组            &#125; catch (JsonProcessingException e) &#123;                e.printStackTrace();            &#125;            return dataBufferFactory.wrap(bytes); //包装成数据缓冲区        &#125;));    &#125;&#125;\n\nResultCodeEnum.java\n@Getterpublic enum ResultCodeEnum &#123;    SUCCESS(200,&quot;成功&quot;),    FAIL(500,&quot;失败&quot;);    public int code;    public String desc;    ResultCodeEnum(int code, String desc)&#123;        this.code = code;        this.desc = desc;    &#125;    public static ResultCodeEnum getByCode(int codeVal)&#123;        for(ResultCodeEnum resultCodeEnum : ResultCodeEnum.values())&#123;            if(resultCodeEnum.code == codeVal)&#123;                return resultCodeEnum;            &#125;        &#125;        return null;    &#125;&#125;\n\nResult.java\n@Datapublic class Result&lt;T&gt; &#123;    private Boolean success;    private Integer code;    private String message;    private T data;    public static Result ok() &#123;        Result result = new Result();        result.setSuccess(true);        result.setCode(ResultCodeEnum.SUCCESS.getCode());        result.setMessage(ResultCodeEnum.SUCCESS.getDesc());        return result;    &#125;    public static &lt;T&gt; Result ok(T data) &#123;        Result result = new Result();        result.setSuccess(true);        result.setCode(ResultCodeEnum.SUCCESS.getCode());        result.setMessage(ResultCodeEnum.SUCCESS.getDesc());        result.setData(data);        return result;    &#125;    public static Result fail() &#123;        Result result = new Result();        result.setSuccess(false);        result.setCode(ResultCodeEnum.FAIL.getCode());        result.setMessage(ResultCodeEnum.FAIL.getDesc());        return result;    &#125;    public static &lt;T&gt; Result fail(T data) &#123;        Result result = new Result();        result.setSuccess(false);        result.setCode(ResultCodeEnum.FAIL.getCode());        result.setMessage(ResultCodeEnum.FAIL.getDesc());        result.setData(data);        return result;    &#125;    public static Result fail(Integer code,String message) &#123;        Result result = new Result();        result.setSuccess(false);        result.setCode(code);        result.setMessage(message);        return result;    &#125;&#125;\n\ngateway实现redis权限数据拉取(gateway)RedisTemplate-&gt;RedisConfig(重写序列化，@Bean创建RedisTemplate bean)-&gt;RedisUtil(封装对redis的操作，具体是用redistemplate来操作的)\n为什么重写redistemplate?\n\n这里不重新他的一个序列化会造成一个乱码的问题，重写了RedisTemplate:\nobjectMapper-&gt;Jackson2jsonRedisSerializer-&gt;redisTemplate，注意@Bean注入\n\n\n\n网关读取权限内容有三种形式。\n1、网关层直接与数据库交互\n2、网关层与 redis 进行交互\n3、网关层与 redis 进行交互，redis 没有，则通过 feign 调用 auth 服务获取。\n选择第二种形式，完全信任缓存，同时引出数据库与缓存数据一致性的方案。\npom.xml\n&lt;dependency&gt;    &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;    &lt;artifactId&gt;gson&lt;/artifactId&gt;    &lt;version&gt;2.8.6&lt;/version&gt;&lt;/dependency&gt;\n\n自定义获取权限改为从 redis:\npackage com.jingdianjichi.club.gateway.auth;import cn.dev33.satoken.stp.StpInterface;import com.alibaba.cloud.commons.lang.StringUtils;import com.google.gson.Gson;import com.google.gson.reflect.TypeToken;import com.jingdianjichi.club.gateway.entity.AuthPermission;import com.jingdianjichi.club.gateway.entity.AuthRole;import com.jingdianjichi.club.gateway.redis.RedisUtil;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.stereotype.Component;import javax.annotation.Resource;import java.util.Collections;import java.util.LinkedList;import java.util.List;import java.util.stream.Collectors;@Componentpublic class StpInterfaceImpl implements StpInterface &#123;    @Resource    private RedisUtil redisUtil;    private String authPermissionPrefix = &quot;auth.permission&quot;;    private String authRolePrefix = &quot;auth.role&quot;;    @Override    public List&lt;String&gt; getPermissionList(Object loginId, String loginType) &#123;        return getAuth(loginId.toString(), authPermissionPrefix);    &#125;    @Override    public List&lt;String&gt; getRoleList(Object loginId, String loginType) &#123;        return getAuth(loginId.toString(), authRolePrefix);    &#125;    private List&lt;String&gt; getAuth(String loginId, String prefix) &#123;        String authKey = redisUtil.buildKey(prefix, loginId.toString());        String authValue = redisUtil.get(authKey);        if (StringUtils.isBlank(authValue)) &#123; //若空返回空            return Collections.emptyList();        &#125;        List&lt;String&gt; authList = new LinkedList&lt;&gt;();        if (authRolePrefix.equals(prefix)) &#123;            List&lt;AuthRole&gt; roleList = new Gson().fromJson(authValue, new TypeToken&lt;List&lt;AuthRole&gt;&gt;() &#123;            &#125;.getType());            authList = roleList.stream().map(AuthRole::getRoleKey).collect(Collectors.toList());        &#125; else if (authPermissionPrefix.equals(prefix)) &#123;            List&lt;AuthPermission&gt; permissionList = new Gson().fromJson(authValue, new TypeToken&lt;List&lt;AuthPermission&gt;&gt;() &#123;            &#125;.getType());            authList = permissionList.stream().map(AuthPermission::getPermissionKey).collect(Collectors.toList());        &#125;        return authList;    &#125;&#125;\n\nRedisTemplate 重写优化：原生 redis 的 template 的序列化器会产生乱码问题，重写改为 jackson。\nSpring date-redis中RedisTemplate的Jackson序列化设置_redistemplate序列化时date带有类型信息-CSDN博客\npackage com.jingdianjichi.club.gateway.config;import com.fasterxml.jackson.annotation.JsonAutoDetect;import com.fasterxml.jackson.annotation.JsonTypeInfo;import com.fasterxml.jackson.annotation.PropertyAccessor;import com.fasterxml.jackson.databind.DeserializationFeature;import com.fasterxml.jackson.databind.ObjectMapper;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;import org.springframework.data.redis.serializer.RedisSerializer;import org.springframework.data.redis.serializer.StringRedisSerializer;@Configurationpublic class RedisConfig &#123;   /*总结来说，通过在RedisConfig类中使用@Bean注解定义redisTemplate方法，Spring容器会在启动时创建并注册这个RedisTemplate Bean。之后，应用程序的其他部分可以通过@Autowired或@Resource注解来自动获取并使用这个Bean。*/    @Bean    public RedisTemplate&lt;String,Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory)&#123;        RedisTemplate&lt;String,Object&gt; redisTemplate = new RedisTemplate&lt;&gt;();        RedisSerializer&lt;String&gt; redisSerializer = new StringRedisSerializer();        redisTemplate.setConnectionFactory(redisConnectionFactory);        redisTemplate.setKeySerializer(redisSerializer);        redisTemplate.setHashKeySerializer(redisSerializer);        redisTemplate.setValueSerializer(jackson2JsonRedisSerializer());        redisTemplate.setHashValueSerializer(jackson2JsonRedisSerializer());        return redisTemplate;    &#125;    private Jackson2JsonRedisSerializer&lt;Object&gt; jackson2JsonRedisSerializer()&#123;        Jackson2JsonRedisSerializer&lt;Object&gt; jsonRedisSerializer = new Jackson2JsonRedisSerializer&lt;&gt;(Object.class);         ObjectMapper objectMapper = new ObjectMapper();        objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); //设置 ObjectMapper 的访问级别，使其能够序列化所有字段，无论它们是否有 public 访问权限。        objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES,false);        objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY);        jsonRedisSerializer.setObjectMapper(objectMapper); //将配置好的 ObjectMapper 设置到 Jackson2JsonRedisSerializer 中。        return jsonRedisSerializer;    &#125;&#125;\n\nRedisUtil 的封装\npackage com.jingdianjichi.club.gateway.config;import lombok.extern.slf4j.Slf4j;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.stereotype.Component;import javax.annotation.Resource;import java.util.Set;import java.util.concurrent.TimeUnit;import java.util.stream.Collectors;import java.util.stream.Stream;/** * RedisUtil工具类* * @author: ChickenWing * @date: 2023/1/15 */@Component@Slf4jpublic class RedisUtil &#123;    @Resource    private RedisTemplate redisTemplate; //通过DI拿到被RedisConfig改后的RedisTemplate    private static final String CACHE_KEY_SEPARATOR = &quot;.&quot;;    /**     * 构建缓存key     */    public String buildKey(String... strObjs) &#123;        return Stream.of(strObjs).collect(Collectors.joining(CACHE_KEY_SEPARATOR));    &#125;    /**     * 是否存在key     */    public boolean exist(String key) &#123;        return redisTemplate.hasKey(key);    &#125;    /**     * 删除key     */    public boolean del(String key) &#123;        return redisTemplate.delete(key);    &#125;    public void set(String key, String value) &#123;        redisTemplate.opsForValue().set(key, value);    &#125;    public boolean setNx(String key, String value, Long time, TimeUnit timeUnit) &#123;        return redisTemplate.opsForValue().setIfAbsent(key, value, time, timeUnit);    &#125;    public String get(String key) &#123;        return (String) redisTemplate.opsForValue().get(key);    &#125;    public Boolean zAdd(String key, String value, Long score) &#123;        return redisTemplate.opsForZSet().add(key, value, Double.valueOf(String.valueOf(score)));    &#125;    public Long countZset(String key) &#123;        return redisTemplate.opsForZSet().size(key);    &#125;    public Set&lt;String&gt; rangeZset(String key, long start, long end) &#123;        return redisTemplate.opsForZSet().range(key, start, end);    &#125;    public Long removeZset(String key, Object value) &#123;        return redisTemplate.opsForZSet().remove(key, value);    &#125;    public void removeZsetList(String key, Set&lt;String&gt; value) &#123;        value.stream().forEach((val) -&gt; redisTemplate.opsForZSet().remove(key, val));    &#125;    public Double score(String key, Object value) &#123;        return redisTemplate.opsForZSet().score(key, value);    &#125;    public Set&lt;String&gt; rangeByScore(String key, long start, long end) &#123;        return redisTemplate.opsForZSet().rangeByScore(key, Double.valueOf(String.valueOf(start)), Double.valueOf(String.valueOf(end)));    &#125;    public Object addScore(String key, Object obj, double score) &#123;        return redisTemplate.opsForZSet().incrementScore(key, obj, score);    &#125;    public Object rank(String key, Object obj) &#123;        return redisTemplate.opsForZSet().rank(key, obj);    &#125;&#125;\n\n用户模块开发(auth_user)依然有从DTO-&gt;BO-&gt;entity的converter，此部分忽略掉描述\ncontroller包@RestController@RequestMapping(&quot;/user/&quot;)@Slf4jpublic class UserController &#123;    @Resource    private AuthUserDomainService authUserDomainService;    /**     * 用户注册     */    @RequestMapping(&quot;register&quot;)    public Result&lt;Boolean&gt; register(@RequestBody AuthUserDTO authUserDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;UserController.register.dto:&#123;&#125;&quot;, JSON.toJSONString(authUserDTO));            &#125;            checkUserInfo(authUserDTO);            AuthUserBO authUserBO = AuthUserDTOConverter.INSTANCE.convertDTOToBO(authUserDTO);            return Result.ok(authUserDomainService.register(authUserBO));        &#125; catch (Exception e) &#123;            log.error(&quot;UserController.register.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;注册用户失败&quot;);        &#125;    &#125;    /**     * 修改用户信息     */    @RequestMapping(&quot;update&quot;)    public Result&lt;Boolean&gt; update(@RequestBody AuthUserDTO authUserDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;UserController.update.dto:&#123;&#125;&quot;, JSON.toJSONString(authUserDTO));            &#125;            checkUserInfo(authUserDTO);            AuthUserBO authUserBO = AuthUserDTOConverter.INSTANCE.convertDTOToBO(authUserDTO);            return Result.ok(authUserDomainService.update(authUserBO));        &#125; catch (Exception e) &#123;            log.error(&quot;UserController.update.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;更新用户信息失败&quot;);        &#125;    &#125;    /**     * 获取用户信息     */    @RequestMapping(&quot;getUserInfo&quot;)    public Result&lt;AuthUserDTO&gt; getUserInfo(@RequestBody AuthUserDTO authUserDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;UserController.getUserInfo.dto:&#123;&#125;&quot;, JSON.toJSONString(authUserDTO));            &#125;            Preconditions.checkArgument(!StringUtils.isBlank(authUserDTO.getUserName()), &quot;用户名不能为空&quot;);            AuthUserBO authUserBO = AuthUserDTOConverter.INSTANCE.convertDTOToBO(authUserDTO);            AuthUserBO userInfo = authUserDomainService.getUserInfo(authUserBO);            return Result.ok(AuthUserDTOConverter.INSTANCE.convertBOToDTO(userInfo));        &#125; catch (Exception e) &#123;            log.error(&quot;UserController.update.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;更新用户信息失败&quot;);        &#125;    &#125;    /**     * 批量获取用户信息     */    @RequestMapping(&quot;listByIds&quot;)    public Result&lt;List&lt;AuthUserDTO&gt;&gt; listUserInfoByIds(@RequestBody List&lt;String&gt; userNameList) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;UserController.listUserInfoByIds.dto:&#123;&#125;&quot;, JSON.toJSONString(userNameList));            &#125;            Preconditions.checkArgument(!CollectionUtils.isEmpty(userNameList), &quot;id集合不能为空&quot;);            List&lt;AuthUserBO&gt; userInfos = authUserDomainService.listUserInfoByIds(userNameList);            return Result.ok(AuthUserDTOConverter.INSTANCE.convertBOToDTO(userInfos));        &#125; catch (Exception e) &#123;            log.error(&quot;UserController.listUserInfoByIds.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;批量获取用户信息失败&quot;);        &#125;    &#125;    /**     * 用户退出     */    @RequestMapping(&quot;logOut&quot;)    public Result logOut(@RequestParam String userName) &#123;        try &#123;            log.info(&quot;UserController.logOut.userName:&#123;&#125;&quot;, userName);            Preconditions.checkArgument(!StringUtils.isBlank(userName), &quot;用户名不能为空&quot;);            StpUtil.logout(userName);            return Result.ok();        &#125; catch (Exception e) &#123;            log.error(&quot;UserController.logOut.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;用户登出失败&quot;);        &#125;    &#125;    /**     * 删除用户     */    @RequestMapping(&quot;delete&quot;)    public Result&lt;Boolean&gt; delete(@RequestBody AuthUserDTO authUserDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;UserController.delete.dto:&#123;&#125;&quot;, JSON.toJSONString(authUserDTO));            &#125;            AuthUserBO authUserBO = AuthUserDTOConverter.INSTANCE.convertDTOToBO(authUserDTO);            return Result.ok(authUserDomainService.update(authUserBO));        &#125; catch (Exception e) &#123;            log.error(&quot;UserController.update.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;删除用户信息失败&quot;);        &#125;    &#125;    private void checkUserInfo(@RequestBody AuthUserDTO authUserDTO) &#123;        Preconditions.checkArgument(!StringUtils.isBlank(authUserDTO.getUserName()), &quot;用户名不能为空&quot;);    &#125;    /**     * 用户启用/禁用     */    @RequestMapping(&quot;changeStatus&quot;)    public Result&lt;Boolean&gt; changeStatus(@RequestBody AuthUserDTO authUserDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;UserController.changeStatus.dto:&#123;&#125;&quot;, JSON.toJSONString(authUserDTO));            &#125;            Preconditions.checkNotNull(authUserDTO.getStatus(), &quot;用户状态不能为空&quot;);            AuthUserBO authUserBO = AuthUserDTOConverter.INSTANCE.convertDTOToBO(authUserDTO);            return Result.ok(authUserDomainService.update(authUserBO));        &#125; catch (Exception e) &#123;            log.error(&quot;UserController.changeStatus.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;启用/禁用用户信息失败&quot;);        &#125;    &#125;    @RequestMapping(&quot;doLogin&quot;)    public Result&lt;SaTokenInfo&gt; doLogin(@RequestParam(&quot;validCode&quot;) String validCode) &#123;        try &#123;            Preconditions.checkArgument(!StringUtils.isBlank(validCode), &quot;验证码不能为空!&quot;);            return Result.ok(authUserDomainService.doLogin(validCode));        &#125; catch (Exception e) &#123;            log.error(&quot;UserController.doLogin.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;用户登录失败&quot;);        &#125;    &#125;    // 查询登录状态，浏览器访问： http://localhost:8081/user/isLogin    @RequestMapping(&quot;isLogin&quot;)    public String isLogin() &#123;        return &quot;当前会话是否登录：&quot; + StpUtil.isLogin();    &#125;&#125;\n\n\n\ndomain包AuthUserDomainServiceImpl.java（用户注册、更新、删除、登录和信息查询，redis）\n\n资源注入\n\n\n@Resource：用于自动注入Spring管理的Bean，如各种服务（Service）和RedisUtil。\n\n\n成员变量\n\n\n定义了用于构建Redis键的前缀、盐值（salt）、登录验证码前缀（LOGIN_PREFIX）。\n\n\n注册方法\n\n\n@Override：覆盖接口中定义的方法。\n@SneakyThrows：使用Lombok注解来隐藏抛出的异常。\n@Transactional：声明事务支持，指定异常回滚。\npublic Boolean register(AuthUserBO authUserBO)：注册用户的方法。\n\n\n注册逻辑\n\n\n检查用户是否存在。\n密码加密存储。（md5+salt）\n设置默认头像和昵称。\n插入用户数据到数据库。\n建立用户与角色的关联。\n将角色和权限信息存储到Redis。\n\n\n更新和删除方法\n\n\npublic Boolean update(AuthUserBO authUserBO)：更新用户信息的方法。\npublic Boolean delete(AuthUserBO authUserBO)：逻辑删除用户的方法，同时更新Redis中的缓存。\n\n\n登录和获取用户信息方法\n\n\npublic SaTokenInfo doLogin(String validCode)：处理用户登录的方法，使用Sa-Token进行认证。\npublic AuthUserBO getUserInfo(AuthUserBO authUserBO)：根据用户名获取用户信息的方法。\n\n\n批量获取用户信息方法\n\n\npublic List&lt;AuthUserBO&gt; listUserInfoByIds(List&lt;String&gt; userNameList)：根据用户ID列表批量获取用户信息的方法。\n\n\n事务和异常处理\n\n\n注册、更新和删除方法使用@Transactional注解，确保操作的原子性。\n使用@SneakyThrows来处理可能抛出的异常，避免显式声明异常。\n\n\n日志记录\n\n\nlog变量用于记录日志信息。\n\n\n缓存操作\n\n\n使用RedisUtil进行Redis的读写操作，如存储用户的角色和权限信息。\n\n\n密码安全\n\n\n使用SaSecureUtil.md5BySalt方法对用户密码进行MD5加盐加密。\n\n\n默认资源\n\n\n为新用户设置了默认的头像和昵称。\n\n\n服务交互\n\n\n通过调用AuthUserService、AuthUserRoleService等的方法，实现业务逻辑。\n\n这个AuthUserDomainServiceImpl类通过实现AuthUserDomainService接口，提供了用户注册、更新、删除、登录和信息查询等服务，同时与Redis缓存进行交互，以提高系统的响应速度和性能。\n@Service@Slf4jpublic class AuthUserDomainServiceImpl implements AuthUserDomainService &#123;    @Resource    private AuthUserService authUserService;    @Resource    private AuthUserRoleService authUserRoleService;    @Resource    private AuthPermissionService authPermissionService;    @Resource    private AuthRolePermissionService authRolePermissionService;    @Resource    private AuthRoleService authRoleService;    private String salt = &quot;chicken&quot;;    @Resource    private RedisUtil redisUtil;    private String authPermissionPrefix = &quot;auth.permission&quot;;    private String authRolePrefix = &quot;auth.role&quot;;    private static final String LOGIN_PREFIX = &quot;loginCode&quot;;    @Override    @SneakyThrows    @Transactional(rollbackFor = Exception.class)    public Boolean register(AuthUserBO authUserBO) &#123;        //校验用户是否存在        AuthUser existAuthUser = new AuthUser();        existAuthUser.setUserName(authUserBO.getUserName());        List&lt;AuthUser&gt; existUser = authUserService.queryByCondition(existAuthUser);        if (existUser.size() &gt; 0) &#123;            return true;        &#125;        AuthUser authUser = AuthUserBOConverter.INSTANCE.convertBOToEntity(authUserBO);        if (StringUtils.isNotBlank(authUser.getPassword())) &#123;            authUser.setPassword(SaSecureUtil.md5BySalt(authUser.getPassword(), salt));        &#125;        if (StringUtils.isBlank(authUser.getAvatar())) &#123;            authUser.setAvatar(&quot;http://117.72.10.84:9000/user/icon/微信图片_20231203153718(1).png&quot;);        &#125;        if (StringUtils.isBlank(authUser.getNickName())) &#123;            authUser.setNickName(&quot;lzrj&quot;);        &#125;        authUser.setStatus(AuthUserStatusEnum.OPEN.getCode());        authUser.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());        Integer count = authUserService.insert(authUser);        //建立一个初步的角色的关联        AuthRole authRole = new AuthRole();        authRole.setRoleKey(AuthConstant.NORMAL_USER);        AuthRole roleResult = authRoleService.queryByCondition(authRole);        Long roleId = roleResult.getId();        Long userId = authUser.getId();        AuthUserRole authUserRole = new AuthUserRole();        authUserRole.setUserId(userId);        authUserRole.setRoleId(roleId);        authUserRole.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());        authUserRoleService.insert(authUserRole);        String roleKey = redisUtil.buildKey(authRolePrefix, authUser.getUserName());        List&lt;AuthRole&gt; roleList = new LinkedList&lt;&gt;();        roleList.add(authRole);        redisUtil.set(roleKey, new Gson().toJson(roleList));        AuthRolePermission authRolePermission = new AuthRolePermission();        authRolePermission.setRoleId(roleId);        List&lt;AuthRolePermission&gt; rolePermissionList = authRolePermissionService.                queryByCondition(authRolePermission);        List&lt;Long&gt; permissionIdList = rolePermissionList.stream()                .map(AuthRolePermission::getPermissionId).collect(Collectors.toList());        //根据roleId查权限        List&lt;AuthPermission&gt; permissionList = authPermissionService.queryByRoleList(permissionIdList);        String permissionKey = redisUtil.buildKey(authPermissionPrefix, authUser.getUserName());        redisUtil.set(permissionKey, new Gson().toJson(permissionList));        return count &gt; 0;    &#125;    @Override    public Boolean update(AuthUserBO authUserBO) &#123;        AuthUser authUser = AuthUserBOConverter.INSTANCE.convertBOToEntity(authUserBO);        Integer count = authUserService.updateByUserName(authUser);        return count &gt; 0;    &#125;    @Override    public Boolean delete(AuthUserBO authUserBO) &#123;        AuthUser authUser = new AuthUser();        authUser.setId(authUserBO.getId());        authUser.setIsDeleted(IsDeletedFlagEnum.DELETED.getCode());        Integer count = authUserService.update(authUser);        //有任何的更新，都要与缓存进行同步的修改        return count &gt; 0;    &#125;    @Override    public SaTokenInfo doLogin(String validCode) &#123;        String loginKey = redisUtil.buildKey(LOGIN_PREFIX, validCode);        String openId = redisUtil.get(loginKey);        if (StringUtils.isBlank(openId)) &#123;            return null;        &#125;        AuthUserBO authUserBO = new AuthUserBO();        authUserBO.setUserName(openId);        this.register(authUserBO);        StpUtil.login(openId);        SaTokenInfo tokenInfo = StpUtil.getTokenInfo();        return tokenInfo;    &#125;    @Override    public AuthUserBO getUserInfo(AuthUserBO authUserBO) &#123;        AuthUser authUser = new AuthUser();        authUser.setUserName(authUserBO.getUserName());        List&lt;AuthUser&gt; userList = authUserService.queryByCondition(authUser);        if (CollectionUtils.isEmpty(userList)) &#123;            return new AuthUserBO();        &#125;        AuthUser user = userList.get(0);        return AuthUserBOConverter.INSTANCE.convertEntityToBO(user);    &#125;    @Override    public List&lt;AuthUserBO&gt; listUserInfoByIds(List&lt;String&gt; userNameList) &#123;        List&lt;AuthUser&gt; userList = authUserService.listUserInfoByIds(userNameList);        if (CollectionUtils.isEmpty(userList)) &#123;            return Collections.emptyList();        &#125;        return AuthUserBOConverter.INSTANCE.convertEntityToBO(userList);    &#125;&#125;\n\ninfra层\n对这五张表的增删查改\n常见加密&amp;密码加密前言\n数据库如果说存储明文的密码是非常的危险的，一旦被攻击啊，或者数据泄漏，用户的信息疯狂的暴露出去，黑客什么都能干，这是非常不行，所以我们要做加密，让黑客即使拿到了密码信息， 也不知道原始的密码，就登录不成功。\n加密的方式\n\n摘要加密\nmd5，sha1，sha256\n摘要主要就是哈希值，通过我们的散列的算法。摘要的概念主要是验证完整性和唯一性，不管我们的密码是多长啊，或者多复杂的啊，得到的值都是固定长度。\n摘要加密有一定的风险。123456 用 md5 加密。他其实是固定的，大家也可以到一些网站有反解密。\n\n对称加密\n我们约定了一个密钥。这个密钥一定要好好保存，不能泄漏，一旦泄漏就可以进行想你想的解密了。\n加密的过程：密码+密钥 生成\n解密的过程：密文+密钥 反解\n密钥一定一定要做好其中的保存。\n常见的对称加密的算法：AES，DES，3DESC，SM4\n\n非对称加密\n一个公钥，一个私钥。\n公钥去加密，私钥去解密。\n私钥去加密，公钥去解密。\n常见的算法：RSA，ECC，国密的 SM2\n算法的时性能上，差一点，加密的数量没有对称加密快。\n\n\n加盐？是做饭吗？\n摘要算法比如 md5，光加密 123456，结果都是一样的，如果是破解的库里正好有这个 md5 就很容易知道逆向是 123456。来一手加盐。盐是随机的字符串，他来与原密码进行一波二次加密。这样获取到的很难破解出来。如果不加盐，简单密码很容易撞库的。\nAuthUserDomainServiceImpl.java，satoken:md5+salt，这里的salt是一个字符串\n@Override@SneakyThrows@Transactional(rollbackFor = Exception.class)public Boolean register(AuthUserBO authUserBO) &#123;    //校验用户是否存在    AuthUser existAuthUser = new AuthUser();    existAuthUser.setUserName(authUserBO.getUserName());    List&lt;AuthUser&gt; existUser = authUserService.queryByCondition(existAuthUser);    if (existUser.size() &gt; 0) &#123;        return true;    &#125;    AuthUser authUser = AuthUserBOConverter.INSTANCE.convertBOToEntity(authUserBO);    if (StringUtils.isNotBlank(authUser.getPassword())) &#123;        authUser.setPassword(SaSecureUtil.md5BySalt(authUser.getPassword(), salt)); //satoken:md5+salt，这里的salt是一个字符串    &#125;    if (StringUtils.isBlank(authUser.getAvatar())) &#123;        authUser.setAvatar(&quot;http://117.72.10.84:9000/user/icon/微信图片_20231203153718(1).png&quot;);    &#125;   \t......&#125;\n\n角色模块开发(auth_role)controllerRolePermissionController.java\npackage com.jingdianjichi.auth.application.controller;import com.alibaba.fastjson.JSON;import com.google.common.base.Preconditions;import com.jingdianjichi.auth.application.convert.AuthRolePermissionDTOConverter;import com.jingdianjichi.auth.application.dto.AuthRolePermissionDTO;import com.jingdianjichi.auth.domain.entity.AuthRolePermissionBO;import com.jingdianjichi.auth.domain.service.AuthRolePermissionDomainService;import com.jingdianjichi.auth.entity.Result;import lombok.extern.slf4j.Slf4j;import org.springframework.util.CollectionUtils;import org.springframework.web.bind.annotation.RequestBody;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import javax.annotation.Resource;/** * 角色权限controller * * @author: ChickenWing * @date: 2023/11/2 */@RestController@RequestMapping(&quot;/rolePermission/&quot;)@Slf4jpublic class RolePermissionController &#123;    @Resource    private AuthRolePermissionDomainService authRolePermissionDomainService;    /**     * 新增角色权限关联关系     */    @RequestMapping(&quot;add&quot;)    public Result&lt;Boolean&gt; add(@RequestBody AuthRolePermissionDTO authRolePermissionDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;RolePermissionController.add.dto:&#123;&#125;&quot;, JSON.toJSONString(authRolePermissionDTO));            &#125;            Preconditions.checkArgument(!CollectionUtils.isEmpty(authRolePermissionDTO.getPermissionIdList()),&quot;权限关联不能为空&quot;);            Preconditions.checkNotNull(authRolePermissionDTO.getRoleId(),&quot;角色不能为空!&quot;);            AuthRolePermissionBO rolePermissionBO = AuthRolePermissionDTOConverter.INSTANCE.convertDTOToBO(authRolePermissionDTO);            return Result.ok(authRolePermissionDomainService.add(rolePermissionBO));        &#125; catch (Exception e) &#123;            log.error(&quot;PermissionController.add.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;新增角色权限失败&quot;);        &#125;    &#125;&#125;\n\nRoleController.java\npackage com.jingdianjichi.auth.application.controller;import com.alibaba.fastjson.JSON;import com.google.common.base.Preconditions;import com.jingdianjichi.auth.application.convert.AuthRoleDTOConverter;import com.jingdianjichi.auth.application.dto.AuthRoleDTO;import com.jingdianjichi.auth.domain.entity.AuthRoleBO;import com.jingdianjichi.auth.domain.service.AuthRoleDomainService;import com.jingdianjichi.auth.entity.Result;import lombok.extern.slf4j.Slf4j;import org.apache.commons.lang3.StringUtils;import org.springframework.web.bind.annotation.RequestBody;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import javax.annotation.Resource;/** * 角色controller * * @author: ChickenWing * @date: 2023/11/2 */@RestController@RequestMapping(&quot;/role/&quot;)@Slf4jpublic class RoleController &#123;    @Resource    private AuthRoleDomainService authRoleDomainService;    /**     * 新增角色     */    @RequestMapping(&quot;add&quot;)    public Result&lt;Boolean&gt; add(@RequestBody AuthRoleDTO authRoleDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;RoleController.add.dto:&#123;&#125;&quot;, JSON.toJSONString(authRoleDTO));            &#125;            Preconditions.checkArgument(!StringUtils.isBlank(authRoleDTO.getRoleKey()), &quot;角色key不能为空&quot;);            Preconditions.checkArgument(!StringUtils.isBlank(authRoleDTO.getRoleName()), &quot;角色名称不能为空&quot;);            AuthRoleBO authRoleBO = AuthRoleDTOConverter.INSTANCE.convertDTOToBO(authRoleDTO);            return Result.ok(authRoleDomainService.add(authRoleBO));        &#125; catch (Exception e) &#123;            log.error(&quot;UserController.register.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;新增角色失败&quot;);        &#125;    &#125;    /**     * 修改角色     */    @RequestMapping(&quot;update&quot;)    public Result&lt;Boolean&gt; update(@RequestBody AuthRoleDTO authRoleDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;RoleController.update.dto:&#123;&#125;&quot;, JSON.toJSONString(authRoleDTO));            &#125;            Preconditions.checkNotNull(authRoleDTO.getId(), &quot;角色id不能为空&quot;);            AuthRoleBO authRoleBO = AuthRoleDTOConverter.INSTANCE.convertDTOToBO(authRoleDTO);            return Result.ok(authRoleDomainService.update(authRoleBO));        &#125; catch (Exception e) &#123;            log.error(&quot;RoleController.update.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;更新角色信息失败&quot;);        &#125;    &#125;    /**     * 删除角色     */    @RequestMapping(&quot;delete&quot;)    public Result&lt;Boolean&gt; delete(@RequestBody AuthRoleDTO authRoleDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;RoleController.delete.dto:&#123;&#125;&quot;, JSON.toJSONString(authRoleDTO));            &#125;            AuthRoleBO authRoleBO = AuthRoleDTOConverter.INSTANCE.convertDTOToBO(authRoleDTO);            return Result.ok(authRoleDomainService.delete(authRoleBO));        &#125; catch (Exception e) &#123;            log.error(&quot;RoleController.delete.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;删除角色信息失败&quot;);        &#125;    &#125;&#125;\n\nPermissionController.java\npackage com.jingdianjichi.auth.application.controller;import com.alibaba.fastjson.JSON;import com.google.common.base.Preconditions;import com.jingdianjichi.auth.application.convert.AuthPermissionDTOConverter;import com.jingdianjichi.auth.application.dto.AuthPermissionDTO;import com.jingdianjichi.auth.domain.entity.AuthPermissionBO;import com.jingdianjichi.auth.domain.service.AuthPermissionDomainService;import com.jingdianjichi.auth.entity.Result;import lombok.extern.slf4j.Slf4j;import org.apache.commons.lang3.StringUtils;import org.springframework.web.bind.annotation.RequestBody;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import javax.annotation.Resource;/** * 权限controller * * @author: ChickenWing * @date: 2023/11/2 */@RestController@RequestMapping(&quot;/permission/&quot;)@Slf4jpublic class PermissionController &#123;    @Resource    private AuthPermissionDomainService authPermissionDomainService;    /**     * 新增权限     */    @RequestMapping(&quot;add&quot;)    public Result&lt;Boolean&gt; add(@RequestBody AuthPermissionDTO authPermissionDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;PermissionController.add.dto:&#123;&#125;&quot;, JSON.toJSONString(authPermissionDTO));            &#125;            Preconditions.checkArgument(!StringUtils.isBlank(authPermissionDTO.getName()), &quot;权限名称不能为空&quot;);            Preconditions.checkNotNull(authPermissionDTO.getParentId(), &quot;权限父id不能为空&quot;);            AuthPermissionBO permissionBO = AuthPermissionDTOConverter.INSTANCE.convertDTOToBO(authPermissionDTO);            return Result.ok(authPermissionDomainService.add(permissionBO));        &#125; catch (Exception e) &#123;            log.error(&quot;PermissionController.add.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;新增权限失败&quot;);        &#125;    &#125;    /**     * 修改权限     */    @RequestMapping(&quot;update&quot;)    public Result&lt;Boolean&gt; update(@RequestBody AuthPermissionDTO authPermissionDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;PermissionController.update.dto:&#123;&#125;&quot;, JSON.toJSONString(authPermissionDTO));            &#125;            Preconditions.checkNotNull(authPermissionDTO.getId(), &quot;权限id不能为空&quot;);            AuthPermissionBO permissionBO = AuthPermissionDTOConverter.INSTANCE.convertDTOToBO(authPermissionDTO);            return Result.ok(authPermissionDomainService.update(permissionBO));        &#125; catch (Exception e) &#123;            log.error(&quot;PermissionController.update.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;更新权限信息失败&quot;);        &#125;    &#125;    /**     * 删除权限     */    @RequestMapping(&quot;delete&quot;)    public Result&lt;Boolean&gt; delete(@RequestBody AuthPermissionDTO authPermissionDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;PermissionController.delete.dto:&#123;&#125;&quot;, JSON.toJSONString(authPermissionDTO));            &#125;            Preconditions.checkNotNull(authPermissionDTO.getId(), &quot;权限id不能为空&quot;);            AuthPermissionBO permissionBO = AuthPermissionDTOConverter.INSTANCE.convertDTOToBO(authPermissionDTO);            return Result.ok(authPermissionDomainService.delete(permissionBO));        &#125; catch (Exception e) &#123;            log.error(&quot;PermissionController.delete.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;删除权限信息失败&quot;);        &#125;    &#125;    /**     * 查询用户权限     */    @RequestMapping(&quot;getPermission&quot;)    public Result&lt;Boolean&gt; getPermission(String userName) &#123;        try &#123;            log.info(&quot;PermissionController.getPermission.userName:&#123;&#125;&quot;,userName);            Preconditions.checkArgument(!StringUtils.isBlank(userName), &quot;用户id不能为空&quot;);            return Result.ok(authPermissionDomainService.getPermission(userName));        &#125; catch (Exception e) &#123;            log.error(&quot;PermissionController.getPermission.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;查询用户权限信息失败&quot;);        &#125;    &#125;&#125;\n\ndomainAuthPermissionDomainServiceImpl.java(权限)\n\n业务方法实现\n\n\n@Override：覆盖接口中定义的方法。\npublic Boolean add(AuthPermissionBO authPermissionBO)：添加权限的方法，将业务对象（BO）转换为实体对象（Entity），设置未删除标志，并插入数据库。\npublic Boolean update(AuthPermissionBO authPermissionBO)：更新权限的方法，将BO转换为Entity，并更新数据库。\npublic Boolean delete(AuthPermissionBO authPermissionBO)：逻辑删除权限的方法，更新删除标志。\n\n\n权限获取方法\n\n\npublic List&lt;String&gt; getPermission(String userName)\n  ：根据用户名获取权限列表的方法。  - 使用`RedisUtil`构建权限的Redis键。  - 从Redis中获取权限的JSON字符串。  - 如果Redis中没有数据，则返回空列表。  - 使用Gson反序列化JSON字符串为`AuthPermission`列表。  - 从权限列表中提取权限键（Permission Key）。3. 日志记录- `log`变量用于记录日志信息。4. 缓存操作- 使用`RedisUtil`进行Redis的读写操作，如获取用户权限信息。5. 数据转换- 使用`AuthPermissionBOConverter`将业务对象（BO）转换为数据库实体（Entity）。6. 逻辑删除- 设置`IsDeletedFlagEnum.UN_DELETED.getCode()`和`IsDeletedFlagEnum.DELETED.getCode()`来标记记录的删除状态。这个`AuthPermissionDomainServiceImpl`类通过实现`AuthPermissionDomainService`接口，提供了权限的增删改以及根据用户名获取权限列表的服务。它利用了Redis缓存来提高获取权限列表的性能，并采用了逻辑删除的方式来管理权限数据。通过这种方式，应用程序可以灵活地进行权限控制和验证。```java@Service@Slf4jpublic class AuthPermissionDomainServiceImpl implements AuthPermissionDomainService &#123;    @Resource    private AuthPermissionService authPermissionService;    @Resource    private RedisUtil redisUtil;    private String authPermissionPrefix = &quot;auth.permission&quot;;    @Override    public Boolean add(AuthPermissionBO authPermissionBO) &#123;        AuthPermission authPermission = AuthPermissionBOConverter.INSTANCE.convertBOToEntity(authPermissionBO);        authPermission.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());        Integer count = authPermissionService.insert(authPermission);        return count &gt; 0;    &#125;    @Override    public Boolean update(AuthPermissionBO authPermissionBO) &#123;        AuthPermission authPermission = AuthPermissionBOConverter.INSTANCE.convertBOToEntity(authPermissionBO);        Integer count = authPermissionService.update(authPermission);        return count &gt; 0;    &#125;    @Override    public Boolean delete(AuthPermissionBO authPermissionBO) &#123;        AuthPermission authPermission = new AuthPermission();        authPermission.setId(authPermissionBO.getId());        authPermission.setIsDeleted(IsDeletedFlagEnum.DELETED.getCode());        Integer count = authPermissionService.update(authPermission);        return count &gt; 0;    &#125;    @Override    public List&lt;String&gt; getPermission(String userName) &#123;        String permissionKey = redisUtil.buildKey(authPermissionPrefix, userName);        String permissionValue = redisUtil.get(permissionKey);        if (StringUtils.isBlank(permissionValue)) &#123;            return Collections.emptyList();        &#125;        List&lt;AuthPermission&gt; permissionList = new Gson().fromJson(permissionValue,                new TypeToken&lt;List&lt;AuthPermission&gt;&gt;() &#123;                &#125;.getType());        List&lt;String&gt; authList = permissionList.stream().map(AuthPermission::getPermissionKey).collect(Collectors.toList());        return authList;    &#125;&#125;\n\n\n\nAuthRoleDomainServiceImpl（角色）\n\n业务方法实现@Override：覆盖接口中定义的方法。\n添加角色方法public Boolean add(AuthRoleBO authRoleBO)：\n添加角色的方法。\n使用 AuthRoleBOConverter 将业务对象（BO）转换为实体对象（Entity）。\n设置角色未删除标志。\n调用 authRoleService 的 insert 方法将实体插入数据库。\n返回操作影响的行数是否大于0。\n\n\n\n\n更新角色方法public Boolean update(AuthRoleBO authRoleBO)：\n更新角色的方法。\n类似于添加方法，但调用 update 方法更新数据库中的实体。\n\n\n\n\n删除角色方法public Boolean delete(AuthRoleBO authRoleBO)：\n逻辑删除角色的方法。\n创建一个新的 AuthRole 实体，设置ID和逻辑删除标志。\n调用 authRoleService 的 update 方法更新数据库中的实体。8.\n\n\n\n\n日志记录log \n变量用于记录日志信息。\n\n\n逻辑删除设置 \nIsDeletedFlagEnum.UN_DELETED.getCode() 和 IsDeletedFlagEnum.DELETED.getCode() 来标记记录的删除状态。\n\n\n\n这个 AuthRoleDomainServiceImpl 类通过实现 AuthRoleDomainService 接口，提供了角色的增删改服务。它利用了逻辑删除的方式来管理角色数据，通过这种方式，应用程序可以灵活地进行角色管理和权限分配。注意，代码中没有显示具体的日志输出语句，但 @Slf4j 注解会在类中添加日志变量，可以在方法中使用 log 进行日志记录。此外，@SneakyThrows 注解未在此代码片段中使用，如果存在，它通常用于隐藏方法抛出的异常。\n@Service@Slf4jpublic class AuthRoleDomainServiceImpl implements AuthRoleDomainService &#123;    @Resource    private AuthRoleService authRoleService;    @Override    public Boolean add(AuthRoleBO authRoleBO) &#123;        AuthRole authRole = AuthRoleBOConverter.INSTANCE.convertBOToEntity(authRoleBO);        authRole.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());        Integer count = authRoleService.insert(authRole);        return count &gt; 0;    &#125;    @Override    public Boolean update(AuthRoleBO authRoleBO) &#123;        AuthRole authRole = AuthRoleBOConverter.INSTANCE.convertBOToEntity(authRoleBO);        Integer count = authRoleService.update(authRole);        return count &gt; 0;    &#125;    @Override    public Boolean delete(AuthRoleBO authRoleBO) &#123;        AuthRole authRole = new AuthRole();        authRole.setId(authRoleBO.getId());        authRole.setIsDeleted(IsDeletedFlagEnum.DELETED.getCode());        Integer count = authRoleService.update(authRole);        return count &gt; 0;    &#125;&#125;\n\nAuthRolePermissionDomainServiceImpl.java(角色权限关联)\n添加角色权限关联方法\n\npublic Boolean add(AuthRolePermissionBO authRolePermissionBO)\n  ：添加角色与权限关联的方法。  - 首先创建一个`AuthRolePermission`列表，用于存储多个角色权限关联对象。  - 通过`authRolePermissionBO`获取角色ID。  - 遍历`authRolePermissionBO`中的权限ID列表。  - 对于每个权限ID，创建一个新的`AuthRolePermission`实体，设置角色ID、权限ID和未删除标志。  - 将创建的实体添加到列表中。  - 使用`authRolePermissionService`的`batchInsert`方法批量插入关联数据到数据库。  - 返回操作影响的行数是否大于0。这个`AuthRolePermissionDomainServiceImpl`类通过实现`AuthRolePermissionDomainService`接口，提供了添加角色与权限关联的服务。它允许一个角色与多个权限进行关联，通过批量插入的方式提高数据存储的效率。使用逻辑删除来管理角色权限关联数据，使得数据不会从数据库中真正删除，便于进行数据恢复或审计。注意，代码中没有提供删除或更新角色权限关联的实现，这可能是因为这些功能要么不需要实现，要么在其他部分的代码中实现。```java@Service@Slf4jpublic class AuthRolePermissionDomainServiceImpl implements AuthRolePermissionDomainService &#123;    @Resource    private AuthRolePermissionService authRolePermissionService;    @Override    public Boolean add(AuthRolePermissionBO authRolePermissionBO) &#123;        List&lt;AuthRolePermission&gt; rolePermissionList = new LinkedList&lt;&gt;();        Long roleId = authRolePermissionBO.getRoleId();        authRolePermissionBO.getPermissionIdList().forEach(permissionId -&gt; &#123;            AuthRolePermission authRolePermission = new AuthRolePermission();            authRolePermission.setRoleId(roleId);            authRolePermission.setPermissionId(permissionId);            authRolePermission.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());            rolePermissionList.add(authRolePermission);        &#125;);        int count = authRolePermissionService.batchInsert(rolePermissionList);        return count &gt; 0;    &#125;&#125;\n\n\n\ninfra层\n用户角色关联(user_role,这里主要是infra层的东西)controller（UserController的注册模块）其实就是UserController，在进行register等相关操作时会进行与默认角色的关联\ndomainAuthUserRoleDomainServiceImpl.java\n\n用户存在性检查：首先检查要注册的用户是否已存在。如果存在，则返回true。\n用户BO转换：将AuthUserBO（业务对象）转换为AuthUser实体。\n密码加密：如果用户密码不为空，则使用MD5加盐的方式加密密码。\n默认头像和昵称：如果用户没有提供头像或昵称，则设置默认值。\n用户状态设置：设置用户状态为开启（AuthUserStatusEnum.OPEN）和未删除（IsDeletedFlagEnum.UN_DELETED）。\n用户插入数据库：将用户实体插入数据库，并检查插入操作是否成功。\n角色关联：为新用户分配一个默认角色（普通用户），并将角色与用户关联。\nRedis缓存角色信息：使用Redis缓存用户的角色信息，以便快速检索。\n权限查询与缓存：查询角色拥有的权限，并将权限信息缓存到Redis。\n事务管理：使用@Transactional注解确保方法在出现异常时可以回滚。（也可以用TransactionnalTemplate）\n异常处理：使用@SneakyThrows注解来重新抛出检查型异常。\n返回结果：如果用户插入成功，则返回true。\n\n@Override@SneakyThrows@Transactional(rollbackFor = Exception.class) //事务public Boolean register(AuthUserBO authUserBO) &#123;    //校验用户是否存在    AuthUser existAuthUser = new AuthUser();    existAuthUser.setUserName(authUserBO.getUserName());    List&lt;AuthUser&gt; existUser = authUserService.queryByCondition(existAuthUser);    if (existUser.size() &gt; 0) &#123;        return true;    &#125;    AuthUser authUser = AuthUserBOConverter.INSTANCE.convertBOToEntity(authUserBO);    if (StringUtils.isNotBlank(authUser.getPassword())) &#123;        authUser.setPassword(SaSecureUtil.md5BySalt(authUser.getPassword(), salt));    &#125;    if (StringUtils.isBlank(authUser.getAvatar())) &#123;        authUser.setAvatar(&quot;http://117.72.10.84:9000/user/icon/微信图片_20231203153718(1).png&quot;);    &#125;    if (StringUtils.isBlank(authUser.getNickName())) &#123;        authUser.setNickName(&quot;lzrj&quot;);    &#125;    authUser.setStatus(AuthUserStatusEnum.OPEN.getCode());    authUser.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());    Integer count = authUserService.insert(authUser);    //建立一个初步的角色的关联    AuthRole authRole = new AuthRole();    authRole.setRoleKey(AuthConstant.NORMAL_USER);    AuthRole roleResult = authRoleService.queryByCondition(authRole);    Long roleId = roleResult.getId();    Long userId = authUser.getId();    AuthUserRole authUserRole = new AuthUserRole();    authUserRole.setUserId(userId);    authUserRole.setRoleId(roleId);    authUserRole.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());    authUserRoleService.insert(authUserRole);    String roleKey = redisUtil.buildKey(authRolePrefix, authUser.getUserName());    List&lt;AuthRole&gt; roleList = new LinkedList&lt;&gt;();    roleList.add(authRole);    redisUtil.set(roleKey, new Gson().toJson(roleList));    AuthRolePermission authRolePermission = new AuthRolePermission();    authRolePermission.setRoleId(roleId);    List&lt;AuthRolePermission&gt; rolePermissionList = authRolePermissionService.            queryByCondition(authRolePermission);    List&lt;Long&gt; permissionIdList = rolePermissionList.stream()            .map(AuthRolePermission::getPermissionId).collect(Collectors.toList());    //根据roleId查权限    List&lt;AuthPermission&gt; permissionList = authPermissionService.queryByRoleList(permissionIdList);    String permissionKey = redisUtil.buildKey(authPermissionPrefix, authUser.getUserName());    redisUtil.set(permissionKey, new Gson().toJson(permissionList));    return count &gt; 0;&#125;\n\n为什么这里遇到@Transactional注解：Spring——事务注解@Transactional【建议收藏】-CSDN博客\n@Transactional 注解在 Java 应用程序中，尤其是在使用 Spring 框架时，是一个非常重要的特性。这个注解通常用于声明方法在执行时应该被视为一个事务的边界。以下是使用 @Transactional 注解的一些主要原因：\n\n确保数据一致性：在涉及数据库操作的方法中，@Transactional 确保方法执行过程中的所有数据库操作要么全部成功，要么在遇到异常时全部撤销，以保持数据的一致性。\n简化代码：使用 @Transactional 注解可以避免在每个数据库操作后手动管理事务的开始和提交，简化了代码。\n声明式事务管理：Spring 支持声明式事务管理，@Transactional 注解就是这一概念的实现之一，它允许将事务管理逻辑从业务逻辑代码中分离出来。\n回滚策略：通过 @Transactional 注解，可以定义哪些异常会导致事务回滚。在您提供的代码中，rollbackFor = Exception.class 表示如果抛出任何类型的异常，事务都会回滚。\n支持嵌套事务：当一个事务方法调用另一个带有 @Transactional 注解的方法时，Spring 会处理这些方法之间的事务嵌套。\n提高性能：Spring 事务管理器可以针对不同的事务策略进行优化，比如懒加载事务、使用适当的隔离级别等，以提高应用程序性能。\n可伸缩性：随着应用程序的扩展，@Transactional 注解可以很容易地应用于新的方法或类，而不需要对现有代码进行大量修改。\n\n在您的代码示例中，@Transactional 注解应用于注册用户的方法上，这意味着从检查用户是否存在到用户信息写入数据库、角色和权限信息缓存到 Redis 的整个过程被视为一个单一的事务。如果在这个过程的任何地方发生异常，整个操作将回滚，以确保用户信息和相关的角色、权限设置要么完全应用，要么完全不应用，避免数据不一致的问题。\nauth-domain\npackage com.jingdianjichi.auth.domain.constants;/** * auth服务常量 */public class AuthConstant &#123;    public static final String NORMAL_USER = &quot;normal_user&quot;;&#125;\n\ninfra层\n接下来回到gateway模块，在用户登录时做好与redis的交互就可以打通了。\n权限模块开发(auth_permission)controller层PermissionController.java\n@RestController@RequestMapping(&quot;/permission/&quot;)@Slf4jpublic class PermissionController &#123;    @Resource    private AuthPermissionDomainService authPermissionDomainService;    /**     * 新增权限     */    @RequestMapping(&quot;add&quot;)    public Result&lt;Boolean&gt; add(@RequestBody AuthPermissionDTO authPermissionDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;PermissionController.add.dto:&#123;&#125;&quot;, JSON.toJSONString(authPermissionDTO));            &#125;            Preconditions.checkArgument(!StringUtils.isBlank(authPermissionDTO.getName()), &quot;权限名称不能为空&quot;);            Preconditions.checkNotNull(authPermissionDTO.getParentId(), &quot;权限父id不能为空&quot;);            AuthPermissionBO permissionBO = AuthPermissionDTOConverter.INSTANCE.convertDTOToBO(authPermissionDTO);            return Result.ok(authPermissionDomainService.add(permissionBO));        &#125; catch (Exception e) &#123;            log.error(&quot;PermissionController.add.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;新增权限失败&quot;);        &#125;    &#125;    /**     * 修改权限     */    @RequestMapping(&quot;update&quot;)    public Result&lt;Boolean&gt; update(@RequestBody AuthPermissionDTO authPermissionDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;PermissionController.update.dto:&#123;&#125;&quot;, JSON.toJSONString(authPermissionDTO));            &#125;            Preconditions.checkNotNull(authPermissionDTO.getId(), &quot;权限id不能为空&quot;);            AuthPermissionBO permissionBO = AuthPermissionDTOConverter.INSTANCE.convertDTOToBO(authPermissionDTO);            return Result.ok(authPermissionDomainService.update(permissionBO));        &#125; catch (Exception e) &#123;            log.error(&quot;PermissionController.update.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;更新权限信息失败&quot;);        &#125;    &#125;    /**     * 删除权限     */    @RequestMapping(&quot;delete&quot;)    public Result&lt;Boolean&gt; delete(@RequestBody AuthPermissionDTO authPermissionDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;PermissionController.delete.dto:&#123;&#125;&quot;, JSON.toJSONString(authPermissionDTO));            &#125;            Preconditions.checkNotNull(authPermissionDTO.getId(), &quot;权限id不能为空&quot;);            AuthPermissionBO permissionBO = AuthPermissionDTOConverter.INSTANCE.convertDTOToBO(authPermissionDTO);            return Result.ok(authPermissionDomainService.delete(permissionBO));        &#125; catch (Exception e) &#123;            log.error(&quot;PermissionController.delete.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;删除权限信息失败&quot;);        &#125;    &#125;    /**     * 查询用户权限     */    @RequestMapping(&quot;getPermission&quot;)    public Result&lt;Boolean&gt; getPermission(String userName) &#123;        try &#123;            log.info(&quot;PermissionController.getPermission.userName:&#123;&#125;&quot;,userName);            Preconditions.checkArgument(!StringUtils.isBlank(userName), &quot;用户id不能为空&quot;);            return Result.ok(authPermissionDomainService.getPermission(userName));        &#125; catch (Exception e) &#123;            log.error(&quot;PermissionController.getPermission.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;查询用户权限信息失败&quot;);        &#125;    &#125;&#125;\n\nAuthPermissionDTO.java\n@Datapublic class AuthPermissionDTO implements Serializable &#123;    private Long id;        private String name;        private Long parentId;        private Integer type;        private String menuUrl;        private Integer status;        private Integer show;        private String icon;        private String permissionKey;&#125;\n\nAuthPermissionDTOConverter.java\n@Mapperpublic interface AuthPermissionDTOConverter &#123;    AuthPermissionDTOConverter INSTANCE = Mappers.getMapper(AuthPermissionDTOConverter.class);    AuthPermissionBO convertDTOToBO(AuthPermissionDTO authPermissionDTO);&#125;\n\ndomain层AuthPermissionBOConverter.java\n@Mapperpublic interface AuthPermissionBOConverter &#123;    AuthPermissionBOConverter INSTANCE = Mappers.getMapper(AuthPermissionBOConverter.class);    AuthPermission convertBOToEntity(AuthPermissionBO authPermissionBO);&#125;\n\nAuthPermissionBO.java\n@Datapublic class AuthPermissionBO implements Serializable &#123;    private Long id;        private String name;        private Long parentId;        private Integer type;        private String menuUrl;        private Integer status;        private Integer show;        private String icon;        private String permissionKey;&#125;\n\nAuthPermissionService.java\n@Service@Slf4jpublic class AuthPermissionDomainServiceImpl implements AuthPermissionDomainService &#123;    @Resource    private AuthPermissionService authPermissionService;    @Resource    private RedisUtil redisUtil;    private String authPermissionPrefix = &quot;auth.permission&quot;;    @Override    public Boolean add(AuthPermissionBO authPermissionBO) &#123;        AuthPermission authPermission = AuthPermissionBOConverter.INSTANCE.convertBOToEntity(authPermissionBO);        authPermission.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());        Integer count = authPermissionService.insert(authPermission);        return count &gt; 0;    &#125;    @Override    public Boolean update(AuthPermissionBO authPermissionBO) &#123;        AuthPermission authPermission = AuthPermissionBOConverter.INSTANCE.convertBOToEntity(authPermissionBO);        Integer count = authPermissionService.update(authPermission);        return count &gt; 0;    &#125;    @Override    public Boolean delete(AuthPermissionBO authPermissionBO) &#123;        AuthPermission authPermission = new AuthPermission();        authPermission.setId(authPermissionBO.getId());        authPermission.setIsDeleted(IsDeletedFlagEnum.DELETED.getCode());        Integer count = authPermissionService.update(authPermission);        return count &gt; 0;    &#125;    @Override    public List&lt;String&gt; getPermission(String userName) &#123;        String permissionKey = redisUtil.buildKey(authPermissionPrefix, userName);        String permissionValue = redisUtil.get(permissionKey);        if (StringUtils.isBlank(permissionValue)) &#123;            return Collections.emptyList();        &#125;        List&lt;AuthPermission&gt; permissionList = new Gson().fromJson(permissionValue,                new TypeToken&lt;List&lt;AuthPermission&gt;&gt;() &#123;                &#125;.getType());        List&lt;String&gt; authList = permissionList.stream().map(AuthPermission::getPermissionKey).collect(Collectors.toList());        return authList;    &#125;&#125;\n\ninfra层AuthPermission.java\npublic class AuthPermission implements Serializable &#123;    private static final long serialVersionUID = -56518358607843924L;        private Long id;        private String name;        private Long parentId;        private Integer type;        private String menuUrl;        private Integer status;        private Integer show;        private String icon;        private String permissionKey;    /**     * 创建人     */    private String createdBy;    /**     * 创建时间     */    private Date createdTime;    /**     * 更新人     */    private String updateBy;    /**     * 更新时间     */    private Date updateTime;        private Integer isDeleted;    public Long getId() &#123;        return id;    &#125;    public void setId(Long id) &#123;        this.id = id;    &#125;    public String getName() &#123;        return name;    &#125;    public void setName(String name) &#123;        this.name = name;    &#125;    public Long getParentId() &#123;        return parentId;    &#125;    public void setParentId(Long parentId) &#123;        this.parentId = parentId;    &#125;    public Integer getType() &#123;        return type;    &#125;    public void setType(Integer type) &#123;        this.type = type;    &#125;    public String getMenuUrl() &#123;        return menuUrl;    &#125;    public void setMenuUrl(String menuUrl) &#123;        this.menuUrl = menuUrl;    &#125;    public Integer getStatus() &#123;        return status;    &#125;    public void setStatus(Integer status) &#123;        this.status = status;    &#125;    public Integer getShow() &#123;        return show;    &#125;    public void setShow(Integer show) &#123;        this.show = show;    &#125;    public String getIcon() &#123;        return icon;    &#125;    public void setIcon(String icon) &#123;        this.icon = icon;    &#125;    public String getPermissionKey() &#123;        return permissionKey;    &#125;    public void setPermissionKey(String permissionKey) &#123;        this.permissionKey = permissionKey;    &#125;    public String getCreatedBy() &#123;        return createdBy;    &#125;    public void setCreatedBy(String createdBy) &#123;        this.createdBy = createdBy;    &#125;    public Date getCreatedTime() &#123;        return createdTime;    &#125;    public void setCreatedTime(Date createdTime) &#123;        this.createdTime = createdTime;    &#125;    public String getUpdateBy() &#123;        return updateBy;    &#125;    public void setUpdateBy(String updateBy) &#123;        this.updateBy = updateBy;    &#125;    public Date getUpdateTime() &#123;        return updateTime;    &#125;    public void setUpdateTime(Date updateTime) &#123;        this.updateTime = updateTime;    &#125;    public Integer getIsDeleted() &#123;        return isDeleted;    &#125;    public void setIsDeleted(Integer isDeleted) &#123;        this.isDeleted = isDeleted;    &#125;&#125;\n\nAuthPermissionDao.xml\n\ntype, show：这些列名使用了反引号，因为 type 和 show 是 MySQL 的保留字。在 SQL 中，保留字是具有特定意义的关键字，如果用作列名或表名，需要用反引号括起来，以避免语法错误。\n\n&lt;!--新增所有列--&gt;&lt;insert id=&quot;insert&quot; keyProperty=&quot;id&quot; useGeneratedKeys=&quot;true&quot;&gt;    insert into auth_permission(name, parent_id, `type`, menu_url, status, `show`, icon, permission_key, created_by, created_time, update_by, update_time, is_deleted)    values (#&#123;name&#125;, #&#123;parentId&#125;, #&#123;type&#125;, #&#123;menuUrl&#125;, #&#123;status&#125;, #&#123;show&#125;, #&#123;icon&#125;, #&#123;permissionKey&#125;, #&#123;createdBy&#125;, #&#123;createdTime&#125;, #&#123;updateBy&#125;, #&#123;updateTime&#125;, #&#123;isDeleted&#125;)&lt;/insert&gt;\n\nAuthPermissionServiceImpl.java\n@Service(&quot;authPermissionService&quot;)public class AuthPermissionServiceImpl implements AuthPermissionService &#123;    @Resource    private AuthPermissionDao authPermissionDao;    /**     * 通过ID查询单条数据     *     * @param id 主键     * @return 实例对象     */    @Override    public AuthPermission queryById(Long id) &#123;        return this.authPermissionDao.queryById(id);    &#125;    /**     * 新增数据     *     * @param authPermission 实例对象     * @return 实例对象     */    @Override    public int insert(AuthPermission authPermission) &#123;        return this.authPermissionDao.insert(authPermission);    &#125;    /**     * 修改数据     *     * @param authPermission 实例对象     * @return 实例对象     */    @Override    public int update(AuthPermission authPermission) &#123;        return this.authPermissionDao.update(authPermission);    &#125;    /**     * 通过主键删除数据     *     * @param id 主键     * @return 是否成功     */    @Override    public boolean deleteById(Long id) &#123;        return this.authPermissionDao.deleteById(id) &gt; 0;    &#125;    @Override    public List&lt;AuthPermission&gt; queryByRoleList(List&lt;Long&gt; roleIdList) &#123;        return this.authPermissionDao.queryByRoleList(roleIdList);    &#125;&#125;\n\n角色权限关联开发（auth_role_permission）controllerRolePermissionController\n@RestController@RequestMapping(&quot;/rolePermission/&quot;)@Slf4jpublic class RolePermissionController &#123;    @Resource    private AuthRolePermissionDomainService authRolePermissionDomainService;    /**     * 新增角色权限关联关系     */    @RequestMapping(&quot;add&quot;)    public Result&lt;Boolean&gt; add(@RequestBody AuthRolePermissionDTO authRolePermissionDTO) &#123;        try &#123;            if (log.isInfoEnabled()) &#123;                log.info(&quot;RolePermissionController.add.dto:&#123;&#125;&quot;, JSON.toJSONString(authRolePermissionDTO));            &#125;            Preconditions.checkArgument(!CollectionUtils.isEmpty(authRolePermissionDTO.getPermissionIdList()),&quot;权限关联不能为空&quot;);            Preconditions.checkNotNull(authRolePermissionDTO.getRoleId(),&quot;角色不能为空!&quot;);            AuthRolePermissionBO rolePermissionBO = AuthRolePermissionDTOConverter.INSTANCE.convertDTOToBO(authRolePermissionDTO);            return Result.ok(authRolePermissionDomainService.add(rolePermissionBO));        &#125; catch (Exception e) &#123;            log.error(&quot;PermissionController.add.error:&#123;&#125;&quot;, e.getMessage(), e);            return Result.fail(&quot;新增角色权限失败&quot;);        &#125;    &#125;&#125;\n\nAuthRolePermissionDTO.java\n@Datapublic class AuthRolePermissionDTO implements Serializable &#123;    private static final long serialVersionUID = 459343371709166261L;        private Long id;        private Long roleId;        private Long permissionId;    private List&lt;Long&gt; permissionIdList;&#125;\n\ndomain层AuthRolePermissionDomainServiceImpl.java\n@Service@Slf4jpublic class AuthRolePermissionDomainServiceImpl implements AuthRolePermissionDomainService &#123;    @Resource    private AuthRolePermissionService authRolePermissionService;    @Override    public Boolean add(AuthRolePermissionBO authRolePermissionBO) &#123;        List&lt;AuthRolePermission&gt; rolePermissionList = new LinkedList&lt;&gt;();        Long roleId = authRolePermissionBO.getRoleId();        authRolePermissionBO.getPermissionIdList().forEach(permissionId -&gt; &#123;            AuthRolePermission authRolePermission = new AuthRolePermission();            authRolePermission.setRoleId(roleId);            authRolePermission.setPermissionId(permissionId);            authRolePermission.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());            rolePermissionList.add(authRolePermission);        &#125;);        int count = authRolePermissionService.batchInsert(rolePermissionList);        return count &gt; 0;    &#125;&#125;\n\nAuthRolePermissionBO.java\n@Datapublic class AuthRolePermissionBO implements Serializable &#123;    private static final long serialVersionUID = 459343371709166261L;        private Long id;        private Long roleId;        private Long permissionId;    private List&lt;Long&gt; permissionIdList;&#125;\n\ninfra层AuthRolePermissionServiceImpl.java\n@Service(&quot;authRolePermissionService&quot;)public class AuthRolePermissionServiceImpl implements AuthRolePermissionService &#123;    @Resource    private AuthRolePermissionDao authRolePermissionDao;    /**     * 通过ID查询单条数据     *     * @param id 主键     * @return 实例对象     */    @Override    public AuthRolePermission queryById(Long id) &#123;        return this.authRolePermissionDao.queryById(id);    &#125;    /**     * 新增数据     *     * @param authRolePermission 实例对象     * @return 实例对象     */    @Override    public AuthRolePermission insert(AuthRolePermission authRolePermission) &#123;        this.authRolePermissionDao.insert(authRolePermission);        return authRolePermission;    &#125;    @Override    public int batchInsert(List&lt;AuthRolePermission&gt; authRolePermissionList) &#123;        return this.authRolePermissionDao.insertBatch(authRolePermissionList);    &#125;    /**     * 修改数据     *     * @param authRolePermission 实例对象     * @return 实例对象     */    @Override    public AuthRolePermission update(AuthRolePermission authRolePermission) &#123;        this.authRolePermissionDao.update(authRolePermission);        return this.queryById(authRolePermission.getId());    &#125;    /**     * 通过主键删除数据     *     * @param id 主键     * @return 是否成功     */    @Override    public boolean deleteById(Long id) &#123;        return this.authRolePermissionDao.deleteById(id) &gt; 0;    &#125;    @Override    public List&lt;AuthRolePermission&gt; queryByCondition(AuthRolePermission authRolePermission) &#123;        return this.authRolePermissionDao.queryAllByLimit(authRolePermission);    &#125;&#125;\n\nAuthRolePermission.java\npublic class AuthRolePermission implements Serializable &#123;    private static final long serialVersionUID = 459343371709166261L;        private Long id;        private Long roleId;        private Long permissionId;    /**     * 创建人     */    private String createdBy;    /**     * 创建时间     */    private Date createdTime;    /**     * 更新人     */    private String updateBy;    /**     * 更新时间     */    private Date updateTime;        private Integer isDeleted;    public Long getId() &#123;        return id;    &#125;    public void setId(Long id) &#123;        this.id = id;    &#125;    public Long getRoleId() &#123;        return roleId;    &#125;    public void setRoleId(Long roleId) &#123;        this.roleId = roleId;    &#125;    public Long getPermissionId() &#123;        return permissionId;    &#125;    public void setPermissionId(Long permissionId) &#123;        this.permissionId = permissionId;    &#125;    public String getCreatedBy() &#123;        return createdBy;    &#125;    public void setCreatedBy(String createdBy) &#123;        this.createdBy = createdBy;    &#125;    public Date getCreatedTime() &#123;        return createdTime;    &#125;    public void setCreatedTime(Date createdTime) &#123;        this.createdTime = createdTime;    &#125;    public String getUpdateBy() &#123;        return updateBy;    &#125;    public void setUpdateBy(String updateBy) &#123;        this.updateBy = updateBy;    &#125;    public Date getUpdateTime() &#123;        return updateTime;    &#125;    public void setUpdateTime(Date updateTime) &#123;        this.updateTime = updateTime;    &#125;    public Integer getIsDeleted() &#123;        return isDeleted;    &#125;    public void setIsDeleted(Integer isDeleted) &#123;        this.isDeleted = isDeleted;    &#125;&#125;\n\n缓存与数据一致性问题（延迟双删）\n根据以上的流程没有问题，但是当数据变更的时候，如何把缓存变到最新，使我们下面要讨论的问题。\n\n更新了数据库，再更新缓存\n假设数据库更新成功，缓存更新失败，在缓存失效和过期的时候，读取到的都是老数据缓存。\n\n更新缓存，更新数据库\n缓存更新成功了，数据库更新失败，是不是读取的缓存的都是错误的。\n\n\n以上两种，全都不推荐。\n\n先删除缓存，再更新数据库\n有一定的使用量。即使数据库更新失败。缓存也可以会刷。\n存在的问题是什么？\n高并发情况下！！\n比如说有两个线程，一个是 A 线程，一个是 B 线程。\nA 线程把数据删了，正在更新数据库，这个时候 B 线程来了，发现缓存没了，又查数据，又放入缓存。缓存里面存的就一直是老数据了。\n\n\n延迟双删：:star:\n\n**延时是确保 **修改数据库 -&gt; 清空缓存前，其他事务的更改缓存操作已经执行完。redis缓存为什么要延时双删-CSDN博客\n\n扩展思路\n\n消息队列补偿\n删除失败的缓存，作为消息打入 mq，mq 消费者进行监听，再次进行重试刷缓存。\n\ncanal\n监听数据库的变化，做一个公共服务，专门来对接缓存刷新。优点业务解耦，业务太多冗余代码复杂度。\n\n\n网关与auth微服务缓存打通主要跟注册有关\nAuthUserDomainServiceImpl.java\n@Override@SneakyThrows@Transactional(rollbackFor = Exception.class)public Boolean register(AuthUserBO authUserBO) &#123;    //校验用户是否存在    AuthUser existAuthUser = new AuthUser();    existAuthUser.setUserName(authUserBO.getUserName());    List&lt;AuthUser&gt; existUser = authUserService.queryByCondition(existAuthUser);    if (existUser.size() &gt; 0) &#123;        return true;    &#125;    AuthUser authUser = AuthUserBOConverter.INSTANCE.convertBOToEntity(authUserBO);    if (StringUtils.isNotBlank(authUser.getPassword())) &#123;        authUser.setPassword(SaSecureUtil.md5BySalt(authUser.getPassword(), salt));    &#125;    if (StringUtils.isBlank(authUser.getAvatar())) &#123;        authUser.setAvatar(&quot;http://117.72.10.84:9000/user/icon/微信图片_20231203153718(1).png&quot;);    &#125;    if (StringUtils.isBlank(authUser.getNickName())) &#123;        authUser.setNickName(&quot;别名&quot;);    &#125;    authUser.setStatus(AuthUserStatusEnum.OPEN.getCode());    authUser.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());    Integer count = authUserService.insert(authUser);    //建立一个初步的角色的关联    AuthRole authRole = new AuthRole();    authRole.setRoleKey(AuthConstant.NORMAL_USER); //普通角色    AuthRole roleResult = authRoleService.queryByCondition(authRole); //查到对应的角色返回结果，这里主要是拿角色的id    Long roleId = roleResult.getId();    Long userId = authUser.getId();    AuthUserRole authUserRole = new AuthUserRole();    authUserRole.setUserId(userId); //用户角色 设置 userId    authUserRole.setRoleId(roleId); //用户角色 设置 roleId    authUserRole.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());    authUserRoleService.insert(authUserRole);    String roleKey = redisUtil.buildKey(authRolePrefix, authUser.getUserName()); //key:角色前缀+用户名    List&lt;AuthRole&gt; roleList = new LinkedList&lt;&gt;();    roleList.add(authRole);    redisUtil.set(roleKey, new Gson().toJson(roleList)); //key:角色前缀+用户名 value:列表形式的role，在这里只有普通用户    AuthRolePermission authRolePermission = new AuthRolePermission();    authRolePermission.setRoleId(roleId); //给角色权限设置roleId    List&lt;AuthRolePermission&gt; rolePermissionList = authRolePermissionService.            queryByCondition(authRolePermission); //查询到权限list    List&lt;Long&gt; permissionIdList = rolePermissionList.stream()  //拿到角色list对应的权限id list            .map(AuthRolePermission::getPermissionId).collect(Collectors.toList());    List&lt;AuthPermission&gt; permissionList = authPermissionService.queryByRoleList(permissionIdList);//根据权限id list查询权限本身list    String permissionKey = redisUtil.buildKey(authPermissionPrefix, authUser.getUserName());//key:权限前缀+用户名    redisUtil.set(permissionKey, new Gson().toJson(permissionList));    return count &gt; 0;&#125;\n\nAuthPermissionDao.java\nList&lt;AuthPermission&gt; queryByRoleList(@Param(&quot;list&quot;) List&lt;Long&gt; roleIdList);\n\nAuthPermissionDao.xml\n&lt;select id=&quot;queryByRoleList&quot; resultMap=&quot;AuthPermissionMap&quot;&gt;    select * from auth_permission    where id in    &lt;foreach open=&quot;(&quot; close=&quot;)&quot; collection=&quot;list&quot; item=&quot;id&quot; separator=&quot;,&quot;&gt;        #&#123;id&#125;    &lt;/foreach&gt;&lt;/select&gt;\n\n[mybatis中resultMap的理解_result map-CSDN博客](https://blog.csdn.net/u012843873/article/details/80198185?ops_request_misc=%7B%22request%5Fid%22%3A%22172259150816800178584486%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172259150816800178584486&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~baidu_landing_v2~default-1-80198185-null-null.142^v100^pc_search_result_base8&amp;utm_term=mybatic resultmap&amp;spm&#x3D;1018.2226.3001.4187)\n回到网关层\nStpInterfaceImpl.java\n@Componentpublic class StpInterfaceImpl implements StpInterface &#123;    @Resource    private RedisUtil redisUtil;    private String authPermissionPrefix = &quot;auth.permission&quot;;    private String authRolePrefix = &quot;auth.role&quot;;    @Override    public List&lt;String&gt; getPermissionList(Object loginId, String loginType) &#123;        return getAuth(loginId.toString(), authPermissionPrefix);    &#125;    @Override    public List&lt;String&gt; getRoleList(Object loginId, String loginType) &#123;        return getAuth(loginId.toString(), authRolePrefix);    &#125;    private List&lt;String&gt; getAuth(String loginId, String prefix) &#123; //根据register过程中创建的Redis key进行查询，包含角色和权限两种        String authKey = redisUtil.buildKey(prefix, loginId.toString());        String authValue = redisUtil.get(authKey);        if (StringUtils.isBlank(authValue)) &#123;            return Collections.emptyList();        &#125;        List&lt;String&gt; authList = new LinkedList&lt;&gt;();        if (authRolePrefix.equals(prefix)) &#123; //角色List            List&lt;AuthRole&gt; roleList = new Gson().fromJson(authValue, new TypeToken&lt;List&lt;AuthRole&gt;&gt;() &#123;            &#125;.getType());            authList = roleList.stream().map(AuthRole::getRoleKey).collect(Collectors.toList());        &#125; else if (authPermissionPrefix.equals(prefix)) &#123; //权限List             List&lt;AuthPermission&gt; permissionList = new Gson().fromJson(authValue, new TypeToken&lt;List&lt;AuthPermission&gt;&gt;() &#123;            &#125;.getType());            authList = permissionList.stream().map(AuthPermission::getPermissionKey).collect(Collectors.toList());        &#125;        return authList;    &#125;&#125;\n\n在登录后就会拿到token，在redis中存放有k v，保存有登录状态。在网关层会有拦截器根据路由进行对应的拦截，验证是否登录&#x2F;有权限。\n拿到token之后，就可以通过isLogin去验证是否登录了（在请求header中带有isLogin）\n权限认证 (sa-token.cc)\n登录开发（微信公众号，测试号）全流程：扫码微信-&gt;微信发送消息到服务器，校验签名确保来自微信（get）-&gt;服务器再把消息进行包装， 通过前缀+验证码（一个随机数）作为redis key，fromUserName(openId)作为value存到redis，并把包含验证码的消息发送到微信-&gt;用户验证码（微信）,从redis拿到openId（即用户名）-&gt;用satoken用openId进行登录，然后利用satoken返回一个token，后续登录就会带上这个token\n这里用的是测试号，并不会生成真正的验证码到手机上，只是为了开发接口。\n登录注册模块 \n\n注册用户与验证 \n\n短信的方式，通过向手机号发送验证码，来实现用户的验证并登录（考虑的成本是短信的费用）\n\n邮箱的注册登录。\n用户注册的时候，留一个邮箱，我们往邮箱里通过邮箱服务器发送一个链接，用户点击之后，实现一个激活，激活成功之后就完成了注册。（0 成本，坏处这种发送的邮件很容易进垃圾箱）\n\n个人公众号模式（个人开发者无公司的，比较适合使用，0 成本）\n用户登录的时候，弹出我们的这个公众号的码。扫码后，用户输入我们提示的验证码。可以随机比如说 nadbuge，通过我们的公众号对接的回调。能拿到一定的信息，用户的 openId。进而记录用户的信息\n\n企业的服务号（必须要有营业执照，自己玩的不上线的话，也可以用测试号）\n好处就是不仅打通了各种回调，而且还能拿到用户的信息。\n\n\n\n登录功能 \n传统的 pc 形式，都是登录之后，写入 cookie。前端再次请求的时候，带着 cookie 一个身份识别就可以完成认证。\n坏处是什么？小程序呀，app 呀，其实是没有 cookie 这个概念的。\n单点登录(SSO)详解——超详细-CSDN博客\n为了更好的扩展，我们就直接选择 token的模式。token 放入 header 来实现用户身份的识别与鉴权。\n\n踢人下线 \n发现风险用户，可以通过后台直接把用户踢掉，禁止其再访问，token 也可以直接置为失效的形式。\n\n集成 redis （保存token）\n如果说我们选择了 token，然后不做 token 的保存，服务重启呀，分布式微服务啊，数据是无法共享并且会产生丢失问题，所以用 redis 来存储一些信息，实现共享。\n\n自定义我们的 token 风格和前缀 \n比如正常的 token 可能是 uuid，我们可以选择其他形式。\n然后就是 token 的前端的传递，也可以去定义前缀，固定前缀才生效。\n\n记住我 \n当我们去勾选记住我的时候，下次登录就自动实现了。\n前后端分离，没有 token 的时候，必然会产生无法实现的问题，我们就选择在前端的 localstorage 来做。\n\n\n登录流程整体采取个人号的登录模式，选取某信号的 openId 作为用户的唯一标识！\n\n整体流程：\n\n用户扫公众号码。然后发一条消息：验证码。\n\n通过 api 回复一个随机的验证码。存入 redis\n\nkey: 前缀+验证码\nvalue: fromUsername(也就是openId)\n\n\n用户在验证码框输入之后，点击登录，进入我们的注册模块，同时关联角色和权限。就实现了网关的统一鉴权。\n\n用户就可以进行操作，用户可以根据个人的 openId 来维护个人信息。\n\n用户登录成功之后，返回 token，前端的所有请求都带着 token 就可以访问了。\n\n\n服务设计\n开一个新的服务，叫我们的 jc-club-wechat。专门用于对接微信的 api 和微信的消息的回调。\n\n回调：关注公众号，发送验证码\n\n\n通过 nacos 注册中心来调用我们的 auth 服务，来实现用户的注册。\n\n另一种扩展方案，wechat 和 auth 不直接交互。\n\n通过 mq 来做。wechat 接收回调后，反向发出 mq。自身的 auth 来订阅 mq 进行消费。\n\n\n\n公众号开发文档里面的例子只有python的没有java的\n测试号地址：https://mp.weixin.qq.com/debug/cgi-bin/sandboxinfo?action=showinfo&amp;t=sandbox/index\n公众号开发文档：https://developers.weixin.qq.com/doc/offiaccount/Getting_Started/Overview.html\n回调消息接入指南：https://developers.weixin.qq.com/doc/offiaccount/Basic_Information/Access_Overview.html\n接收公众号消息体文档：https://developers.weixin.qq.com/doc/offiaccount/Message_Management/Receiving_standard_messages.html\n\n公众号验签开发\n用户向公众号发送消息时，公众号方收到的消息发送者是一个OpenID，是使用用户微信号加密后的结果，每个用户对每个公众号有一个唯一的OpenID。\n\n\n填写服务器配置：\n登录微信公众平台官网后，在公众平台官网的开发-基本设置页面，勾选协议成为开发者，点击“修改配置”按钮，填写服务器地址（URL）、Token和EncodingAESKey，其中URL是开发者用来接收微信消息和事件的接口URL。Token可由开发者可以任意填写，用作生成签名（该Token会和接口URL中包含的Token进行比对，从而验证安全性）。EncodingAESKey由开发者手动填写或随机生成，将用作消息体加解密密钥。\n同时，开发者可选择消息加解密方式：明文模式、兼容模式和安全模式。模式的选择与服务器配置在提交后都会立即生效，请开发者谨慎填写及选择。加解密方式的默认状态为明文模式，选择兼容模式和安全模式需要提前配置好相关加解密代码，详情请参考消息体签名及加解密部分的文档 。\n\n\n验证消息的确来自微信服务器\n开发者提交信息后，微信服务器将发送GET请求到填写的服务器地址URL上，GET请求携带参数如下表所示：\n\nCallBackController.java\n@GetMapping(&quot;callback&quot;)public String callback(@RequestParam(&quot;signature&quot;) String signature,                       @RequestParam(&quot;timestamp&quot;) String timestamp,                       @RequestParam(&quot;nonce&quot;) String nonce,                       @RequestParam(&quot;echostr&quot;) String echostr) &#123;    log.info(&quot;get验签请求参数：signature:&#123;&#125;，timestamp:&#123;&#125;，nonce:&#123;&#125;，echostr:&#123;&#125;&quot;,            signature, timestamp, nonce, echostr);    String shaStr = SHA1.getSHA1(token, timestamp, nonce, &quot;&quot;);    if (signature.equals(shaStr)) &#123;        return echostr;    &#125;    return &quot;unknown&quot;;&#125;\n\n这里signature是微信根据传入的token、timestamp、nonce根据sha1计算生成的，是微信回调来的。\n\n\n内网穿透（natapp）不同电脑下载地址：https://natapp.cn/#download\n内网穿透使用指南：\nhttps://natapp.cn/article/natapp_newbie\nwindows 启动方式：\n进到目录下，运行exe\nstart natapp -authtoken=xxxx\n\n配置内网穿透：\n\n会生成一个公网的分配的地址，从本地地址-&gt;公网地址，实现穿透\n监听用户行为&amp;自动回复消息(消息事件监听+策略模式实现解耦)controller解释关键点\n\n**MessageUtil.parseXml**：这是一个自定义方法，用于将 XML 格式的字符串解析成 Map&lt;String, String&gt;。\n**WxChatMsgHandler 和 wxChatMsgFactory**：WxChatMsgHandler 是一个处理微信消息的接口或类，wxChatMsgFactory 是一个工厂类，用于根据消息类型获取对应的消息处理器。\n**msgTypeKey**：这个字符串键值用于标识不同的消息类型，例如 “text”、”image”、”event.subscribe” 等。\n\n主要逻辑流程\n\n接收并记录微信发送的消息。\n将 XML 格式的消息解析成 Map。\n提取消息类型和事件类型。\n构建消息类型键值，并根据键值从工厂中获取对应的消息处理器。\nsubscribe消息\ntext消息\n\n\n使用消息处理器处理消息，返回处理结果。\n\nCallBackController.java\nprivate static final String token = &quot;adwidhaidwoaid&quot;;@Resourceprivate WxChatMsgFactory wxChatMsgFactory;@PostMapping(value = &quot;callback&quot;, produces = &quot;application/xml;charset=UTF-8&quot;)public String callback(        @RequestBody String requestBody,        @RequestParam(&quot;signature&quot;) String signature,        @RequestParam(&quot;timestamp&quot;) String timestamp,        @RequestParam(&quot;nonce&quot;) String nonce,        @RequestParam(value = &quot;msg_signature&quot;, required = false) String msgSignature) &#123;    log.info(&quot;接收到微信消息：requestBody：&#123;&#125;&quot;, requestBody);    Map&lt;String, String&gt; messageMap = MessageUtil.parseXml(requestBody);    String msgType = messageMap.get(&quot;MsgType&quot;);    String event = messageMap.get(&quot;Event&quot;) == null ? &quot;&quot; : messageMap.get(&quot;Event&quot;);    log.info(&quot;msgType:&#123;&#125;,event:&#123;&#125;&quot;, msgType, event);    StringBuilder sb = new StringBuilder();    sb.append(msgType);    if (!StringUtils.isEmpty(event)) &#123;        sb.append(&quot;.&quot;);        sb.append(event);    &#125;    String msgTypeKey = sb.toString();    WxChatMsgHandler wxChatMsgHandler = wxChatMsgFactory.getHandlerByMsgType(msgTypeKey);    if (Objects.isNull(wxChatMsgHandler)) &#123;         return &quot;unknown&quot;;    &#125;    String replyContent = wxChatMsgHandler.dealMsg(messageMap);    log.info(&quot;replyContent:&#123;&#125;&quot;, replyContent);    return replyContent;&#125;\n\nUtilsMessageUtil.java\npublic class MessageUtil &#123;    /**     * 解析微信发来的请求（String-&gt;XML）.     *     * @param msg 消息     * @return map     */    public static Map&lt;String, String&gt; parseXml(final String msg) &#123;        // 将解析结果存储在HashMap中        Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();        // 从request中取得输入流        try (InputStream inputStream = new ByteArrayInputStream(msg.getBytes(StandardCharsets.UTF_8.name()))) &#123;            // 读取输入流            SAXReader reader = new SAXReader(); //saxreader            Document document = reader.read(inputStream);            // 得到xml根元素            Element root = document.getRootElement();            // 得到根元素的所有子节点            List&lt;Element&gt; elementList = root.elements();            // 遍历所有子节点            for (Element e : elementList) &#123;                map.put(e.getName(), e.getText());            &#125;        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;        return map;    &#125;&#125;\n\nhandlerWxChatMsgHandler.java\n有两个类继承它：\n\nSubscribeMsgHandler.java\n\nReceiveTextMsgHandler.java\n\n\npublic interface WxChatMsgHandler &#123;    WxChatMsgTypeEnum getMsgType();    String dealMsg(Map&lt;String, String&gt; messageMap);&#125;\n\npackage com.jingdianjichi.wx.handler;import com.jingdianjichi.wx.redis.RedisUtil;import lombok.extern.slf4j.Slf4j;import org.springframework.stereotype.Component;import javax.annotation.Resource;import java.util.Map;import java.util.Random;import java.util.concurrent.TimeUnit;@Component@Slf4jpublic class ReceiveTextMsgHandler implements WxChatMsgHandler &#123;    private static final String KEY_WORD = &quot;验证码&quot;;    private static final String LOGIN_PREFIX = &quot;loginCode&quot;;    @Resource    private RedisUtil redisUtil;    @Override    public WxChatMsgTypeEnum getMsgType() &#123;        return WxChatMsgTypeEnum.TEXT_MSG;    &#125;    @Override    public String dealMsg(Map&lt;String, String&gt; messageMap) &#123;        log.info(&quot;接收到文本消息事件&quot;);        String content = messageMap.get(&quot;Content&quot;);        if (!KEY_WORD.equals(content)) &#123;            return &quot;&quot;;        &#125;        String fromUserName = messageMap.get(&quot;FromUserName&quot;);        String toUserName = messageMap.get(&quot;ToUserName&quot;);        Random random = new Random();        int num = random.nextInt(1000);        String numKey = redisUtil.buildKey(LOGIN_PREFIX, String.valueOf(num));        redisUtil.setNx(numKey, fromUserName, 5L, TimeUnit.MINUTES);        String numContent = &quot;您当前的验证码是：&quot; + num + &quot;！ 5分钟内有效&quot;;        String replyContent = &quot;&lt;xml&gt;\\n&quot; +                &quot;  &lt;ToUserName&gt;&lt;![CDATA[&quot; + fromUserName + &quot;]]&gt;&lt;/ToUserName&gt;\\n&quot; +                &quot;  &lt;FromUserName&gt;&lt;![CDATA[&quot; + toUserName + &quot;]]&gt;&lt;/FromUserName&gt;\\n&quot; +                &quot;  &lt;CreateTime&gt;12345678&lt;/CreateTime&gt;\\n&quot; +                &quot;  &lt;MsgType&gt;&lt;![CDATA[text]]&gt;&lt;/MsgType&gt;\\n&quot; +                &quot;  &lt;Content&gt;&lt;![CDATA[&quot; + numContent + &quot;]]&gt;&lt;/Content&gt;\\n&quot; +                &quot;&lt;/xml&gt;&quot;;        return replyContent;    &#125;&#125;\n\npackage com.jingdianjichi.wx.handler;import lombok.extern.slf4j.Slf4j;import org.springframework.stereotype.Component;import java.util.Map;@Component@Slf4jpublic class SubscribeMsgHandler implements WxChatMsgHandler &#123;    @Override    public WxChatMsgTypeEnum getMsgType() &#123;        return WxChatMsgTypeEnum.SUBSCRIBE;    &#125;    @Override    public String dealMsg(Map&lt;String, String&gt; messageMap) &#123;        log.info(&quot;触发用户关注事件！&quot;);        String fromUserName = messageMap.get(&quot;FromUserName&quot;);        String toUserName = messageMap.get(&quot;ToUserName&quot;);        String subscribeContent = &quot;感谢您的关注&quot;;        String content = &quot;&lt;xml&gt;\\n&quot; +                &quot;  &lt;ToUserName&gt;&lt;![CDATA[&quot; + fromUserName + &quot;]]&gt;&lt;/ToUserName&gt;\\n&quot; +                &quot;  &lt;FromUserName&gt;&lt;![CDATA[&quot; + toUserName + &quot;]]&gt;&lt;/FromUserName&gt;\\n&quot; +                &quot;  &lt;CreateTime&gt;12345678&lt;/CreateTime&gt;\\n&quot; +                &quot;  &lt;MsgType&gt;&lt;![CDATA[text]]&gt;&lt;/MsgType&gt;\\n&quot; +                &quot;  &lt;Content&gt;&lt;![CDATA[&quot; + subscribeContent + &quot;]]&gt;&lt;/Content&gt;\\n&quot; +                &quot;&lt;/xml&gt;&quot;;        return content;    &#125;&#125;\n\nredis这里也用到了RedisUtil.java，和gateway模块的一致，所以后续思路可以把这部分提取出来当成common模块的。\nReceiveTextMsgHandler.java\nString numKey = redisUtil.buildKey(LOGIN_PREFIX, String.valueOf(num));        redisUtil.setNx(numKey, fromUserName, 5L, TimeUnit.MINUTES); //key为登录的前缀（字符串）+验证码（validCode）        String numContent = &quot;您当前的验证码是：&quot; + num + &quot;！ 5分钟内有效&quot;;\n\n公众号登录验证码逻辑UserController.java\n@RequestMapping(&quot;doLogin&quot;)public Result&lt;SaTokenInfo&gt; doLogin(@RequestParam(&quot;validCode&quot;) String validCode) &#123;    try &#123;        Preconditions.checkArgument(!StringUtils.isBlank(validCode), &quot;验证码不能为空!&quot;);        return Result.ok(authUserDomainService.doLogin(validCode));    &#125; catch (Exception e) &#123;        log.error(&quot;UserController.doLogin.error:&#123;&#125;&quot;, e.getMessage(), e);        return Result.fail(&quot;用户登录失败&quot;);    &#125;&#125;\n\nAuthUserDomainServiceImpl.java\n通过前缀+验证码-&gt;从redis拿到openId（即用户名），用satoken用openId进行登录，然后利用satoken返回一个token\n@Overridepublic SaTokenInfo doLogin(String validCode) &#123;    String loginKey = redisUtil.buildKey(LOGIN_PREFIX, validCode);    String openId = redisUtil.get(loginKey);    if (StringUtils.isBlank(openId)) &#123;        return null;    &#125;    AuthUserBO authUserBO = new AuthUserBO();    authUserBO.setUserName(openId);    this.register(authUserBO); //校验是否存在，存在直接返回，不存在就注册    StpUtil.login(openId);    SaTokenInfo tokenInfo = StpUtil.getTokenInfo();    return tokenInfo;&#125;\n\n\n\n第二部分前后端部署前端：\n下好node.js，\npnpm install\n\n下载好依赖。\n\n后端：\n如果服务器没那么大空间，Jenkins跑起来有点困难，可以就配置好相关配置后install打好jar包，扔到服务器上：\nnohup java -jar ***.jar\n\n\n\n\n\n细节优化1、分类和标签的性能优化，一次性查询出来，组装成树结构\n2、去出题的按钮的权限交互。用户登录成功后，返回给前端，当前用户的相关权限。前端存到本地 localstorage 里面，进行按钮级别的前端交互。对于一些敏感的写操作，后端也应该提供一些权限接口\n3、退出功能，token 失效的功能\n4、个人信息页面的查询功能。\n5、上传头像的功能。\n6、每次注册的时候，相同的 openId 要做校验。\n1. 避免重复注册AuthUserDomainServiceImpl.java\n注意这里调了register的接口：登录—&gt;注册（如果已经注册了就返回，没有注册就注册）-&gt;返回satoken提供了的tokenInfo。\n@Overridepublic SaTokenInfo doLogin(String validCode) &#123;    String loginKey = redisUtil.buildKey(LOGIN_PREFIX, validCode);    String openId = redisUtil.get(loginKey);    if (StringUtils.isBlank(openId)) &#123;        return null;    &#125;    AuthUserBO authUserBO = new AuthUserBO();    authUserBO.setUserName(openId);    this.register(authUserBO);    StpUtil.login(openId);    SaTokenInfo tokenInfo = StpUtil.getTokenInfo();    return tokenInfo;&#125;\n\nAuthUserDomainServiceImpl.java\n@Override@SneakyThrows@Transactional(rollbackFor = Exception.class)public Boolean register(AuthUserBO authUserBO) &#123;    //校验用户是否存在    AuthUser existAuthUser = new AuthUser();    existAuthUser.setUserName(authUserBO.getUserName());    List&lt;AuthUser&gt; existUser = authUserService.queryByCondition(existAuthUser);    if (existUser.size() &gt; 0) &#123; //这里如果已经注册过了，就直接返回了        return true;    &#125;    ...&#125;\n\n2.个人信息查询UserController.java\n@RequestMapping(&quot;getUserInfo&quot;)public Result&lt;AuthUserDTO&gt; getUserInfo(@RequestBody AuthUserDTO authUserDTO) &#123;    try &#123;        if (log.isInfoEnabled()) &#123;            log.info(&quot;UserController.getUserInfo.dto:&#123;&#125;&quot;, JSON.toJSONString(authUserDTO));        &#125;        Preconditions.checkArgument(!StringUtils.isBlank(authUserDTO.getUserName()), &quot;用户名不能为空&quot;);        AuthUserBO authUserBO = AuthUserDTOConverter.INSTANCE.convertDTOToBO(authUserDTO);        AuthUserBO userInfo = authUserDomainService.getUserInfo(authUserBO);        return Result.ok(AuthUserDTOConverter.INSTANCE.convertBOToDTO(userInfo));    &#125; catch (Exception e) &#123;        log.error(&quot;UserController.update.error:&#123;&#125;&quot;, e.getMessage(), e);        return Result.fail(&quot;更新用户信息失败&quot;);    &#125;&#125;\n\nauthUserDomainServiceImpl.java\n@Overridepublic AuthUserBO getUserInfo(AuthUserBO authUserBO) &#123;    AuthUser authUser = new AuthUser();    authUser.setUserName(authUserBO.getUserName());    List&lt;AuthUser&gt; userList = authUserService.queryByCondition(authUser);    if (CollectionUtils.isEmpty(userList)) &#123;        return new AuthUserBO();    &#125;    AuthUser user = userList.get(0);    return AuthUserBOConverter.INSTANCE.convertEntityToBO(user);&#125;\n\nauthUserServiceImpl.java\n@Overridepublic List&lt;AuthUser&gt; queryByCondition(AuthUser authUser) &#123;    return this.authUserDao.queryAllByLimit(authUser);&#125;\n\n3.用户退出UserController.java\n@RequestMapping(&quot;logOut&quot;)public Result logOut(@RequestParam String userName) &#123;    try &#123;        log.info(&quot;UserController.logOut.userName:&#123;&#125;&quot;, userName);        Preconditions.checkArgument(!StringUtils.isBlank(userName), &quot;用户名不能为空&quot;);        StpUtil.logout(userName);        return Result.ok();    &#125; catch (Exception e) &#123;        log.error(&quot;UserController.logOut.error:&#123;&#125;&quot;, e.getMessage(), e);        return Result.fail(&quot;用户登出失败&quot;);    &#125;&#125;\n\n4. 用户上传头像oss模块下的FileController.java\n接口定义：/upload 是一个 HTTP 请求映射，用于接收文件上传请求。\n参数：MultipartFile uploadFile 是上传的文件，String bucket 是桶的名称，String objectName 是对象名称（文件路径）。\n调用服务：调用 fileService.uploadFile 方法上传文件，并获取文件的 URL。\n返回结果：使用 Result.ok(url) 返回上传后的文件 URL。\n@RequestMapping(&quot;/upload&quot;)public Result upload(MultipartFile uploadFile, String bucket, String objectName) throws Exception &#123;    String url = fileService.uploadFile(uploadFile, bucket, objectName);    return Result.ok(url);&#125;\n\nfileService.java\n调用适配器：调用 storageAdapter.uploadFile 方法，将文件上传到指定的桶和对象名称。\n更新对象名称：将 objectName 更新为 objectName + &quot;/&quot; + uploadFile.getOriginalFilename()，这一步是为了构建文件的完整路径。\n获取 URL：调用 storageAdapter.getUrl 方法，获取文件的访问 URL 并返回。\npublic String uploadFile(MultipartFile uploadFile, String bucket, String objectName)&#123;    storageAdapter.uploadFile(uploadFile,bucket,objectName);    objectName = objectName + &quot;/&quot; + uploadFile.getOriginalFilename();    return storageAdapter.getUrl(bucket, objectName);&#125;\n\nMinioStorageAdapter.java\n创建桶：调用 minioUtil.createBucket(bucket) 方法，确保桶存在。如果桶不存在则创建。\n上传文件：根据 objectName 是否为空，决定文件上传的路径。如果 objectName 不为空，则将文件上传到 objectName + &quot;/&quot; + uploadFile.getOriginalFilename()。如果为空，则上传到 uploadFile.getOriginalFilename()。\n获取 URL：构建并返回文件的 URL。\n@Override@SneakyThrowspublic void uploadFile(MultipartFile uploadFile, String bucket, String objectName) &#123;    minioUtil.createBucket(bucket);    if (objectName != null) &#123;        minioUtil.uploadFile(uploadFile.getInputStream(), bucket, objectName + &quot;/&quot; + uploadFile.getOriginalFilename());    &#125; else &#123;        minioUtil.uploadFile(uploadFile.getInputStream(), bucket, uploadFile.getOriginalFilename());    &#125;&#125;@Override@SneakyThrowspublic String getUrl(String bucket, String objectName) &#123;    return url + &quot;/&quot; + bucket + &quot;/&quot; + objectName;&#125;\n\n5.分类题目数量更新SubjectCategoryController.java\n@PostMapping(&quot;/queryPrimaryCategory&quot;)public Result&lt;List&lt;SubjectCategoryDTO&gt;&gt; queryPrimaryCategory(@RequestBody SubjectCategoryDTO subjectCategoryDTO) &#123;    try &#123;        SubjectCategoryBO subjectCategoryBO = SubjectCategoryDTOConverter.INSTANCE.                convertDtoToCategoryBO(subjectCategoryDTO);        List&lt;SubjectCategoryBO&gt; subjectCategoryBOList = subjectCategoryDomainService.queryCategory(subjectCategoryBO);        List&lt;SubjectCategoryDTO&gt; subjectCategoryDTOList = SubjectCategoryDTOConverter.INSTANCE.                convertBoToCategoryDTOList(subjectCategoryBOList);        return Result.ok(subjectCategoryDTOList);    &#125; catch (Exception e) &#123;        log.error(&quot;SubjectCategoryController.queryPrimaryCategory.error:&#123;&#125;&quot;, e.getMessage(), e);        return Result.fail(&quot;查询失败&quot;);    &#125;&#125;\n\nSubjectCategoryDomainServiceImpl.java\n@Overridepublic List&lt;SubjectCategoryBO&gt; queryCategory(SubjectCategoryBO subjectCategoryBO) &#123;    SubjectCategory subjectCategory = SubjectCategoryConverter.INSTANCE            .convertBoToCategory(subjectCategoryBO);    subjectCategory.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());    List&lt;SubjectCategory&gt; subjectCategoryList = subjectCategoryService.queryCategory(subjectCategory);    List&lt;SubjectCategoryBO&gt; boList = SubjectCategoryConverter.INSTANCE            .convertBoToCategory(subjectCategoryList);    if (log.isInfoEnabled()) &#123;        log.info(&quot;SubjectCategoryController.queryPrimaryCategory.boList:&#123;&#125;&quot;,                JSON.toJSONString(boList));    &#125;    boList.forEach(bo -&gt; &#123;        Integer subjectCount = subjectCategoryService.querySubjectCount(bo.getId());        bo.setCount(subjectCount);    &#125;);    return boList;&#125;\n\nSubjectCategoryServiceImpl.java\n@Override    public List&lt;SubjectCategory&gt; queryCategory(SubjectCategory subjectCategory) &#123;        return this.subjectCategoryDao.queryCategory(subjectCategory);    &#125;    @Override    public Integer querySubjectCount(Long id) &#123;        return this.subjectCategoryDao.querySubjectCount(id);    &#125;\n\nSubjectCategoryDao.xml\n&lt;select id=&quot;querySubjectCount&quot; resultType=&quot;java.lang.Integer&quot;&gt;    select count(distinct subject_id)    from subject_mapping a,         subject_label b    where a.label_id = b.id    and b.category_id = #&#123;id&#125;&lt;/select&gt;\n\n6. 分类标签性能优化:star:SubjectCategoryDomainServiceImpl.java核心是使用CompletableFuture和Java流来并行处理任务：\n\n对每个category，启动一个异步任务来获取标签列表，并将任务结果以CompletableFuture的形式收集到列表中。\n遍历completableFutureList，获取每个任务的结果，并将非空结果合并到map中。 【Java 8 新特性】Java CompletableFuture supplyAsync()详解_completablefuture.supplyasync-CSDN博客\n通过这种方式，可以并行处理多个任务，提高了程序的效率。\n\nSubjectCategoryController.java\n/** * 查询分类及标签一次性 */@PostMapping(&quot;/queryCategoryAndLabel&quot;)public Result&lt;List&lt;SubjectCategoryDTO&gt;&gt; queryCategoryAndLabel(@RequestBody SubjectCategoryDTO subjectCategoryDTO) &#123;    try &#123;        if (log.isInfoEnabled()) &#123;            log.info(&quot;SubjectCategoryController.queryCategoryAndLabel.dto:&#123;&#125;&quot;                    , JSON.toJSONString(subjectCategoryDTO));        &#125;        Preconditions.checkNotNull(subjectCategoryDTO.getId(), &quot;分类id不能为空&quot;);        SubjectCategoryBO subjectCategoryBO = SubjectCategoryDTOConverter.INSTANCE.                convertDtoToCategoryBO(subjectCategoryDTO);        List&lt;SubjectCategoryBO&gt; subjectCategoryBOList = subjectCategoryDomainService.queryCategoryAndLabel(subjectCategoryBO); //查种类和标签        List&lt;SubjectCategoryDTO&gt; dtoList = new LinkedList&lt;&gt;();        subjectCategoryBOList.forEach(bo -&gt; &#123;            SubjectCategoryDTO dto = SubjectCategoryDTOConverter.INSTANCE.convertBoToCategoryDTO(bo);            List&lt;SubjectLabelDTO&gt; labelDTOList = SubjectLabelDTOConverter.INSTANCE.convertBOToLabelDTOList(bo.getLabelBOList());            dto.setLabelDTOList(labelDTOList);            dtoList.add(dto);        &#125;);        return Result.ok(dtoList);    &#125; catch (Exception e) &#123;        log.error(&quot;SubjectCategoryController.queryPrimaryCategory.error:&#123;&#125;&quot;, e.getMessage(), e);        return Result.fail(&quot;查询失败&quot;);    &#125;&#125;\n\n自定义线程工厂：\nCustomNameThreadFactory.java\n// 导入所需的类和接口。import java.util.concurrent.ThreadFactory;import java.util.concurrent.atomic.AtomicInteger;import org.apache.commons.lang3.StringUtils;public class CustomNameThreadFactory implements ThreadFactory &#123;    // 用于生成线程池编号的静态原子类。    private static final AtomicInteger poolNumber = new AtomicInteger(1);    // 线程所属的线程组。    private final ThreadGroup group;    // 用于生成线程编号的原子类。    private final AtomicInteger threadNumber = new AtomicInteger(1);    // 线程名称的前缀。    private final String namePrefix;    // 构造函数，接受一个字符串参数来设置线程名称的前缀。    CustomNameThreadFactory(String name) &#123;        SecurityManager s = System.getSecurityManager();        // 如果存在安全管理器，则使用安全管理器的线程组，否则使用当前线程的线程组。        group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup();        // 如果传入的名称为空或空白，则默认使用 &quot;pool&quot; 作为名称。        if (StringUtils.isBlank(name)) &#123;            name = &quot;pool&quot;;        &#125;        // 构造线程名称的前缀，包括线程池编号和 &quot;-thread-&quot;。        namePrefix = name + &quot;-&quot; + poolNumber.getAndIncrement() + &quot;-thread-&quot;;    &#125;    // 实现 ThreadFactory 接口的 newThread 方法，用于创建新的线程。    @Override    public Thread newThread(Runnable r) &#123;        // 创建一个新的线程，使用 group 作为线程组，r 作为要执行的任务。        Thread t = new Thread(group, r,                // 线程名称由前缀、线程编号和递增后的编号组成。                namePrefix + threadNumber.getAndIncrement(),                0);        // 如果线程是守护线程，则将其设置为非守护线程。        if (t.isDaemon())&#123;            t.setDaemon(false);        &#125;        // 如果线程的优先级不是普通优先级，则将其设置为普通优先级。        if (t.getPriority() != Thread.NORM_PRIORITY)&#123;            t.setPriority(Thread.NORM_PRIORITY);        &#125;        // 返回新创建的线程。        return t;    &#125;&#125;\n\nSubjectCategoryDomainServiceImpl.java\n创建并初始化SubjectCategory对象：\n\n设置ParentId为categoryId。\n设置IsDeleted为未删除状态。\n\n查询类别列表：\n\n调用subjectCategoryService.queryCategory方法查询类别列表。\n\n日志记录：\n\n记录查询结果的日志。\n\n转换类别列表：\n\n使用SubjectCategoryConverter将SubjectCategory列表转换为SubjectCategoryBO列表。\n\n并行处理标签列表：\n\n为每个类别创建一个异步任务，调用getLabelBOList方法获取标签列表。\n使用CompletableFuture并行处理这些任务。\n\n收集并合并结果：\n\n等待所有异步任务完成，并将结果合并到一个Map&lt;Long, List&lt;SubjectLabelBO&gt;&gt;中。\n\n设置标签列表：\n\n为每个SubjectCategoryBO对象设置对应的标签列表。\n\n返回结果：\n\n返回包含标签列表的SubjectCategoryBO列表。\n\n@Resourceprivate ThreadPoolExecutor labelThreadPool;@SneakyThrows@Overridepublic List&lt;SubjectCategoryBO&gt; queryCategoryAndLabel(SubjectCategoryBO subjectCategoryBO) &#123;    Long id = subjectCategoryBO.getId();    String cacheKey = &quot;categoryAndLabel.&quot; + subjectCategoryBO.getId();    List&lt;SubjectCategoryBO&gt; subjectCategoryBOS = cacheUtil.getResult(cacheKey,            SubjectCategoryBO.class, (key) -&gt; getSubjectCategoryBOS(id));    return subjectCategoryBOS;&#125;private List&lt;SubjectCategoryBO&gt; getSubjectCategoryBOS(Long categoryId) &#123;        SubjectCategory subjectCategory = new SubjectCategory();        subjectCategory.setParentId(categoryId);        subjectCategory.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());        List&lt;SubjectCategory&gt; subjectCategoryList = subjectCategoryService.queryCategory(subjectCategory);        if (log.isInfoEnabled()) &#123;            log.info(&quot;SubjectCategoryController.queryCategoryAndLabel.subjectCategoryList:&#123;&#125;&quot;,                    JSON.toJSONString(subjectCategoryList));        &#125;        List&lt;SubjectCategoryBO&gt; categoryBOList = SubjectCategoryConverter.INSTANCE.convertBoToCategory(subjectCategoryList);        Map&lt;Long, List&lt;SubjectLabelBO&gt;&gt; map = new HashMap&lt;&gt;();        List&lt;CompletableFuture&lt;Map&lt;Long, List&lt;SubjectLabelBO&gt;&gt;&gt;&gt; completableFutureList = categoryBOList.stream().map(category -&gt;                CompletableFuture.supplyAsync(() -&gt; getLabelBOList(category), labelThreadPool).collect(Collectors.toList()); //对于每个category，调用异步的CompletableFuture.supplyAsync()执行getLabelBOList方法和ThreadPoolExecutor作为Executor去多线程+异步的获取labelBOList        completableFutureList.forEach(future -&gt; &#123;            try &#123;                Map&lt;Long, List&lt;SubjectLabelBO&gt;&gt; resultMap = future.get();                if (!MapUtils.isEmpty(resultMap)) &#123;                    map.putAll(resultMap);                &#125;            &#125; catch (Exception e) &#123;                e.printStackTrace();            &#125;        &#125;);        categoryBOList.forEach(categoryBO -&gt; &#123;            if (!CollectionUtils.isEmpty(map.get(categoryBO.getId()))) &#123;                categoryBO.setLabelBOList(map.get(categoryBO.getId()));            &#125;        &#125;);        return categoryBOList;    &#125;//通过Category查找对应的labelListprivate Map&lt;Long, List&lt;SubjectLabelBO&gt;&gt; getLabelBOList(SubjectCategoryBO category) &#123;        if (log.isInfoEnabled()) &#123;            log.info(&quot;getLabelBOList:&#123;&#125;&quot;, JSON.toJSONString(category));        &#125;        Map&lt;Long, List&lt;SubjectLabelBO&gt;&gt; labelMap = new HashMap&lt;&gt;();        SubjectMapping subjectMapping = new SubjectMapping();        subjectMapping.setCategoryId(category.getId());        List&lt;SubjectMapping&gt; mappingList = subjectMappingService.queryLabelId(subjectMapping);        if (CollectionUtils.isEmpty(mappingList)) &#123;            return null;        &#125;        List&lt;Long&gt; labelIdList = mappingList.stream().map(SubjectMapping::getLabelId).collect(Collectors.toList());        List&lt;SubjectLabel&gt; labelList = subjectLabelService.batchQueryById(labelIdList);        List&lt;SubjectLabelBO&gt; labelBOList = new LinkedList&lt;&gt;();        labelList.forEach(label -&gt; &#123;            SubjectLabelBO subjectLabelBO = new SubjectLabelBO();            subjectLabelBO.setId(label.getId());            subjectLabelBO.setLabelName(label.getLabelName());            subjectLabelBO.setCategoryId(label.getCategoryId());            subjectLabelBO.setSortNum(label.getSortNum());            labelBOList.add(subjectLabelBO);        &#125;);        labelMap.put(category.getId(), labelBOList);        return labelMap;&#125;\n\n这段代码的核心是使用CompletableFuture和Java流来并行处理任务：\n\n对每个category，启动一个异步任务来获取标签列表，并将任务结果以CompletableFuture的形式收集到列表中。\n遍历completableFutureList，获取每个任务的结果，并将非空结果合并到map中。 【Java 8 新特性】Java CompletableFuture supplyAsync()详解_completablefuture.supplyasync-CSDN博客\n通过这种方式，可以并行处理多个任务，提高了程序的效率。\n\n7. 用户权限获取AuthPermissionDomainServiceImpl.java\n将存储在Redis中的权限数据转换为一个易于使用的权限键列表，以便在应用程序中进行权限检查。如果Redis中没有找到用户的权限数据，则返回一个空列表。\n@Overridepublic List&lt;String&gt; getPermission(String userName) &#123;    String permissionKey = redisUtil.buildKey(authPermissionPrefix, userName);    String permissionValue = redisUtil.get(permissionKey);    if (StringUtils.isBlank(permissionValue)) &#123;        return Collections.emptyList();    &#125;    List&lt;AuthPermission&gt; permissionList = new Gson().fromJson(permissionValue,            new TypeToken&lt;List&lt;AuthPermission&gt;&gt;() &#123;            &#125;.getType()); //使用Google的Gson库将权限字符串反序列化为AuthPermission对象的列表。TypeToken用于指定泛型类型。    List&lt;String&gt; authList = permissionList.stream().map(AuthPermission::getPermissionKey).collect(Collectors.toList());    return authList; &#125;\n\n8. 利用minio&#x2F;mc突破图片7天权限\n有两个问题：\n\nminio上传头像只能保存7天\n生成的url很长，需要简化\n\ndocker pull minio/mcdocker run -it --entrypoint=/bin/sh minio/mcmc config host add &lt;ALIAS&gt; &lt;YOUR-S3-ENDPOINT&gt; &lt;YOUR-ACCESS-KEY&gt; &lt;YOUR-SECRET-KEY&gt; [--api API-SIGNATURE]mc config host add minio http://xxx.xx.xx.xxx:9000 GrVCPXySKgGoJiGgXmtv 0xlqSI9GXvnBOtp0GwUj5OshKNBk9JgwoexotbVVmc ls miniomc anonymous //可以设置什么mc anonymous set download minio/jichi\n\nurl: bucket+name\nFileController.java\n\nMinioStorageAdapter.java\n\nFileController.java\n\nMinioStorageAdapter.java\n\n功能规划搜索功能（完成）全文检索，技术选型 es。\n安装 es。\nxxl-job 定时任务，去做一个数据同步，全量数据导入\nes 全文检索，做高亮\n点赞（完成）自己点赞过的，这里肯定要有一个点赞过的 icon 的一个标识\n后面的数量，意味着这道题目被多少个人点过赞。\n如何去防刷点赞。疯狂的点赞，取消点赞。前端配合防抖，后端的点赞数量放到 redis 里面。数据库的持久化，可以通过定时任务来定时的刷新同步。\n\n我的点赞（完成）展示，我们当前当过赞的所有的数据，来进行一波展示。\n\n收藏（完成）\n我的收藏（完成）\n纠错（完成）纠错当用户发现题目有问题，错误的话，就可以通过这个方式，来进行反馈。\n\n快速刷题（完成）\n在这个位置去加一个上一题，下一题。\n贡献榜（完成）按照我的周维度，月维度，来做数据的存储。zset。和 redis 做大量的交互。\nfeign 的微服务间调用（完成）会涉及到微服务之间的逻辑调用。这个就用 feign 了。\n打通用户上下文（完成）配合 threadlocal，基于 token 来实现用户信息的上下文传递。\n二级缓存的使用（完成）点赞里面。\n用户上下文打通链路流程：\n\n详细设计：\n\nLoginfilter(实现Globalfilter接口，通过filter拿到token，解析出loginId，然后传到后面的过滤链中)\n-&gt;LoginInterceptor(实现HandlerInterceptor，检验loginId是否存在且非空，如果存在，将其保存到自定义的线程局部变量上下文LoginContextHolder中，通过InheritableThreadLocal来实现)\n以上都不拦截doLogin操作\ngateway网关自定义拦截headerLoginFilter.java\n// 引入Spring组件注解，标识这是一个Spring组件@Component// 使用lombok的@Slf4j注解自动为类生成日志对象@Slf4jpublic class LoginFilter implements GlobalFilter &#123;    // 实现GlobalFilter接口的filter方法，该方法会在请求被路由之前调用    @Override    // 使用@SneakyThrows注解来避免显式声明异常，简化代码    @SneakyThrows    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123;        // 获取请求和响应对象        ServerHttpRequest request = exchange.getRequest();        ServerHttpResponse response = exchange.getResponse();                // 创建请求的构建器，用于修改请求头信息        ServerHttpRequest.Builder mutate = request.mutate();                // 获取请求的URL路径        String url = request.getURI().getPath();                // 记录请求的URL到日志        log.info(&quot;LoginFilter.filter.url:&#123;&#125;&quot;, url);                // 如果请求的URL是&quot;/user/doLogin&quot;，则直接放行，不进行拦截        if (url.equals(&quot;/user/doLogin&quot;)) &#123;            return chain.filter(exchange);        &#125;                // 尝试获取当前请求的token信息，这里使用了SaToken框架        SaTokenInfo tokenInfo = StpUtil.getTokenInfo();                // 将token信息记录到日志中，这里使用了Gson库来将对象转换为JSON字符串        log.info(&quot;LoginFilter.filter.url:&#123;&#125;&quot;, new Gson().toJson(tokenInfo));                // 从token信息中获取登录用户的ID        String loginId = (String) tokenInfo.getLoginId();                // 将登录用户的ID添加到请求头中        mutate.header(&quot;loginId&quot;, loginId);                // 将修改后的请求和原始的响应以及过滤器链一起构建成一个新的ServerWebExchange对象        // 并调用chain.filter方法继续过滤链的执行        return chain.filter(exchange.mutate().request(mutate.build()).build());    &#125;&#125;\n\n通过filter拿到token，解析出loginId，然后传到后面的过滤链中。\n基于threadLocal实现上下文传递mvc的全局处理：GlobalConfig.java\n// 标记这个类是一个Spring配置类@Configurationpublic class GlobalConfig extends WebMvcConfigurationSupport &#123;    // 覆盖configureMessageConverters方法来添加自定义的消息转换器    @Override    protected void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123;        // 首先调用父类的configureMessageConverters方法        super.configureMessageConverters(converters);        // 添加一个MappingJackson2HttpMessageConverter到转换器列表中        converters.add(mappingJackson2HttpMessageConverter());    &#125;    // 覆盖addInterceptors方法来添加自定义的拦截器    @Override    protected void addInterceptors(InterceptorRegistry registry) &#123;        // 添加一个自定义的拦截器LoginInterceptor        registry.addInterceptor(new LoginInterceptor())                // 拦截所有路径                .addPathPatterns(&quot;/**&quot;)                // 排除/user/doLogin路径，不对登录请求进行拦截                .excludePathPatterns(&quot;/user/doLogin&quot;);    &#125;    /**     * 自定义的MappingJackson2HttpMessageConverter实现     * 目前实现的功能：     * - 忽略空值，即使对象的字段为null也不会在JSON中出现     * - 只序列化非空字段，空字段不会被序列化到JSON中     */    private MappingJackson2HttpMessageConverter mappingJackson2HttpMessageConverter() &#123;        // 创建ObjectMapper实例        ObjectMapper objectMapper = new ObjectMapper();        // 配置ObjectMapper，当对象的字段为null时不抛出异常        objectMapper.configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false);        // 设置序列化时包含非空字段        objectMapper.setSerializationInclusion(JsonInclude.Include.NON_NULL);        // 创建MappingJackson2HttpMessageConverter并使用自定义的ObjectMapper        return new MappingJackson2HttpMessageConverter(objectMapper);    &#125;&#125;\n\n登录拦截器：LoginInterceptor.java\npublic class LoginInterceptor implements HandlerInterceptor &#123;    // 在请求处理之前执行的方法    @Override    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123;        // 从请求头中获取loginId        String loginId = request.getHeader(&quot;loginId&quot;);                // 判断loginId是否存在且非空        if (StringUtils.isNotBlank(loginId)) &#123;            // 如果存在，将其保存到自定义的线程局部变量上下文LoginContextHolder中            LoginContextHolder.set(&quot;loginId&quot;, loginId);        &#125;                // 返回true表示继续执行拦截器链中的下一个拦截器或处理器        return true;    &#125;    // 请求处理完成后执行的方法    @Override    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, @Nullable Exception ex) throws Exception &#123;        // 从上下文中移除loginId，清理线程局部变量        LoginContextHolder.remove();    &#125;&#125;\n\n登录上下文对象: LoginContextHolder\nInheritableThreadLocal详解-CSDN博客\npublic class LoginContextHolder &#123;    // 使用InheritableThreadLocal来创建线程局部变量，允许子线程继承父线程的值    private static final InheritableThreadLocal&lt;Map&lt;String, Object&gt;&gt; THREAD_LOCAL =            new InheritableThreadLocal&lt;&gt;();    // 将键值对放入线程局部变量中    public static void set(String key, Object val) &#123;        Map&lt;String, Object&gt; map = getThreadLocalMap();        map.put(key, val);    &#125;    // 根据键从线程局部变量中获取值    public static Object get(String key)&#123;        Map&lt;String, Object&gt; threadLocalMap = getThreadLocalMap();        return threadLocalMap.get(key);    &#125;    // 专门用于获取loginId的方法    public static String getLoginId()&#123;        return (String) getThreadLocalMap().get(&quot;loginId&quot;);    &#125;    // 清除线程局部变量中的所有数据    public static void remove()&#123;        THREAD_LOCAL.remove();    &#125;    // 获取线程局部变量中存储的Map，如果Map不存在，则创建一个新的Map    public static Map&lt;String, Object&gt; getThreadLocalMap() &#123;        Map&lt;String, Object&gt; map = THREAD_LOCAL.get();        if (Objects.isNull(map)) &#123;            map = new ConcurrentHashMap&lt;&gt;(); // 使用线程安全的ConcurrentHashMap            THREAD_LOCAL.set(map);        &#125;        return map;    &#125;&#125;\n\n之后就可以根据这个上下文，封装一下，去拿loginId\npublic class LoginUtil &#123;    public static String getLoginId() &#123;        return LoginContextHolder.getLoginId();    &#125;&#125;\n\n微服务之间的Feign调用微服务之间的调用\nopenfeign 是 spring cloud 搞出来的一个升级版，netflix 的 feign 这个不维护了。\nopenfeign 他就是声明式的 webservice 的客户端，使用 feign，编写调用更加的简单，主要打上注解就可以进行一个调用。\nString responese = service.hello();\n\n一行代码直接搞定。\nfeign 就帮助我们把 http 的调用编的非常的容易和方便，他整体的实现就是利用了 resttemplate 对 http 的一个封装。\nfeign 通过注解的方式配置之后，就可以完成接口的自动绑定，那我们调用 feign 的时候就像调接口一样，内置负载。内部封装了 ribbon。\n实操：\n首先，微服务之间要暴露出提供给其他服务的接口。在这里以auth包中的接口暴露给subject包的接口为例。\nauth:\njc-club-auth-api包中的UserFeignService接口，这里注意@FeignClient注解后面的&quot;jc-club-auth-dev&quot;实则是在starter包中对应的bootstrap.yaml中的服务名称（这个东西是注册到nacos上面的）\n@FeignClient(&quot;jc-club-auth-dev&quot;)public interface UserFeignService &#123;    // 调用该接口实则是调用的对应的domainService    @RequestMapping(&quot;/user/getUserInfo&quot;)    Result&lt;AuthUserDTO&gt; getUserInfo(@RequestBody AuthUserDTO authUserDTO);    @RequestMapping(&quot;/user/listByIds&quot;)    Result&lt;List&lt;AuthUserDTO&gt;&gt; listUserInfoByIds(@RequestBody List&lt;String&gt; userNameList);&#125;\n\n// 对应的domainService@Overridepublic AuthUserBO getUserInfo(AuthUserBO authUserBO) &#123;    AuthUser authUser = new AuthUser();    authUser.setUserName(authUserBO.getUserName());    List&lt;AuthUser&gt; userList = authUserService.queryByCondition(authUser);    if (CollectionUtils.isEmpty(userList)) &#123;        return new AuthUserBO();    &#125;    AuthUser user = userList.get(0);    return AuthUserBOConverter.INSTANCE.convertEntityToBO(user);&#125;@Overridepublic List&lt;AuthUserBO&gt; listUserInfoByIds(List&lt;String&gt; userNameList) &#123;    List&lt;AuthUser&gt; userList = authUserService.listUserInfoByIds(userNameList);    if (CollectionUtils.isEmpty(userList)) &#123;        return Collections.emptyList();    &#125;    return AuthUserBOConverter.INSTANCE.convertEntityToBO(userList);&#125;\n\n\n\n在jc-club-auth-application-controller包中的pom.xml文件中，添加对该api包的依赖\n&lt;dependency&gt;    &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;    &lt;artifactId&gt;jc-club-auth-api&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt;\n\n\n\nsubject:\n在jc-club-subject的infra包中的pom.xml中添加依赖\n&lt;dependency&gt;    &lt;groupId&gt;com.jingdianjichi&lt;/groupId&gt;    &lt;artifactId&gt;jc-club-auth-api&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt;\n\n在jc-club-subject的infra包中添加UserRpc.java\n@Componentpublic class UserRpc &#123;\t    //auth-api模块中的UserFeignService接口    @Resource    private UserFeignService userFeignService;    public UserInfo getUserInfo(String userName) &#123;        AuthUserDTO authUserDTO = new AuthUserDTO();        authUserDTO.setUserName(userName);        //调用UserFeignService中暴露的接口        Result&lt;AuthUserDTO&gt; result = userFeignService.getUserInfo(authUserDTO);        UserInfo userInfo = new UserInfo();        if (!result.getSuccess()) &#123;            return userInfo;        &#125;        AuthUserDTO data = result.getData();        userInfo.setUserName(data.getUserName());        userInfo.setNickName(data.getNickName());        userInfo.setAvatar(data.getAvatar());        return userInfo;    &#125;&#125;\n\n进行测试，能拿到userInfo\n@RestController@RequestMapping(&quot;/subject/category&quot;)@Slf4jpublic class TestFeignController &#123;    @Resource    private UserRpc userRpc;    @GetMapping(&quot;testFeign&quot;)    public void testFeign() &#123;        UserInfo userInfo = userRpc.getUserInfo(&quot;lzrj&quot;);        log.info(&quot;testFeign.userInfo:&#123;&#125;&quot;, userInfo);    &#125;&#125;\n\nopenFeign拦截器实现用户上下文打通\nimport feign.RequestInterceptor;import feign.RequestTemplate;import org.springframework.stereotype.Component;import org.springframework.web.context.request.ServletRequestAttributes;import javax.servlet.http.HttpServletRequest;import org.apache.commons.lang3.StringUtils;import java.util.Objects;// 将Feign拦截器注册为Spring组件@Componentpublic class FeignRequestInterceptor implements RequestInterceptor &#123;    // 实现apply方法，该方法将在Feign客户端发出请求之前被调用    @Override    public void apply(RequestTemplate requestTemplate) &#123;        // 从RequestContextHolder获取当前的ServletRequestAttributes        ServletRequestAttributes requestAttributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();                // 从ServletRequestAttributes中获取HttpServletRequest对象        HttpServletRequest request = requestAttributes.getRequest();                // 检查HttpServletRequest是否非空        if (Objects.nonNull(request)) &#123;            // 从HttpServletRequest的请求头中获取loginId            String loginId = request.getHeader(&quot;loginId&quot;);                        // 检查loginId是否非空且非仅包含空白字符            if (StringUtils.isNotBlank(loginId)) &#123;                // 如果loginId存在，将其添加到Feign请求模板的请求头中                requestTemplate.header(&quot;loginId&quot;, loginId);            &#125;        &#125;    &#125;&#125;\n\n@Configurationpublic class FeignConfiguration &#123;    @Bean    public RequestInterceptor requestInterceptor()&#123;        return new FeignRequestInterceptor();    &#125;&#125;\n\n通过FeignRequestInterceptor在调用微服务之前，就可以把相关请求的loginId封装到请求中，进行跨微服务的loginId的传递：\nguava本地缓存(已经升级成Caffiene)泛型+函数式编程\nguava:\nimport com.google.common.cache.Cache;import com.google.common.cache.CacheBuilder;import com.google.common.collect.Lists;import com.google.gson.JsonObject;import org.apache.commons.collections4.CollectionUtils;import org.apache.commons.lang3.StringUtils;import java.util.List;import java.util.Map;import java.util.concurrent.TimeUnit;import org.springframework.stereotype.Component;// 将CacheUtil类标记为Spring组件@Componentpublic class CacheUtil&lt;K, V&gt; &#123;    // 使用Guava的CacheBuilder构建一个本地缓存    private Cache&lt;String, String&gt; localCache =            CacheBuilder.newBuilder()                    // 设置缓存最大容量为5000                    .maximumSize(5000)                    // 设置写入后10秒过期                    .expireAfterWrite(10, TimeUnit.SECONDS)                    .build();    // 根据缓存键获取缓存结果，如果缓存未命中则调用function获取数据并缓存结果    public List&lt;V&gt; getResult(String cacheKey, Class&lt;V&gt; clazz,                             Function&lt;String, List&lt;V&gt;&gt; function) &#123;        List&lt;V&gt; resultList = new ArrayList&lt;&gt;();        // 尝试从缓存中获取内容        String content = localCache.getIfPresent(cacheKey);        if (StringUtils.isNotBlank(content)) &#123;            // 如果缓存中有数据，解析JSON字符串到List中            resultList = JSON.parseArray(content, clazz);        &#125; else &#123;            // 如果缓存未命中，调用function获取数据            resultList = function.apply(cacheKey);            // 如果获取的数据不为空，则将数据序列化为JSON字符串并缓存            if (!CollectionUtils.isEmpty(resultList)) &#123;                localCache.put(cacheKey, JSON.toJSONString(resultList));            &#125;        &#125;        return resultList;    &#125;    // 根据缓存键获取Map类型的缓存结果，如果缓存未命中则调用function获取数据并缓存结果    // 注意：此方法的实现目前为空，需要根据具体需求进行实现    public Map&lt;K, V&gt; getMapResult(String cacheKey, Class&lt;V&gt; clazz,                                  Function&lt;String, Map&lt;K, V&gt;&gt; function) &#123;        return new HashMap&lt;&gt;();    &#125;&#125;\n\n在这用到了queryCategoryAndLabel：\n@SneakyThrows@Overridepublic List&lt;SubjectCategoryBO&gt; queryCategoryAndLabel(SubjectCategoryBO subjectCategoryBO) &#123;    Long id = subjectCategoryBO.getId();    String cacheKey = &quot;categoryAndLabel.&quot; + subjectCategoryBO.getId();    // 调用本地缓存    List&lt;SubjectCategoryBO&gt; subjectCategoryBOS = cacheUtil.getResult(cacheKey,            SubjectCategoryBO.class, (key) -&gt; getSubjectCategoryBOS(id)); //如果本地缓存没有 就调用getSubjectCategoryBOS    return subjectCategoryBOS;&#125;\n\n全文检索功能ElasticSearch从入门到精通，史上最全（持续更新，未完待续，每天一点点）_elasticsearch从入门到精通,史上最全-CSDN博客\n功能设计\n技术选型：elasticsearch。\n目的是，网站现在整体的题目预计会到好几百，方便快速的搜索到自己想看的内容。\n实现形式：\n\n同步：新增题目-&gt;MYSQL-&gt;es\n\n\n异步：mysql 存储完后，发送 mq\n\n\n异步canal：监听 mysql 变更的 binlog，实现 es 的存储\n\n\n\n实际操作[通过HTTP的方式操作ES-CSDN博客](https://blog.csdn.net/sss294438204/article/details/122884953?ops_request_misc=%7B%22request%5Fid%22%3A%22172355571716800211536069%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172355571716800211536069&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-122884953-null-null.142^v100^pc_search_result_base8&amp;utm_term=es http&amp;spm&#x3D;1018.2226.3001.4187)\n接口：\n\nes分词问题原生的不太行，用这个\nhttps://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.3.1/elasticsearch-analysis-ik-7.3.1.zip\n\n解压后，上传到服务器 的 ik 文件夹下面：\nmkdir /soft/ik进入容器内部docker exec -it elasticsearch /bin/bashcd pluginsmkdir ik回到外部docker cp /soft/ik/. 73438a827b55:/usr/share/elasticsearch/plugins/ik重启esdocker restart 73438a827b55\n\n编码: 试手subject-infra层pom.xml\n&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt;    &lt;version&gt;2.4.2&lt;/version&gt;&lt;/dependency&gt;\n\nTestFeignController.java\n@GetMapping(&quot;testCreateIndex&quot;)   public void testCreateIndex() &#123;       subjectEsService.createIndex();   &#125;   @GetMapping(&quot;addDocs&quot;)   public void addDocs() &#123;       subjectEsService.addDoc();   &#125;   @GetMapping(&quot;find&quot;)   public void find() &#123;       subjectEsService.find();   &#125;   @GetMapping(&quot;search&quot;)   public void search() &#123;       subjectEsService.search();   &#125;\n\n实体类：SubjectInfoEs.java\n@Data@AllArgsConstructor@NoArgsConstructor@Document(indexName = &quot;subject_index&quot;, createIndex = false)public class SubjectInfoEs &#123;    @Field(type = FieldType.Long)    @Id    private Long id;    @Field(type = FieldType.Text, analyzer = &quot;ik_smart&quot;)    private String subjectName;    @Field(type = FieldType.Text, analyzer = &quot;ik_smart&quot;)    private String subjectAnswer;    @Field(type = FieldType.Keyword)    private String createUser;    @Field(type = FieldType.Date, index = false)    private Date createTime;&#125;\n\nSubjectEsRepository.java，继承自ElasticsearchRepository。这个接口是Spring Data Elasticsearch的一部分，用于提供对Elasticsearch的访问和操作。\n@Componentpublic interface SubjectEsRepository extends ElasticsearchRepository&lt;SubjectInfoEs, Long&gt; &#123;&#125;\n\nSubjectEsService.java\npublic interface SubjectEsService &#123;    void createIndex();    void addDoc();    void find();    void search();&#125;\n\nSubjectEsServiceImpl.java\n@Service@Slf4jpublic class SubjectEsServiceImpl implements SubjectEsService &#123;    @Resource    private ElasticsearchRestTemplate elasticsearchRestTemplate;    @Resource    private SubjectEsRepository subjectEsRepository;    @Override    public void createIndex() &#123;        IndexOperations indexOperations =                elasticsearchRestTemplate.indexOps(SubjectInfoEs.class);        indexOperations.create();        Document mapping = indexOperations.createMapping(SubjectInfoEs.class);        indexOperations.putMapping(mapping);    &#125;    @Override    public void addDoc() &#123;        List&lt;SubjectInfoEs&gt; list = new ArrayList&lt;&gt;();        list.add(new SubjectInfoEs(1L,&quot;redis是什么&quot;,&quot;redis是一个缓存&quot;,&quot;鸡翅&quot;,new Date()));        list.add(new SubjectInfoEs(2L,&quot;mysql是什么&quot;,&quot;mysql是数据库&quot;,&quot;鸡翅&quot;,new Date()));        subjectEsRepository.saveAll(list);    &#125;    @Override    public void find() &#123;        Iterable&lt;SubjectInfoEs&gt; all = subjectEsRepository.findAll();        for (SubjectInfoEs subjectInfoEs : all)&#123;            log.info(&quot;subjectInfoEs:&#123;&#125;&quot;,JSON.toJSONString(subjectInfoEs));        &#125;    &#125;    @Override    public void search() &#123;        NativeSearchQuery nativeSearchQuery = new NativeSearchQueryBuilder()                .withQuery(QueryBuilders.matchQuery(&quot;subjectName&quot;,&quot;redis&quot;))                .build();        SearchHits&lt;SubjectInfoEs&gt; search = elasticsearchRestTemplate.                search(nativeSearchQuery, SubjectInfoEs.class);        List&lt;SearchHit&lt;SubjectInfoEs&gt;&gt; searchHits = search.getSearchHits();        log.info(&quot;searchHits:&#123;&#125;&quot;, JSON.toJSONString(searchHits));    &#125;&#125;\n\nsubject-starter中的application.yaml\nelasticsearch: rest:  uris:http://172.72.14.166:9200\n\n编码：自定义封装es集群连接统一管理希望的一个目的\n\n有自己的封装好的工具\n集群，索引等等都要兼容的配置的概念\n不想用 data 的这种方式，不够扩展\n\n\n配置类：读取配置文件自定义的属性，支持集群，节点等等一些信息\n\n@Configuration + @ConfigurationProperties + @Data（必须提供set方法）\n@Configuration +  @Value\n\n集群类：集群的名称、集群的节点\n索引类：集群名称、索引名称\n封装的请求类：查询条件、查询字段、页数、条数、快照、快照缓存时间、排序字段、排序类型、高亮\n封装的返回类：文档id（保证唯一）、所有跟restClient交互的封装成一个Map\n自定义工具类：目的就是为了提供一个RestHighLevelClient，在原生client的基础上封装一些好用的api\n整体基于 es 的原生的 client 来去做。\nsubject-infra层pom.xml\n&lt;dependency&gt;    &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt;    &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt;    &lt;version&gt;7.5.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt;    &lt;artifactId&gt;elasticsearch-rest-client&lt;/artifactId&gt;    &lt;version&gt;7.5.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt;    &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt;    &lt;version&gt;7.5.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;    &lt;artifactId&gt;commons-collections4&lt;/artifactId&gt;    &lt;version&gt;4.4&lt;/version&gt;&lt;/dependency&gt;\n\n\n\nes集群类EsClusterConfig.java\n@Datapublic class EsClusterConfig implements Serializable &#123;    /**     * 集群名称     */    private String name;    /**     * 集群节点     */    private String nodes;&#125;\n\nEsConfigProperties.java\n@Component@ConfigurationProperties(prefix = &quot;es.cluster&quot;) //这部分是跟application.yaml中的对应public class EsConfigProperties &#123;    private List&lt;EsClusterConfig&gt; esConfigs = new ArrayList&lt;&gt;();    public List&lt;EsClusterConfig&gt; getEsConfigs() &#123;        return esConfigs;    &#125;    public void setEsConfigs(List&lt;EsClusterConfig&gt; esConfigs) &#123;        this.esConfigs = esConfigs;    &#125;&#125;\n\nsubject-starter中的application.yaml\nes:  cluster:    esConfigs[0]:      name: 73438a827b55      nodes: 117.72.14.166:9200\n\nEsIndexInfo.java\n@Datapublic class EsIndexInfo implements Serializable &#123;    /**     * 集群名称     */    private String clusterName;    /**     * 索引名称     */    private String indexName;&#125;\n\nEsSearchRequest.java\n@Datapublic class EsSearchRequest &#123;    /**     * 查询条件     */    private BoolQueryBuilder bq;    /**     * 查询字段     */    private String[] fields;    /**     * 页数     */    private int from;    /**     * 条数     */    private int size;    /**     * 需要快照     */    private Boolean needScroll;    /**     * 快照缓存时间     */    private Long minutes;    /**     * 排序字段     */    private String sortName;    /**     * 排序类型     */    private SortOrder sortOrder;    /**     * 高亮builder     */    private HighlightBuilder highlightBuilder;&#125;\n\nEsSourceData.java\n@Datapublic class EsSourceData implements Serializable &#123;    private String docId;    private Map&lt;String, Object&gt; data;&#125;\n\nEsRestClient.java\n这个类封装了与Elasticsearch集群交互的常见操作\n\n类定义和日志记录：使用@Component注解表明这是一个Spring组件，使用@Slf4j来引入日志记录功能。\n客户端映射：clientMap是一个静态的HashMap，用于存储不同Elasticsearch集群的RestHighLevelClient实例。\n配置属性注入：通过@Resource注解注入EsConfigProperties，这是一个配置属性类，用于获取Elasticsearch集群的配置信息。\n请求选项：定义了一个静态的RequestOptions对象COMMON_OPTIONS，用于后续的请求。\n初始化方法：initialize方法在组件初始化时被调用，用于根据配置创建和初始化RestHighLevelClient实例。\n创建客户端方法：initRestClient是一个私有方法，用于根据给定的集群配置创建RestHighLevelClient实例。\n获取客户端方法：getClient是一个静态方法，用于根据集群名称获取对应的RestHighLevelClient实例。\n文档操作：类中定义了一系列的静态方法，用于执行Elasticsearch中的文档操作，如插入(insertDoc)、更新(updateDoc)、批量更新(batchUpdateDoc)、删除(delete和deleteDoc)、检查文档是否存在(isExistDocById)、获取文档(getDocById)等。\n搜索功能：searchWithTermQuery方法用于执行基于布尔查询构建器的搜索请求，并支持高亮显示、排序和滚动(scroll)。\n批量插入：batchInsertDoc方法用于批量插入文档。\n更新查询：updateByQuery方法允许执行基于查询的更新操作。\n分词功能：getAnalyze方法提供了一个分词功能，可以对输入的文本进行分词。\n\n@Component@Slf4jpublic class EsRestClient &#123;    public static Map&lt;String, RestHighLevelClient&gt; clientMap = new HashMap&lt;&gt;();    @Resource    private EsConfigProperties esConfigProperties;    private static final RequestOptions COMMON_OPTIONS;    static &#123;        RequestOptions.Builder builder = RequestOptions.DEFAULT.toBuilder();        COMMON_OPTIONS = builder.build();    &#125;    @PostConstruct    public void initialize() &#123;        List&lt;EsClusterConfig&gt; esConfigs = esConfigProperties.getEsConfigs();        for (EsClusterConfig esConfig : esConfigs) &#123;            log.info(&quot;initialize.config.name:&#123;&#125;,node:&#123;&#125;&quot;, esConfig.getName(), esConfig.getNodes());            RestHighLevelClient restHighLevelClient = initRestClient(esConfig);            if (restHighLevelClient != null) &#123;                clientMap.put(esConfig.getName(), restHighLevelClient);            &#125; else &#123;                log.error(&quot;config.name:&#123;&#125;,node:&#123;&#125;.initError&quot;, esConfig.getName(), esConfig.getNodes());            &#125;        &#125;    &#125;    private RestHighLevelClient initRestClient(EsClusterConfig esClusterConfig) &#123;        String[] ipPortArr = esClusterConfig.getNodes().split(&quot;,&quot;);        List&lt;HttpHost&gt; httpHostList = new ArrayList&lt;&gt;(ipPortArr.length);        for (String ipPort : ipPortArr) &#123;            String[] ipPortInfo = ipPort.split(&quot;:&quot;);            if (ipPortInfo.length == 2) &#123;                HttpHost httpHost = new HttpHost(ipPortInfo[0], NumberUtils.toInt(ipPortInfo[1]));                httpHostList.add(httpHost);            &#125;        &#125;        HttpHost[] httpHosts = new HttpHost[httpHostList.size()];        httpHostList.toArray(httpHosts);        RestClientBuilder builder = RestClient.builder(httpHosts);        RestHighLevelClient restHighLevelClient = new RestHighLevelClient(builder);        return restHighLevelClient;    &#125;\t//返回集群名称对应的RestHighLevelClient    private static RestHighLevelClient getClient(String clusterName) &#123;        return clientMap.get(clusterName);    &#125;\t//新增文档    public static boolean insertDoc(EsIndexInfo esIndexInfo, EsSourceData esSourceData) &#123;        try &#123;            IndexRequest indexRequest = new IndexRequest(esIndexInfo.getIndexName());            indexRequest.source(esSourceData.getData());            indexRequest.id(esSourceData.getDocId());            getClient(esIndexInfo.getClusterName()).index(indexRequest, COMMON_OPTIONS);            return true;        &#125; catch (Exception e) &#123;            log.error(&quot;insertDoc.exception:&#123;&#125;&quot;, e.getMessage(), e);        &#125;        return false;    &#125;    public static boolean updateDoc(EsIndexInfo esIndexInfo, EsSourceData esSourceData) &#123;        try &#123;            UpdateRequest updateRequest = new UpdateRequest();            updateRequest.index(esIndexInfo.getIndexName());            updateRequest.id(esSourceData.getDocId());            updateRequest.doc(esSourceData.getData());            getClient(esIndexInfo.getClusterName()).update(updateRequest, COMMON_OPTIONS);            return true;        &#125; catch (Exception e) &#123;            log.error(&quot;updateDoc.exception:&#123;&#125;&quot;, e.getMessage(), e);        &#125;        return false;    &#125;    public static boolean batchUpdateDoc(EsIndexInfo esIndexInfo,                                         List&lt;EsSourceData&gt; esSourceDataList) &#123;        try &#123;            boolean flag = false;            BulkRequest bulkRequest = new BulkRequest();            for (EsSourceData esSourceData : esSourceDataList) &#123;                String docId = esSourceData.getDocId();                if (StringUtils.isNotBlank(docId)) &#123;                    UpdateRequest updateRequest = new UpdateRequest();                    updateRequest.index(esIndexInfo.getIndexName());                    updateRequest.id(esSourceData.getDocId());                    updateRequest.doc(esSourceData.getData());                    bulkRequest.add(updateRequest);                    flag = true;                &#125;            &#125;            if (flag) &#123;                BulkResponse bulk = getClient(esIndexInfo.getClusterName()).bulk(bulkRequest, COMMON_OPTIONS);                if (bulk.hasFailures()) &#123;                    return false;                &#125;            &#125;            return true;        &#125; catch (Exception e) &#123;            log.error(&quot;batchUpdateDoc.exception:&#123;&#125;&quot;, e.getMessage(), e);        &#125;        return false;    &#125;    public static boolean delete(EsIndexInfo esIndexInfo) &#123;        try &#123;            DeleteByQueryRequest deleteByQueryRequest =                    new DeleteByQueryRequest(esIndexInfo.getIndexName());            deleteByQueryRequest.setQuery(QueryBuilders.matchAllQuery());            BulkByScrollResponse response = getClient(esIndexInfo.getClusterName()).deleteByQuery(                    deleteByQueryRequest, COMMON_OPTIONS            );            long deleted = response.getDeleted();            log.info(&quot;deleted.size:&#123;&#125;&quot;, deleted);            return true;        &#125; catch (Exception e) &#123;            log.error(&quot;delete.exception:&#123;&#125;&quot;, e.getMessage(), e);        &#125;        return false;    &#125;    public static boolean deleteDoc(EsIndexInfo esIndexInfo, String docId) &#123;        try &#123;            DeleteRequest deleteRequest = new DeleteRequest(esIndexInfo.getIndexName());            deleteRequest.id(docId);            DeleteResponse response = getClient(esIndexInfo.getClusterName()).delete(deleteRequest, COMMON_OPTIONS);            log.info(&quot;deleteDoc.response:&#123;&#125;&quot;, JSON.toJSONString(response));            return true;        &#125; catch (Exception e) &#123;            log.error(&quot;deleteDoc.exception:&#123;&#125;&quot;, e.getMessage(), e);        &#125;        return false;    &#125;    public static boolean isExistDocById(EsIndexInfo esIndexInfo, String docId) &#123;        try &#123;            GetRequest getRequest = new GetRequest(esIndexInfo.getIndexName());            getRequest.id(docId);            return getClient(esIndexInfo.getClusterName()).exists(getRequest, COMMON_OPTIONS);        &#125; catch (Exception e) &#123;            log.error(&quot;isExistDocById.exception:&#123;&#125;&quot;, e.getMessage(), e);        &#125;        return false;    &#125;    public static Map&lt;String, Object&gt; getDocById(EsIndexInfo esIndexInfo, String docId) &#123;        try &#123;            GetRequest getRequest = new GetRequest(esIndexInfo.getIndexName());            getRequest.id(docId);            GetResponse response = getClient(esIndexInfo.getClusterName()).get(getRequest, COMMON_OPTIONS);            Map&lt;String, Object&gt; source = response.getSource();            return source;        &#125; catch (Exception e) &#123;            log.error(&quot;isExistDocById.exception:&#123;&#125;&quot;, e.getMessage(), e);        &#125;        return null;    &#125;    public static Map&lt;String, Object&gt; getDocById(EsIndexInfo esIndexInfo, String docId,                                                 String[] fields) &#123;        try &#123;            GetRequest getRequest = new GetRequest(esIndexInfo.getIndexName());            getRequest.id(docId);            FetchSourceContext fetchSourceContext = new FetchSourceContext(true, fields, null);            getRequest.fetchSourceContext(fetchSourceContext);            GetResponse response = getClient(esIndexInfo.getClusterName()).get(getRequest, COMMON_OPTIONS);            Map&lt;String, Object&gt; source = response.getSource();            return source;        &#125; catch (Exception e) &#123;            log.error(&quot;isExistDocById.exception:&#123;&#125;&quot;, e.getMessage(), e);        &#125;        return null;    &#125;\t//执行Elasticsearch搜索，支持复杂的查询条件、字段选择、高亮显示、排序和滚动搜索。    public static SearchResponse searchWithTermQuery(EsIndexInfo esIndexInfo,                                                     EsSearchRequest esSearchRequest) &#123;        try &#123;            BoolQueryBuilder bq = esSearchRequest.getBq();            String[] fields = esSearchRequest.getFields();            int from = esSearchRequest.getFrom();            int size = esSearchRequest.getSize();            Long minutes = esSearchRequest.getMinutes();            Boolean needScroll = esSearchRequest.getNeedScroll();            String sortName = esSearchRequest.getSortName();            SortOrder sortOrder = esSearchRequest.getSortOrder();            SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();            searchSourceBuilder.query(bq);            searchSourceBuilder.fetchSource(fields, null).from(from).size(size);            if (Objects.nonNull(esSearchRequest.getHighlightBuilder())) &#123;                searchSourceBuilder.highlighter(esSearchRequest.getHighlightBuilder());            &#125;            if (StringUtils.isNotBlank(sortName)) &#123;                searchSourceBuilder.sort(sortName);            &#125;            searchSourceBuilder.sort(new ScoreSortBuilder().order(SortOrder.DESC));            SearchRequest searchRequest = new SearchRequest();            searchRequest.searchType(SearchType.DEFAULT);            searchRequest.indices(esIndexInfo.getIndexName());            searchRequest.source(searchSourceBuilder);            if (needScroll) &#123;                Scroll scroll = new Scroll(TimeValue.timeValueMinutes(minutes));                searchRequest.scroll(scroll);            &#125;            SearchResponse search = getClient(esIndexInfo.getClusterName()).search(searchRequest, COMMON_OPTIONS);            return search;        &#125; catch (Exception e) &#123;            log.error(&quot;searchWithTermQuery.exception:&#123;&#125;&quot;, e.getMessage(), e);        &#125;        return null;    &#125;    public static boolean batchInsertDoc(EsIndexInfo esIndexInfo, List&lt;EsSourceData&gt; esSourceDataList) &#123;        if (log.isInfoEnabled()) &#123;            log.info(&quot;批量新增ES:&quot; + esSourceDataList.size());            log.info(&quot;indexName:&quot; + esIndexInfo.getIndexName());        &#125;        try &#123;            boolean flag = false;            BulkRequest bulkRequest = new BulkRequest();            for (EsSourceData source : esSourceDataList) &#123;                String docId = source.getDocId();                if (StringUtils.isNotBlank(docId)) &#123;                    IndexRequest indexRequest = new IndexRequest(esIndexInfo.getIndexName());                    indexRequest.id(docId);                    indexRequest.source(source.getData());                    bulkRequest.add(indexRequest);                    flag = true;                &#125;            &#125;            if (flag) &#123;                BulkResponse response = getClient(esIndexInfo.getClusterName()).bulk(bulkRequest, COMMON_OPTIONS);                if (response.hasFailures()) &#123;                    return false;                &#125;            &#125;        &#125; catch (Exception e) &#123;            log.error(&quot;batchInsertDoc.error&quot;, e);        &#125;        return true;    &#125;    public static boolean updateByQuery(EsIndexInfo esIndexInfo, QueryBuilder queryBuilder, Script script, int batchSize) &#123;        if (log.isInfoEnabled()) &#123;            log.info(&quot;updateByQuery.indexName:&quot; + esIndexInfo.getIndexName());        &#125;        try &#123;            UpdateByQueryRequest updateByQueryRequest = new UpdateByQueryRequest(esIndexInfo.getIndexName());            updateByQueryRequest.setQuery(queryBuilder);            updateByQueryRequest.setScript(script);            updateByQueryRequest.setBatchSize(batchSize);            updateByQueryRequest.setAbortOnVersionConflict(false);            BulkByScrollResponse response = getClient(esIndexInfo.getClusterName()).updateByQuery(updateByQueryRequest, RequestOptions.DEFAULT);            List&lt;BulkItemResponse.Failure&gt; failures = response.getBulkFailures();        &#125; catch (Exception e) &#123;            log.error(&quot;updateByQuery.error&quot;, e);        &#125;        return true;    &#125;    /**     * 分词方法     */    public static List&lt;String&gt; getAnalyze(EsIndexInfo esIndexInfo, String text) throws Exception &#123;        List&lt;String&gt; list = new ArrayList&lt;String&gt;();        Request request = new Request(&quot;GET&quot;, &quot;_analyze&quot;);        JSONObject entity = new JSONObject();        entity.put(&quot;analyzer&quot;, &quot;ik_smart&quot;);        entity.put(&quot;text&quot;, text);        request.setJsonEntity(entity.toJSONString());        Response response = getClient(esIndexInfo.getClusterName()).getLowLevelClient().performRequest(request);        JSONObject tokens = JSONObject.parseObject(EntityUtils.toString(response.getEntity()));        JSONArray arrays = tokens.getJSONArray(&quot;tokens&quot;);        for (int i = 0; i &lt; arrays.size(); i++) &#123;            JSONObject obj = JSON.parseObject(arrays.getString(i));            list.add(obj.getString(&quot;token&quot;));        &#125;        return list;    &#125;&#125;\n\n新增题目同步到es+带高亮的网站全文搜索subject-infra的SubjectInfoEs.java\n@Datapublic class SubjectInfoEs extends PageInfo implements Serializable &#123;    private Long subjectId;    private Long docId;    private String subjectName;    private String subjectAnswer;    private String createUser;    private Long createTime;    private Integer subjectType;    private String keyWord;\t//相关性的分数，搜索的结果    private BigDecimal score;&#125;\n\nsubject-infra的EsSubjectFields.java\n负责与Elasticsearch（ES）的交互，包括数据的插入和查询。\npublic class EsSubjectFields &#123;    public static final String DOC_ID = &quot;doc_id&quot;;    public static final String SUBJECT_ID = &quot;subject_id&quot;;    public static final String SUBJECT_NAME = &quot;subject_name&quot;;    public static final String SUBJECT_ANSWER = &quot;subject_answer&quot;;    public static final String SUBJECT_TYPE = &quot;subject_type&quot;;    public static final String CREATE_USER = &quot;create_user&quot;;    public static final String CREATE_TIME = &quot;create_time&quot;;    public static final String[] FIELD_QUERY = &#123;            SUBJECT_ID, SUBJECT_NAME, SUBJECT_ANSWER, SUBJECT_TYPE, DOC_ID, CREATE_USER, CREATE_TIME    &#125;;&#125;\n\nsubject-infra的SubjectEsService.java\npublic interface SubjectEsService &#123;    boolean insert(SubjectInfoEs subjectInfoEs);\t//做一个分页的    PageResult&lt;SubjectInfoEs&gt; querySubjectList(SubjectInfoEs subjectInfoEs);&#125;\n\nSubjectEsServiceImpl.java\n\n插入方法：insert方法实现了将SubjectInfoEs对象转换为ES的文档并插入到ES中。它首先调用convert2EsSourceData方法将SubjectInfoEs对象转换为ES的源数据格式，然后使用EsRestClient的insertDoc方法执行插入操作。\n转换方法：convert2EsSourceData是一个私有方法，用于将SubjectInfoEs对象的属性转换为一个Map，这个Map将作为ES文档的数据部分。\n查询方法：querySubjectList方法实现了分页查询ES中的数据。它首先创建一个EsSearchRequest查询请求，然后使用EsRestClient的searchWithTermQuery方法执行查询，并将结果转换为PageResult&lt;SubjectInfoEs&gt;对象。\n结果转换方法：convertResult是一个私有方法，用于将ES查询结果的SearchHit转换为SubjectInfoEs对象。它还处理了高亮显示查询关键字的功能。\n查询构建方法：createSearchListQuery是一个私有方法，用于构建查询请求。它使用BoolQueryBuilder来构建查询条件，并设置了高亮显示的配置。\n获取ES索引信息方法：getEsIndexInfo是一个私有方法，用于获取ES的索引信息，包括集群名称和索引名称。\n\n@Service@Slf4jpublic class SubjectEsServiceImpl implements SubjectEsService &#123;    @Override    public boolean insert(SubjectInfoEs subjectInfoEs) &#123;        EsSourceData esSourceData = new EsSourceData();        Map&lt;String, Object&gt; data = convert2EsSourceData(subjectInfoEs);        esSourceData.setDocId(subjectInfoEs.getDocId().toString());        esSourceData.setData(data);        return EsRestClient.insertDoc(getEsIndexInfo(), esSourceData);    &#125;    private Map&lt;String, Object&gt; convert2EsSourceData(SubjectInfoEs subjectInfoEs) &#123;        Map&lt;String, Object&gt; data = new HashMap&lt;&gt;();        data.put(EsSubjectFields.SUBJECT_ID, subjectInfoEs.getSubjectId());        data.put(EsSubjectFields.DOC_ID, subjectInfoEs.getDocId());        data.put(EsSubjectFields.SUBJECT_NAME, subjectInfoEs.getSubjectName());        data.put(EsSubjectFields.SUBJECT_ANSWER, subjectInfoEs.getSubjectAnswer());        data.put(EsSubjectFields.SUBJECT_TYPE, subjectInfoEs.getSubjectType());        data.put(EsSubjectFields.CREATE_USER, subjectInfoEs.getCreateUser());        data.put(EsSubjectFields.CREATE_TIME, subjectInfoEs.getCreateTime());        return data;    &#125;\t//带高亮的网站全文搜索    @Override    public PageResult&lt;SubjectInfoEs&gt; querySubjectList(SubjectInfoEs req) &#123;        PageResult&lt;SubjectInfoEs&gt; pageResult = new PageResult&lt;&gt;();        EsSearchRequest esSearchRequest = createSearchListQuery(req);        SearchResponse searchResponse = EsRestClient.searchWithTermQuery(getEsIndexInfo(), esSearchRequest);        List&lt;SubjectInfoEs&gt; subjectInfoEsList = new LinkedList&lt;&gt;();        SearchHits searchHits = searchResponse.getHits();        if (searchHits == null || searchHits.getHits() == null) &#123;            pageResult.setPageNo(req.getPageNo());            pageResult.setPageSize(req.getPageSize());            pageResult.setRecords(subjectInfoEsList);            pageResult.setTotal(0);            return pageResult;        &#125;        SearchHit[] hits = searchHits.getHits();        for (SearchHit hit : hits) &#123;            SubjectInfoEs subjectInfoEs = convertResult(hit);            if (Objects.nonNull(subjectInfoEs)) &#123;                subjectInfoEsList.add(subjectInfoEs);            &#125;        &#125;        pageResult.setPageNo(req.getPageNo());        pageResult.setPageSize(req.getPageSize());        pageResult.setRecords(subjectInfoEsList);        pageResult.setTotal(Long.valueOf(searchHits.getTotalHits().value).intValue());        return pageResult;    &#125;    /** * 将Elasticsearch搜索结果的SearchHit对象转换为SubjectInfoEs对象。 * @param hit Elasticsearch返回的搜索结果条目。 * @return 转换后的SubjectInfoEs对象，如果结果为空则返回null。 */private SubjectInfoEs convertResult(SearchHit hit) &#123;    // 获取搜索结果的源数据映射。    Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap();    // 如果源数据映射为空，则返回null。    if (CollectionUtils.isEmpty(sourceAsMap)) &#123;        return null;    &#125;        // 创建SubjectInfoEs对象用于存储转换结果。    SubjectInfoEs result = new SubjectInfoEs();        // 从源数据映射中获取题目ID，并设置到result对象。    result.setSubjectId(MapUtils.getLong(sourceAsMap, EsSubjectFields.SUBJECT_ID));    // 从源数据映射中获取题目名称，并设置到result对象。    result.setSubjectName(MapUtils.getString(sourceAsMap, EsSubjectFields.SUBJECT_NAME));    // 从源数据映射中获取题目答案，并设置到result对象。    result.setSubjectAnswer(MapUtils.getString(sourceAsMap, EsSubjectFields.SUBJECT_ANSWER));    // 从源数据映射中获取文档ID，并设置到result对象。    result.setDocId(MapUtils.getLong(sourceAsMap, EsSubjectFields.DOC_ID));    // 从源数据映射中获取题目类型，并设置到result对象。    result.setSubjectType(MapUtils.getInteger(sourceAsMap, EsSubjectFields.SUBJECT_TYPE));        // 获取搜索结果的相关性分数，并转换为百分比形式，设置到result对象。    result.setScore(new BigDecimal(String.valueOf(hit.getScore()))            .multiply(new BigDecimal(&quot;100.00&quot;).setScale(2, RoundingMode.HALF_UP)));    // 获取高亮字段，处理题目名称的高亮显示。    Map&lt;String, HighlightField&gt; highlightFields = hit.getHighlightFields();    HighlightField subjectNameField = highlightFields.get(EsSubjectFields.SUBJECT_NAME);    if (Objects.nonNull(subjectNameField)) &#123;        // 获取题目名称的高亮片段。        Text[] fragments = subjectNameField.getFragments();        StringBuilder subjectNameBuilder = new StringBuilder();        for (Text fragment : fragments) &#123;            // 拼接高亮片段。            subjectNameBuilder.append(fragment);        &#125;        // 设置处理后的高亮题目名称。        result.setSubjectName(subjectNameBuilder.toString());    &#125;    // 处理题目答案的高亮显示。    HighlightField subjectAnswerField = highlightFields.get(EsSubjectFields.SUBJECT_ANSWER);    if (Objects.nonNull(subjectAnswerField)) &#123;        Text[] fragments = subjectAnswerField.getFragments();        StringBuilder subjectAnswerBuilder = new StringBuilder();        for (Text fragment : fragments) &#123;            subjectAnswerBuilder.append(fragment);        &#125;        // 设置处理后的高亮题目答案。        result.setSubjectAnswer(subjectAnswerBuilder.toString());    &#125;    // 返回填充好的SubjectInfoEs对象。    return result;&#125;    /** * 创建一个用于查询题目列表的EsSearchRequest对象。 * @param req 包含查询条件的SubjectInfoEs对象。 * @return 配置好的EsSearchRequest对象。 */private EsSearchRequest createSearchListQuery(SubjectInfoEs req) &#123;    // 创建EsSearchRequest对象用于存储搜索请求的配置。    EsSearchRequest esSearchRequest = new EsSearchRequest();        // 创建一个布尔查询构造器，用于组合多个查询条件。    BoolQueryBuilder bq = new BoolQueryBuilder();        // 创建一个匹配查询构造器，用于匹配题目名称字段。    MatchQueryBuilder subjectNameQueryBuilder =            QueryBuilders.matchQuery(EsSubjectFields.SUBJECT_NAME, req.getKeyWord());        // 将题目名称的匹配查询添加到布尔查询中，并设置提升因子为2，以提高相关性。    bq.should(subjectNameQueryBuilder);    subjectNameQueryBuilder.boost(2);        // 创建一个匹配查询构造器，用于匹配题目答案字段。    MatchQueryBuilder subjectAnswerQueryBuilder =            QueryBuilders.matchQuery(EsSubjectFields.SUBJECT_ANSWER, req.getKeyWord());        // 将题目答案的匹配查询添加到布尔查询中。    bq.should(subjectAnswerQueryBuilder);        // 创建一个匹配查询构造器，用于匹配题目类型字段，必须是简答题类型。    MatchQueryBuilder subjectTypeQueryBuilder =            QueryBuilders.matchQuery(EsSubjectFields.SUBJECT_TYPE, SubjectInfoTypeEnum.BRIEF.getCode());        // 必须匹配题目类型的查询添加到布尔查询中。    bq.must(subjectTypeQueryBuilder);        // 设置至少应该匹配的should子句的数量为1。    bq.minimumShouldMatch(1);        // 创建高亮显示构造器，设置高亮显示的前缀和后缀标签。    HighlightBuilder highlightBuilder = new HighlightBuilder().field(&quot;*&quot;).requireFieldMatch(false);    highlightBuilder.preTags(&quot;&lt;span style = \\&quot;color:red\\&quot;&gt;&quot;);    highlightBuilder.postTags(&quot;&lt;/span&gt;&quot;);        // 设置EsSearchRequest对象的布尔查询构造器。    esSearchRequest.setBq(bq);    // 设置高亮显示构造器。    esSearchRequest.setHighlightBuilder(highlightBuilder);    // 设置需要返回的字段。    esSearchRequest.setFields(EsSubjectFields.FIELD_QUERY);    // 设置从第几个文档开始返回结果，用于分页。    esSearchRequest.setFrom((req.getPageNo() - 1) * req.getPageSize());    // 设置每页返回的文档数量。    esSearchRequest.setSize(req.getPageSize());    // 设置不需要滚动搜索。    esSearchRequest.setNeedScroll(false);        // 返回配置好的搜索请求对象。    return esSearchRequest;&#125;    private EsIndexInfo getEsIndexInfo() &#123;        EsIndexInfo esIndexInfo = new EsIndexInfo();        esIndexInfo.setClusterName(&quot;73438a827b55&quot;);        esIndexInfo.setIndexName(&quot;subject_index&quot;);        return esIndexInfo;    &#125;&#125;\n\nSubjectInfoDomainServiceImpl.java\n@Override@Transactional(rollbackFor = Exception.class)public void add(SubjectInfoBO subjectInfoBO) &#123;    ......    //同步到es    SubjectInfoEs subjectInfoEs = new SubjectInfoEs();    subjectInfoEs.setDocId(new IdWorkerUtil(1, 1, 1).nextId());    subjectInfoEs.setSubjectId(subjectInfo.getId());    subjectInfoEs.setSubjectAnswer(subjectInfoBO.getSubjectAnswer());    subjectInfoEs.setCreateTime(new Date().getTime());    subjectInfoEs.setCreateUser(&quot;lzrj&quot;);    subjectInfoEs.setSubjectName(subjectInfo.getSubjectName());    subjectInfoEs.setSubjectType(subjectInfo.getSubjectType());    subjectEsService.insert(subjectInfoEs);   &#125;\n\nSubjectController.java\n/** * 全文检索 */@PostMapping(&quot;/getSubjectPageBySearch&quot;)public Result&lt;PageResult&lt;SubjectInfoEs&gt;&gt; getSubjectPageBySearch(@RequestBody SubjectInfoDTO subjectInfoDTO) &#123;    try &#123;        if (log.isInfoEnabled()) &#123;            log.info(&quot;SubjectController.getSubjectPageBySearch.dto:&#123;&#125;&quot;, JSON.toJSONString(subjectInfoDTO));        &#125;        Preconditions.checkArgument(StringUtils.isNotBlank(subjectInfoDTO.getKeyWord()), &quot;关键词不能为空&quot;);        SubjectInfoBO subjectInfoBO = SubjectInfoDTOConverter.INSTANCE.convertDTOToBO(subjectInfoDTO);        subjectInfoBO.setPageNo(subjectInfoDTO.getPageNo());        subjectInfoBO.setPageSize(subjectInfoDTO.getPageSize());        PageResult&lt;SubjectInfoEs&gt; boPageResult = subjectInfoDomainService.getSubjectPageBySearch(subjectInfoBO);        return Result.ok(boPageResult);    &#125; catch (Exception e) &#123;        log.error(&quot;SubjectCategoryController.getSubjectPageBySearch.error:&#123;&#125;&quot;, e.getMessage(), e);        return Result.fail(&quot;全文检索失败&quot;);    &#125;&#125;\n\nSubjectInfoDomainServiceImpl.java\n@Overridepublic PageResult&lt;SubjectInfoEs&gt; getSubjectPageBySearch(SubjectInfoBO subjectInfoBO) &#123;    SubjectInfoEs subjectInfoEs = new SubjectInfoEs();    subjectInfoEs.setPageNo(subjectInfoBO.getPageNo());    subjectInfoEs.setPageSize(subjectInfoBO.getPageSize());    subjectInfoEs.setKeyWord(subjectInfoBO.getKeyWord());    return subjectEsService.querySubjectList(subjectInfoEs);&#125;\n\n手写Mybatis拦截器自动填充数据(方法级别拦截器)LoginContextHolder和LoginUtil都放在common层里\n/** * 填充createBy, createTime等公共字段的拦截器 */@Component@Slf4j// 声明拦截器，指定要拦截的Executor类中的update方法，以及该方法的参数类型@Intercepts(&#123;    @Signature(type = Executor.class, method = &quot;update&quot;, args = &#123;MappedStatement.class, Object.class&#125;)&#125;)public class MybatisInterceptor implements Interceptor &#123;    @Override    public Object intercept(Invocation invocation) throws Throwable &#123;        // 获取拦截方法的参数        MappedStatement mappedStatement = (MappedStatement) invocation.getArgs()[0];        SqlCommandType sqlCommandType = mappedStatement.getSqlCommandType();        Object parameter = invocation.getArgs()[1];                // 如果参数为空，直接执行原方法        if (parameter == null) &#123;            return invocation.proceed();        &#125;                // 获取当前登录用户的id        String loginId = LoginUtil.getLoginId();        // 如果没有登录用户，直接执行原方法        if (StringUtils.isBlank(loginId)) &#123;            return invocation.proceed();        &#125;                // 根据SqlCommandType是INSERT或UPDATE，调用不同的处理方法        if (SqlCommandType.INSERT == sqlCommandType || SqlCommandType.UPDATE == sqlCommandType) &#123;            replaceEntityProperty(parameter, loginId, sqlCommandType);        &#125;                // 执行原方法        return invocation.proceed();    &#125;    /**     * 根据不同的参数类型，调用不同的属性替换方法     * @param parameter 拦截方法的参数对象     * @param loginId 当前登录用户的id     * @param sqlCommandType SQL命令类型     */    private void replaceEntityProperty(Object parameter, String loginId, SqlCommandType sqlCommandType) &#123;        if (parameter instanceof Map) &#123;            replaceMap((Map) parameter, loginId, sqlCommandType);        &#125; else &#123;            replace(parameter, loginId, sqlCommandType);        &#125;    &#125;    /**     * 处理Map类型的参数     * @param parameter Map参数     * @param loginId 登录用户的id     * @param sqlCommandType SQL命令类型     */    private void replaceMap(Map parameter, String loginId, SqlCommandType sqlCommandType) &#123;        for (Object val : parameter.values()) &#123;            replace(val, loginId, sqlCommandType);        &#125;    &#125;    /**     * 处理普通对象或集合类型的参数     * @param parameter 参数对象     * @param loginId 登录用户的id     * @param sqlCommandType SQL命令类型     */    private void replace(Object parameter, String loginId, SqlCommandType sqlCommandType) &#123;    if (SqlCommandType.INSERT == sqlCommandType) &#123;        dealInsert(parameter, loginId);    &#125; else &#123;        dealUpdate(parameter, loginId);    &#125;  &#125;  /**   * 处理UPDATE操作的字段替换   * @param parameter 参数对象   * @param loginId 登录用户的id   */  private void dealUpdate(Object parameter, String loginId) &#123;    // 获取所有字段，包括继承的字段    Field[] fields = getAllFields(parameter);    for (Field field : fields) &#123;      try &#123;        field.setAccessible(true);        // 如果字段已经有值，则跳过        Object o = field.get(parameter);        if (Objects.nonNull(o)) &#123;          field.setAccessible(false);          continue;        &#125;        // 根据字段名设置不同的值        if (&quot;updateBy&quot;.equals(field.getName())) &#123;          field.set(parameter, loginId);        &#125; else if (&quot;updateTime&quot;.equals(field.getName())) &#123;          field.set(parameter, new Date());        &#125; else &#123;          // 其他字段不处理        &#125;        field.setAccessible(false);      &#125; catch (Exception e) &#123;        log.error(&quot;dealUpdate.error:&#123;&#125;&quot;, e.getMessage(), e);      &#125;    &#125;  &#125;  /**   * 处理INSERT操作的字段替换   * @param parameter 参数对象   * @param loginId 登录用户的id   */  private void dealInsert(Object parameter, String loginId) &#123;    // 获取所有字段，包括继承的字段    Field[] fields = getAllFields(parameter);    for (Field field : fields) &#123;      try &#123;        field.setAccessible(true);        // 如果字段已经有值，则跳过        Object o = field.get(parameter);        if (Objects.nonNull(o)) &#123;          field.setAccessible(false);          continue;        &#125;        // 根据字段名设置不同的值        if (&quot;isDeleted&quot;.equals(field.getName())) &#123;          field.set(parameter, 0);        &#125; else if (&quot;createdBy&quot;.equals(field.getName())) &#123;          field.set(parameter, loginId);        &#125; else if (&quot;createdTime&quot;.equals(field.getName())) &#123;          field.set(parameter, new Date());        &#125; else &#123;          // 其他字段不处理        &#125;        field.setAccessible(false);      &#125; catch (Exception e) &#123;        log.error(&quot;dealInsert.error:&#123;&#125;&quot;, e.getMessage(), e);      &#125;    &#125;  &#125;  /**   * 递归获取对象所有字段，包括父类的字段   * @param object 对象   * @return 字段数组   */  private Field[] getAllFields(Object object) &#123;    Class&lt;?&gt; clazz = object.getClass();    List&lt;Field&gt; fieldList = new ArrayList&lt;&gt;();    while (clazz != null) &#123;      // 添加当前类的所有字段到列表      fieldList.addAll(new ArrayList&lt;&gt;(Arrays.asList(clazz.getDeclaredFields())));      clazz = clazz.getSuperclass();    &#125;    // 转换列表为数组    Field[] fields = new Field[fieldList.size()];    fieldList.toArray(fields);    return fields;  &#125;  // MyBatis插件接口方法，实际使用时会增强目标对象  @Override  public Object plugin(Object target) &#123;    return Plugin.wrap(target, this);  &#125;  // 用于接收MyBatis传入的属性，一般不使用  @Override  public void setProperties(Properties properties) &#123;  &#125;&#125;\n\n题目排行榜功能设计排行榜一般来说实时的，非实时的。\n实时的方案\n\n数据库统计\n\n现在数据库里面的 createby 字段。用户的标识是唯一的，那我直接通过 group by 的形式统计 count。\nselect count(1),create_by from subject_info group by create_by limit 0,5;\n数据量比较小，并发也比较小。这种方案是 ok 的。保证可以走到索引，返回速度快，不要产生慢 sql。\n在数据库层面加一层缓存，接受一定的延时性。\n\nredis 的 sorted set\n有序集合，不允许重复的成员，然后每一个 key 都会包含一个 score 分数的概念。redis 根据分数可以帮助我们做从小到大，和从大到小的一个处理。\n有序集合的 key 不可重复，score 重复。\n它通过我们的一个哈希表来实现的，添加，删除，查找，复杂度 o(1) ，最大数量是 2的32 次方-1。\nzaddzrangezincrbyzscore\n\n这种的好处在于，完全不用和数据库做任何的交互，纯纯的通过缓存来做，速度非常快，要避免一些大 key 的问题。\n\n\n非实时\n定时任务 xxl-job\n统计数据库的数据形式，帮助我们统计完成后，直接写入缓存。缓存的外部的交互展示。\n传统数据库实现排行榜SubjectController.java\n/** * 获取题目贡献榜 */@PostMapping(&quot;/getContributeList&quot;)public Result&lt;List&lt;SubjectInfoDTO&gt;&gt; getContributeList() &#123;    try &#123;        List&lt;SubjectInfoBO&gt; boList = subjectInfoDomainService.getContributeList();        List&lt;SubjectInfoDTO&gt; dtoList = SubjectInfoDTOConverter.INSTANCE.convertBOToDTOList(boList);        return Result.ok(dtoList);    &#125; catch (Exception e) &#123;        log.error(&quot;SubjectCategoryController.getContributeList.error:&#123;&#125;&quot;, e.getMessage(), e);        return Result.fail(&quot;获取贡献榜失败&quot;);    &#125;&#125;\n\nSubjectDomainInfoServiceImpl.java\n@Overridepublic List&lt;SubjectInfoBO&gt; getContributeList() &#123;    List&lt;SubjectInfo&gt; subjectInfoList = subjectInfoService.getContributeCount();    if (CollectionUtils.isEmpty(subjectInfoList)) &#123;        return Collections.emptyList();    &#125;    List&lt;SubjectInfoBO&gt; boList = new LinkedList&lt;&gt;();    subjectInfoList.forEach((subjectInfo -&gt; &#123;        SubjectInfoBO subjectInfoBO = new SubjectInfoBO();        subjectInfoBO.setSubjectCount(subjectInfo.getSubjectCount());        //这里用到了UserRpc        UserInfo userInfo = userRpc.getUserInfo(subjectInfo.getCreatedBy());        subjectInfoBO.setCreateUser(userInfo.getNickName());        subjectInfoBO.setCreateUserAvatar(userInfo.getAvatar());        boList.add(subjectInfoBO);    &#125;));    return boList;&#125;\n\nUserRpc.java\n@Componentpublic class UserRpc &#123;    @Resource    private UserFeignService userFeignService;    public UserInfo getUserInfo(String userName) &#123;        AuthUserDTO authUserDTO = new AuthUserDTO();        authUserDTO.setUserName(userName);        Result&lt;AuthUserDTO&gt; result = userFeignService.getUserInfo(authUserDTO);        UserInfo userInfo = new UserInfo();        if (!result.getSuccess()) &#123;            return userInfo;        &#125;        AuthUserDTO data = result.getData();        userInfo.setUserName(data.getUserName());        userInfo.setNickName(data.getNickName());        //新增 设置头像        userInfo.setAvatar(data.getAvatar());        return userInfo;    &#125;&#125;\n\nsubjectInfoServiceImpl.java\n@Overridepublic List&lt;SubjectInfo&gt; getContributeCount() &#123;    return this.subjectInfoDao.getContributeCount();&#125;\n\nSubjectInfoDao.xml\n&lt;select id=&quot;getContributeCount&quot; resultType=&quot;com.jingdianjichi.subject.infra.basic.entity.SubjectInfo&quot;&gt;    select count(1) as subjectCount,           created_by as createdBy    from subject_info    where is_deleted = 0    and created_by is not null    group by created_by    limit 0,5&lt;/select&gt;\n\n基于redis的zset实现排行榜subject-domain/pom.xml\n&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;    &lt;version&gt;2.4.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;    &lt;artifactId&gt;jackson-core&lt;/artifactId&gt;    &lt;version&gt;2.12.7&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;    &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;    &lt;version&gt;2.12.7&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;    &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;    &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt;\n\nsubject-doamin/RedisUtil.java\npublic Set&lt;ZSetOperations.TypedTuple&lt;String&gt;&gt; rankWithScore(String key, long start, long end) &#123;    Set&lt;ZSetOperations.TypedTuple&lt;String&gt;&gt; set = redisTemplate.opsForZSet().reverseRangeWithScores(key, start, end);    return set;&#125;\n\nredis——Zset有序集合之reverseRangeWithScore函数使用_reverserangewithscores-CSDN博客\nSubjectInfoDomainServiceImpl.java\n排行榜接口\nprivate static final String RANK_KEY = &quot;subject_rank&quot;;@Overridepublic List&lt;SubjectInfoBO&gt; getContributeList() &#123;    Set&lt;ZSetOperations.TypedTuple&lt;String&gt;&gt; typedTuples = redisUtil.rankWithScore(RANK_KEY, 0, 5);    if (log.isInfoEnabled()) &#123;        log.info(&quot;getContributeList.typedTuples:&#123;&#125;&quot;, JSON.toJSONString(typedTuples));    &#125;    if (CollectionUtils.isEmpty(typedTuples)) &#123;        return Collections.emptyList();    &#125;    List&lt;SubjectInfoBO&gt; boList = new LinkedList&lt;&gt;();    typedTuples.forEach((rank -&gt; &#123;        SubjectInfoBO subjectInfoBO = new SubjectInfoBO();        subjectInfoBO.setSubjectCount(rank.getScore().intValue());        // 这个是openId        UserInfo userInfo = userRpc.getUserInfo(rank.getValue());        subjectInfoBO.setCreateUser(userInfo.getNickName());        subjectInfoBO.setCreateUserAvatar(userInfo.getAvatar());        boList.add(subjectInfoBO);    &#125;));    // 返回一个包含题目信息的list    return boList;&#125;\n\n点赞和收藏点赞和收藏功能设计点赞与收藏的逻辑是非常一样的，我们这里就选取点赞功能来给大家做开发。\n按照我们的程序员 club 的设计，点赞业务其实涉及几个方面：\n\n我们肯定要知道一个题目被多少人点过赞\n还要知道，每个人他点赞了哪些题目。\n\n点赞的业务特性：频繁。用户一多，时时刻刻都在进行点赞啊，收藏啊等等处理，如果说我们采取传统的数据库的模式啊，这个交互量是非常大的，很难去抗住这个并发问题，所以我们采取 redis 的方式来做。\n查询的数据交互，我们可以和 redis 直接来做，持久化的数据，通过数据库查询即可，这个数据如何去同步到数据库，我们就采取的定时任务 xxl-job 定期来刷数据。\n\n记录的时候三个关键信息，点赞的人，被点赞的题目，点赞的状态。\n我们最终的数据结构就是 hash，string 类型。\n\nhash，存到一个键里面，键里是一个 map，他又分为 hashkey 和 hashval。\n谁点赞了哪个题目+状态：hashkey，subjectId:userId，val 就存的是点赞的状态 1 是点赞 0 是不点赞。\n点赞数量：string 类型 key subjectId，val 即使我们的题目被点赞的数量。\n有没有点过赞，key存在说明点过（并非记录状态）：key为string 类型， subjectId:userId。\n\n\n\n表结构：\n\n新增点赞\n直接操作 redis\n存 hash，存数量，存点赞的人与题目的 key。\n取消点赞\n上面的反逻辑，数量会-1，hash 里面的状态会更新，点赞人与题目关联的 key 会被删除\n查询当前题目被点赞的数量\n直接与 redis 交互，读题目的被点赞数量的 key\n查询当前题目被当前用户是否点过赞\n直接查 redis 就可以了。\n我的点赞\n直接查数据库做分页逻辑的展示。\n点赞功能开发RedisUtil.java\n// key可以用来区分这些不同的哈希表。hashKey 则是这些哈希表内部的键public void putHash(String key, String hashKey, Object hashVal) &#123;    redisTemplate.opsForHash().put(key, hashKey, hashVal);&#125;\n\nSubjectLikedDomainServiceImpl.java\n// 定义常量，用于作为Redis中存储主题点赞信息的哈希表的键private static final String SUBJECT_LIKED_KEY = &quot;subject.liked&quot;;// 定义常量，用于作为Redis中存储主题点赞数量的键private static final String SUBJECT_LIKED_COUNT_KEY = &quot;subject.liked.count&quot;;// 定义常量，用于作为Redis中存储主题点赞详细信息的键private static final String SUBJECT_LIKED_DETAIL_KEY = &quot;subject.liked.detail&quot;;/** * 添加点赞信息到Redis。 *  * @param subjectLikedBO 包含点赞操作的业务对象，其中包含主题ID、点赞用户ID和状态。 */public void add(SubjectLikedBO subjectLikedBO) &#123;    // 从业务对象中获取主题ID    Long subjectId = subjectLikedBO.getSubjectId();    // 从业务对象中获取点赞用户的ID    String likeUserId = subjectLikedBO.getLikeUserId();    // 从业务对象中获取点赞状态    Integer status = subjectLikedBO.getStatus();        // 构建用于存储点赞状态的哈希表的字段名    String hashKey = buildSubjectLikedKey(subjectId.toString(), likeUserId);        // 将点赞状态存储到Redis哈希表中    redisUtil.putHash(SUBJECT_LIKED_KEY, hashKey, status);        // 构建存储点赞详细信息的键，格式为 &quot;subject.liked.detail + 主题ID + . + 点赞用户ID&quot;    String detailKey = SUBJECT_LIKED_DETAIL_KEY + &quot;.&quot; + subjectId + &quot;.&quot; + likeUserId;        // 构建存储点赞数量的键，格式为 &quot;subject.liked.count + . + 主题ID&quot;    String countKey = SUBJECT_LIKED_COUNT_KEY + &quot;.&quot; + subjectId;        // 判断点赞状态是否为 &quot;点赞&quot;    if (SubjectLikedStatusEnum.LIKED.getCode() == status) &#123;        // 如果是点赞，增加点赞数量        redisUtil.increment(countKey, 1);        // 存储点赞详细信息，这里假设点赞详细信息只存储为 &quot;1&quot;        redisUtil.set(detailKey, &quot;1&quot;);    &#125; else &#123;        // 如果不是点赞状态，执行以下操作        Integer count = redisUtil.getInt(countKey);        // 如果点赞数量为null或小于等于0，则不执行任何操作        if (Objects.isNull(count) || count &lt;= 0) &#123;            return;        &#125;        // 减少点赞数量        redisUtil.increment(countKey, -1);        // 删除点赞详细信息        redisUtil.del(detailKey);    &#125;&#125;\n\n题目详情增加点赞数据SubjectLikedDomainServiceImpl.java\n@Override    public Boolean isLiked(String subjectId, String userId) &#123;        String detailKey = SUBJECT_LIKED_DETAIL_KEY + &quot;.&quot; + subjectId + &quot;.&quot; + userId;        return redisUtil.exist(detailKey);&#125;@Overridepublic Integer getLikedCount(String subjectId) &#123;    String countKey = SUBJECT_LIKED_COUNT_KEY + &quot;.&quot; + subjectId;    Integer count = redisUtil.getInt(countKey);    if (Objects.isNull(count) || count &lt;= 0) &#123;        return 0;    &#125;    return redisUtil.getInt(countKey);&#125;\n\nSubjectInfoDomainServiceImpl.java\n@Overridepublic SubjectInfoBO querySubjectInfo(SubjectInfoBO subjectInfoBO) &#123;    SubjectInfo subjectInfo = subjectInfoService.queryById(subjectInfoBO.getId());    SubjectTypeHandler handler = subjectTypeHandlerFactory.getHandler(subjectInfo.getSubjectType());    SubjectOptionBO optionBO = handler.query(subjectInfo.getId().intValue());    SubjectInfoBO bo = SubjectInfoConverter.INSTANCE.convertOptionAndInfoToBo(optionBO, subjectInfo);    SubjectMapping subjectMapping = new SubjectMapping();    subjectMapping.setSubjectId(subjectInfo.getId());    subjectMapping.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());    List&lt;SubjectMapping&gt; mappingList = subjectMappingService.queryLabelId(subjectMapping);    List&lt;Long&gt; labelIdList = mappingList.stream().map(SubjectMapping::getLabelId).collect(Collectors.toList());    List&lt;SubjectLabel&gt; labelList = subjectLabelService.batchQueryById(labelIdList);    List&lt;String&gt; labelNameList = labelList.stream().map(SubjectLabel::getLabelName).collect(Collectors.toList());    bo.setLabelName(labelNameList);    bo.setLiked(subjectLikedDomainService.isLiked(subjectInfoBO.getId().toString(), LoginUtil.getLoginId()));    bo.setLikedCount(subjectLikedDomainService.getLikedCount(subjectInfoBO.getId().toString()));    assembleSubjectCursor(subjectInfoBO, bo);    return bo;&#125;\n\nxxljob定时任务完成XXL-JOB 是一个轻量级分布式任务调度平台，其核心设计目标是开发迅速、学习简单、轻量级、易扩展。现已开放源代码并接入多家公司线上产品线，开箱即用。\n\n分布式任务调度平台XXL-JOB (xuxueli.com)\n特性\n\n1、简单：支持通过 Web 页面对任务进行 CRUD 操作，操作简单，一分钟上手；\n2、动态：支持动态修改任务状态、启动 &#x2F; 停止任务，以及终止运行中任务，即时生效；\n3、调度中心 HA（中心式）：调度采用中心式设计，“调度中心” 自研调度组件并支持集群部署，可保证调度中心 HA；\n4、执行器 HA（分布式）：任务分布式执行，任务 “执行器” 支持集群部署，可保证任务执行 HA；\n5、注册中心：执行器会周期性自动注册任务，调度中心将会自动发现注册的任务并触发执行。同时，也支持手动录入执行器地址；\n6、弹性扩容缩容：一旦有新执行器机器上线或者下线，下次调度时将会重新分配任务；\n7、路由策略：执行器集群部署时提供丰富的路由策略，包括：第一个、最后一个、轮询、随机、一致性 HASH、最不经常使用、最近最久未使用、故障转移、忙碌转移等；\n8、故障转移：任务路由策略选择 “故障转移” 情况下，如果执行器集群中某一台机器故障，将会自动 Failover 切换到一台正常的执行器发送调度请求。\n9、阻塞处理策略：调度过于密集执行器来不及处理时的处理策略，策略包括：单机串行（默认）、丢弃后续调度、覆盖之前调度；\n10、任务超时控制：支持自定义任务超时时间，任务运行超时将会主动中断任务；\n11、任务失败重试：支持自定义任务失败重试次数，当任务失败时将会按照预设的失败重试次数主动进行重试；其中分片任务支持分片粒度的失败重试；\n12、任务失败告警；默认提供邮件方式失败告警，同时预留扩展接口，可方便的扩展短信、钉钉等告警方式；\n13、分片广播任务：执行器集群部署时，任务路由策略选择 “分片广播” 情况下，一次任务调度将会广播触发集群中所有执行器执行一次任务，可根据分片参数开发分片任务；\n14、动态分片：分片广播任务以执行器为维度进行分片，支持动态扩容执行器集群从而动态增加分片数量，协同进行业务处理；在进行大数据量业务操作时可显著提升任务处理能力和速度。\n15、事件触发：除了 “Cron 方式” 和 “任务依赖方式” 触发任务执行之外，支持基于事件的触发任务方式。调度中心提供触发任务单次执行的 API 服务，可根据业务事件灵活触发。\n16、任务进度监控：支持实时监控任务进度；\n17、Rolling 实时日志：支持在线查看调度结果，并且支持以 Rolling 方式实时查看执行器输出的完整的执行日志；\n18、GLUE：提供 Web IDE，支持在线开发任务逻辑代码，动态发布，实时编译生效，省略部署上线的过程。支持 30 个版本的历史版本回溯。\n19、脚本任务：支持以 GLUE 模式开发和运行脚本任务，包括 Shell、Python、NodeJS、PHP、PowerShell 等类型脚本；\n20、命令行任务：原生提供通用命令行任务 Handler（Bean 任务，”CommandJobHandler”）；业务方只需要提供命令行即可；\n21、任务依赖：支持配置子任务依赖，当父任务执行结束且执行成功后将会主动触发一次子任务的执行，多个子任务用逗号分隔；\n22、一致性：“调度中心” 通过 DB 锁保证集群分布式调度的一致性，一次任务调度只会触发一次执行；\n23、自定义任务参数：支持在线配置调度任务入参，即时生效；\n24、调度线程池：调度系统多线程触发调度运行，确保调度精确执行，不被堵塞；\n25、数据加密：调度中心和执行器之间的通讯进行数据加密，提升调度信息安全性；\n26、邮件报警：任务失败时支持邮件报警，支持配置多邮件地址群发报警邮件；\n27、推送 maven 中央仓库：将会把最新稳定版推送到 maven 中央仓库，方便用户接入和使用；\n28、运行报表：支持实时查看运行数据，如任务数量、调度次数、执行器数量等；以及调度报表，如调度日期分布图，调度成功分布图等；\n29、全异步：任务调度流程全异步化设计实现，如异步调度、异步运行、异步回调等，有效对密集调度进行流量削峰，理论上支持任意时长任务的运行；\n30、跨语言：调度中心与执行器提供语言无关的 RESTful API 服务，第三方任意语言可据此对接调度中心或者实现执行器。除此之外，还提供了 “多任务模式” 和 “httpJobHandler” 等其他跨语言方案；\n31、国际化：调度中心支持国际化设置，提供中文、英文两种可选语言，默认为中文；\n32、容器化：提供官方 docker 镜像，并实时更新推送 dockerhub，进一步实现产品开箱即用；\n33、线程池隔离：调度线程池进行隔离拆分，慢任务自动降级进入 “Slow” 线程池，避免耗尽调度线程，提高系统稳定性；\n34、用户管理：支持在线管理系统用户，存在管理员、普通用户两种角色；\n35、权限控制：执行器维度进行权限控制，管理员拥有全量权限，普通用户需要分配执行器权限后才允许相关操作；\n\n其实把东西配置好就行\nsubject-starter/application.yaml\nxxl:  job:    admin:      addresses: http://127.0.0.1:8080/xxl-job-admin     accessToken: default_token    executor:      appname: jc-club-subjcet      address:      ip: 127.0.0.1      port: 9999      logpath: /data/applogs/xxl-job/jobhandler      logretentiondays: 30\n\nXxlJobConfig.java\n@Value(&quot;$&#123;xxl.job.admin.addresses&#125;&quot;)private String adminAddresses;@Value(&quot;$&#123;xxl.job.accessToken&#125;&quot;)private String accessToken;@Value(&quot;$&#123;xxl.job.executor.appname&#125;&quot;)private String appname;@Value(&quot;$&#123;xxl.job.executor.address&#125;&quot;)private String address;@Value(&quot;$&#123;xxl.job.executor.ip&#125;&quot;)private String ip;@Value(&quot;$&#123;xxl.job.executor.port&#125;&quot;)private int port;@Value(&quot;$&#123;xxl.job.executor.logpath&#125;&quot;)private String logPath;@Value(&quot;$&#123;xxl.job.executor.logretentiondays&#125;&quot;)private int logRetentionDays;//配置执行器@Beanpublic XxlJobSpringExecutor xxlJobExecutor() &#123;    logger.info(&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; xxl-job config init.&quot;);    XxlJobSpringExecutor xxlJobSpringExecutor = new XxlJobSpringExecutor();    xxlJobSpringExecutor.setAdminAddresses(adminAddresses);    xxlJobSpringExecutor.setAppname(appname);    xxlJobSpringExecutor.setAddress(address);    xxlJobSpringExecutor.setIp(ip);    xxlJobSpringExecutor.setPort(port);    xxlJobSpringExecutor.setAccessToken(accessToken);    xxlJobSpringExecutor.setLogPath(logPath);    xxlJobSpringExecutor.setLogRetentionDays(logRetentionDays);    return xxlJobSpringExecutor;&#125;\n\nSyncLikedJob.java\n@Component@Slf4jpublic class SyncLikedJob &#123;    @Resource    private SubjectLikedDomainService subjectLikedDomainService;    /**     * 同步点赞数据任务     */    @XxlJob(&quot;syncLikedJobHandler&quot;)    public void syncLikedJobHandler() throws Exception &#123;        XxlJobHelper.log(&quot;syncLikedJobHandler.start&quot;);        try &#123;            subjectLikedDomainService.syncLiked();        &#125; catch (Exception e) &#123;            XxlJobHelper.log(&quot;syncLikedJobHandler.error&quot; + e.getMessage());        &#125;    &#125;&#125;\n\nSubjectLikedDomainServiceImpl.java\n@Overridepublic void syncLiked() &#123;    //redisUtil.getHashAndDelete(SUBJECT_LIKED_KEY)从Redis中获取键为SUBJECT_LIKED_KEY的哈希表，并在获取后删除此哈希表。    Map&lt;Object, Object&gt; subjectLikedMap = redisUtil.getHashAndDelete(SUBJECT_LIKED_KEY);    if (log.isInfoEnabled()) &#123;        log.info(&quot;syncLiked.subjectLikedMap:&#123;&#125;&quot;, JSON.toJSONString(subjectLikedMap));    &#125;    if (MapUtils.isEmpty(subjectLikedMap)) &#123;        return;    &#125;    //批量同步到数据库    List&lt;SubjectLiked&gt; subjectLikedList = new LinkedList&lt;&gt;();    subjectLikedMap.forEach((key, val) -&gt; &#123;        SubjectLiked subjectLiked = new SubjectLiked();        String[] keyArr = key.toString().split(&quot;:&quot;);        String subjectId = keyArr[0];        String likedUser = keyArr[1];        subjectLiked.setSubjectId(Long.valueOf(subjectId));        subjectLiked.setLikeUserId(likedUser);        subjectLiked.setStatus(Integer.valueOf(val.toString()));        subjectLiked.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());        subjectLikedList.add(subjectLiked);    &#125;);    subjectLikedService.batchInsertOrUpdate(subjectLikedList);&#125;\n\nSubjectLikedServiceImpl.java\n@Overridepublic void batchInsertOrUpdate(List&lt;SubjectLiked&gt; subjectLikedList) &#123;    this.subjectLikedDao.batchInsertOrUpdate(subjectLikedList);&#125;\n\nRedisUtil.java\n\n定义Map：创建一个新的HashMap实例，用于存储从Redis中获取的键值对。\n使用Cursor遍历哈希表：通过调用redisTemplate.opsForHash().scan(key, ScanOptions.NONE)获取一个Cursor，它可以用来遍历Redis哈希表中的所有条目。ScanOptions.NONE表示不使用任何扫描选项。\n遍历Cursor：使用while循环遍历Cursor，直到没有更多的条目。\n获取条目：在循环内部，使用cursor.next()获取当前的条目，它是一个Map.Entry对象。\n提取键和值：从Map.Entry对象中提取键（hashKey）和值（value）。\n将键值对放入Map：使用map.put(hashKey, value)将提取的键和值放入之前创建的Map中。\n删除哈希表中的条目：使用redisTemplate.opsForHash().delete(key, hashKey)从Redis的哈希表中删除当前遍历到的键值对。\n返回Map：遍历完成后，返回包含所有键值对的Map。\n\npublic Map&lt;Object, Object&gt; getHashAndDelete(String key) &#123;    Map&lt;Object, Object&gt; map = new HashMap&lt;&gt;();    Cursor&lt;Map.Entry&lt;Object, Object&gt;&gt; cursor = redisTemplate.opsForHash().scan(key, ScanOptions.NONE);    while (cursor.hasNext()) &#123;        Map.Entry&lt;Object, Object&gt; entry = cursor.next();        Object hashKey = entry.getKey();        Object value = entry.getValue();        map.put(hashKey, value);        redisTemplate.opsForHash().delete(key, hashKey);    &#125;    return map;&#125;\n\n我的点赞功能开发SubjectLikedController.java\n/** * 查询我的点赞列表 */@PostMapping(&quot;/getSubjectLikedPage&quot;)public Result&lt;PageResult&lt;SubjectLikedDTO&gt;&gt; getSubjectLikedPage(@RequestBody SubjectLikedDTO subjectLikedDTO) &#123;    try &#123;        if (log.isInfoEnabled()) &#123;            log.info(&quot;SubjectController.getSubjectLikedPage.dto:&#123;&#125;&quot;, JSON.toJSONString(subjectLikedDTO));        &#125;        SubjectLikedBO subjectLikedBO = SubjectLikedDTOConverter.INSTANCE.convertDTOToBO(subjectLikedDTO);        subjectLikedBO.setPageNo(subjectLikedDTO.getPageNo());        subjectLikedBO.setPageSize(subjectLikedDTO.getPageSize());        PageResult&lt;SubjectLikedBO&gt; boPageResult = subjectLikedDomainService.getSubjectLikedPage(subjectLikedBO);        return Result.ok(boPageResult);    &#125; catch (Exception e) &#123;        log.error(&quot;SubjectCategoryController.getSubjectLikedPage.error:&#123;&#125;&quot;, e.getMessage(), e);        return Result.fail(&quot;分页查询我的点赞失败&quot;);    &#125;&#125;\n\nSubjectLikedDomainServiceImpl.java\n@Overridepublic PageResult&lt;SubjectLikedBO&gt; getSubjectLikedPage(SubjectLikedBO subjectLikedBO) &#123;    // 创建一个分页结果对象    PageResult&lt;SubjectLikedBO&gt; pageResult = new PageResult&lt;&gt;();    // 设置当前页码和每页显示的记录数    pageResult.setPageNo(subjectLikedBO.getPageNo());    pageResult.setPageSize(subjectLikedBO.getPageSize());    // 计算查询的起始索引    int start = (subjectLikedBO.getPageNo() - 1) * subjectLikedBO.getPageSize();    // 将BO对象转换为Entity对象    SubjectLiked subjectLiked = SubjectLikedBOConverter.INSTANCE.convertBOToEntity(subjectLikedBO);    // 设置点赞用户的ID为当前登录用户的ID    subjectLiked.setLikeUserId(LoginUtil.getLoginId());    // 执行条件查询，获取点赞记录的总数    int count = subjectLikedService.countByCondition(subjectLiked);    // 如果没有记录，则直接返回空的分页结果    if (count == 0) &#123;        return pageResult;    &#125;    // 执行分页查询，获取点赞记录的列表    List&lt;SubjectLiked&gt; subjectLikedList = subjectLikedService.queryPage(subjectLiked, start,            subjectLikedBO.getPageSize());    // 将Entity列表转换为BO列表    List&lt;SubjectLikedBO&gt; subjectInfoBOS = SubjectLikedBOConverter.INSTANCE.convertListInfoToBO(subjectLikedList);    // 遍历BO列表，为每个点赞记录添加主题名称    subjectInfoBOS.forEach(info -&gt; &#123;        SubjectInfo subjectInfo = subjectInfoService.queryById(info.getSubjectId());        info.setSubjectName(subjectInfo.getSubjectName());    &#125;);    // 设置分页结果中的记录列表和总数    pageResult.setRecords(subjectInfoBOS);    pageResult.setTotal(count);    // 返回分页结果对象    return pageResult;&#125;\n\nSubjectLikedServiceImpl.java\n@Overridepublic int countByCondition(SubjectLiked subjectLiked) &#123;    return this.subjectLikedDao.countByCondition(subjectLiked);&#125;//分页查询@Overridepublic List&lt;SubjectLiked&gt; queryPage(SubjectLiked subjectLiked, int start, Integer pageSize) &#123;    return this.subjectLikedDao.queryPage(subjectLiked, start, pageSize);&#125;\n\n快速刷题功能开发SubjectInfoDTO.java\n新增字段\n/** * 下一题 */private Long nextSubjectId;/** * 上一题 */private Long lastSubjectId;\n\nSubjectInfoDomainService.java\n这段代码的主要逻辑是：\n\n根据题目ID查询题目实体。\n根据题目类型获取相应的处理器，并使用它查询题目选项信息。\n将题目选项和题目信息转换为业务对象BO。\n查询题目的标签ID列表，并批量查询标签列表。\n提取标签名称并设置到业务对象BO中。\n设置是否已点赞的状态和点赞数量。\n组装题目的上下文信息，包括上一个和下一个题目的ID。\n返回封装好的业务对象BO。\n\n@Overridepublic SubjectInfoBO querySubjectInfo(SubjectInfoBO subjectInfoBO) &#123;    // 根据题目信息BO中的ID查询题目实体    SubjectInfo subjectInfo = subjectInfoService.queryById(subjectInfoBO.getId());    // 根据题目类型获取相应的处理器    SubjectTypeHandler handler = subjectTypeHandlerFactory.getHandler(subjectInfo.getSubjectType());    // 使用处理器查询题目选项信息    SubjectOptionBO optionBO = handler.query(subjectInfo.getId().intValue());    // 将题目选项和题目信息转换为业务对象BO    SubjectInfoBO bo = SubjectInfoConverter.INSTANCE.convertOptionAndInfoToBo(optionBO, subjectInfo);    // 创建题目映射对象，设置题目ID和未删除标志    SubjectMapping subjectMapping = new SubjectMapping();    subjectMapping.setSubjectId(subjectInfo.getId());    subjectMapping.setIsDeleted(IsDeletedFlagEnum.UN_DELETED.getCode());    // 查询题目标签ID列表    List&lt;SubjectMapping&gt; mappingList = subjectMappingService.queryLabelId(subjectMapping);    // 从映射列表中提取标签ID    List&lt;Long&gt; labelIdList = mappingList.stream().map(SubjectMapping::getLabelId).collect(Collectors.toList());    // 批量查询标签列表    List&lt;SubjectLabel&gt; labelList = subjectLabelService.batchQueryById(labelIdList);    // 从标签列表中提取标签名称    List&lt;String&gt; labelNameList = labelList.stream().map(SubjectLabel::getLabelName).collect(Collectors.toList());    // 设置标签名称到业务对象BO中    bo.setLabelName(labelNameList);    // 设置是否已点赞的状态    bo.setLiked(subjectLikedDomainService.isLiked(subjectInfoBO.getId().toString(), LoginUtil.getLoginId()));    // 设置点赞数量    bo.setLikedCount(subjectLikedDomainService.getLikedCount(subjectInfoBO.getId().toString()));    // 组装题目的上下文信息，如上一个和下一个题目的ID    assembleSubjectCursor(subjectInfoBO, bo);    // 返回封装好的业务对象BO    return bo;&#125;// 私有方法，用于组装题目的上下文信息private void assembleSubjectCursor(SubjectInfoBO subjectInfoBO, SubjectInfoBO bo) &#123;    // 获取分类ID、标签ID和题目ID    Long categoryId = subjectInfoBO.getCategoryId();    Long labelId = subjectInfoBO.getLabelId();    Long subjectId = subjectInfoBO.getId();    // 如果分类ID或标签ID为空，则不进行上下文信息的组装    if (Objects.isNull(categoryId) || Objects.isNull(labelId)) &#123;        return;    &#125;    // 查询下一个题目的ID    Long nextSubjectId = subjectInfoService.querySubjectIdCursor(subjectId, categoryId, labelId, 1);    // 设置下一个题目的ID到业务对象BO中    bo.setNextSubjectId(nextSubjectId);    // 查询上一个题目的ID    Long lastSubjectId = subjectInfoService.querySubjectIdCursor(subjectId, categoryId, labelId, 0);    // 设置上一个题目的ID到业务对象BO中    bo.setLastSubjectId(lastSubjectId);&#125;\n\nSubjectInfoDao.xml\nquerySubjectIdCursor对应的sql语句\n&lt;select id=&quot;querySubjectIdCursor&quot; resultType=&quot;java.lang.Long&quot;&gt;    select a.id    from subject_info a,    subject_mapping b    where a.id = b.subject_id    and b.category_id = #&#123;categoryId&#125;    and b.label_id = #&#123;labelId&#125;    &lt;if test=&quot;cursor !=null and cursor == 1&quot;&gt;        and a.id &gt; #&#123;subjectId&#125;    &lt;/if&gt;    &lt;if test=&quot;cursor !=null and cursor == 0&quot;&gt;        and a.id &amp;lt; #&#123;subjectId&#125;    &lt;/if&gt;    limit 0,1&lt;/select&gt;\n","categories":["后端"],"tags":["Java","后端","微服务"]},{"title":"RPC和Http请求的区别","url":"/2024/08/01/2024-08-01-RPC%E5%92%8CHttp%E8%AF%B7%E6%B1%82%E7%9A%84%E5%8C%BA%E5%88%AB/","content":"RPC和Http请求的区别看这个：RPC简介及框架选择，RPC与REST的区别_rpc控制client, client返回主机测试结果和状态-CSDN博客\nRPC、REST API深入理解_rpc与普通api接口的区别-CSDN博客\n弄清楚这些接口(http,https,api,RPC,webservice,Restful api ,OpenAPI）_rpc接口和api接口-CSDN博客\nrestful API、SOAP、RPC的区别_soap api和restful api优缺点-CSDN博客\n","categories":["博客"],"tags":["RPC","http"]},{"title":"利用ollama一键式部署SoulChat和性能对比","url":"/2024/08/05/2024-08-05-%E5%88%A9%E7%94%A8ollama%E4%B8%80%E9%94%AE%E5%BC%8F%E9%83%A8%E7%BD%B2SoulChat%E5%92%8C%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/","content":"利用ollama一键式部署SoulChat和性能对比scutcyr&#x2F;SoulChat: 中文领域心理健康对话大模型SoulChat (github.com)\nliutechs&#x2F;soulchatfa (ollama.com)\n部署过程采用ollama进行一键式部署：\nssh bjtc@162.105.16.236password: 000000curl -fsSL https://ollama.com/install.sh | sh //下载ollmaollama run liutechs/soulchatfa //利用ollma下载SoulChat\n\n运行和对比\n失恋\n\nSoulChat:\n\n\nKimi:\n2.\n\n\n\n宿舍关系\n\nSoulChat:\n\n\nKimi:\n\n\n\n\n期末考试\n\nSoulChat\n\n\nKimi:\n\n\n\n\n科研压力\n\nSoulChat\n\n\nKimi:\n\n\n\n\n实习工作\n\nSoulChat\n\n\nKimi:\n\n\n\n\n\n","categories":["大模型"],"tags":["HuatuoGPT2","Ollama"]},{"title":"医疗垂直领域大模型WiNGPT2的部署和性能对比","url":"/2024/08/06/2024-08-06-WiNGPT2%E7%9A%84%E9%83%A8%E7%BD%B2%E5%92%8C%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/","content":"医疗垂直领域大模型WiNGPT2的部署和性能对比WiNGPT2部署和运行git clone https://github.com/winninghealth/WiNGPT2.gitcd WiNGPT2mkdir winninghealthcd winninghealthgit clone https://hf-mirror.com/winninghealth/WiNGPT2-7B-Chatcd ..\n\n若没有以下这三个库，则安装gradio、tiktoken、pip install einops flash_attn\npip install gradiopip install tiktokenpip install einops flash_attn\n\n选一个目录作为cache（前提是这个目录已经存在且有权限读写）\n# 遇到报错 [Errno 13] Permission denied: &#x27;/data/.cache/huggingface/modules/transformers_modules/WiNGPT2-7B-Chat&#x27;export HF_HOME=&quot;/home/bjtc/verticalLLM/lzrj/WiNGPT2/cache&quot;\n\n安装frpc_linux_amd64\ngit clone https://hf-mirror.com/lalazzz/frpc_linux_amd64_v0.2Rename the downloaded file to: frpc_linux_amd64_v0.2cp  frpc_linux_amd64_v0.2 /home/bjtc/miniconda3/lib/python3.12/site-packages/gradiochmod +x /home/bjtc/miniconda3/lib/python3.12/site-packages/gradio/frpc_linux_amd64_v0.2\n\nset share=True，并运行\nvi demo.py#按照如下内容更改if __name__ == &quot;__main__&quot;:    demo.launch(share=True)#运行python demo.py\n\n\n在public URL: https://76d07266e8096cd673.gradio.live 可访问该模型\n\n性能对比\n出现急性心肌梗死一般对身体带来哪些伤害\n\nWiNGPT2\n\n一、基础心血管病变：(1)冠状动脉粥样硬化斑块形成：长期的血管内皮细胞损伤和脂质代谢紊乱以及血液成分改变引起动脉壁脂肪沉积，使管壁增厚变硬，弹性减弱，平滑肌细胞及结缔组织增生，血小板在局部黏附聚集，释放一系列凝血因子而导致血栓形成，致使管腔狭窄。根据血脂升高的程度、血液黏滞度的高低和微循环障碍情况不同，以左前降支为例，仅5%～10%有临床症状，主要表现胸闷、气短、心绞痛，还有心律失常、高血压等。而大约50%左右的病人没有症状，这些患者在缺血发作时，很难准确地估计到是心肌供氧不足导致的，常常认为自己是在过度劳累。一部分患者仅仅表现为不稳定型心绞痛，或是无痛性心肌梗死，因为这类患者有微血管功能不全。还有少部分人在发生心肌梗死后还没有诊断出。(2)心肌毛细血管密度相对较低：有人曾做过测定，发现人类与灵长类动物之间的心肌毛细血管分布较恒定，其他哺乳动物如犬、猪等则为多倍，而爬行类及鸟类动物则是较少的，这说明了动物进化过程中心脏的功能有所降低，主要是由于心肌中毛细血管分布所决定的。因此，心脏对缺血耐受能力差。(3)侧支循环发育不良：患冠心病后，可促使代偿性的侧支循环建立，以增加心肌供氧。但是，在大多数情况下，心肌内的血流供应只是减少，而不是像人们想象的那样通过侧支循环得以改善。因此可以说，在心肌缺血的同时，也增加了心肌梗死的危险性。(4)微血管堵塞：各种原因引起的心肌缺血都会导致无复流现象。其中主要原因是微血管堵塞所致。如果不能很快恢复，就可能导致缺血部位坏死，从而形成陈旧性瘢痕。二、心脏以外的因素：主要与心室顺应性降低有关。急性期在舒张早期开始低容积压力负荷。部分患者还同时合并外周血管阻力明显增高，则在舒张早期就出现高容低压负荷状态。在多数慢性期患者，舒张早期则为正常的低容低压负荷状态，而在晚期往往又转为正常高容低压或高容高压负荷。三、原发性和继发性因素：原发性心肌损害包括肾上腺素能异常、儿茶酚胺性损害、体力衰竭、内分泌疾患、高龄等。而继发性心肌损害常见于急性心肌炎、高血压病、糖尿病、各种炎症引起的发热性疾病、手术创伤、人工瓣膜置换术后及药物中毒等情况。四、全身其他器官系统的相互影响：各种引起休克、感染、心力衰竭、严重贫血和电解质紊乱的情况都可能加重心肌缺血的程度。一般来说，除严重感染性休克或终末期衰竭等原因之外，当其他重要器官的功能异常得不到及时纠正时，往往导致死亡率的升高。五、危险因素的相互作用：不同病人引起心肌梗死的危险因素的组合是不同的。除了个体的不同以外，许多危险因素还可以互相作用。例如，肥胖可以通过加速胰岛素分泌水平并促进肌肉摄取葡萄糖的能力增强来抵消体力活动所增加的能量消耗，同时还可能加重其他危险因素的危害程度，如高血压等。同样，体力活动也可以减轻一些其他危险因素的影响，如轻度超重者通过增加体力活动可以有效地防止体脂过量的堆积。五、神经体液因素：无论是动脉血压升高还是降低都会使冠脉血流下降。压力感受器可以迅速通过调整自主神经张力和心率来平衡动脉血压的变化，而静脉系统则缺乏这样的反馈机制，所以会导致反射性心动过缓。七、心室重构：由于冠心病患者的特殊病理生理变化，随着病程进展，会出现心肌舒缩性能减弱，进而心脏逐渐扩大，最终发展成为收缩功能下降直至衰竭。这一过程被称为“心室重构”，这一病理变化为本症的特征之一。目前研究已证明，心肌重构不仅是心肌缺血的一种后果，而且也是多种疾病过程中的共同通路。总之，急性心肌梗死起病急骤，病情凶险，不经治疗，平均生存期仅为1.76小时。因此说抢救心肌梗死是心脏科急诊的重要内容之一，而急性心肌梗死并发心源性休克也是危重症医学领域最困难、最重要的医疗急救课题之一。\n\n\nKimi:\n急性心肌梗死是一种严重的心脏病，通常由冠状动脉血管发生动脉粥样硬化病变而引起血管腔狭窄或阻塞，造成心肌缺血、缺氧或坏死。这种病症对身体带来的伤害主要包括：\n\n心肌损伤：由于心肌细胞对缺氧非常敏感，一旦血液供应中断，心肌细胞会迅速受损并可能发生坏死。\n\n心脏功能下降：心肌梗死后，心脏的泵血能力可能减弱，导致心力衰竭，影响全身血液循环。\n\n心律失常：心肌梗死可能导致心脏电生理活动异常，引起各种心律失常，如室性心动过速或心室颤动，这些情况可能危及生命。\n\n心源性休克：大面积心肌梗死可能导致心脏泵血功能严重不足，引起心源性休克，这是一种生命威胁的紧急情况。\n\n心理影响：心肌梗死不仅对身体造成影响，还可能对患者的心理造成重大压力，导致焦虑和抑郁等情绪问题。\n\n生活质量下降：心肌梗死后，患者可能需要长期服用药物，改变生活方式，并且可能无法恢复到病前的活动水平，这会影响患者的生活质量。\n\n经济负担：治疗心肌梗死需要大量的医疗资源和长期管理，这可能给患者及其家庭带来经济负担。\n\n死亡风险：如果心肌梗死未得到及时和适当的治疗，可能会导致患者死亡。\n\n\n急性心肌梗死是一种需要紧急医疗干预的病症，及时识别症状并寻求专业医疗帮助至关重要。\n\n\n\n\n肝肿瘤指标高就是癌症吗\n\nWiNGPT2\n有的肝肿瘤指标高并不一定是癌症，癌症即恶性肿瘤，它是机体在各种致瘤&#x2F;促瘤因素作用下，局部组织的某一个细胞在基因水平上失去对其生长的正常调控，导致其克隆性异常增生而形成的病变。学界一般将癌未满年龄限定，或从良性向恶性转变阶段的肿瘤统称为“瘤”，通常指肉眼可见的能够钻孔到达浆膜面的限局性病变，但亦有例外情况，例如一些良性甲状腺肿块在肉眼观察似乎并无深部侵袭性，但显微镜下却有可能浸润至邻近组织深处；又如局限性的膀胱乳头状瘤经电灼后，可在影像学上残留少量肿瘤痕迹，待其增大后肉眼可见，并能侵入深层组织。体检检查中一些项目的异常可能与癌症有关，需要进一步做相关筛查确诊。一般来说肝肿瘤标志物高的情况下不能确诊患者是不是患有肝癌，只是一种辅助诊断的参考指标。其它辅助检查比如B超、CT等需要结合在一起看。很多检查需要多次复查才有意义，需间隔一段时间，才能了解比较结果是否有较大变化。确诊是否为癌症尚需依靠病理活检免疫组化明确诊断。有些肝病是遗传性的，家族史里有这个病患者，那么下一代是有一定概率也会得的，就如乙肝大三阳、小三阳。发病早：肝病发病比较隐蔽，刚开始不易发现，但是到了后期的时候，就会变得很厉害。很容易形成肝腹水，这个时候病情已经很严重了。危害二：传染性高：乙肝、丙肝等肝病具有很强的传染性，而且易演变为慢性、难治性肝炎。危害三：恶化速度快：因为病毒复制不断刺激肝脏，时间久了会引起肝脏的炎症反应，导致肝脏纤维化，这是属于一种病理改变，纤维化的出现表示病情正在朝着肝硬化的方向转变，此时若是不能够及时控制病情，那将是肝硬化或者是肝癌，这两个疾病的出现生命将会受到威胁。\n\n\nKimi:\n肝肿瘤指标高并不一定意味着患有癌症。肿瘤指标，也称为肿瘤标志物，是用于评估肿瘤存在可能性的一类物质，它们可能由肿瘤细胞合成释放，或在机体对肿瘤细胞反应时升高。然而，肿瘤标志物的升高也可见于非肿瘤性疾病，例如炎症、感染，甚至生活习惯如熬夜、酗酒等都可能导致肿瘤标志物升高6。因此，单纯依据肿瘤标志物的升高来自我诊断肿瘤是不科学的。\n在体检或身体检查中，如果发现肝脏有肿瘤，也不一定就是肝癌。肿瘤有良性和恶性之分，肝脏肿瘤可以是良性病变，如肝血管瘤、肝囊肿等，并不一定代表肝癌7。当发现肝脏有肿瘤时，及时进行明确诊断是非常重要的。\n对于肝脏肿瘤的诊断，除了肿瘤标志物，还需要结合临床症状、影像学检查（如腹部彩超、CT、MRI）等其他检查结果来综合判断8。如果影像学检查发现肝脏有异常占位，并且肿瘤标志物升高，医生会根据具体情况可能建议进一步的检查，如肝脏穿刺活检等，以获得病理诊断，因为病理诊断是癌症诊断的金标准8。\n此外，对于肿瘤标志物的检测，连续观察其动态变化更有意义。突然的升高值得注意，但肿瘤标志物升高时不可轻易诊断为恶性肿瘤，都需要结合其他相关检查、临床症状、体格检查等综合判断9。如果不属于高危人群，身体也没有任何不适，肿瘤标志物只是轻度升高，可以选择改善生活方式后再次复查肿瘤标志物，必要时可以完善相关检查10。\n因此，如果体检发现肝肿瘤指标升高，建议及时咨询专业医生，进行进一步的检查和诊断。同时，保持良好的生活习惯，避免过度焦虑和恐慌，因为这些情绪本身也可能影响身体健康。\n\n\n\n\n经常摇动婴儿睡觉会有什么不良反应吗\n\nWiNGPT2\n有些妈妈为了让宝宝能更快入睡，就喜欢摇晃着宝宝入睡，对于没经验的新手妈妈来说，看到宝宝哭闹就会下意识的去摇晃，结果就成了习惯，摇晃宝宝睡觉是有很多危害的。经常摇晃宝宝睡觉的五大危害1、容易让宝宝患上脑震荡当用力摇晃宝宝时候，宝宝的大脑会处于自由基攻击的状态，宝宝颅内的大脑每天都在不停快速震动，这种震动会让宝宝出现脑震荡甚至脑损伤的症状。同时还会让宝宝患上暂时性失聪或者耳聋等症状，严重的甚至会留下后遗症，影响孩子的一生。2、容易让宝宝患上胃出血如果家长摇晃宝宝的力度过大，会让宝宝在睡眠过程中窒息到引起惊厥。强烈震荡还会导致宝宝呕吐，一旦宝宝呕吐物误吸入呼吸道，可能会阻塞宝宝呼吸通道，宝宝呼吸不畅就会挣扎、踢腿，有可能会把自己的脸、嘴巴、眼睛等挤伤擦伤，还极有可能会使宝宝出现胃出血的症状，这些都是因为在剧烈摇晃的时候，各部位之间的碰撞引起的。3、容易让宝宝患上呼吸暂停综合征宝宝在睡眠中突然被剧烈摇晃后，大脑就会被强制性拉扯，这样就会增加大脑供血量，胸廓、肺、血液之间为了满足需求会发生短暂的不协调，就会导致宝宝在睡眠中窒息。若宝宝因某些因素存在呼吸道不通畅，就会引起明显的气流堵塞，造成宝宝呼吸暂停，因为孩子呼吸中枢兴奋性较低，抑制程度较高，稍有缺氧，就被大脑感知到，并引发呼吸暂停。即使一次呼吸停止也只有几秒，不够长的时间也不会产生任何症状，但如果持续时间较长，一分钟以上就会出现缺氧。每次睡觉均会发生呼吸暂停，长此以往，就会对宝宝的身体健康造成巨大的伤害。4、容易导致宝宝患上睡眠障碍现在许多家庭都是独生子女，父母都是十分宠爱孩子，任由孩子想怎样就怎样，其中就有不少家长就喜欢抱着宝宝睡觉，感觉宝宝睡着了再放下，殊不知正是这么做的不对行为，给宝宝养成了错误的习惯，而且在婴儿时期就得出了“抱睡”的结论。而且抱睡会严重影响宝宝自身的情绪、自身肢体的正常发育、入睡时伴随的手舞足蹈等动作都会干扰宝宝大脑的正常工作。而且摇晃睡觉也不是一个好的办法，宝宝睡觉可以用被子把宝宝包裹起来，头部稍微露出些，不但保暖还能帮助宝宝进入睡眠状态。\n\n\nKimi:\n经常摇动婴儿睡觉可能会对宝宝的健康和发育造成不良影响。首先，由于婴儿的大脑和颈部肌肉尚未完全发育，剧烈或过度的摇晃可能导致所谓的“摇晃婴儿综合征”，这可能会引起大脑损伤、血管撕裂和脑神经纤维受损，严重时甚至可能导致瘫痪、死亡或遗留发育迟缓、智力低下等问题。此外，过度依赖摇晃来帮助婴儿入睡，可能会影响婴儿学习自主入睡的能力，从而在没有摇晃的情况下难以入睡。\n对于婴儿的睡眠环境，建议提供优质的睡眠条件，包括适宜的声音、光线、空气、温度和湿度，以帮助宝宝安稳入睡。同时，家长应避免在婴儿睡前让他们玩得过于兴奋，帮助宝宝养成规律的睡眠习惯。如果宝宝已经习惯了被摇晃才能入睡，可以尝试逐渐减少摇晃的强度和频率，或者采取其他安抚方式，比如轻轻拍拍、语言安抚或使用安抚巾等，以帮助宝宝逐渐适应不依赖摇晃的入睡方式。\n总之，虽然适度的摇晃有时可以安抚婴儿，但为了避免潜在的风险和培养良好的睡眠习惯，家长应谨慎使用摇晃的方式，并考虑采取其他更安全的安抚和入睡方法。\n\n\n\n\n宝宝15个月37.3度算发烧吗？\n\nWiNGPT2\n通常情况下，婴儿的正常体温在36.5℃-37.5℃之间。而当宝宝的体温超过38℃时，则被认为是发烧。所以根据宝宝的体温测量结果来看，37.3℃处于轻微发热状态，属于轻度的发烧。不过，要考虑到宝宝的个体差异和环境因素的影响，如果宝宝没有其他不适症状并且精神状态良好，我们可以先观察一段时间，注意保持室内通风，适当给予一些物理降温的方法，比如用温水擦拭宝宝的手心、脚心等部位来帮助散热。\n\n\nKimi:\n宝宝的正常体温范围通常是36.0°C至37.2°C，这取决于测量方法和宝宝的年龄。对于15个月大的宝宝来说，37.3°C的体温略高于正常范围的上限，但并不一定意味着宝宝发烧。体温可能会因为多种因素而波动，例如运动、哭闹、刚吃完饭或环境温度等。如果宝宝的体温达到37.3°C，并伴有其他症状，如头痛、无力、肌肉酸痛、咳嗽、流鼻涕等不适时，则可能是发烧，需要及时就医治疗。\n需要注意的是，通常认为体温超过38.5°C时，可以给孩子使用退烧药，但这并不是唯一的判断标准。如果孩子体温不到38.5°C，但已经出现了精神不振、打蔫、肌肉酸痛等表现，也可以给孩子使用退烧药。\n如果宝宝体温略高但没有其他不适症状，可以先观察宝宝的一般行为和反应，确保宝宝有充足的休息和水分，如果体温持续升高或出现其他症状，应及时咨询医生。\n\n\n\n\n泛发型白癜风的症状表现\n\nWiNGPT2\n皮损为乳白色，白斑界限清楚，色素反见毛孔缩小、皮肤萎缩等病变。而且患病的部位白斑可逐渐扩大或者相互融合，连成大片的不规则形状，严重时毳毛及毛发脱落，汗腺毛孔也随之闭塞，夏季容易受到紫外线强烈照射，产生症状会更加严重。甚至有的患者会因此而有斑秃或者全秃的现象出现。泛发型白癜风是皮肤病中常见多发的疾病之一，早期没有得到有效的治疗会有严重的危害性。严重的话会影响自身形象美观，甚至导致五官外貌、排尿感觉、神经障碍、并发症等。首先白癜风最典型的症状就是皮损可以发生在全身任何部位，会呈对称分布。一般无自觉症状，但是部分患者的发病过程会相对比较慢，会在一年左右，有的病情严重的患者甚至几年就可以发生全身的变白。通常为大小不一的局限性脱失斑，患处的毛发可正常，也可变白。此种疾病一般发生在易受摩擦及阳光照晒的暴露部位较多，特别是颜面部、颈部、腰腹部、骶尾处、前臂伸面与手指背部等处。其次是皱褶及皱襞部多发。皮损可见于很多部位，单侧的白斑也可能由神经因素所致，任何年龄均可发病，但以青少年为主。此外泛发性白癜风皮损呈纯白色圆形或不规则的脱失斑，表面光滑，边界清楚，边缘色素增多。变白的皮肤对日光较正常皮肤敏感，稍晒太阳即发红。此病一般不会引起甲亢。本病一般无自觉症状，少数病人在发病前或同时有患处局部瘙痒感。白癜风常伴其他自身免疫性疾病，如糖尿病、甲状腺疾病、肾上腺功能不全、硬皮病、异位性皮炎、斑秃等如何预防：由于白癜风初起为一小片色素减退斑，故而有时难以及时发现。一旦扩散，说明病情已较为严重。此时应配合医生，尽快分析病因，检查出自己的过敏原，并积极寻求治疗方法，定期随访观察。\n\n\nKimi:\n泛发型白癜风是白癜风的一种类型，其主要症状表现为皮肤上出现多处白斑，这些白斑的总面积通常超过体表皮肤的50%以上。这些白斑可以发生在身体的任何部位，形状可能是圆形、椭圆形或不规则形，颜色通常为乳白色或瓷白色，边界清楚。患者通常无自觉症状，但在某些情况下，发病前或发病初期可能会有炎症表现，如湿疹样或体癣样，进展期可能有短时瘙痒。泛发型白癜风的白斑分布广泛，通常以片状形式存在，不会单个存在，往往连成一片，形状不规则，皮损具有对称性。此外，泛发型白癜风患者常伴有毛发变白，因为黑色素细胞受损程度更严重。\n泛发型白癜风的发病机制复杂，可能与自身免疫、精神神经、内分泌等因素有关。病程较长，多数患者的病情处于进展期，治疗可能较为困难。因此，对泛发型白癜风的治疗应综合分析其病因病势，尽量寻找并祛除可能的诱发因素。\n在治疗方面，泛发型白癜风皮损较少者可以遵医嘱应用糖皮质激素、钙调磷酸酶抑制剂、维生素D3衍生物等药物治疗，也可使用308mm准分子激光治疗，均有一定的疗效。如果皮损超过体表面积的95%，可以考虑用脱色方法治疗，使色素脱失。患者在日常生活中还需注意避免太阳暴晒，以免导致病情加重。\n\n\n\n\n\n","categories":["大模型"],"tags":["WiNGPT2","LLM"]},{"title":"线程池数量到底如何配置？","url":"/2024/08/06/2024-08-06-%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%95%B0%E9%87%8F%E5%88%B0%E5%BA%95%E5%A6%82%E4%BD%95%E9%85%8D%E7%BD%AE%EF%BC%9F/","content":"线程池数量到底如何配置？可能很多人都看到过一个线程数设置的理论:\n\nCPU 密集型的程序-核心数 +1\n1&#x2F;0 密集型的程序-核心数*2\n\n不会吧，不会吧，真的有人按照这个理论规划线程数?\n线程数和CPU利用率的小测试抛开一些操作系统，计算机原理不谈，说一个基本的理论(不用纠结是否严谨，只为好理解)：\n一个CPU核心，单位时间内只能执行一个线程的指令那么理论上，我一个线程只需要不停的执行指令，就可以跑满一个核心的利用率。\n来写个死循环空跑的例子验证一下：\npublic class CPUUtilizationTest&#123;\tpublic static void main(String[] args)&#123;//死循环，什么都不做\t\twhile(true)&#123;\t\t\t&#125;\t&#125;&#125;\n\n\n\n测试CPU：6核心12线程\n现在的CPU利用率：\n\n从图上可以看到，3号核心利用率已经被跑满了\n基于上面的理论，多开几个线程试试呢?\npublic class CPUUtilizationTest&#123;    public static void main(String[]args)&#123;        for(int j=0;j&lt;6;j++)&#123;            new Thread(newRunnable()&#123;                @Override                public void run()&#123;                    while(true)&#123;                                            &#125;).start();                &#125;            &#125;       &#125;\n\n此时再看CPU利用率，1&#x2F;2&#x2F;5&#x2F;7&#x2F;9&#x2F;11 几个核心的利用率已经被跑满。\n\n那如果开12个线程呢，是不是会把所有核心的利用率都跑满?答案一定是会的:\n如果此时我把上面例子的线程数继续增加到24个线程，会出现什么结果呢?\n\n从上图可以看到，CPU利用率和上一步一样，还是所有核心100%，不过此时负载已经从11.x增加到了22.x（load average解释参考https://scoutapm.com/blog/understanding-load-averages），说明此时CPU更繁忙，线程的任务无法及时执行。\n现代CPU基本都是多核心的，比如我这里测试用的AMD 3600，6核心12线程（超线程），我们可以简单的认为它就是12核心CPU。那么我这个CPU就可以同时做12件事，互不打扰。\n如果要执行的线程大于核心数，那么就需要通过操作系统的调度了。操作系统给每个线程分配CPU时间片资源，然后不停的切换，从而实现“并行”执行的效果。\n但是这样真的更快吗？从上面的例子可以看出，一个线程就可以把一个核心的利用率跑满。如果每个线程都很“霸道”，不停的执行指令，不给CPU空闲的时间，并且同时执行的线程数大于CPU的核心数，就会导致操作系统更频繁的执行切换线程执行，以确保每个线程都可以得到执行。\n不过切换是有代价的，每次切换会伴随着寄存器数据更新，内存页表更新等操作。虽然一次切换的代价和I&#x2F;O操作比起来微不足道，但如果线程过多，线程切换的过于频繁，甚至在单位时间内切换的耗时已经大于程序执行的时间，就会导致CPU资源过多的浪费在上下文切换上，而不是在执行程序，得不偿失。\n上面死循环空跑的例子，有点过于极端了，正常情况下不太可能有这种程序。\n大多程序在运行时都会有一些 I&#x2F;O操作，可能是读写文件，网络收发报文等，这些 I&#x2F;O 操作在进行时时需要等待反馈的。比如网络读写时，需要等待报文发送或者接收到，在这个等待过程中，线程是等待状态，CPU没有工作。此时操作系统就会调度CPU去执行其他线程的指令，这样就完美利用了CPU这段空闲期，提高了CPU的利用率。\n上面的例子中，程序不停的循环什么都不做，CPU要不停的执行指令，几乎没有啥空闲的时间。如果插入一段I&#x2F;O操作呢，I&#x2F;O 操作期间 CPU是空闲状态，CPU的利用率会怎么样呢？先看看单线程下的结果：\npublic class CPUUtilizationTest&#123; public static void main(String[] args)throws InterruptedException&#123; for(int n =0; n &lt;1; n++)&#123; new Thread(newRunnable()&#123; @Override public void run()&#123; while(true)&#123; //每次空循环 1亿 次后，sleep 50ms，模拟 I/O等待、切换 for(int i =0; i &lt;100_000_000l; i++)&#123;  &#125; try&#123; Thread.sleep(50); &#125; catch(InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; &#125; &#125;).start(); &#125; &#125;&#125;\n\n\n唯一有利用率的9号核心，利用率也才50%，和前面没有sleep的100%相比，已经低了一半了。现在把线程数调整到12个看看：\n\n单个核心的利用率60左右，和刚才的单线程结果差距不大，还没有把CPU利用率跑满，现在将线程数增加到18：\n\n此时单核心利用率，已经接近100%了。由此可见，当线程中有 I&#x2F;O 等操作不占用CPU资源时，操作系统可以调度CPU可以同时执行更多的线程。\n现在将I&#x2F;O事件的频率调高看看呢，把循环次数减到一半，50_000_000，同样是18个线程：此时每个核心的利用率，大概只有70%左右了。\n线程数和CPU利用率的小总结上面的例子，只是辅助，为了更好的理解线程数&#x2F;程序行为&#x2F;CPU状态的关系，来简单总结一下：\n\n一个极端的线程（不停执行“计算”型操作时），就可以把单个核心的利用率跑满，多核心CPU最多只能同时执行等于核心数的“极端”线程数\n如果每个线程都这么“极端”，且同时执行的线程数超过核心数，会导致不必要的切换，造成负载过高，只会让执行更慢\nI&#x2F;O 等暂停类操作时，CPU处于空闲状态，操作系统调度CPU执行其他线程，可以提高CPU利用率，同时执行更多的线程\nI&#x2F;O 事件的频率频率越高，或者等待&#x2F;暂停时间越长，CPU的空闲时间也就更长，利用率越低，操作系统可以调度CPU执行更多的线程\n\n线程数规划的公式前面的铺垫，都是为了帮助理解，现在来看看书本上的定义。《Java 并发编程实战》介绍了一个线程数计算的公式：\n\n如果希望程序跑到CPU的目标利用率，需要的线程数公式为：\n\n公式很清晰，现在来带入上面的例子试试看：\n如果我期望目标利用率为90%（多核90），那么需要的线程数为：\n核心数12 * 利用率0.9 * (1 + 50(sleep时间)&#x2F;50(循环50_000_000耗时)) ≈ 22\n现在把线程数调到22，看看结果：\n\n现在CPU利用率大概80+，和预期比较接近了，由于线程数过多，还有些上下文切换的开销，再加上测试用例不够严谨，所以实际利用率低一些也正常。\n把公式变个形，还可以通过线程数来计算CPU利用率：\n\n线程数22 &#x2F; (核心数12 * (1 + 50(sleep时间)&#x2F;50(循环50_000_000耗时))) ≈ 0.9\n虽然公式很好，但在真实的程序中，一般很难获得准确的等待时间和计算时间，因为程序很复杂，不只是“计算”。一段代码中会有很多的内存读写，计算，I&#x2F;O 等复合操作，精确的获取这两个指标很难，所以光靠公式计算线程数过于理想化。\n真实程序中的线程数那么在实际的程序中，或者说一些Java的业务系统中，线程数（线程池大小）规划多少合适呢？\n先说结论：没有固定答案，先设定预期，比如我期望的CPU利用率在多少，负载在多少，GC频率多少之类的指标后，再通过测试不断的调整到一个合理的线程数\n比如一个普通的，SpringBoot 为基础的业务系统，默认Tomcat容器+HikariCP连接池+G1回收器，如果此时项目中也需要一个业务场景的多线程（或者线程池）来异步&#x2F;并行执行业务流程。\n此时我按照上面的公式来规划线程数的话，误差一定会很大。因为此时这台主机上，已经有很多运行中的线程了，Tomcat有自己的线程池，HikariCP也有自己的后台线程，JVM也有一些编译的线程，连G1都有自己的后台线程。这些线程也是运行在当前进程、当前主机上的，也会占用CPU的资源。\n所以受环境干扰下，单靠公式很难准确的规划线程数，一定要通过测试来验证。\n流程一般是这样：\n\n分析当前主机上，有没有其他进程干扰\n分析当前JVM进程上，有没有其他运行中或可能运行的线程\n设定目标\n目标CPU利用率 - 我最高能容忍我的CPU飙到多少？\n目标GC频率&#x2F;暂停时间 - 多线程执行后，GC频率会增高，最大能容忍到什么频率，每次暂停时间多少？\n执行效率 - 比如批处理时，我单位时间内要开多少线程才能及时处理完毕\n……\n梳理链路关键点，是否有卡脖子的点，因为如果线程数过多，链路上某些节点资源有限可能会导致大量的线程在等待资源（比如三方接口限流，连接池数量有限，中间件压力过大无法支撑等）\n不断的增加&#x2F;减少线程数来测试，按最高的要求去测试，最终获得一个“满足要求”的线程数**\n\n而且而且而且！不同场景下的线程数理念也有所不同：\n\nTomcat中的maxThreads，在Blocking I&#x2F;O和No-Blocking I&#x2F;O下就不一样\nDubbo 默认还是单连接呢，也有I&#x2F;O线程（池）和业务线程（池）的区分，I&#x2F;O线程一般不是瓶颈，所以不必太多，但业务线程很容易称为瓶颈\nRedis 6.0以后也是多线程了，不过它只是I&#x2F;O 多线程，“业务”处理还是单线程\n\n所以，不要纠结设置多少线程了。没有标准答案，一定要结合场景，带着目标，通过测试去找到一个最合适的线程数。\n可能会有疑问：“我们系统也没啥压力，不需要那么合适的线程数，只是一个简单的异步场景，不影响系统其他功能就可以”\n很正常，很多的内部业务系统，并不需要啥性能，稳定好用符合需求就可以了。那么我的推荐的线程数是：CPU核心数\n附录Java 获取CPU核心数Runtime.getRuntime().availableProcessors()//获取逻辑核心数，如6核心12线程，那么返回的是12\n\nLinux 获取CPU核心数# 总核数 = 物理CPU个数 X 每颗物理CPU的核数 # 总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数# 查看物理CPU个数cat /proc/cpuinfo|grep&quot;physical id&quot;|sort|uniq|wc-l# 查看每个物理CPU中core的个数(即核数)cat /proc/cpuinfo|grep&quot;cpu cores&quot;|uniq# 查看逻辑CPU的个数cat /proc/cpuinfo|grep&quot;processor&quot;|wc-l\n\n","categories":["后端"],"tags":["Java","后端","线程池"]},{"title":"Java面试汇总","url":"/2024/08/06/2024-08-06-Java%E9%9D%A2%E8%AF%95%E6%B1%87%E6%80%BB/","content":"Java面试汇总项目问题数联网交换机Netty核心面试题20连问，由浅入深 助你轻松吊打面试官_netty面试题-CSDN博客\nTomcat与Netty比较_netty和tomcat-CSDN博客\nprogrammer club后端微服务-programmer-club项目的设计与实现心得 | Roger-Lv’s space\n项目介绍​\t大家在求职的过程中，免不了要进行面试题的学习，网上的pdf 很多，大家一般都是基于此来进行背诵或者收集，重复的题目及答案的质量参差不齐，这个个人项目，做一个线上化的面试题网站，来进行资源整合。学习面试的同时，将所学习的技术结合到一起。我们采用的是主流的微服务架构 alibaba，配合主流的中间件，前端主要是以 react 配合 antdesiqn 来进行，以C端为主的一个网站形式。叫他programmer_club，整体为一个社区的形式，主要实现的功能有刷题，练题，交流群，模拟面试。我在这里面设计技术选型，架构设计，功能的设计及落地。其中刷题模块、登录注册鉴权等模块以及优化等是我来进行主要落地实现的。\n使用DDD（领域驱动设计)的原因主要有以下几点:\n\n提高可维护性\nDDD通过将复杂的业务场景划分为简单的领域，有利于代码的阅读和维护。这有助于开发者更好地组织代码，降低系统复杂度。\n通过明确领域边界和概念，DDD使得每个领域的代码更加内聚，降低了领域之间的耦合，提高了代码的可维护性。\n\n\n提高可扩展性:\nDDD强调业务领域的划分和建模，领域之间的解耦降低了系统间的合度，有利于未来的功能扩展和新技术引入。\n清晰的领域模型设计可以更容易地支持新功能的添加和旧功能的修改，而不会影响到其他不相关的领域。\n\n\n提高灵活性:\n基于领域模型的设计使得系统能够更快地响应业务变化，提高适应性。\n当业务需求发生变化时，DDD的灵活性允许开发者通过修改或扩展领域模型来应对这些变化，而不需要对整个系统进行大规模的重构。\n\n\n促进团队沟通:\n通过清晰地定义领域边界，DDD有助于团队之间的交流和协作。每个团队成员都可以更加专注于自己所在的领域，减少跨领域沟通的成本。\n清晰的领域模型还可以作为团队成员之间的共同语言，促进对业务需求和系统设计的深入讨论和理解。\n\n\n支持复杂业务场景:\n对于涉及多个业务领域目业务逻辑复杂的项目，DDD能够显著提高系统的可维护性、可扩展性和灵活性。它可以帮助开发者更好地理解和把握业务需求，实现高质量的软件开发。\n\n\n使用业务变化：\n在业务领域变化频繁的情况下，DDD能够方便地进行模型的调整和优化，以适应不断变化的业务需求。这有助于降低因业务变动导致的开发成本，提高系统的适应能力。\n\n\n支持团队协作:\n在大型项目中，DDD有助于明确各团队的职责范围，提高团队之间的沟通协作效率。通过将系统划分为不同的领域，每个团队可以专注于自己所在领域的开发，减少了跨团队的依赖和冲突。\n\n\n\nDDD通过强调业务领域的划分和建模，提高了软件系统的可维护性、可扩展性和灵活性。这使得DDD成为应对复杂业务场景、团队协作和业务变化的有效方法论。然而，需要注意的是，DDD对开发者经验和领域知识要求较高，开发者需要避免过度设计和降低学习成本。\n是怎么在这个项目里面使用satoken的？​\t这个问题从两个方面来回答的吧：\n\n一方面是技术选型涉及的成本，大家都知道权限是每个项目都绕不开的，如何快速的接入，并且具备较好的扩展性，功能完备，使我们最开始需要考虑的一个东西，Sa-Token十分轻量，功能齐全，学习成本低，可以快速接入。\n另一方面就是复杂性考虑: Sa-Token 是一个轻量级 Java 权限认证框架，主要解决:登录认证、权限认证、单点登录、OAuth2.0、分布式Session会话、微服务网关鉴权 等一系列权限相关问题，正好符合我们的微服务分布式项目的场景，无需实现任何接口，无需创建任何配置文件，只需要一句静态代码的调用，便可以完成会话登录认证相比 Shiro、SpringSecurity 等框架的复杂，使用之后就知道 Sa-Token 的 API 设计是多么的好用,\n\n​\t说到 token 必须先说一下 cookie。传统的常规的一般是由 cookie 进行完成，Cookie 有两个特性:可由后端控制写入，每次请求自动提交。这就使得我们在前端代码中，无需任何特殊操作，就能完成鉴权的全部流程。但是在app、小程序等前后端分离场景中，一般是没有 Cookie 这一功能的。所以我们就引入 token 的这个概念。拆解出来主要是两步，一步是登录后，后端返回 token，另一部是前端请求带着 token，将 token 放到 header 里面。实现了 token 的传递之后，token 的生成过程，可以包含各种信息，比如用户的用户名，相关的权限，都可以包含在里面，这样一个 token 就可以帮助我们带来很多信息，鉴权等功能也就非常容易做了，同时还解决了cookie 问题。\nsession、cookie和token的区别_cookie,session,token的区别-CSDN博客\n登录认证是怎么做的\n如何对接公众号登录\n对接公众号主要是希望用微信的唯一的 openld，来作为唯一的标识，也方便用户的登录。\n\n整体流程主要是用户扫公众号码。然后发一条消息:验证码。\n我们通过 api 回复一个随机的码，存入redis 的主要结构，key是一个前缀+validCode，value是 OpenId。\n用户在验证码框输入之后，点击登录，进入我们的注册模块，同时关联角色和权限(数据库操作)，就实现了网关的统一鉴权，用户就可以进行操作，用户可以根据个人的 openld 来维护个人信息。\n用户登录成功之后，返回 token（satoken通过openId调用一个自带的方法登录，有一个自带的方法返回token），前端的所有请求都带着 token 就可以访问从服务涉及上，我们开一个新服务，专门用于对接某信的 api 和微信的消息的回调。\n\n\n你是如何监听用户发给公众号的消息的?\n主要是对接公众号的回调消息平台配置。重点主要分为三步:填写服务器配置，验证服务器地址的有效性，依据接口文档实现业务逻辑。\n\n在公众号配置界面填写服务器地址(URL)、Token和EncodingAESKey。\n其中URL是开发者用来接收微信消息和事件的接口URL。\nToken可由开发者可以任意填写，用作生成签名(该Token会和接口URL中包含的Token进行比对，从而验证安全性)。\nEncodingAESKey由开发者手动填写或随机生成，将用作消息体加解密密钥。\n\n\n验证消息的确来自微信服务器:某信服务器将发送GET请求到填写的服务器地址URL上，GET请求携带参数有签名，内容，时间戳之类的，后台服务要通过一样的加密形式来进行校验。\n依据接口文档实现业务逻辑:验证URL有效性成功后即接入生效，用户每次向公众号发送消息，开发者填写的服务器配置URL将得到微信服务器推送过来的消息和事件，开发者可以依据自身业务逻辑进行响应，如回复消息。\n\n\n回调消息的验证校验是如何做的？\n开发者通过检验signature对请求进行校验。若确认此次GET请求来自微信服务器，请原样返回echostr参数内容，则接入生效，成为开发者成功，否则接入失败。加密&#x2F;校验流程如下:\n1)将token、timestamp、nonce三个参数进行字典序排序\n2)将三个参数字符串拼接成一个字符串进行sha1加密\n3)开发者获得加密后的字符串可与signature对比，标识该请求来源于微信\n\n\ngateway网关是怎么设计的​\tgateway 网关，作为我们项目的整个流量入口，目前主要实现了路由，负载，统一鉴权，全局过滤器，异常处理这些功能。路由和负载承载了后台微服务的 ur 转发和前缀匹配。统一鉴权主要是配合 satoken，在 gateway 集成 redis，同时实现 satoken 提供的权限读取接口，在其中自定义读取逻辑，实现鉴权的校验。在其中还实现了登录拦截器，用于传递 loginld 到微服务中，借助了 header 的传递。\n分布式会话的鉴权在微服务中是怎么做的​\t分布式会话鉴权的重点主要是如何获取到权限数据，然后进行校验处理，一般其实有三种形式：\n\n在网关处集成ORM框架，直接从数据库查询数据。\n先从Redis中获取数据，获取不到时走ORM框架查询数据库。\n从Redis中获取缓存数据。\n\n​\t我们采取的是第三种直接从redis 中获取缓存的权限数据，这有一个要求，就是我们的 redis 的高可用性必须要高。因为我们是内部使用，这块可以采取刷新等措施，来处理极端异常情况，例如权限缓存丢失。如果想要保障的话，可以采用第二种方式，也是常见的缓存没有查数据库。从角度来看，个人觉得我们这种场景下，再集成数据库 orm 导致网关有点重，所以我们直接与缓存做交互。\ngateway如何实现全局异常处理​\tgateway 的全局异常处理主要需要我们实现一个接口ErrorWebExceptionHandler，实现其中的 handle 方法在方法内，我们能获取到其中request与response，webhandler 会帮助我们拦住所有异常的情况。然后我们可以在里面做拦截的进一步处理，更改状态码，状态错误信息等等。最后通过 response 可以将其返回出去。\n设计模式讲解java单例模式中的饿汉模式和懒汉模式的区别与使用_饿汉式和懒汉式用那个-CSDN博客\nJava基础ArrayList集合和LinkedList集合底层原理_linkedarraylist底层-CSDN博客\nJVM、JRE、JDK的关系JVM、JRE 和 JDK 是 Java 生态系统中的三个核心组件，它们在 Java 开发和运行时环境中扮演着不同的角色。\nJVM (Java Virtual Machine)\nJava 虚拟机是一种抽象计算机，它为 Java 程序提供了运行环境。JM 的主要职责是执行 Java 字节码，并将其转换为机器代码，以便在特定平台上运行。JVM 是实现 Java 平台无关性的关键组件。\n\n功能:\n字节码执行: JVM 负责加载、验证和执行Java 字节码。\n内存管理: JVM 管理堆内存和栈内存，并执行垃圾回收(GarbageCollection)\n安全性: JVM 提供了安全机制，确保Java 应用在受控环境中运行\n\n\n\nJRE (Java Runtime Environment)\nJava 运行时环境是一个软件包，它提供了运行 Java 应用程序所需的所有组件。JRE 包含 JVM 以及 Java 类库和其他支持文件。JRE 是运行 Java 应用程序的最低要求。\n\n组成:\n\nJVM:JRE包含 JVM，用于执行 Java 字节码。\n核心类库:JRE 包含 Java 标准类库(如java.lang、java.util等)，这些类库为 Java 应用提供基础功能。\n其他支持文件:包括配置文件、资源文件等。\n\n\n\nJDK (Java Development Kit)\nJava 开发工具包是为 Java 开发者提供的完整开发环境。JDK 包含 JRE 以及开发 Java 应用程序所需的工具和库。JDK是开发和编译 Java 程序的必备工具。\n\n组成:\n\nJRE:JDK 包含一个完整的 JRE 环境。\n**开发工具:**包括编译器(javac)、调试器(jdb)、打包工具(jar)等，用于开发、编译和调试 Java 程序。\n**额外的库:**提供了额外的库和头文件，用于开发Java 应用程序。\n\n\n\n关系：\n\nJVM 是JRE的一部分:JVM 是JRE中的核心组件，负责执行Java 字节码。\nJRE 是 JDK 的一部分:JRE提供了运行 Java 应用程序所需的环境。而JDK则在此基础上添加了开发工具和额外的库。\n\n总结：\n\nJVM:执行 Java 字节码的虚拟机，提供内存管理和安全机制。\nJRE:包含 JVM 和核心类库，提供运行 Java 应用程序的环境。\nJDK:包含 JRE 和开发工具，提供开发、编译和调试 Java 应用程序的完整环境。\n\nJava三大特性Java大特性是面向对象编程（OOP）的核心概念:封装、继承和多态。这些特性使得 Java 程序具有良好的结构和可维护性。\n\n封装（Encapsulation）\n封装是将对象的状态(属性)和行为(方法)组合在一起，并对外隐藏对象的内部细节，只暴露必要的接口。通过封装，可以保护对象的状态不被外部直接修改，增强了代码的安全性和可维护性。\n\n实现方式：\n使用private关键字将属性声明为私有的。\n提供public的 getter 和 setter 方法来访问和修改私有属性。\n\n\n\n\n继承（Inheritance）\n继承是面向对象编程中的一个机制，通过继承，一个类可以继承另一个类的属性和方法，从而实现代码的重用。被继承的类称为父类(超类)，继承的类称为子类(派生类)。\n\n实现方式:\n使用extends关键字来声明一个类继承另一个类\n\n\n\n\n多态(Polymorphism)\n多态是指同一个方法在不同对象中具有不同的实现方式。多态性允许对象在不同的上下文中以不同的形式表现。多态可以通过方法重载(Overloading)和方法重写(Overriding)来实现。\n\n方法重载:在同一个类中，方法名相同但参数列表不同。\n方法重写:在子类中重新定义父类中的方法。\n\n\n\n总结：\n\n封装:通过将数据和方法封装在类中，并使用访问控制符来保护数据。\n继承:通过继承机制，实现代码的重用和扩展。\n多态:通过方法重载和方法重写，实现同一方法在不同对象中的不同表现。\n\n什么是封装？封装(Encapsulation)是面向对象编程(OOP)中的一个基本概念。它涉及到将对象的状态(属性)和行为(方法)封装在一个类中，并对外部隐藏内部实现细节，只暴露必要的接口。这种做法有助于提高代码的安全性、可维护性和可重用性。\n\n属性私有化\n将类的属性声明为私有(private)，以防止外部直接访问和修改这些属性\n\n提供公共的访问方法\n通过公共(public)的 getter 和 setter 方法来控制对私有属性的访问和修改。这些方法允许外部代码在受控的情况下读取和修改属性值。\n\n隐藏实现细节\n封装还包括隐藏类内部的实现细节，只暴露必要的接口给外部使用者。这有助于降低代码的复杂性，提高模块化程度\n\n\n封装的优点：\n\n**数据保护:**通过私有化属性，可以防止外部代码直接修改对象的状态，从而保护数据的完整性简化接口:只暴露必要的方法，隐藏不需要的实现细节，使得类的接口更加简洁明了\n**提高可维护性:**封装使得类的实现细节可以独立于外部代码进行修改，只要接口不变，外部代码不需要做任何改变。\n**增强灵活性: **通过 getter 和 setter 方法，可以在访问或修改属性时添加额外的逻辑，比如数据验证或事件触发。\n\n什么是继承继承(Inheritance)是面向对象编程(OOP)中的一个核心概念。它允许一个类(子类或派生类)继承另一个类(父类或超类)的属性和方法，从而实现代码的重用和扩展。通过继承，子类可以复用父类的代码，并且可以新增或重写(覆盖)父类的方法以实现特定的功能。\n继承的基本概念：\n\n**父类(Super Class):**被继承的类，提供属性和方法。\n**子类(Sub Class):**继承父类的类，可以复用父类的代码，并且可以新增或重写父类的方法。\n**extends关键字:**用于声明一个类继承另一个类。\n\n继承的特点：\n\n单继承: Java 只支持单继承，即一个类只能有一个直接父类。\n**继承层次: **子类可以继续被其他类继承，形成继承层次结构。\n**super关键字: **用于引用父类的属性和方法，特别是在子类重写父类的方法时，可以通过super调用父类的方法。\n\n继承的优点：\n\n代码重用: 子类可以复用父类的代码，减少代码重复。\n代码扩展: 子类可以在继承父类的基础上新增属性和方法，扩展功能。\n**多态性: **通过继承和方法重写，可以实现多态性，使得同一方法在不同对象中具有不同的实现。\n\n继承中的一些注意事项\n\n**构造方法:**子类的构造方法会调用父类的构造方法。如果父类没有无参构造方法，子类必须显式调用父类的有1参构造方法。\n**方法重写(Overriding):**子类可以重写父类的方法，以提供特定的实现。重写的方法必须具有相同的方法2签名(方法名、参数列表和返回类型)。\n**super关键字:**用于调用父类的构造方法或父类的方法。例如，在子类的构造方法中使用super调用父类的构》造方法。\n\n什么是多态？多态(Polymorphism)是面向对象编程(OOP)中的一个核心概念，它允许相同的操作在不同的对象上表现出不同的行为。多态性使得一个接口可以有多种实现，从而提高代码的灵活性和可扩展性。\n多态的类型\n多态主要有两种形式:\n\n编译时多态(静态多态)):通过方法重载(Method Overloading)实现:\n运行时多态(动态多态):通过方法重写(Method Overriding)和接口实现(InterfaceImplementation)实现。\n\n编译时多态(方法重载)\n编译时多态是通过方法重载实现的，即同一个类中多个方法具有相同的名称，但参数列表不同。编译器在编译时根据方法的参数列表来决定调用哪个方法。\n运行时多态(方法重写)\n运行时多态是通过方法重写实现的，即子类重写父类的方法。在运行时，Java 虚拟机根据对象的实际类型调用对应的方法。\n接口和抽象类的多态性多态性还可以通过接口和抽象类实现。子类或实现类可以提供不同的实现，从而实现多态性。\n多态的优点\n\n**代码重用:**通过多态性，可以使用同一个接口或父类来操作不同的对象，减少代码重复。\n**灵活性和可扩展性:**多态性使得代码更加灵活，可以轻松地扩展新的子类或实现类而不影响现有代码。\n**简化代码:**通过多态性，可以使用统一的接口来处理不同的对象，简化代码逻辑。\n\n总结多态是面向对象编程中的一个重要特性，它允许相同的操作在不同的对象上表现出不同的行为。通过方法重载和方法重写，以及接口和抽象类的实现，多态性提高了代码的灵活性、可扩展性和可维护性。\n重载和重写重载(Overoading)和重写(Overriding)是面向对象编程中两个重要的概念，它们在方法定义和调用时有不同的用途和规则。\n重载(Overloading)\n定义: 在同一个类中，方法名称相同，但参数列表(参数的类型、数量或顺序)不同的多个方法。\n特性:\n\n**方法名称:**相同。\n**参数列表:**必须不同(参数的类型、数量、或顺序)。\n**返回类型:**可以相同也可以不同。\n**访问修饰符:**可以相同也可以不同。\n**静态&#x2F;实例方法:**都可以重载。\n**编译时决定:**方法的选择在编译时由编译器根据参数列表决定。\n\n重写(Overriding)\n**定义:**在子类中定义一个方法，该方法与父类中的某个方法具有相同的方法名称、参数列表和返回类型，以便在子类中提供该方法的具体实现。\n特性:\n\n方法名称:相同。\n参数列表:必须相同。\n返回类型:必须相同(Java5及以后可以是协变返回类型，即返回类型可以是父类方法返回类型的子类型)。\n访问修饰符:访问级别不能比父类方法更严格(可以更宽松)。\n静态&#x2F;实例方法:只能重写实例方法，不能重写静态方法。\n运行时决定:方法的选择在运行时由JVM 根据对象的实际类型决定(动态绑定)。\n\n总结\n\n重载:\n发生在同一个类中。\n方法名称相同，参数列表不同。\n编译时决定调用哪个方法(静态绑定)。\n\n\n重写：\n发生在子类和父类之间。\n方法名称、参数列表和返回类型必须相同(或协变返回类型）。\n运行时决定调用哪个方法(动态绑定)。\n\n\n\n构造器能否被重写？构造器不能被重写\n**定义:**构造器不能被重写(Overridden)。重写是指在子类中提供一个与父类方法具有相同签名的方法，以便在子类中提供该方法的具体实现。但构造器不属于类的继承成员，因此不能被子类重写。\n原因:\n\n**构造器的作用:**构造器的主要作用是初始化对象的状态。每个类都有自己的构造器，用于初始化该类的实例。子类不能直接继承父类的构造器，因为子类的初始化过程可能与父类不同。\n**方法签名不同:**重写要求方法签名(包括方法名称和参数列表)相同，而构造器在子类中的名称与父类不同2(构造器名称必须与类名相同)。\n**构造器不是类成员:**构造器不属于类的成员方法，它们是特殊的初始化方法，不参与继承机制。\n\n构造器可以被重载：\n虽然构造器不能被重写，但它们可以被重载(Overloaded)。构造器重载是指在同一个类中定义多个构造器，这些构造器具有相同的名称(类名)，但参数列表不同。\n结论：\n\n构造器不能被重写:因为构造器不属于类的继承成员，并且它们的名称必须与类名相同。\n构造器可以被重载:在同一个类中，可以定义多个构造器，只要它们的参数列表不同。\n\nString、StringBuilder、StringBuffer的区别\nString\n特性:\n\n不可变性:String对象是不可变的。一旦创建，字符串的内容就不能被改变。任何对字符串的修改都会生成一个新的String对象。\n线程安全:由于String对象是不可变的，它们是线程安全的，可以在多个线程中安全地共享。\n\n使用场景：\n\n适用于字符串内容不会发生变化的场景，例如字符串常量、少量的字符串操作等,\n\n\nStringBuilder\n特性:\n\n可变性:StringBuilder对象是可变的，可以对字符串内容进行修改，而不会生成新的对象。\n非线程安全:StringBuilder不是线程安全的，它的方法没有同步，因此在多线程环境中使用时需要额外注意。\n\n使用场景:\n\n适用于在单线程环境中需要频繁修改字符串内容的场景，性能比StringBuffer更高。\n\n\nStringBuffer\n特性:\n\n可变性: StringBuffer对象是可变的，可以对字符串内容进行修改，而不会生成新的对象。\n线程安全: StringBuffer是线程安全的，它的方法是同步的，可以在多线程环境中安全使用。\n\n使用场景:\n\n适用于在多线程环境中需要频繁修改字符串内容的场景。\n\n线程安全的原因：\n\n在诸多方法上加了同步锁synchronized。\n\n\n\nJDK1.8的字符串常量拼接是怎样的过程？编译时优化：\n\n编译时常量折叠:对于编译时已知的字符串常量，Java 编译器会进行常量折叠(Constant Folding)。这意味着在编译阶段，编译器会直接计算出拼接结果，并将其作为一个单一的字符串常量存储在.class文件中。例如:在编译时，这段代码会被优化为:\nString s1 = &quot;Hello &quot; + &quot;World!&quot;;// 等同于String s1 = &quot;Hello World!&quot;;\n\n非常量表达式:如果拼接的字符串包含变量或方法调用，编译器不能在编译时确定结果，因此需要在运行时进行拼接在 JDK 1.8 中，编译器会将这些拼接操作转换为使用StringBuilder的代码。例如:在编译时，这段代码会被转换为:\nString str1 = &quot;Hello&quot;;String str2 = &quot;World!&quot;;String result = s1 + &quot; &quot; + s2;//等同于StringBuilder sb = new StringBuilder();sb.append(str1);sb.append(&quot; &quot;);sb.append(str2);String result = sb.toString();\n\n运行时处理：\n\nStringBuilder的使用:\n在运行时，对于非常量的字符串拼接，StringBuilder被用来构建最终的字符串。StringBuilder是可变的，因此可以高效地进行字符串的拼接操作。\n例如:在运行时，StringBuilder会依次调用append方法，将各个部分拼接起来，并最终调用toString方法生成结果字符串。\n性能优化：\n\n循环拼接一个长字符串，建议使用StringBuilder，虽然“+”拼接字符串编译后也会变成StringBuilder，但是每次循环处理都会new一个StringBuilder对象，耗时会大大增加。而直接使用StringBuilder，new一次就可以了，效率相对高。\n例子：\n/** * 循环使用+拼接字符串 */@Testpublic void testLoopStringConcatenation03ByPlus() &#123;    long startTime = System.currentTimeMillis();    int count = 10000;    String str = &quot;testLoopStringConcatenation03ByPlus:&quot;;    for (int i = 0; i &lt; count; i++) &#123;        str = str + &quot;-&quot; + i;    &#125;    System.out.println(str);    long endTime = System.currentTimeMillis();    System.out.println(&quot;testLoopStringConcatenation03ByPlus，拼接字符串&quot; + count + &quot;次，花费&quot; + (endTime - startTime) + &quot;秒&quot;);&#125;/** * 测试循环使用StringBuilder拼接字符串耗时 */@Testpublic void testLoopStringConcatenation04ByStringBuilder() &#123;    long startTime = System.currentTimeMillis();    int count = 100000;    StringBuilder stringBuilder = new StringBuilder(&quot;testLoopStringConcatenation04ByStringBuilder:&quot;);    for (int i = 0; i &lt; count; i++) &#123;        stringBuilder.append(&quot;-&quot;);        stringBuilder.append(i);    &#125;    String str = stringBuilder.toString();    System.out.println(str);    long endTime = System.currentTimeMillis();    System.out.println(&quot;testLoopStringConcatenation04ByStringBuilder，拼接字符串&quot; + count + &quot;次，花费&quot; + (endTime - startTime) + &quot;秒&quot;);&#125;\n\ntestLoopStringConcatenation03ByPlus，拼接字符串10000次，花费463秒。\ntestLoopStringConcatenation04ByStringBuilder，拼接字符串10000次，花费13秒。\n可以看出，差异明显，不在一个量级了。\n\n\n\n\n总结：\n在 JDK 1.8 中，字符串常量的拼接过程包括编译时的常量折叠和运行时的StringBuilder优化。常量折叠在编译时完成，而对于包含变量或方法调用的拼接，编译器会将其转换为StringBuilder操作，以提高运行时的性能。\n锁Synchronized的底层实现原理（原理解析，面试必备）_synchronized底层实现原理-CSDN博客\nJava中涉及到的锁_java的锁-CSDN博客\n可重入锁详解（什么是可重入）-CSDN博客\n浅谈synchronized、wait、notify和notifyAll_synchronized,wait,notify-CSDN博客\nJava中的锁升级_java 锁升级-CSDN博客\nSynchronized锁升级：无锁-＞ 偏向锁 -＞ 轻量级锁 -＞ 重量级锁_synchronized 有多种锁状态,会从无锁 -&gt; 偏向锁 -&gt; 轻量级锁 -&gt; 重量级锁一步步-CSDN博客\nAQS谈谈Java多线程离不开的AQS_java aqs-CSDN博客\nCountDownLatchCountDownLatch介绍和使用【Java多线程必备】-CSDN博客\nsleep和wait线程的 sleep() 方法与 wait() 方法的区别_线程sleep和wait的区别-CSDN博客\nSparkSpark优化-CSDN博客\nSpark的shuffle阶段和MR的shuffle阶段分别是什么？区别是什么？_.spark 的shuffle 、mr 的shuffle 、flink 的 shuffle 有什么区-CSDN博客\n宽依赖之间会划分stage，而Stage之间就是Shuffle\nStage以RDD宽依赖（也就是shuffle）为界\n[Spark_Spark中 Stage, Job 划分依据 , Job, Stage, Task 高阶知识_spark stage-CSDN博客](https://blog.csdn.net/u010003835/article/details/132291007?ops_request_misc=%7B%22request%5Fid%22%3A%220A9E7024-0075-4926-A46C-F7E31153B849%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=0A9E7024-0075-4926-A46C-F7E31153B849&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-132291007-null-null.142^v100^pc_search_result_base8&amp;utm_term=spark stage&amp;spm&#x3D;1018.2226.3001.4187)\nspark-常用算子_spark 常用算子-CSDN博客\nMySQL深入学习MySQL事务：ACID特性的实现原理 - 编程迷思 - 博客园 (cnblogs.com)\nRedis20道经典Redis面试题-CSDN博客\nRedis的线程模式_redis io-threads-CSDN博客\n处理请求是单线程（瓶颈不是CPU，瓶颈最有可能是机器内存或者网络带宽），但后续网络I&#x2F;O变成了多线程\nRedis中的跳表是怎么回事_redis跳表原理-CSDN博客\nDocker【面试】Docker 面试篇_docker面经-CSDN博客\nspark三种模式【Standalone 模式、yarn 运行模式、local(本机)】_standalone模式-CSDN博客\n方法论如何监控慢SQL\n启用慢查询日志\n慢查询日志是 MySQL 内置的一种功能，用于记录执行时间超过指定阈值的 SQL 查询。\n配置 MySQL 配置文件(my.cnf 或 my.ini)\n在 MySQL 配置文件中添加或修改以下参数:\n[mysqld]slow_query_log=1slow_query_log_file=/var/log/mysql/slow-query.loglong_query_time =2log queries not using indexes =1\n\n\nslow_query_log: 启用慢查询日志。\nslow_query_log_file: 指定慢查询日志文件的路径。\nlong_query_time: 定义慢查询的阈值(单位:秒)。\n·log_queries_not _using_indexes: 记录末使用索引的查询。\n\n重启 MySQL服务\n修改配置文件后，重启 MySQL服务以使配置生效:\nsudo systemctl restart mysql\n\n使用 MySQL内置的性能模式(Performance Schema)\nPerformance Schema是 MySQL 内置的一个工具，用于收集数据库内部的运行时统计信息。可以通过以下步骤启用和使用 Performance Schema:\n启用Performance Scheme\n在MySQL配置文件中添加或修改以下参数：\n[mysqld]performance_schema =ON\n\n重启MySQL服务\n修改配置文件后，重启MySQL服务以使配置生效：\nsudo systemctl restart mysql\n\n查询慢查询信息\n使用以下SQL语句查询慢查询信息：\nSELECT * FROM performance_schema.events_statements_summary_by_digest ORDER BY SUM_TIMER_WAIT DESC LIMIT 10\n\n使用 MySQL 企业监控工具\nMySQL提供了企业版的监控工具，如 MySQL Enterprise Monitor，它可以自动收集、分析和报告慢查询信息。\n这个工具适合企业环境下的全面监控和管理。\n\n使用第三方监控工具\n有许多第三方监控工具可以帮助你监控 MySQL的性能，包括慢查询。这些工具通常提供更丰富的功能和更友好的界面。常见的第三方工具包括:\n\n**Percona Monitoring and Management (PMM):**一个开源的监控和管理工具，专为 MySQL和MongoDB 设计。\n**New Relic:**一个强大的应用性能监控工具，支持 MySQL 和其他数据库。\n**Datadog:**一个综合性的监控平台，支持 MySQL 和其他数据库。\n\n\n使用 SQL分析工具\nMySQL提供了EXPLAIN语句，用于分析 SQL查询的执行计划。通过分析执行计划，可以识别和优化慢查询\n使用EXPLAIN分析查询\nEXPLAIN SELECT * FROM your_table WHERE your_condition;\n\nEXPLAIN的输出结果包含了查询执行的详细信息，包括使用的索引、扫描的行数等。通过分析这些信息，可以找出查询的性能瓶颈并进行优化。\n\n\n总结\n监控慢 SQL是一个持续的过程，需要结合多种工具和方法。以下是一个综合的监控策略:\n\n启用慢查询日志:记录执行时间超过阈值的查询。\n使用 Performance Schema:收集和分析详细的运行时统计信息。\n使用企业监控工具:如 MySQLEnterprise Monitor，进行全面的监控和管理。\n使用第三方监控工具:如 Percona Monitoring and Management(PMM)、New Relic、Datadog 等。\n使用 SQL 分析工具:如EXPLAIN，分析和优化查询执行计划。\n\nMySQL常用监控指标\nQPS: 数据库每秒处理的请求数量\nshow global status where variable_name in(&#x27;Queries&quot;,&#x27;uptime&#x27;);\n\nQPS &#x3D;(Queries2 -Queries1)&#x2F;(uptime2 -uptime1)\n\nTPS: 数据库每秒处理的事务数量\nshow global status where variable name in(&#x27;com insert&#x27;,com delete&#x27;,com update&#x27;,&#x27;uptime&#x27;);\n\n事务数TC  ≈ ‘com_insert’,’com_delete’,’com_update’\nTPS ≈ (TC2 -TC1)&#x2F;(uptime2 -uptime1)\n\n并发数：数据库实例当前并行处理的会话数量\nshow global status like &#x27;Threads_running&#x27;;\n\n连接数：连接到数据库会话的数量\nshow global status like &#x27;Threads connected&#x27;;\n\n缓存命中率：查询命中缓存的比例\ninnodb缓冲池查询总数:\nshow global status like &#x27;innodb_buffer_pool_read_requests&#x27;;\n\ninnodb从磁盘查询数:\nshow global status like &#x27;innodb_buffer_pool_reads&#x27;;\n\n生产中配置报警阈值:innodb buffer pool read requests &#x2F;(innodb buffer pool read requests +innodb buffer pool reads)&gt;0.95\n\n可用性:数据库是否可以正常对外服务\n周期性连接数据库并执行 select @@version;\n\n阻塞：当前阻塞的会话数\nselect waiting_pid as &#x27;被阳塞线程&#x27;,\twaiting_query as &#x27;被阻塞SQL&#x27;,\tblocking_pid as &#x27;阻塞线程&#x27;,\tblocking_query as &#x27;阻塞SQL&#x27;,\twait_age as &#x27;阻塞时间’,\tsql_ki1l_blocking_query as&#x27;建议操作&#x27;from sys.innodb_lock_waitswhere(unix_timestamp()-unix_timestamp(wait started))&gt;阻塞秒数\n\n慢查询：慢查询情况\n开启慢查询日志。my.inf\nslow_query_log=onslow_query_log_file=存放目录long_query_time=0.1秒log_queries_not_using_indexes=on\n\n慢sql优化方向\n检查查询语句本身。确保使用了合适的索引，避免全表扫描。比如，在WHERE、JOIN或ORDER BY子句中涉及的列上创建索引，这样可以大大提升查询速度。\n优化数据库设计。比如，使用表分区来处理大表，或者根据实际需要在规范化和反规范化之间做出平衡，以减少复杂的JOIN操作。\n调整 MVSQL的配置参数。比如，增加 InnoDB 缓冲池的大小，让更多的数据可以缓存在内存中，减少磁盘 &#x2F;&#x2F;O 操作。同时，根据需要调整查询缓存的大小。\n使用一些性能分析工具，比如EXPLAIN，来分析查询的执行计划，找出性能瓶颈。PerformanceSchema 也是一个很好的工具，可以帮助收集详细的性能数据。\n持续的监控和调优是必不可少的。使用一些监控工具，比如Percona Monitoring and Management(PMM) 或 Datadog，来实时监控数据库的性能，并定期审查和优化慢查询，确保数据库始终保持高效。\n\n详细解读：\n\n优化查询语句\n使用适当的索引\n\n创建索引: 确保查询使用了适当的索引。对频繁出现在WHERE、JOIN、ORDER BY和GROUP BY子句中的列创建索引。\nCREATE INDEX idx_column_name on table_name(column_name);\n\n复合索引：对于多列查询，考虑使用复合索引(多列索引)。\nCREATE INDEX idx_columns ON table_ name(column1,column2);\n\n避免全表扫描\n\n使用合适的过滤条件: 确保WHERE子句中的条件能够有效地利用索引，避免全表扫描。\nSELECT * FROM table_name WHERE index_colum = &#x27;value&#x27;;\n\n限制返回的行数：使用LIMIT字句限制返回的行数，减少数据库的负担。\nSELECT * FROM table name WHERE condition LIMIT 10;\n\n优化JOIN操作\n\n使用小表驱动大表：在JOIN操作中，确保小表在前，大表在后。\nSELECT * FROM small_table ST JOIN large_table LT on ST.id=LT.id;\n\n避免不必要的复杂查询\n\n简化查询：尽量简化查询，避免使用不必要的子查询和嵌套查询。\n# 避免复杂的嵌套查询SELECT*FROM table_name WHERE id IN(SELECT id FROM another_table WHERE condition);# 使用JOIN替代SELECT * FROM table_name JOIN another_table ON table_name.id = another_table.id WHERE condition;  \n\n\n优化数据库设计\n规范化与反规范化\n\n规范化:确保数据库设计符合第三范式，减少数据几余，\n反规范化:在某些情况下，为了性能，可以适度反规范化，减少复杂的JOIN操作。\n\n分区表\n\n表分区:对于非常大的表，可以使用表分区，将数据分成更小的部分，提高查询性能。\nCREATETABLE orders\torder id INT,\torder date DATE,\t...)PARTITIONBYRANGE(YEAR(order date))(PARTITION PO VALUES LESS THAN(2020),PARTITION PI VALUES LESS THAN(2021),PARTITION P2 VALUES LESS THAN(2022));\n\n\n优化服务器配置\n调整 MySQL 配置参数\n\n**调整缓冲池大小:**对于InnoDB 存储引擎，调整innodb_buffer_pool_size参数，使其尽量大(但不要超过物理内存的 70-80%)。\n[mysqld]innodb_buffer_pool_size = 4G\n\n**调整查询缓存:**根据应用需求，调整查询缓存大小。\n[mysqld]query_cache_size =64M\n\n使用合适的存储引擎：\n\n选择适当的存储引擎:根据应用需求选择合适的存储引警(如InnoDB、MyISAM)。\n\n\n使用性能分析工具\n使用EXPLAIN分析查询\n\n分析执行计划：使用EXPLAIN分析查询的执行计划，识别性能瓶颈。\nEXPLAIN SELECT*FROM your table WHERE your condition;\n\n使用性能模式（Performance Schema）\n\n收集性能数据:使用 Performance Schema 收集详细的性能数据，分析慢查询。\nSELECT*FROM performance_schema.events_statements_summary_by_digest ORDER BY SUM_TIMER_WAIT DESC LIMIT 10;\n\n\n监控和调优\n持续监控\n\n**使用监控工具:**使用 MySQLEnterprise Monitor、Percona Monitoring and Management (PMM)、New Relic、Datadog 等工具持续监控数据库性能。\n\n定期调优\n\n**定期审查查询:**定期审查和优化慢查询，确保数据库性能持续提升。\n\n\n\nTomcat你是否傻傻分不清SpringBoot默认线程池和内置Tomcat线程池？_springboot 默认线程池-CSDN博客\nJVMJVM的主要组成部分\n类加载子系统（五步）\n\n描述:类加载子系统负责将 .class 文件加载到内存中，并进行验证、准备、解析和初始化。\n主要功能:\n加载:从文件系统或网络中读取 .class 文件。\n验证:确保字节码文件的正确性和安全性。\n准备:为类的静态变量分配内存并设置默认初始值。\n解析:将符号引用转换为直接引用。\n初始化:执行类的静态初始化块和静态变量的初始化。\n\n\n\n\n运行时数据区（五部分）\nJVM 在运行时将内存划分为多个不同的数据区域，每个区域都有特定的用途。\n\n方法区(Method Area): 存储已加载的类信息、常量、静态变量、即时编译器编译后的代码等。\n堆(Heap): 存储所有对象实例和数组，是垃圾收集的主要区域。\nJava 栈(Java Stacks): 每个线程都有自己的 Java 栈，存储局部变量表、操作数栈、动态链接、方法返回地址等信息。\n本地方法栈(Native Method stacks): 为本地方法调用服务，存储本地方法调用的状态。\n程序计数器(Program Counter Register):每个线程都有自己的程序计数器，指示当前线程执行的字节码行号。\n\n\n执行引擎（三部分）\n\n描述: 执行引擎负责执行字节码指令,\n主要组件:\n解释器(Interpreter): 逐条解释执行字节码指令，速度较慢。\n即时编译器(Just-In-Time Compiler, JIT): 将热点代码(频繁执行的代码)编译为本地机器码，提高执行速度。\n**垃圾收集器(Garbage Colector, GC):**自动管理内存，回收不再使用的对象，防止内存泄漏。\n\n\n\n\n本地接口\n\n**描述:**本地接口(通常是Java Native Interface,JNI)允许Java 代码与本地(非Java)代码进行交互。\n主要功能:\n调用本地方法(通常是用C或C++编写的)。\n允许 Java 代码使用操作系统特性或访问硬件。\n\n\n\n\n本地方法库\n\n描述:本地方法库是存储本地方法实现的动态链接库(如.d 文件或.so 文件)。\n主要功能:\n提供本地方法的具体实现。\n由本地接口调用以执行本地代码。\n\n\n\n\n\n总结：\n\n类加载子系统: 负责加载、验证、准备、解析和初始化类。\n运行时数据区: 包括方法区、堆、Java 栈、本地方法栈和程序计数器。\n执行引擎: 包括解释器、即时编译器和垃圾收集器。\n本地接口: 允许 Java 代码与本地代码交互。\n本地方法库: 存储本地方法实现的动态链接库。\n\nJVM堆的内部结构是什么？​\tJVM 堆是 Java 虚拟机用于存储对象实例和数组的内存区域。堆内存是 JVM 管理的主要内存区域之一，堆内存的管理和优化对 Java 应用程序的性能至关重要。堆内存的内部结构通常分为几个不同的区域，以便更高效地进行内存分配和垃圾回收。\n\n新生代(Young Generation)\n新生代用于存储新创建的对象。大多数对象在新生代中创建，并且很快就会被垃圾回收。新生代进一步分为三个区域：\n\n**Eden 区(Eden Space): **大多数新对象首先分配在 Eden 区。当 Eden 区填满时，会触发一次轻量级的垃圾回收(Minor GC)。\n**幸存者区(Survivor Spaces): **新生代中有两个幸存者区，称为S0(Survivor0)和S1(Survivor 1)。在一次 Minor GC之后，仍然存活的对象会从 Eden 区和当前的幸存者区复制到另一个幸存者区（标记复制）。两个幸存者区会在每次 GC 后交替使用。\n\n\n老年代(Old Generation)\n老年代用于存储生命周期较长的对象。那些在新生代经历了多次垃圾（默认15次）回收仍然存活的对象会被移动到老年代。老年代的垃圾回收相对较少，但每次回收的时间较长，称为 Major GC 或 FuI GC。\n\n永久代(Permanent Generation)和元空间(Metaspace)\n\n**永久代(Permanent Generation): **在JDK8之前，永久代用于存储类的元数据、常量池、方法信息等。永久代的大小是固定的，容易导致OutOfMemoryError错误。\n**元空间(Metaspace): **从JDK8开始，永久代被元空间取代。元空间不在JVM堆中，而是使用本地内存。元空间的大小可以动态调整，减少了OutOfMemoryError的风险。\n\n\n\nJVM堆和栈的区别​\t在 JVM(Java Virtual Machine)中，堆(Heap)和栈(Stack)是两种不同的内存区域，它们在内存管理和程序执行中扮演着不同的角色。以下是它们的主要区别:\n\n存储内容\n\n堆：\n用于存储所有的对象实例和数组。\n所有对象实例和数组都在堆中分配内存。\n\n\n栈：\n用于存储局部变量表、操作数栈、动态链接、方法返回地址)。\n每个线程都有自己的栈，栈中的数据与线程–对应。\n\n\n\n\n内存管理方式\n\n堆：\n由垃圾收集器(Garbage Collector)进行自动管理，负责分配和回收对象内存。\n堆内存是全局共享的，所有线程都可以访问堆中的对象。\n\n\n栈：\n由编译器自动管理，内存分配和释放按照方法调用的顺序进行(LIFO，后进先出)。\n栈内存是线程私有的，每个线程都有自己的栈，互不干扰。\n\n\n\n\n生命周期：\n\n堆：\n对象在堆中的生命周期由垃圾收集器决定，只要有引用指向对象，对象就会存在对象的生命周期可以跨越多个方法调用，直到没有引用指向它时才会被垃圾收集器回收。\n\n\n栈：\n局部变量的生命周期与方法调用的生命周期一致，方法调用结束时，栈帧被销毁，局部变量也随之销毁。\n栈中的数据在方法调用结束后立即释放。\n\n\n\n\n内存大小:\n\n堆：\n适合存储需要较长生命周期的大量对象。\n通常较大，可以通过 JVM 参数(如-Xms和-Xmx)进行配置。\n\n\n栈：\n通常较小，每个线程的栈大小可以通过 JVM 参数(如-Xss)进行配置。\n适合存储短生命周期的小数据。\n\n\n\n\n线程安全\n\n堆：\n由于是全局共享的，堆中的对象在多线程环境下需要进行同步控制，以避免线程安全问题。\n\n\n栈：\n由于是线程私有的，栈中的数据天然是线程安全的，不需要额外的同步控制。\n\n\n\n\n访问速度\n\n堆：\n访问速度相对较慢，因为需要通过引用进行访问，并且涉及到垃圾收集器的管理。\n\n\n栈：\n访问速度相对较快，因为栈中数据直接通过栈帧进行访问，且且栈的内存分配和释放效率高。\n\n\n\n\n内存溢出\n\n堆：\n如果堆内存不足，会抛出OutOfMemoryError(如java.lang.OutOfMemoryError: Java heap space)。\n\n\n栈：\n如果栈内存不足，会抛出StackOverflowError(如java.lang.StackOverflowError)。\n\n\n\n\n\n总结\n\n堆: 用于存储对象实例和数组，由垃圾收集器管理，生命周期较长，内存较大，线程共享。\n栈: 用于存储局部变量和方法调用信息，由编译器管理，生命周期短，内存较小，线程私有。\n\nJVM运行时的数据区域如何理解？Java 虚拟机(JM)在运行时将内存划分为若干不同的数据区域，每个区域都有特定的用途。\nJVM 运行时数据区域\nJVM 运行时数据区域主要包括以下几个部分:\n\n方法区(Method Area)\n堆(Heap)\nJava 栈(Java Stacks)\n本地方法栈(Native Method Stacks)\n程序计数器(Program Counter Register)\n\n方法区(Method Area)\n\n描述: 方法区是所有线程共享的内存区域，用于存储已被 JVM 加载的类信息、常量、即时编译器静态变量、编译后的代码等数据。\n功能:\n存储类的结构信息(如类的名称、访问修饰符、字段描述、方法描述等)。\n包括字面量和符号引用。存储运行时常量池。\n存储静态变量\n存储编译后的代码。\n\n\n在 HotSpot JVM 中，方法区的一部分实现为永久代(PermGen)，在 Java8 及以后版本中被称为元空间(Metaspace)。\n\n堆(Heap)\n\n描述: 堆是所有线程共享的内存区域，用于存储所有对象实例和数组。\n功能:\n动态分配对象内存。\n垃圾收集器主要在堆上工作，回收不再使用的对象内存。\n\n\n堆通常分为年轻代(Young Generation)和老年代(Old Generation)，年轻代又进一步划分为 Eden 区和两个Survivor区(S0和S1)。\n\nJava 栈(Java Stacks)\n\n描述: 每个线程都有自己的 Java 栈，栈帧(Stack Frame)在栈中按顺序存储。\n功能:\n存储局部变量表、操作数栈、动态链接、方法返回地址等信息。\n每调用一个方法，就会创建一个新的栈帧，方法执行完毕后栈帧被销毁。\n\n\n栈帧包括:\n局部变量表:存储方法的局部变量，个包括参数和方法内部的局部变量\n操作数栈:用于操作数的临时存储。\n动态链接:指向常量池的方法引用，\n方法返回地址:方法调用后的返回地址，\n\n\n\n本地方法栈（Native Method Stacks）\n\n**描述:**本地方法栈与 Java 栈类似，但它为本地(Native)方法服务。\n\n功能:\n\n存储本地方法调用的状态。\n一些 JVM 使用 C 栈来支持本地方法调用。\n\n\n\n程序计数器(Program Counter Register)\n\n**描述:**每个线程都有自己的程序计数器，是一个很小的内存区域。\n功能:\n当前线程所执行的字节码的行号指示器。\n如果当前执行的是本地方法，这个计数器值为空(Undefined)。\n\n\n\n总结\n\n方法区: 存储类信息、常量、静态变量、即时编译代码。\n堆: 存储对象实例和数组，是垃圾收集的主要区域。\nJava 栈: 每个线程有一个，存储方法调用的帧。\n本地方法栈: 存储本地方法调用的状态。\n程序计数器: 存储当前线程执行的字节码行号\n\n为什么要分Eden和Survivor?在JVM 中将新生代(Young Generation)分为 Eden 区和两个Survivor区(S0和S1)的主要原因是为了优化垃圾回收的效率和性能。这种分区策略基于对象的生命周期特点，利用复制算法来减少内存碎片和提高垃圾回收的效率。\n\n优化垃圾回收效率\n新生代的垃圾回收通常使用复制算法(Copying Algorithm)，这种算法的核心思想是将存活的对象从一个区域复制到另一个区域，而不是在原地进行标记和清除。复制算法的步骤如下:\n\n**对象分配:**新创建的对象首先分配在 Eden 区。。\n**Minor GC 触发:**当 Eden 区填满时，会触发一次 Minor GC\n**对象复制:**在 Minor GC 过程中，存活的对象会从 Eden 区和当前使用的 Survivor 区(例如 S0)复制到另一个 Survivor 区(例如 S1)。复制完成后，Eden 区和当前使用的 Survivor 区将被清空。\n**区域交换:**两个 Survivor 区在每次 GC 后交替使用。\n\n这种算法的优点是:\n\n**减少内存碎片: **复制算法通过将存活对象紧密排列在一起，避免了内存碎片的问题。\n**提高回收速度:**复制算法只需要遍历存活对象，而不需要遍历整个内存区域，这使得垃圾回收的速度更快。\n\n\n优化内存分配\n将新生代分为 Eden 区和两个 Survivor 区，能够更好地管理对象的生命周期\n\n大多数对象生命周期短: 大多数新创建的对象很快就会变得不可达并被回收。Eden 区专门用于存储这些短生命周期对象，提高了内存分配和回收的效率。\n\n**幸存者对象管理:**那些在一次或多次 Minor GC后仍然存活的对象会被复制到 Survivor 区。通过在两个Survivor 区之间复制和交换，可以有效管理这些对象的生命周期，直到它们被提升到老年代。\n\n\n\n减少GC停顿时间：\n复制算法和分区策略有助于减少 GC 停顿时间(GC Pause Time)，提高应用程序的响应速度:\n\nMinor GC 更快速: 由于新生代通常较小，并且复制算法只处理存活对象，Minor GC 的停顿时间通常较短。\n**老年代 GC减少:**通过有效管理新生代的对象，减少了老年代的对象数量和垃圾回收频率，从而减少了Major GC 或 Ful GC 的次数和停顿时间。\n\n\n\n示例：\n\n假设有一个新生代大小为1GB，其中Eden区占80%(800MB)，两个Survivor 区各占 10%(100 MB)。对象首先分配在 Eden 区，当 Eden 区填满时，触发 Minor Gc，将存活对象复制到一个 Survivor 区。下次 GC时，再将存活对象从当前 Survivor 区复制到另一个 Survivor 区。\n\n总结：\n\n将新生代分为 Eden 区和两个 Survivor 区的主要目的是优化垃圾回收的效率和性能。通过利用复制算法，可以减少内存碎片，提高垃圾回收速度，并有效管理对象的生命周期，从而减少GC停顿时间，提高应用程序的响应速度。这种分区策略是 JVM 内存管理的重要组成部分，帮助提高Java 应用程序的性能和稳定性。\n\n什么是JVM方法区？JVM 方法区(Method Area)是 JVM 运行时数据区的一部分，用于存储与类和方法相关的元数据。它是所有线程共享的内存区域，包含了 JVM 加载的类信息、常量、静态变量、即时编译器编译后的代码等。方法区的内容在JVM 启动时创建，并在 JVM 运行期间动态扩展或收缩。\n方法区的主要内容：\n\n**类信息:**包括类名、父类名、访问修饰符、接口列表等的元数据。\n**运行时常量池:**存储编译期生成的各种字面量和符号引用，这些引用在类加载后被解析为直接引用。\n**静态变量:**类的静态字段，存储类级别的变量。\n**即时编译器编译后的代码:**即时编译器(JIT)将热点代码编译为本地机器码，存储在方法区中。\n**字段和方法信息:**包括字段描述、方法描述、方法字节码、方法的访问修饰符等。\n\n方法区在不同 JVM 实现中的差异：\n在不同的 JVM 实现中，方法区的具体实现和管理方式可能有所不同。\n以下是一些常见的 JVM 实现方式:\n\nHotSpot JVM(Java7及之前):方法区实现为永久代(Permanent Generation，PermGen)。永久代的内存空间固定，容易**导致内存溢出(OutOfMemoryError)**。\nHotSpot JVM (Java8及之后):方法区实现为元空间(Metaspace)。元空间使用本地内存(Native Memory)，默认情况下可以根据需要动态扩展，减少了内存溢出的风险。\n\n方法区的内存管理：\n方法区的内存管理主要包括以下几个方面:\n\n类加载: 当一个类被加载时，其相关信息会被存储在方法区中。\n类卸载：当一个类不再被使用且没有任何引用时，垃圾收集器可以回收方法区中的类元数据。\n垃圾收集: 方法区的垃圾收集主要针对废弃的类元数据和常量池中的无用常量。相比堆内存的垃圾收集，方法区的垃圾收集频率较低。\n\n方法区相关的异常：\n由于方法区存储了大量的类元数据和常量，可能会出现以下异常:\n\nOutOfMemoryError: PermGen space: 在Java7及之前的版本中，永久代空间不足时会抛出此异常。\nOutOfMemoryError: Metaspace:在 Java8 及之后的版本中，元空间内存不足时会抛出此异常。\n\n总结：\n\n方法区是 JVM 运行时数据区的一部分，用于存储类和方法的元数据。\n方法区存储类信息、运行时常量池、静态变量、即时编译器编译后的代码以及字段和方法信息。\n在不同的 JVM 实现中，方法区的管理方式可能不同，例如 HotSpot JVM 在 Java8 之前使用永久代(PermGen)，在Java8之后使用元空间(Metaspace)。\n方法区的内存管理包括类加载、类卸载和垃圾收集。\n常见的异常包括OutOfMemoryError: PermGen space和OutOfMemoryError: Metaspace.\n\nJava双亲委派机制是什么JVM 的双亲委派机制(Parent Delegation Model)是一种类加载机制，用于确保 Java 类加载过程的安全性和一致性。\n它的主要思想是:每个类加载器在加载类时，首先将请求委派给父类加载器，只有当父类加载器无法完成加载时，才由当前类加载器尝试加载类。\n双亲委派机制的工作流程：\n\n启动类加载器(Bootstrap ClassLoader): 负责加载Java 核心库(位于JAVA HOME&#x2F;lib目录下的类库，如rt.jar)。\n扩展类加载器(Extension ClassLoader): 负责加载Java 扩展库(位于JAVA HOME&#x2F;ib&#x2F;ext目录下的类库)。\n应用程序类加载器(Application ClassLoader): 负责加载应用程序类路径(classpath)上的类。\n\n启动-&gt;扩展-&gt;应用程序类\n加载类的具体步骤如下:\n\n当前类加载器收到类加载请求:当一个类加载器收到加载类的请求时，它不会立即尝试加载该类。\n将请求委派给父类加载器:当前类加载器首先将加载请求委派给父类加载器。\n父类加载器处理请求:\n如果父类加载器存在，则父类加载器会继续将请求向上委派，直到到达启动类加载器。\n启动类加载器尝试加载类，如果成功，则返回类的引用。\n\n\n父类加载器无法加载类:如果启动类加载器无法加载该类，加载失败返回到子类加载器。\n当前类加载器尝试加载类:如果父类加载器无法加载该类，则由当前类加载器尝试加载。\n\n通过这种机制，可以确保核心类库不会被篡改，避免了类的重复加载和类的冲突问题。\n（委派是向上委派的，执行是从上到下的。）\n双亲委派机制的优点：\n\n安全性:通过将类加载请求逐级向上委派，可以避免核心类库被篡改或替换，确保系统安全。\n\n避免类的重复加载:确保每个类只被加载一次，避免类的重复加载和类的冲突问题。\n\n提高加载效率:通过委派机制，可以利用已经加载的类，提高类加载的效率。\n\n\n双亲委派机制的例外（自定义类加载器和一些框架中）：\n尽管双亲委派机制是 Java 类加载的标准机制，但在某些情况下，这一机制会被打破。例如:\n\n自定义类加载器:某些自定义类加载器可能会覆盖默认的双亲委派机制，直接加载类。\nOSGi 框架:OSGi 框架中，类加载机制更加复杂，可能会打破双亲委派机制。\nSPl(Service Provider Interface):在某些服务提供者接口的实现中，可能需要打破双亲委派机制来加载服务实现类。\n\n总结：\n\n双亲委派机制是 Java 类加载过程中的一个重要机制，通过将类加载请求逐级向上委派，确保了类加载的安全性和一致性。\n\nJava双亲委派机制的作用\n保证 Java 核心库的安全性通过双亲委派机制，Java 核心库(如java.lang.Object等)由启动类加载器(Bootstrap ClassLoader)加载。由于启动类加载器是在 JVM 启动时由本地代码实现的，并且它加载的类路径是固定的系统核心库路径，因此可以确呆这些核心类不会被篡改或替换。这样，系统的安全性和稳定性得到了保障。\n\n避免类的重复加载\n双亲委派机制确保了每个类只会被加载一次。如果一个类已经被父类加载器加载过，那么子类加载器就不会再重复加载这个类。这样可以避免类的重复加载，提高类加载的效率，并减少内存消耗。\n\n保证类加载的一致性\n通过双亲委派机制，可以确保同一个类在整个 JVM 中只有一个定义。这样可以避免类的冲突和不一致问题。例如，如果应用程序和第三方库中都定义了一个相同的类名，通过双亲委派机制可以确保最终加载的是位于更高层次的类加载器中的类，从而避免冲突。\n\n提高类加载的效率\n双亲委派机制通过将类加载请求逐级向上委派，可以利用已经加载的类，提高类加载的效率。父类加载器在加载类时，如果该类已经被加载过，那么直接返回该类的引用，从而减少了重复加载的开销。\n\n支持动态扩展\n双亲委派机制允许在不同的类加载器中加载不同的类，从而支持动态扩展。例如，应用程序类加载器(Application ClassLoader)可以加载应用程序特定的类，而扩展类加载器(Extension ClassLoader)可以加载扩展库中的类，这样可以方便地进行动态扩展和模块化开发。\n\n\n总结：\n安全性-&gt;避免重复加载-&gt;避免冲突保持一致性-&gt;提高加载效率-&gt;支持动态扩展。\nSpring MVC什么是Spring MVCSpring MVC是 Spring 框架中的一个模块，用于构建基于 Web 的应用程序。它遵循 Model-View-Controler(MVC)设计模式，将业务逻辑、用户界面和数据分离，以促进代码的可维护性和可扩展性。\n\n模型(Model)模型代表应用程序的数据和业务逻辑。它通常包含数据对象(如POJO)和服务层(如 Spring 服务)来处理业务逻辑。模型负责从数据库或其他数据源获取数据，并将数据传递给视图以显示给用户。\n视图(View)视图负责展示数据，通常是 HTML 页面或其他类型的用户界面。Spring MVC支持多种视图技术，包括 JSP、Thymeleaf、FreeMarker 等。视图从模型获取数据并将其呈现给用户。\n控制器(Controller)控制器处理用户请求并决定将数据传递给哪个视图。它接收用户输入，调用模型进行处理，并选择合适的视图来显示结果。控制器通常使用@Controller 注解来标识，并使用 @RequestMapping 注解来映射 URL 请求。\n\nSpring MVC 的工作流程\n\n用户请求: 用户通过浏览器发送 HTTP 请求到服务器。\n前端控制器(DispatcherServlet): Spring MVC的前端控制器 DispatcherServlet 拦截所有请求并进行分发。\n处理器映射(Handler Mapping): 根据请求 URL，DispatcherServlet 查找相应的控制器。\n控制器处理: 控制器处理请求，调用服务层或数据访问层以获取数据，并将数据封装到型中。\n视图解析器(View Resolver): 控制器返回视图名称， DispatcherServlet 使用视图解析器将视图名称解析为实际的视图对象。\n视图渲染: 视图对象负责将模型数据渲染为用户界面，通常是 HTML页面。\n响应返回: 渲染后的视图返回给 DispatcherServlet，DispatcherServlet 将最终的响应发送回用户浏览器。\n\n核心组件\n\n**DispatcherServlet:**前端控制器，负责接收并分发请求\n**Controller:**处理用户请求，包含业务逻辑。\nModelAndView: 包含模型数据和视图名称的对象。\n**View Resolver:**将视图名称解析为实际的视图对象。\n**Handler Mapping:**根据请求 URL 查找相应的控制器。\n\nSpringMVC的原理及执行流程组件Spring MVC是一个基于Java的实现了MVC设计模式的请求驱动类型的轻量级Web框架，它大量使用了Spring框架中提供的设计模式。Spring MVC框架的核心组件包括:\n\nDispatcherServet:前端控制器，负责接收请求并根据映射关系调用相应的控制器\nHandlerMapping:负责根据请求的URL到HandlerMapping中找到映射的处理器(Controller)。\nHandlerAdapter:负责根据处理器，生成处理器适配器，通过适配器调用实际的处理器。\nController:处理器，执行相应的业务逻辑操作，并返回ModelAndView对象。\nModelAndView:包含了视图逻辑名和模型数据的对象，是连接控制器和视图的桥梁。\nViewResolver:负责解析视图名到具体视图实现类的映射，根据视图名称找到对应的视图实现类。\nView:视图，负责渲染数据并展示给用户。\n\n执行流程Spring MVC 的执行流程大致可以分为以下几个步骤\n\n发送请求到DispatcherServlet: 用户向服务器发送请求，请求被DispatcherServlet捕获。\n查找Handler: DispatcherServlet根据请求URL到HandlerMapping中查找映射的处理器(Controller)。\n调用HandlerAdapter: DispatcherServlet根据处理器，到HandlerAdapter中找到对应的处理器适配器。\n执行Controller: 处理器适配器调用实际的处理器(Controler)执行业务逻辑操作，并返回ModelAndView对象。\n处理ModelAndView: DispatcherServlet根据ModelAndView中的视图名称，到ViewResolver中找到对应的视图实现类。\n渲染视图: 视图实现类根据ModelAndView中的数据和视图模板渲染视图。\n返回响应到客户端: DispatcherServet将渲染后的视图返回给客户端。\n\n什么是DispatcherServletDispatcherServlet 充当前端控制器(Front Controller)，负责接收所有进入的 HTTP 请求并将它们分派给适当的处理器进行处理。 DispatcherServlet 是实现 MVC 模式的关键部分，负责协调整个请求处理流程。\n主要职责\n\n**请求接收和分派:**拦截所有进入的 HTTP 请求并将它们分派给适当的控制器(Controller)\n**处理器映射:**根据请求 URL，查找相应的处理器(通常是控制器方法)。\n**视图解析:**将控制器返回的视图名称解析为实际的视图对象。\n**请求处理:**调用处理器进行请求处理，并将处理结果封装到模型中。\n**视图渲染:**将模型数据传递给视图对象进行渲染，并生成最终的响应。\n\n工作流程\n以下是 DispatcherServlet 的详细工作流程:\n\n初始化:\n在应用程序启动时， DispatcherServlet被初始化。它加载 Spring 应用程序上下文，配置处理器映射、视图解析器等组件。\n\n\n接收请求:\n用户通过浏览器发送 HTTP 请求到服务器。\nDispatcherServlet 拦截所有符合配置的 URL 模式的请求。\n\n\n处理器映射:\nDispatcherServlet 使用处理器映射器(Handler Mapping)根据请求 URL 查找相应的处理器(Controller)。\n\n\n调用处理器:\n找到处理器后， Dispatcherservlet 调用处理器的方法进行请求处理。\n处理器执行业务逻辑，通常会调用服务层或数据访问层获取数据，并将数据封装到型中。\n\n\n视图解析：\n处理器处理完请求后，返回一个包含视图名称和模型数据的ModelAndview 对象。\nDispatcherServlet 使用视图解析器(View Resolver)将视图名称解析为实际的视图对象。\n\n\n视图渲染:\n视图对象负责将模型数据渲染为用户界面，通常是 HTML 页面。\n\n\n响应返回:\n渲染后的视图返回给 DispatcherServlet，Dispatcherservlet 将最终的响应发送回用户浏览器。\n\n\n\n什么是Handler MappingHandler Mapping 负责将 HTTP 请求映射到相应的处理器(通常是控制器方法)。当DispatcherServlet接收到一个请求时，它会使用 Handler Mapping 来确定哪个处理器应该处理这个请求。\n主要职责\n\n**请求映射:**根据请求的 URL、HTTP 方法、请求参数等信息，查找并确定相应的处理器。\n**处理器返回:**返回一个包含处理器对象和处理器拦截器链的 HandlerExecutionchain 对象。\n\n工作流程\n\n请求到达Dispatcherservlet:当一个HTTP 请求到达 DispatcherServlet 时，它会首先交给 Handler Mapping 进行处理。\n**查找处理器:**Handler Mapping根据请求的 URL、HTTP 方法等信息查找匹配的处理器。\n返回处理器: Handler Mapping 返回一个 HandlerExecutionchain 对象，其中包含处理器(通常是控制器方法)和处理器拦截器链。\n处理请求: DispatcherServlet 使用找到的处理器来处理请求，并生成响应。\n\n常见的 Handler Mapping 实现\n\nBeanNameUrlHandlerMapping：\n通过 bean 的名称来映射处理器。\n例如，bean 名称为&#x2F;hello 的处理器会处理 &#x2F;hello 请求。\n\n\nSimpleUrlHandlerMapping：\n通过显式配置的 URL 路径来映射处理器。\n可以在 Spring 配置文件中指定 URL 到处理器的映射关系。\n\n\nDefaultAnnotationHandlerMapping(过时):\n通过注解(如 @RequestMapping )来映射处理器。\n在较新的 Spring 版本中被 RequestMappingHandlerMapping 取代。\n\n\nRequestMappingHandlerMapping\n这是最常用的 Handler Mapping 实现。\n通过注解(如 @RequestMapping、@GetMapping、@PostMapping 等)来映射处理器支持复杂的请求映射规则，包括路径变量、请求参数、请求头等。\n\n\n\n总结Handler Mapping 负责将 HTTP 请求映射到相应的处理器。通过使用不同的 Handler Mapping 实现，开发者可以灵活地配置请求映射规则，以满足各种应用需求。最常用的 Handler Mapping 实现是 RequestMappingHandlerMapping，它通过注解提供了强大的请求映射功能。\n什么是Handler AdapterHandler Adapter 负责将处理器(Handler)适配为具体的处理方法。 Handler Adapter 的主要作用是根据处理器的类型和具体实现，执行相应的处理逻辑。Handler Adapter是 DispatcherServlet 和具体处理器之间的桥梁。\n主要职责\n\n处理器执行:调用处理器的方法来处理请求。\n返回模型和视图:处理完请求后，返回一个ModelAndView 对象，包含视图名称和模型数据。\n\n工作流程\n\n请求到达 DispatcherServlet：当一个 HTTP 请求到达 DispatcherServlet 时，它会先通过HandlerMapping 找到对应的处理器。\n选择 Handler Adapter: DispatcherServlet根据处理器的类型选择合适的 Handler Adapter 。\n执行处理器: Handler Adapter 调用处理器的方法来处理请求。\n**返回结果:**处理完请求后，Handler Adapter返回一个 ModelAndView 对象，DispatcherServlet。再根据这个对象生成最终的响应。\n\n常见的 Handler Adapter 实现\n\nHttpRequestHandlerAdapter\n用于处理实现 HttpRequestHandler 接口的处理器。\n例如实现了 HttpRequestHandler接口的处理器。\n\n\nSimpleControllerHandlerAdapter\n用于处理实现Controller 接口的处理器。\n例如实现了 Controller接口的处理器。\n\n\nRequestMappingHandlerAdapter\n最常用的 Handler Adapter 实现。\n用于处理使用 @RequestMapping 注解的控制器方法。\n支持复杂的请求映射规则和数据绑定。\n\n\n\n总结Handler Adapter 负责将处理器适配为具体的处理方法。通过使用不同的 Handler Adapter 实现，SpringMVC可以灵活地支持多种类型的处理器。最常用的 Handler Adapter 实现是 RequestMappingHandlerAdapter它支持通过注解定义的控制器方法，并提供了强大的请求处理功能。\n什么是View ResolverView Resolver 负责将逻辑视图名称解析为具体的视图对象(如JSP、Thymeleaf 模板等)。ViewResolver的主要作用是根据控制器返回的视图名称，找到相应的视图资源，并将其渲染成最终的 HTML 响应。\n主要职责\n\n视图名称解析: 将控制器返回的逻辑视图名称解析为具体的视图对象。\n视图对象返回: 返回一个 view 对象，该对象可以用来染模型数据\n\n工作流程\n\n**控制器处理请求: **当一个HTTP 请求到达 DispatcherServlet 时，它会通过 Handler Adapter 调用控制器的方法来处理请求。\n**返回视图名称: **控制器方法处理完请求后，会返回一个包含视图名称和模型数据的 ModelAndView 对象。\n视图名称解析: DispatcherServlet使用 View Resolver 将逻辑视图名称解析为具体的视图对象。\n渲染视图: view 对象使用模型数据来渲染最终的 HTML 响应。\n\nSpring MVC 中的@Controller注解有什么作用@controller 注解用于标记一个类作为控制器组件。控制器是处理 HTTP 请求的核心组件，它负责接收请求处理业务逻辑并返回视图或数据响应。\n主要作用\n\n标识控制器类: @contro1ler 注解告诉 Spring 该类是一个控制器，应该由 Spring 容器管理。\n处理请求:控制器类中的方法通过映射注解(如 @RequestMapping、@GetMapping、@PostMapping等)处理 HTTP 请求。\n\n相关注解\n在Spring MVC中，除了 @controller，还有一些常用的注解用于处理请求\n\n@RequestMapping\n用于定义请求 URL 和 HTTP 方法的映射。\n可以应用于类级别和方法级别。\n\n\n@PutMapping@DeleteMapping@GetMapping、@PostMapping\n分别用于处理GET、POST、PUTDELETE 请求。\n是 @RequestMapping 的快捷方式。\n\n\n@RequestParam\n用于绑定请求参数到方法参数。\n可以指定参数名称、是否必需以及默认值。\n\n\n@PathVariable\n用于绑定 URL 路径中的变量到方法参数。\n\n\n@ModelAttribute\n用于将请求参数绑定到模型对象，并将模型对象添加到模型中。\n\n\n@ResponseBody\n用于将方法的返回值直接作为 HTTP 响应体。\n常用于返回 JSON 或 XML 数据。\n\n\n\n总结\n@controller 注解在 Spring MVC 中用于标记一个类为控制器组件，控制器负责处理 HTTP 请求并返回视图或数据响应。通过结合使用各种映射注解(如 @RequestMapping、@GetMapping 等)和参数绑定注解(如 @RequestParam@PathVariable 等)，可以灵活地处理不同类型的请求和参数。\nSpring MVC 中的 @RequestMapping 注解有什么作用?","categories":["博客"],"tags":["Java","后端"]},{"title":"Java线程、多线程与线程池总结","url":"/2024/08/07/2024-08-07-Java%E7%BA%BF%E7%A8%8B%E3%80%81%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%80%BB%E7%BB%93/","content":"Java线程、多线程与线程池总结Java创建线程的三种方法\n继承Thread类创建线程类 （extends）\n\n定义Thread类的子类，并重写该类的run方法，该run方法的方法体就代表了线程要完成的任务。因此把run()方法称为执行体(线程体)。\n\n创建Thread子类的实例，即创建了线程对象。\n\n调用线程对象的start()方法来启动该线程。 \npublic class CreateThreadByExtendThread extends Thread&#123;    int i = 0;    @Override    public void run()&#123;        for (;i&lt;100;i++)&#123;            System.out.println(Thread.currentThread().getName()+&quot;:&quot;+i); //获取本线程的名称        &#125;    &#125;    public static void main(String[]args)&#123;        CreateThreadByExtendThread c1 = new CreateThreadByExtendThread();        CreateThreadByExtendThread c2 = new CreateThreadByExtendThread();        c1.start();        c2.start();    &#125;&#125;\n\n\n通过Runnable接口创建线程类\n\n定义runnable接口的实现类，并重写该接口的run()方法，该run()方法的方法体同样是该线程的线程执行体。\n\n创建 Runnable实现类的实例，并以此实例作为Thread的target来创建Thread对象，该Thread对象才是真正的线程对象。\n\n调用线程对象的start()方法来启动该线程。\npublic class CreateThreadByImplementRunnable implements Runnable&#123;    int i=0;    @Override    public void run()&#123;        while(i&lt;100)&#123;            System.out.println(Thread.currentThread().getName()+&quot;:&quot;+i++);        &#125;    &#125;    public static void main(String[] args)&#123;        CreateThreadByImplementRunnable createThreadByImplementRunnable1=new CreateThreadByImplementRunnable();        CreateThreadByImplementRunnable createThreadByImplementRunnable2=new CreateThreadByImplementRunnable();        Thread thread1= new Thread(createThreadByImplementRunnable1,&quot;Thread-1&quot;);        Thread thread2= new Thread(createThreadByImplementRunnable2,&quot;Thread-2&quot;);        thread1.start();        thread2.start();    &#125;&#125;\n\n\n通过Callable和Future创建线程\ncallable-&gt;callable实现类-&gt;FutureTask&lt;&gt;(callable实现类实例)-&gt;Thread（futuretask实例）\n\n创建Callable接口的实现类，并实现call()方法，该call()方法将作为线程执行体，并且有返回值。\n\n创建Callable实现类的实例，使用FutureTask类来包装Callable对象，该FutureTask对象封装了该Callable对象的call()方\n法的返回值。（FutureTask是一个包装器，它通过接受Callable来创建，它同时实现了Future和Runnable接口）\n\n使用FutureTask对象作为Thread对象的target创建并启动新线程。\n\n调用FutureTask对象的get()方法来获得子线程执行结束后的返回值\nimport java.util.concurrent.Callable;import java.util.concurrent.FutureTask;public class CreateThreadByImplementCallable implements Callable &#123;    @Override    public Integer call()throws Exception&#123;        int i = 0;        for(;i&lt;100;i++)&#123;            System.out.println(Thread.currentThread().getName()+&quot; &quot;+i);            Thread.sleep(100); // 休眠100ms        &#125;        return i;    &#125;    public static void main(String[]args)&#123;        for (int i = 0;i&lt;20;i++)&#123;            CreateThreadByImplementCallable ct = new CreateThreadByImplementCallable();            FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(ct);            Thread t = new Thread(ft);            t.start();        &#125;    &#125;&#125;\n\n\n\nJava创建线程池的五种方法继承的ExecutorService接口\n\nnewCachedThreadPool（没有上限的线程池），如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。\nExecutorService cachedThreadPool = Executors.newCachedThreadPool();cachedThreadPool.execute(new Runnable()&#123;    @Override    public void run() &#123;        System.out.println(&quot;执行线程任务&quot;);&#125;)\n\n\n\nnewFixdedThreadPool（有上限的线程池），创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。\nExecutorService fixedThreadPool = Executors.newFixedThreadPool(3);fixedThreadPool.execute(new Runnable()&#123;    @Override    public void run() &#123;        System.out.println(&quot;执行线程任务&quot;);&#125;)\n\nnewScheduledThreadPool，创建一个定长线程池，支持定时及周期性任务执行。延迟执行示例代码如下：\nScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5);scheduledThreadPool.schedule(new Runnable() &#123;    @Override    public void run() &#123;        System.out.println(&quot;delay 3 seconds&quot;);    &#125;&#125;, 3, TimeUnit.SECONDS);//延迟三秒执行\n\nnewSingleThreadExecutor，创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。\nExecutorService executorService = Executors.newSingleThreadExecutor();executorService.execute(new Runnable()&#123;   @Override   public void run() &#123;       System.out.println(&quot;执行线程任务&quot;);&#125;)\n\nThreadPoolExecutor（自定义创建线程池）\n\n它最长的构造方法有七个参数。\n\n核心线程数量——在线程池当中无论空闲多久都不会被删除的线程\n线程池当中最大的线程数量——线程池当中最大能创建的线程数量\n空闲时间（数值）——临时线程（线程池中出核心线程之外的线程）空闲了多久就会被淘汰的时间。\n空闲时间（单位）——临时线程空闲了多久就会被淘汰的时间单位，要用枚举类TimeUnit类作为参数\n阻塞队列——就是创建一个阻塞队列作为参数传入，就是当线程池当中线程数量已经达到了最大线程数量，允许多少个任务排队获取线程，其余的用参数七那个方案来处理。\n创建线程的方式——不是new一个线程，而是传入一个线程工厂（例如：Executors工具类中的defaultThreadFactory方法返回的就是一个线程工厂）\n要执行的任务过多时的解决方案——当等待队列中也排满时要怎么处理这些任务(任务拒绝策略)\n\n//代码实现   /**     * 之前用工具类进行创建，有好多参数不能自己设置     * 咱直接自己手动创建一个线程池，自己设置参数     * 参数一：核心线程数量                           不能小于0     * 参数二：最大线程数                             不能小于0，数值大于等于核心线程数量     * 参数三：空闲临时线程最大存活时间（数值）           不能小于0     * 参数四：空闲临时线程最大存活时间（单位）            用TimeUnit这个枚举类表示     * 参数五：任务队列，也就是一个堵塞队列               不能为null     * 参数六:创建线程的工厂                            不能为null     * 参数七：任务的拒绝策略                             不能为null     */ ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(        3,  // 核心线程数量        6,              //最大线程数        60,             //空闲临时线程最大存活时间（数值）        TimeUnit.SECONDS,//空闲临时线程最大存活时间（单位）        new ArrayBlockingQueue&lt;&gt;(3),//任务队列，也就是一个堵塞队列，也可以使用LinkedBlockingQueue这个阻塞队列        Executors.defaultThreadFactory(),//用线程池工具类Executors创建线程的工厂        new ThreadPoolExecutor.AbortPolicy()//任务的拒绝策略中其中一个，丢弃任务并抛出RejectedExecutionException        &#125;\n\n\n\n\nExecutorService的submit和execute的区别在 Java 中，ExecutorService 接口是用于管理和执行线程的框架，它定义了两个用于提交任务的方法：submit() 和 execute()。这两种方法有一些区别：\n\n返回值：\n\nsubmit() 方法接受 Callable（因为实现Callable的call也有返回值嘛，而且还要抛出异常） 或 Runnable 任务，并返回一个 Future 对象，可以用于获取任务的执行结果或取消任务的执行。\nexecute() 方法接受 Runnable 任务，但它没有返回值，因此无法获取任务的执行结果。\n\n\n异常处理：\n\nsubmit() 方法可以捕获任务执行过程中抛出的异常，并通过 Future 对象的 get() 方法抛出，从而实现对异常的处理。\nexecute() 方法无法捕获任务执行过程中的异常，因为它没有返回值。\n\n\n\nimport java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Future;import java.util.concurrent.Callable;import java.util.concurrent.TimeUnit;public class SubmitVsExecuteExample &#123;    public static void main(String[] args) &#123;        ExecutorService executorService = Executors.newSingleThreadExecutor();        // 使用 submit() 提交 Callable 任务        Future&lt;String&gt; future = executorService.submit(new MyCallable());        try &#123;            String result = future.get();            System.out.println(&quot;Submit Result: &quot; + result);        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;        // 使用 execute() 提交 Runnable 任务        executorService.execute(new MyRunnable());        executorService.shutdown();    &#125;    static class MyCallable implements Callable&lt;String&gt; &#123;        public String call() throws Exception &#123;            TimeUnit.SECONDS.sleep(2);            return &quot;Callable task completed&quot;;        &#125;    &#125;    static class MyRunnable implements Runnable &#123;        public void run() &#123;            System.out.println(&quot;Runnable task completed&quot;);        &#125;    &#125;&#125;\n\n\n\n","categories":["后端"],"tags":["Java","后端","线程池","多线程","线程"]},{"title":"法律垂类大模型DISC-LawGPT的部署运行和对比","url":"/2024/08/07/2024-08-07-%E6%B3%95%E5%BE%8B%E5%9E%82%E7%B1%BB%E5%A4%A7%E6%A8%A1%E5%9E%8BDISC-LawGPT%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%90%E8%A1%8C%E5%92%8C%E5%AF%B9%E6%AF%94/","content":"法律垂类大模型DISC-LawGPT的部署运行和对比部署和运行# 部署git clone https://github.com/FudanDISC/DISC-LawLLM.gitcd DISC-LawLLMpip install -r requirements.txtmkdir ShengbinYuecd ShengbinYuegit clone https://hf-mirror.com/ShengbinYue/DISC-LawLLMcd ..mkdir cache# 遇到报错 [Errno 13] Permission denied: &#x27;/data/.cache/huggingface/modules/transformers_modules/DISC-LawLLM&#x27;export HF_HOME=&quot;~/verticalLLM/lzjr/DISC-LawLLM/cache&quot; # 如果遇到CUDA error: out of memory 用 watch -n 0.5 nvidia-smi查看显卡占用情况 如果kill不了相关进程，就运行下面的指令，比如有三张卡0,1,2,其中2被另一个程序占用了大量显存且Kill不了，就用下面的命令export CUDA_VISIBLE_DEVICES=0,1# 运行python cli_demo.py\n\n运行成功：\n\n性能对比\n请对以下案件做出分析并给出可能的判决：2021年11月9日，原告与被告南湖国旅公司签订《综合授信协议》，约定原告向被告南湖公司提供授信额度1000万元。同日，原告与被告南湖国旅公司、南湖粤途公司、王子山公司、布某、郭某、郑某、刘某、徐某、胡某、赵某、许某签订《最高额保证合同》，约定为上述债务提供最高额保证担保。2021年11月10日，原告与被告南湖国旅公司签订《流动资金借款合同》，约定贷款金额分别为1000万元，2021年1月10日，原告依约发放上述贷款。但被告南湖国旅公司在原告发放贷款后的2个月内，新增数十笔执行案件，严重危及原告债权，被告布某作为保证人，也发生新的重大执行案件，且在发生上述情况后，均未及时书面通知原告。\n\nDISC-LawGPT：\n\n\nKimi:\n\n\n\n\n请对以下案件做出分析并给出可能的判决：2021年4月17日，刘某1向刘某出具借条一份，内容为：“借条今借到现金贰拾万元（￥200000.00）借款人：刘某1（捺印）2021.4月17号”刘某通过微信转账方式向刘某1交付出借款，分别为2021年4月17日转账30000元、30000元、30000元、10000元，2021年5月29日转账30000元、20000元、30000元、20000元，共计200000元。至本次诉讼，刘某1通过微信转账还款61500元，尚欠138500元。\n\nDISC-LawGPT：\n\n\nKimi:\n\n\n\n\n劳动者（正式工）未提前30日告知用人单位即离职，需要支付违约金吗？\n\nDISC-LawGPT\n\n\nKimi:\n\n\n\n\n请对以下案件做出分析并给出可能的判决：原告与被告于2020年8月11日签订《内江师范学院新校区建设工程配电箱买卖合同》，双方约定由原告向被告内江师范学院新校区项目提供配电箱设备，合同暂定合计1262676.36元，双方并就供货期限、运输及交货方式、验收、货款支付、争议解决等进行约定。合同签订后，原告依约履行，至2021年5月6日完成全部供货，实际供货金额1164220.59元，并已向被告开具全额发票。现被告已支付货款695000元，剩余货款469220.59元未支付。另外，原告于2020年8月31日向被告缴纳了该项目履约保证金63133元，被告未予退还。\n\nDISC-LawGPT:\n\n\nKimi:\n\n\n\n\n网购商品用快递送达，商品在快递途中、签收之前毁损的风险谁承担？\n\nDISC-LawGPT:\n\n\nKimi:\n\n\n\n\n\n","categories":["大模型"],"tags":["LLM","DISC-LawGPTt"]},{"title":"Java的Stream流","url":"/2024/08/08/2024-08-08-Java%E7%9A%84Stream%E6%B5%81/","content":"Java的Stream流[讲透JAVA Stream的collect用法与原理，远比你想象的更强大_stream.collection-CSDN博客](https://blog.csdn.net/veezean/article/details/125857074?ops_request_misc=%7B%22request%5Fid%22%3A%22172258578116800227423214%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172258578116800227423214&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-125857074-null-null.142^v100^pc_search_result_base8&amp;utm_term=Java stream collect&amp;spm&#x3D;1018.2226.3001.4187)\n[Java–Stream流详解_java stream-CSDN博客](https://blog.csdn.net/MinggeQingchun/article/details/123184273?ops_request_misc=%7B%22request%5Fid%22%3A%22172258592916800182196501%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172258592916800182196501&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-123184273-null-null.142^v100^pc_search_result_base8&amp;utm_term=Java stream流&amp;spm&#x3D;1018.2226.3001.4187)\nstream的创建：//1.Stream.of(array) （这里面的1,2,3,4其实是Array的类型）Stream.of(1,2,3,4)        //2.list.Stream()2. list.stream()\n\n操作符常用中间操作符\nfilter：用于过滤 ，接受一个返回boolean值的函数，返回一个流\nlist.stream().filter(number-&gt;number&gt;=2).collect(Collectors.toList());\n\nmap：用于映射 ，映射流中的每一个元素为另一个流中的元素\n//toListlist.stream().(str-&gt;str+&quot;-IT&quot;).collect(Collectors.toList());//toMap  在 toMap 方法中，以每个整数的字节值为键，该整数乘以 2 为值，当遇到重复的键时取最后一个值。（这里实际上可以用任何能区分不同键的方式作为第一个参数，而不一定是 Integer::byteValue）list.stream().collect(Collectors.toMap(Integer::byteValue,num-&gt;num*2,(num1,num2)-&gt;num2));\n\ndinstinct:  用于去重 \nnumbers.stream().filter(i -&gt; i % 2 == 0).distinct().forEach(System.out::println);\n\n教你看懂System.out::println-CSDN博客\n\nsorted: 用于排序  \nList&lt;String&gt; collect = strings1.stream().sorted().collect(Collectors.toList());\n\nlimit: 可以将流限制为指定的元素数\nList&lt;Integer&gt; collect = numbers.stream().limit(3).collect(Collectors.toList());\n\n常用终端操作符\ncollect: 收集器，将流转换为其他形式 \nstrings.stream().collect(Collectors.toSet()); strings.stream().collect(Collectors.toList());strings.stream().collect(Collectors.toMap()); \n\nforEach:遍历流\nstrings.stream().forEach(s -&gt; out.println(s));\n\nCount(计数)\nList&lt;String&gt; names = Arrays.asList(&quot;Alex&quot;, &quot;Brian&quot;, &quot;Charles&quot;, &quot;David&quot;);long count = names.stream().count();\n\n","categories":["后端"],"tags":["Java","后端","Stream"]},{"title":"并发：Java的Future和FutureTask","url":"/2024/08/08/2024-08-08-%E5%B9%B6%E5%8F%91%EF%BC%9AJava%E7%9A%84Future%E5%92%8CFutureTask/","content":"并发：Java的Future和FutureTaskFuture类的作用Future 类是异步思想的典型运用，主要用在一些需要执行耗时任务的场景，避免程序一直原地等待耗时任务执行完成，执行效率太低。具体来说是这样的：当我们执行某一耗时的任务时，可以将这个耗时任务交给一个子线程去异步执行，同时我们可以干点其他事情，不用傻傻等待耗时任务执行完成。等我们的事情干完后，我们再通过 Future 类获取到耗时任务的执行结果。这样一来，程序的执行效率就明显提高了。\n这其实就是多线程中经典的 Future 模式，你可以将其看作是一种设计模式，核心思想是异步调用，主要用在多线程领域，并非 Java 语言独有。\n在 Java 中，Future 类只是一个泛型接口，位于java.util.concurrent包下，其中定义了 5 个方法，主要包括下面这 4 个功能：\n\n取消任务；\n判断任务是否被取消;\n判断任务是否已经执行完成;\n获取任务执行结果。\n\n源码// V 代表了Future执行的任务返回值的类型public interface Future&lt;V&gt; &#123;    // 取消任务执行    // 成功取消返回 true，否则返回 false    boolean cancel(boolean mayInterruptIfRunning);    // 判断任务是否被取消    boolean isCancelled();    // 判断任务是否已经执行完成    boolean isDone();    // 获取任务执行结果    V get() throws InterruptedException, ExecutionException;    // 指定时间内没有返回计算结果就抛出 TimeOutException 异常    V get(long timeout, TimeUnit unit)        throws InterruptedException, ExecutionException, TimeoutExceptio&#125;\n\n\n\nFutureTask的作用FutureTask是Future的具体实现。\nFutureTask实现了RunnableFuture接口。RunnableFuture接口又同时继承了Future 和 Runnable 接口。所以FutureTask既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值，可以作为任务直接被线程执行。\n构造函数public FutureTask(Callable&lt;V&gt; callable) &#123;    if (callable == null)        throw new NullPointerException();    this.callable = callable;    this.state = NEW;       // ensure visibility of callable&#125;    public FutureTask(Runnable runnable, V result) &#123;    this.callable = Executors.callable(runnable, result);    this.state = NEW;       // ensure visibility of callable&#125;\n\n例子import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.FutureTask;public class FutureTaskTest &#123;    public static void main(String[] args) throws InterruptedException, ExecutionException &#123;        long starttime = System.currentTimeMillis();        //input2生成， 需要耗费3秒        FutureTask&lt;Integer&gt; input2_futuretask = new FutureTask&lt;&gt;(new Callable&lt;Integer&gt;() &#123;            @Override            public Integer call() throws Exception &#123;                Thread.sleep(3000);                return 5;            &#125;        &#125;);        new Thread(input2_futuretask).start();        //input1生成，需要耗费2秒        FutureTask&lt;Integer&gt; input1_futuretask = new FutureTask&lt;&gt;(new Callable&lt;Integer&gt;() &#123;            @Override            public Integer call() throws Exception &#123;                Thread.sleep(2000);                return 3;            &#125;        &#125;);        new Thread(input1_futuretask).start();        Integer integer1 = input1_futuretask.get();        Integer integer2 = input2_futuretask.get();        System.out.println(algorithm(integer1, integer2));        long endtime = System.currentTimeMillis();        System.out.println(&quot;用时：&quot; + String.valueOf(endtime - starttime)+&quot;ms&quot;);    &#125;    //这是我们要执行的算法    public static int algorithm(int input, int input2) &#123;        return input + input2;    &#125;&#125;\n\n\n这里用时仅仅只有3013ms，”input2生成， 需要耗费3秒”，这一步占了主要时间。由此观之，整个过程是异步的（不然时间将会是&gt;3+2&#x3D;5s的）。\nCompletableFuture类Future 在实际使用过程中存在一些局限性，比如不支持异步任务的编排组合、获取计算结果的 get() 方法为阻塞调用。\nJava 8 才被引入CompletableFuture 类可以解决Future 的这些缺陷。CompletableFuture 除了提供了更为好用和强大的 Future 特性之外，还提供了函数式编程、异步任务编排组合（可以将多个异步任务串联起来，组成一个完整的链式调用）等能力。\n//programmer-club中的例子 //对于每个category，调用异步的CompletableFuture.supplyAsync()执行getLabelBOList方法和ThreadPoolExecutor作为Executor去多线程+异步的获取labelBOListList&lt;CompletableFuture&lt;Map&lt;Long, List&lt;SubjectLabelBO&gt;&gt;&gt;&gt; completableFutureList = categoryBOList.stream().map(category -&gt;                CompletableFuture.supplyAsync(() -&gt; getLabelBOList(category), labelThreadPool).collect(Collectors.toList());                                                                                                     \n\nCompletableFuture是对Future的扩展和增强。CompletableFuture实现了Future接口，并在此基础上进行了丰富的扩展，完美弥补了Future的局限性，同时CompletableFuture实现了对任务编排的能力(重点)。\n\nCompletionStage接口定义了任务编排的方法，执行某一阶段，可以向下执行后续阶段。异步执行的，默认线程池是ForkJoinPool.commonPool()，但为了业务之间互不影响，且便于定位问题，强烈推荐使用自定义线程池。\n功能常用方法依赖关系\n\nthenApply()：把前面任务的执行结果，交给后面的Function。\nthenCompose()：用来连接两个有依赖关系的任务，结果由第二个任务返回。\n\nand集合关系\n\nthenCombine()：合并任务，有返回值。\nthenAccepetBoth()：两个任务执行完成后，将结果交给thenAccepetBoth处理，无返回值。\nrunAfterBoth()：两个任务都执行完成后，执行下一步操作(Runnable类型任务)。\n\nor聚合关系\n\napplyToEither()：两个任务哪个执行的快，就使用哪一个结果，有返回值。\nacceptEither()：两个任务哪个执行的快，就消费哪一个结果，无返回值。\nrunAfterEither()：任意一个任务执行完成，进行下一步操作(Runnable类型任务)。\n\n并行执行\n\nallOf()：当所有给定的 CompletableFuture 完成时，返回一个新的 CompletableFuture。\nanyOf()：当任何一个给定的CompletablFuture完成时，返回一个新的CompletableFuture。\n\n结果处理\n\nwhenComplete：当任务完成时，将使用结果(或 null)和此阶段的异常(或 null如果没有)执行给定操作。\nexceptionally：返回一个新的CompletableFuture，当前面的CompletableFuture完成时，它也完成，当它异常完成时，给定函数的异常触发这个CompletableFuture的完成。\n\n异步操作提供了四个静态方法来创建一个异步操作：\npublic static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable)public static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable, Executor executor)public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier)public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier, Executor executor)\n\n这四个方法的区别：\n\nrunAsync() 以Runnable函数式接口类型为参数，没有返回结果，supplyAsync() 以Supplier函数式接口类型为参数，返回结果类型为U；Supplier接口的 get()是有返回值的(会阻塞)\n\n使用没有指定Executor的方法时，内部使用ForkJoinPool.commonPool() 作为它的线程池执行异步代码。如果指定线程池，则使用指定的线程池运行。\n\n默认情况下CompletableFuture会使用公共的ForkJoinPool线程池，这个线程池默认创建的线程数是 CPU 的核数（也可以通过 JVM option:\n-Djava.util.concurrent.ForkJoinPool.common.parallelism 来设置ForkJoinPool线程池的线程数）。如果所有CompletableFuture共享一个线程池，那么一旦有任务执行一些很慢的 I&#x2F;O 操作，就会导致线程池中所有线程都阻塞在 I&#x2F;O 操作上，从而造成线程饥饿，进而影响整个系统的性能。所以，强烈建议你要根据不同的业务类型创建不同的线程池，以避免互相干扰\n\n\n异步操作\nRunnable runnable = () -&gt; System.out.println(&quot;无返回结果异步任务&quot;);CompletableFuture.runAsync(runnable);CompletableFuture&lt;String&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123;    System.out.println(&quot;有返回值的异步任务&quot;);    try &#123;        Thread.sleep(5000);    &#125; catch (InterruptedException e) &#123;        e.printStackTrace();    &#125;    return &quot;Hello World&quot;;&#125;);String result = future.get();\n\n获取结果（join&amp;get）\njoin()和get()方法都是用来获取CompletableFuture异步之后的返回值。join()方法抛出的是uncheck异常（即未经检查的异常),不会强制开发者抛出。get()方法抛出的是经过检查的异常，ExecutionException, InterruptedException 需要用户手动处理（抛出或者 try catch）\n结果处理\n当CompletableFuture的计算结果完成，或者抛出异常的时候，我们可以执行特定的 Action。主要是下面的方法：\npublic CompletableFuture&lt;T&gt; whenComplete(BiConsumer&lt;? super T,? super Throwable&gt; action)public CompletableFuture&lt;T&gt; whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action)public CompletableFuture&lt;T&gt; whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action, Executor executor)\n\nAction的类型是BiConsumer&lt;? super T,? super Throwable&gt;，它可以处理正常的计算结果，或者异常情况。方法不以Async结尾，意味着Action使用相同的线程执行，而Async可能会使用其它的线程去执行(如果使用相同的线程池，也可能会被同一个线程选中执行)。这几个方法都会返回CompletableFuture，当Action执行完毕后它的结果返回原始的CompletableFuture的计算结果或者返回异常。\nCompletableFuture&lt;String&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123;    try &#123;        TimeUnit.SECONDS.sleep(1);    &#125; catch (InterruptedException e) &#123;    &#125;    if (new Random().nextInt(10) % 2 == 0) &#123;        int i = 12 / 0;    &#125;    System.out.println(&quot;执行结束！&quot;);    return &quot;test&quot;;&#125;);// 任务完成或异常方法完成时执行该方法// 如果出现了异常,任务结果为nullfuture.whenComplete(new BiConsumer&lt;String, Throwable&gt;() &#123;    @Override    public void accept(String t, Throwable action) &#123;        System.out.println(t+&quot; 执行完成！&quot;);    &#125;&#125;);// 出现异常时先执行该方法future.exceptionally(new Function&lt;Throwable, String&gt;() &#123;    @Override    public String apply(Throwable t) &#123;        System.out.println(&quot;执行失败：&quot; + t.getMessage());        return &quot;异常xxxx&quot;;    &#125;&#125;);future.get();\n\n上面的代码当出现异常时，输出结果如下:\n执行失败：java.lang.ArithmeticException: / by zeronull 执行完成！\n\n","categories":["后端"],"tags":["Java","后端","Future","FutureTask","并发"]},{"title":"Redis实现分布式锁及Redisson","url":"/2024/08/11/2024-08-11-Redis%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%8F%8ARedisson/","content":"Redis实现分布式锁及Redisson​\t分布式锁是控制分布式系统之间同步访问共享资源的一种方式。\n​\t在分布式系统中，常常需要协调他们的动作，若不同的系统或是同一个系统的不同主机之间共享了一个或一组资源，那么访问这些资源的时候，往往需要互斥来防止彼此干扰来保证一致性，这个时候，便需要使用到分布式锁。\n\n例子：商品秒杀超卖1. 无锁\n这是一个订单库存的例子，库存stock为1，这里很容易会发现容易造成多次下单成功的错误。\n2. 加同步锁\n这里在单机情况下确实能够满足不出现超卖的问题。\n缺点：如果作Nginx进行负载均衡+分布式集群部署，依然会出现超卖问题。\n\n原因是同步锁synchronized是JVM级别的，每台服务器在并发情况下，只能锁住一个线程。\n\n\n所以，如何处理这种分布式的情况呢？\n3. Redis or Zookeeper由于系统已经使用到了Redis，为了系统的轻量避免冗余引入新组件，选择通过Redis来进行实现分布式锁。\nRedis实现分布式锁1. SETNX和SET NX命令[Windows版Docker安装Redis教程(保姆级)，适合开发环境快速提供Redis服务_windows docker 安装redis-CSDN博客](https://blog.csdn.net/BXD19931010/article/details/135065606?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=windows docker安装redis&amp;utm_medium&#x3D;distribute.pc_search_result.none-task-blog-2allsobaiduweb~default-3-135065606.142^v100^pc_search_result_base8&amp;spm&#x3D;1018.2226.3001.4187)\n# 创建容器并执行docker run -it --name redis -p 6379:6379 redis --bind 0.0.0.0 --protected-mode no# 后台运行容器docker run -it -d redisdocker ps# exec表示在运行的容器中执行命令 it表示以终端交互的方式执行命令 /bin/bash表示需要指定的命令docker exec it redis /bin/bash# 进入容器后可通过redis-cli命令连接容器内的redis服务器，可通过set创建变量，get获取变量的值redis-cli\n\n​\tRedis实现分布式锁的核心便在于SETNX命令，它是SET if Not eXists的缩写，如果键不存在，则将键设置为给定值，在这种情况下，它等于SET；当键已存在时，不执行任何操作；成功时返回1，失败返回0\n​\t但setnx不能同时完成expire设置失效时长，不能保证setnx和expire的原子性。我们可以使用set命令完成setnx和expire的操作，并且这种操作是原子操作。\n​\t下面是set命令的可选项：\nset key value [EX seconds] [PX milliseconds] [NX|XX]EX seconds：设置失效时长，单位秒PX milliseconds：设置失效时长，单位毫秒NX：key不存在时设置value，成功返回OK，失败返回(nil)XX：key存在时设置value，成功返回OK，失败返回(nil)\n\n\n使用示例：\n\n两次插入相同键不同值，第一次返回成功，第二次返回失败：\n\n\n设置过期时间（十秒）：\n\n\n\n\n\n2. 通过Redis的SETNX实现分布式锁命令 SET resource-name anystring NX EX max-lock-time 是一种在 Redis 中实现锁的简单方法\n#给lock设置了过期时间为60000毫秒(也可以用ex 6000,单位就变成了秒)，当用NX再次赋值，则返回nil,不能重入操作127.0.0.1:6379&gt; set lock true NX px 60000OK127.0.0.1:6379&gt; set lock true NX px 6000(nil)127.0.0.1:6379&gt; get lock&quot;true&quot;127.0.0.1:6379&gt; ttl lock(integer) 43#时间过期后再次get,返回nil,表明key 为 lock的锁已经释放127.0.0.1:6379&gt; get lock(nil)\n\n如果setnx 返回ok 说明拿到了锁；如果setnx 返回 nil，说明拿锁失败，被其他线程占用。\n换成客户端服务器则是如下：\n\n客户端执行以上的命令：\n如果服务器返回 OK ，那么这个客户端获得锁。\n如果服务器返回 NIL ，那么客户端获取锁失败，可以在稍后再重试。\n\n\n\n\n问题一：为什么需要PX&#x2F;XX设置超时时间？答：如果第一个set的进程A不讲道理&#x2F;突然宕机，锁永远释放不了，导致系统中其他机器的其他线程谁也拿不到锁。\n问题二：设置了超时时间还有什么问题吗？\n如果第一个set的进程A又不讲道理，业务步骤时间超过设置的超时时间，那么就会导致其他进程拿到锁（趁虚而入），导致超卖问题。\n同时，等进程A回来了，回手就是把其他进程的锁删了&#x2F;释放其他线程的锁，就会更加趁虚而入导致超卖。\n\n解决办法：\n\n加长锁的过期时间，并添加子线程每隔10秒确认主线程是否在线，如果在线则将过期时间重新设置（给锁续命）。\n给锁加上UUID（锁与线程的唯一性），这样就不会释放别人的锁了。\n\n以上解决方案要确保代码的正确性、健壮性还是比较麻烦的，在此引入Redisson工具。\nRedissonRedisson原理\n这里的原理就是上面提到的那两点。\n问题及解决方案因为Redis是满足AP（高可用+分区容错），当Redis采用集群（主从节点），这里的加锁只会往Redis的一个节点去加锁，比如对主节点加锁了，这时主节点会去从节点那进行锁状态的同步。倘若这时主节点挂掉了，从节点没有有效同步，依然会发生线程不安全的情况。\n解决方案：\n\n采用redlock（红锁）实现：对Redis的所有节点都进行加锁后，才返回响应。\nRedisson-红锁(Redlock)-使用&#x2F;原理 - 自学精灵 (way2j.com)\n\n\n","categories":["后端"],"tags":["Java","Redis","后端","分布式锁"]},{"title":"Java使用ES条件构造器BoolQueryBuilder","url":"/2024/08/14/2024-08-14-Java%E4%BD%BF%E7%94%A8ES%E6%9D%A1%E4%BB%B6%E6%9E%84%E9%80%A0%E5%99%A8BoolQueryBuilder/","content":"Java使用ES条件构造器BoolQueryBuilder1. 检索前构造//1.构建SearchRequest请求对象，指定索引库SearchRequest searchRequest = new SearchRequest(&quot;data_info&quot;);//2.构建SearchSourceBuilder查询对象SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();//2.1 这个条件用于返回所有命中条件的数据数量, 不设置则返回大概数值sourceBuilder.trackTotalHits(true);//3.检索条件构造BoolQueryBuilder bqb = QueryBuilders.boolQuery();\n\n2. 条件构造\nmust可用filter代替，查询效率会更高，因为must会对结果进行_score评估\n\n//3.1 完全匹配bqb.must(QueryBuilders.matchQuery(&quot;code&quot;, 666L);         //3.2 模糊匹配bqb.must(QueryBuilders.matchPhraseQuery(&quot;name&quot;, &quot;张&quot;);         //3.3 in的效果 传单个参数就是完全匹配bqb.must(QueryBuilders.termsQuery(&quot;code&quot;, new Long[]&#123;1L, 2L, 3L&#125;);bqb.must(QueryBuilders.termsQuery(&quot;code&quot;, 1L, 2L, 3L);         //3.4 or条件BoolQueryBuilder shouldQuery = QueryBuilders.boolQuery();shouldQuery.should(QueryBuilders.matchQuery(&quot;code&quot;, 1L);shouldQuery.should(QueryBuilders.matchQuery(&quot;code&quot;, 2L);shouldQuery.minimumShouldMatch(1); //至少满足一个bqb.must(shouldQuery);                   //3.5 非nullbqb.must(QueryBuilders.existsQuery(&quot;iden&quot;));//是null             bqb.mustNot(QueryBuilders.existsQuery(&quot;iden&quot;));//3.6 大于等于gte (gt-大于 lt-小于 lte-小于等于)bqb.must(QueryBuilders.rangeQuery(&quot;time&quot;).gte(new Date());         //3.7 中文完全匹配bqb.must(queryBuilder.matchPhraseQuery(&quot;key&quot;, value));//3.8 匹配多个字段bqb.must(queryBuilder.multiMatchQuery(value, key1, key2, key3));\n\n3. 构造完成进行查询//4.将BoolQueryBuilder对象设置到SearchSourceBuilder对象中sourceBuilder.query(bqb);//5.排序sourceBuilder.sort(&quot;updateTime&quot;, SortOrder.DESC);//6.分页sourceBuilder.from((dto.getPageNum() - 1) * dto.getPageSize());sourceBuilder.size(dto.getPageSize());//7.将SearchSourceBuilder设置到SearchRequest中searchRequest.source(sourceBuilder);//8.调用方法查询数据SearchResponse searchResponse = client.search(searchRequest, RequestOptions.DEFAULT);         //9.解析返回结果SearchHit[] hits = searchResponse.getHits().getHits();for (int i = 0; i &lt; hits.length; i++) &#123;    System.out.println(&quot;返回的结果： &quot; + hits[i].getSourceAsString());&#125;log.info(&quot;返回总数为：&quot; + searchResponse.getHits().getTotalHits());int total = (int)searchResponse.getHits().getTotalHits().value;\n\n","categories":["后端"],"tags":["Java","微服务","ElasticSearch"]},{"title":"Java实现LRU的两种方式","url":"/2024/08/14/2024-08-14-Java%E5%AE%9E%E7%8E%B0LRU%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F/","content":"Java实现LRU的两种方式1. 直接继承LinkedHashMapclass LRUCache extends LinkedHashMap&lt;Integer, Integer&gt;&#123;    private int capacity;        public LRUCache(int capacity) &#123;        super(capacity, 0.75F, true);        this.capacity = capacity;    &#125;    public int get(int key) &#123;        return super.getOrDefault(key, -1);    &#125;    public void put(int key, int value) &#123;        super.put(key, value);    &#125;    @Override    protected boolean removeEldestEntry(Map.Entry&lt;Integer, Integer&gt; eldest) &#123;        return size() &gt; capacity;     &#125;&#125;\n\n2. 哈希+双链表public class LRUCache &#123;    class DLinkedNode &#123;        int key;        int value;        DLinkedNode prev;        DLinkedNode next;        public DLinkedNode() &#123;&#125;        public DLinkedNode(int _key, int _value) &#123;key = _key; value = _value;&#125;    &#125;    private Map&lt;Integer, DLinkedNode&gt; cache = new HashMap&lt;Integer, DLinkedNode&gt;();    private int size;    private int capacity;    private DLinkedNode head, tail;    public LRUCache(int capacity) &#123;        this.size = 0;        this.capacity = capacity;        // 使用伪头部和伪尾部节点        head = new DLinkedNode();        tail = new DLinkedNode();        head.next = tail;        tail.prev = head;    &#125;    public int get(int key) &#123;        DLinkedNode node = cache.get(key);        if (node == null) &#123;            return -1;        &#125;        // 如果 key 存在，先通过哈希表定位，再移到头部        moveToHead(node);        return node.value;    &#125;    public void put(int key, int value) &#123;        DLinkedNode node = cache.get(key);        if (node == null) &#123;            // 如果 key 不存在，创建一个新的节点            DLinkedNode newNode = new DLinkedNode(key, value);            // 添加进哈希表            cache.put(key, newNode);            // 添加至双向链表的头部            addToHead(newNode);            ++size;            if (size &gt; capacity) &#123;                // 如果超出容量，删除双向链表的尾部节点                DLinkedNode tail = removeTail();                // 删除哈希表中对应的项                cache.remove(tail.key);                --size;            &#125;        &#125;        else &#123;            // 如果 key 存在，先通过哈希表定位，再修改 value，并移到头部            node.value = value;            moveToHead(node);        &#125;    &#125;    private void addToHead(DLinkedNode node) &#123;        node.prev = head;        node.next = head.next;        head.next.prev = node;        head.next = node;    &#125;    private void removeNode(DLinkedNode node) &#123;        node.prev.next = node.next;        node.next.prev = node.prev;    &#125;    private void moveToHead(DLinkedNode node) &#123;        removeNode(node);        addToHead(node);    &#125;    private DLinkedNode removeTail() &#123;        DLinkedNode res = tail.prev;        removeNode(res);        return res;    &#125;&#125;\n\n","categories":["算法"],"tags":["Java","算法","LRU"]},{"title":"MySQL分页查询总结","url":"/2024/08/14/2024-08-14-MySQL%E5%88%86%E9%A1%B5%E6%9F%A5%E8%AF%A2%E6%80%BB%E7%BB%93/","content":"MySQL分页查询总结LIMIT语法： LIMIT {[offset,] row_count | row_count OFFSET offset}\nLIMIT子句可以被用于限制被SELECT语句返回的行数。\n使用两个参数时，第一个参数指定返回的偏移量，第二个参数指定返回的行数。初始行的偏移量为0（不是1）：mysql&gt; SELECT * FROM tbl LIMIT 5,10;  # Retrieve rows 6-15使用一个参数时，指定从开头返回的行数：mysql&gt; SELECT * FROM tbl LIMIT 5;     # Retrieve first 5 rows\n\n写法实现：\n-- 分页查询 通用语句SELECT * FROM TABLE LIMIT (pageIndex-1)*pageSize,pageSize-- 第一页 每页100条SELECT * FROM EMP LIMIT 0,100-- 第二页 每页100条SELECT * FROM EMP LIMIT 100,100-- 第801页 每页100条SELECT * FROM EMP LIMIT 80000,100  -- 用时0.046s\n\n","categories":["后端"],"tags":["SQL","MySQL","分页查询"]},{"title":"xxl-job学习笔记","url":"/2024/08/25/2024-08-25-xxl-job%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","content":"xxl-job学习笔记基础概念xxl-job是一个轻量级分布式任务调度平台，其核心设计目标是开发迅速、学习简单、轻量级、易扩展。现已开放源代码并接入多家公司线上产品线，开箱即用。\n任务执行流程\n执行流程\n\n任务执行器根据配置的调度中心的地址，自动注册到调度中心\n\n达到任务出发条件，调度中心下发任务\n\n执行器基于线程池执行任务，并把执行结果放入内存队列、把执行日志写入日志文件中\n\n执行器消费内存队列中的执行结果，主动上报给调度中心\n\n当用户在调度中心查看任务日志，调度中心请求任务执行器，任务执行器读取任务日志文件并返回日志详情\n\n\n搭建xxl-jobxxl-job: 一个分布式任务调度平台，其核心设计目标是开发迅速、学习简单、轻量级、易扩展。现已开放源代码并接入多家公司线上产品线，开箱即用。 (gitee.com)\n使用docker搭建xxl-jobdocker search xxl-jobdocker pull xuxueli/xxl-job-admin:2.4.0docker run  -d \\        -p 8088:8088\\        -v /tool/xxl-job/logs:/data/applogs \\        -v /tool/xxl-job/application.properties:/xxl-job/xxl-job-admin/src/main/resources/application.properties \\        -e PARAMS=&quot;--server.port=8088\\        --spring.datasource.url=jdbc:mysql://xxx.xx.xx.xxx:3306/xxl_job?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;serverTimezone=Asia/Shanghai \\        --spring.datasource.username=root \\        --spring.datasource.password=Wing1Q2W#E&quot; \\        --name xxl-job-admin  \\xuxueli/xxl-job-admin:2.4.0\n\n使用docker ps命令可以查看是否运行成功。\n常规搭建\n下载项目并解压，执行数据库初始化SQL脚本（在doc&#x2F;db目录下），根据数据库脚本创建数据库，有以下八张表（MySQL配置：Mysql超详细安装配置教程(保姆级)_mysql安装及配置超详细教程-CSDN博客）（navicat:Navicat16\\17安装和激活详细讲解（全网最简单且靠谱）_navicat 16-CSDN博客）\n\n\nxxl_job_lock：任务调度锁表；\nxxl_job_group：执行器信息表，维护任务执行器信息；\nxxl_job_info：调度扩展信息表： 用于保存XXL-JOB调度任务的扩展信息，如任务分组、任务名、机器地址、执行器、执行入参和报警邮件等等；\nxxl_job_log：调度日志表： 用于保存XXL-JOB任务调度的历史信息，如调度结果、执行结果、调度入参、调度机器和执行器等等；\nxxl_job_logglue：任务GLUE日志：用于保存GLUE更新历史，用于支持GLUE的版本回溯功能；\nxxl_job_registry：执行器注册表，维护在线的执行器和调度中心机器地址信息；\nxxl_job_user：系统用户表；\n\n注意事项：\n\n调度中心（即xxl-job）支持集群部署，集群情况下各节点务必连接同一个mysql实例;\n如果mysql做主从,调度中心集群节点务必强制走主库;\n默认账号密码：admin&#x2F;123456\n\n\n部署配置调度中心\n\n调度中心项目：xxl-job-admin\n\n作用：统一管理任务调度平台上调度任务，负责触发调度执行，并且提供任务管理平台。\n\n调度中心配置文件地址：&#x2F;xxl-job&#x2F;xxl-job-admin&#x2F;src&#x2F;main&#x2F;resources&#x2F;application.properties\n\n如图所示，这里配置的有对应的数据库的地址、用户名和密码等内容。\n\n\n\n启动xxl-job\n启动成功，访问http://localhost:8080/xxl-job-admin/**，默认登录账号密码 “**admin&#x2F;123456”, 登录后运行界面如下图所示。\n\n\n\n案例使用(pku-service，进行接入)前置条件：xxl-job的服务端已经起好。\n目录结构（需要从xxl-job的项目中将xxl-job-executor-sample-springboot目录copy出来）：\n\n\njava连接xxl-job\n添加依赖maven（pom.xml）\n&lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;            &lt;version&gt;2.4.2&lt;/version&gt;        &lt;/dependency&gt;        &lt;!--xxl-job--&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.xuxueli&lt;/groupId&gt;            &lt;artifactId&gt;xxl-job-core&lt;/artifactId&gt;            &lt;version&gt;2.3.0&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;\n\nyaml文件添加(或者直接application.properties也行)\nxxl:  job:    admin:      addresses: http://*******:8080/xxl-job-admin/  #**** 更换服务器地址      executor:      appname: pku-service         #执行器名字      address:      ip:      port: 9999      logpath: /data/applogs/xxl-job-jobhandler      logretentiondays: 30    accessToken: default_token\n\n配置xxl-job的执行器\n\n将示例工程下的配置类拷贝到pku-service工程下，该类中的属性就是获取配置文件中的配置得到的，同时提供了一个执行器的Bean\nimport com.xxl.job.core.executor.impl.XxlJobSpringExecutor;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import java.util.logging.Logger;@Configurationpublic class XxlJobConfig &#123;    private Logger logger = (Logger) LoggerFactory.getLogger(XxlJobConfig.class);    @Value(&quot;$&#123;xxl.job.admin.addresses&#125;&quot;)    private String adminAddresses;    @Value(&quot;$&#123;xxl.job.accessToken&#125;&quot;)    private String accessToken;    @Value(&quot;$&#123;xxl.job.executor.appname&#125;&quot;)    private String appname;    @Value(&quot;$&#123;xxl.job.executor.address&#125;&quot;)    private String address;    @Value(&quot;$&#123;xxl.job.executor.ip&#125;&quot;)    private String ip;    @Value(&quot;$&#123;xxl.job.executor.port&#125;&quot;)    private int port;    @Value(&quot;$&#123;xxl.job.executor.logpath&#125;&quot;)    private String logPath;    @Value(&quot;$&#123;xxl.job.executor.logretentiondays&#125;&quot;)    private int logRetentionDays;    @Bean    public XxlJobSpringExecutor xxlJobExecutor() &#123;        logger.info(&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; xxl-job config init.&quot;);        XxlJobSpringExecutor xxlJobSpringExecutor = new XxlJobSpringExecutor();        xxlJobSpringExecutor.setAdminAddresses(adminAddresses);        xxlJobSpringExecutor.setAppname(appname);        xxlJobSpringExecutor.setAddress(address);        xxlJobSpringExecutor.setIp(ip);        xxlJobSpringExecutor.setPort(port);        xxlJobSpringExecutor.setAccessToken(accessToken);        xxlJobSpringExecutor.setLogPath(logPath);        xxlJobSpringExecutor.setLogRetentionDays(logRetentionDays);        return xxlJobSpringExecutor;    &#125;    /**     * 针对多网卡、容器内部署等情况，可借助 &quot;spring-cloud-commons&quot; 提供的 &quot;InetUtils&quot; 组件灵活定制注册IP；     *     *      1、引入依赖：     *          &lt;dependency&gt;     *             &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;     *             &lt;artifactId&gt;spring-cloud-commons&lt;/artifactId&gt;     *             &lt;version&gt;$&#123;version&#125;&lt;/version&gt;     *         &lt;/dependency&gt;     *     *      2、配置文件，或者容器启动变量     *          spring.cloud.inetutils.preferred-networks: &#x27;xxx.xxx.xxx.&#x27;     *     *      3、获取IP     *          String ip_ = inetUtils.findFirstNonLoopbackHostInfo().getIpAddress();     */&#125;\n\n\n编写执行器代码（SampleXxlJob.java）\n注意这里的jobHandler的名称要匹配\n/**     * 1、简单任务示例（Bean模式）     */    @XxlJob(&quot;PKUJobHandler&quot;)    public void demoJobHandler() throws Exception &#123;        XxlJobHelper.log(&quot;XXL-JOB, Hello World.&quot;);        System.out.println(&quot;XXL-JOB, Hello World.&quot;);        for (int i = 0; i &lt; 5; i++) &#123;            XxlJobHelper.log(&quot;beat at:&quot; + i);            TimeUnit.SECONDS.sleep(2);        &#125;        // default success    &#125;\n\n\n\n新增执行器\n\n\n\n\n\n属性名称\n说明\n\n\n\nAppName\n是每个执行器集群的唯一标示AppName, 执行器会周期性以AppName为对象进行自动注册。可通过该配置自动发现注册成功的执行器, 供任务调度时使用;\n\n\n名称\n执行器的名称, 因为AppName限制字母数字等组成,可读性不强, 名称为了提高执行器的可读性;\n\n\n排序\n执行器的排序, 系统中需要执行器的地方,如任务新增, 将会按照该排序读取可用的执行器列表;\n\n\n注册方式\n调度中心获取执行器地址的方式；\n\n\n机器地址\n注册方式为”手动录入”时有效，支持人工维护执行器的地址信息；\n\n\n\n创建任务\n登录调度中心，点击下图所示“新建任务”按钮，新建示例任务：\n\n注意这里的JobHandler的名称要匹配。\n基础配置：\n\n执行器：每个任务必须绑定一个执行器, 方便给任务进行分组\n任务描述：任务的描述信息，便于任务管理；\n负责人：任务的负责人；\n报警邮件：任务调度失败时邮件通知的邮箱地址，支持配置多邮箱地址，配置多个邮箱地址时用逗号分隔\n\n调度配置：\n\n调度类型：\n\n无：该类型不会主动触发调度；\n\nCRON：该类型将会通过CRON，触发任务调度；\n\n固定速度：该类型将会以固定速度，触发任务调度；按照固定的间隔时间，周期性触发；\n\n\n\n\n任务配置：\n\n运行模式：\nBEAN模式：任务以JobHandler方式维护在执行器端；需要结合 “JobHandler” 属性匹配执行器中任务；\n\n\nJobHandler：运行模式为 “BEAN模式” 时生效，对应执行器中新开发的JobHandler类“@JobHandler”注解自定义的value值；\n任务参数：任务执行所需的参数；\n\n高级配置：\n\n阻塞处理策略：\n\n阻塞处理策略：调度过于密集执行器来不及处理时的处理策略；\n单机串行（默认）：调度请求进入单机执行器后，调度请求进入FIFO(First Input First Output)队列并以串行方式运行；\n丢弃后续调度：调度请求进入单机执行器后，发现执行器存在运行的调度任务，本次请求将会被丢弃并标记为失败；\n覆盖之前调度：调度请求进入单机执行器后，发现执行器存在运行的调度任务，将会终止运行中的调度任务并清空队列，然后运行本地调度任务；\n\n\n路由策略：\n当执行器集群部署时，提供丰富的路由策略，包括；\n\nFIRST（第一个）：固定选择第一个机器；\nLAST（最后一个）：固定选择最后一个机器；\nROUND（轮询）\nRANDOM（随机）：随机选择在线的机器；\nCONSISTENT_HASH（一致性HASH）：每个任务按照Hash算法固定选择某一台机器，且所有任务均匀散列在不同机器上。\nLEAST_FREQUENTLY_USED（最不经常使用）：使用频率最低的机器优先被选举；\nLEAST_RECENTLY_USED（最近最久未使用）：最久未使用的机器优先被选举；\nFAILOVER（故障转移）：按照顺序依次进行心跳检测，第一个心跳检测成功的机器选定为目标执行器并发起调度；\nBUSYOVER（忙碌转移）：按照顺序依次进行空闲检测，第一个空闲检测成功的机器选定为目标执行器并发起调度；\nSHARDING_BROADCAST(分片广播)：广播触发对应集群中所有机器执行一次任务，同时系统自动传递分片参数；可根据分片参数开发分片任务；\n\n\n\n\n启动JobExecutorApplication\n\n这里已经能够成功调度了。同时注意到执行器这里已经自动注册上了：\n\n\n\n补充：执行器和jobhandler的区别\nXXL-JOB是一个分布式任务调度平台，它具有简单易用、轻量级和易扩展的特点。在XXL-JOB中，执行器（Executor）和任务处理器（JobHandler）是两个核心组件，它们共同协作来完成定时任务的执行。\n执行器是任务的实际执行者，可以理解为承载任务的具体服务实例。每个执行器有自己独特的名称，通常设置为服务名以方便识别。执行器的主要职责是接收来自调度中心的调度请求，并执行相应的任务逻辑。执行器支持集群部署，以实现任务的高可用性和负载均衡  。\nJobHandler则是任务的抽象表示，它负责编写和处理具体的任务代码。开发者需要实现JobHandler接口中的execute方法，该方法是任务执行的入口点。在执行器启动时，会初始化JobHandler并将它们注册到执行器的容器中，以便在接收到调度请求时能够找到并执行相应的任务逻辑  。\n在XXL-JOB的架构中，”调度中心”负责管理调度信息并发出调度请求，而”执行器”则负责接收这些请求并执行JobHandler中的业务逻辑。这种设计使得调度和任务可以相互解耦，提高了系统整体的稳定性和扩展性  。\n总结来说，执行器和JobHandler在XXL-JOB中的区别主要在于：\n\n执行器（Executor）：任务的实际执行者，接收调度请求并执行任务。\n任务处理器（JobHandler）：任务的抽象，包含具体的业务逻辑代码，由执行器执行。\n\n","categories":["后端"],"tags":["Java","后端","微服务","分布式任务调度"]},{"title":"Java反射：获取类字段（getDeclaredFields()）","url":"/2024/08/17/2024-08-17-Java%E5%8F%8D%E5%B0%84%EF%BC%9A%E8%8E%B7%E5%8F%96%E7%B1%BB%E5%AD%97%E6%AE%B5%EF%BC%88getDeclaredFields()%EF%BC%89/","content":"Java反射：获取类字段getFields()方法和getDeclaredFields ()方法1. 概念反射是Java中一种强大的机制，允许在运行时获取、检查和操作类、方法、字段等信息，而不需要在编译时知道这些信息。\n其中字段（Field）在Java中是类中用于存储数据的成员变量。在反射中，可以通过Field类获取和操作类的字段。\n\ngetFields()： 该方法用于获取某个类及其父类中所有的公有字段。公有字段是指用public修饰的字段。\n这个方法对于需要获取类的公有属性时很有用，例如在某些框架或通用库中。\n\ngetDeclaredFields()： 该方法用于获取某个类中声明的所有字段，包括公有、私有、受保护的字段，但不包括继承的字段。\n这个方法对于需要获取类的所有字段时很有用，尤其是在进行一些高级的操作时。\n\n\n\n2. getFields()import java.lang.reflect.Field;public class GetFieldsTest1 &#123;    class User &#123;        public int number;        public String name;        private boolean isAdmin;    &#125;    class Student extends User &#123;        public String school;    &#125;    public static void main(String[] args) &#123;        Field[] fields = Student.class.getFields();        System.out.println(fields.length); // 输出：3        for (Field field : fields) &#123;            System.out.println(field.getName()); // 输出：school, number, name,         &#125;    &#125;&#125;\n\n这里获取了自己的字段和父类中的public字段。\n3. getDeclaredFields()import java.lang.reflect.Field;public class GetFieldsTest2 &#123;    class User &#123;        public int number;        public String name;        private boolean isAdmin;    &#125;    public static void main(String[] args) &#123;        Field[] fields = User.class.getDeclaredFields();        System.out.println(fields.length); // 输出：4        for (Field field : fields) &#123;            System.out.println(field.getName()); // 输出：number, name, isAdmin, this$0        &#125;    &#125;&#125;\n\n这里还有个this$0。在Java中，this$0是一个在匿名内部类或局部内部类中使用的特殊的引用变量。它指向外部类的一个实例，即内部类被创建的那个外部类的实例。\n4. Field的一些方法//方法:get(Object obj) 返回指定对象obj上此 Field 表示的字段的值field.get(obj)//方法: set(Object obj, Object value)  将指定对象变量上此 Field 对象表示的字段设置为指定的新值field.set(obj,value)\n\n","categories":["后端"],"tags":["Java","反射"]},{"title":"两万字讲清楚：现在的AI产品有多难做？","url":"/2024/09/05/2024-09-05-%E4%B8%A4%E4%B8%87%E5%AD%97%E8%AE%B2%E6%B8%85%E6%A5%9A%EF%BC%9A%E7%8E%B0%E5%9C%A8%E7%9A%84AI%E4%BA%A7%E5%93%81%E6%9C%89%E5%A4%9A%E9%9A%BE%E5%81%9A%EF%BC%9F/","content":"两万字讲清楚：现在的AI产品有多难做？https://mp.weixin.qq.com/s/pMt_VMs6uq5wsPPscOyefA\n这篇文章深入探讨了AI产品经理在处理大型AI模型时应该考虑的关键问题和机遇。\n1. 关注API而非仅仅是产品\n核心观点：产品经理应该深入理解大模型的API，因为这是模型能力的直接体现。产品的最终形态往往是API能力的延伸，但可能会因为各种工程限制而与API的能力有所差异。\n实际意义：了解API的能力和限制可以帮助产品经理更准确地设计产品功能，避免过度依赖模型无法实现的功能。\n\n2. AI与移动互联网的类比不恰当\n核心观点：简单地将AI技术应用到所有应用中并不是一个有效策略。只有那些真正能够从AI中获得显著优势的应用才应该进行AI重构。\n实际意义：这要求产品经理进行深入的需求分析和成本效益分析，以确定AI的投入是否真正值得。\n\n3. 产品经理需要学会调用API\n核心观点：产品经理应该具备直接与AI模型交互的能力，这有助于更好地理解模型的能力和局限。\n实际意义：这种能力可以帮助产品经理在产品开发过程中做出更准确的决策，并能够快速迭代产品以适应模型的变化。\n\n4. 大模型的长处在于跨内容媒介和模态\n核心观点：大模型的一个主要优势是能够处理和转换不同类型的数据和媒介，如文本、图像和声音。\n实际意义：这为创造新型的多媒体产品提供了可能，产品经理可以探索如何利用这一能力来增强用户体验。\n\n5. 大模型的局限性\n核心观点：尽管大模型功能强大，但它们在成本、上下文处理、数据准确性等方面存在局限。\n实际意义：产品经理在设计产品时需要考虑这些局限，确保产品在实际使用中能够稳定运行，并且提供准确的服务。\n\n6. 大模型可能永远无法解决的问题\n核心观点：某些问题，如成本和性能的平衡，可能永远无法通过技术进步完全解决。\n实际意义：产品经理需要在设计产品时考虑到这些长期存在的问题，并寻找创新的方法来减轻它们的影响。\n\n7. 大模型目前工程上的难点\n核心观点：数据的获取和处理，以及安全机制的设置，是当前大模型应用中的工程挑战。\n实际意义：产品经理需要与数据科学家和工程师紧密合作，确保数据的质量和安全性，同时优化模型的性能。\n\n8. 大模型未来可能会被解决的问题\n核心观点：随着技术的发展，大模型在意图理解、创作和推理能力方面的弱点可能会得到改善。\n实际意义：产品经理应该关注这些进步，以便及时更新产品功能，利用模型的新能力。\n\n9. 从RAG角度理解大模型产品\n核心观点：RAG技术通过结合检索和生成，提高了模型在特定任务上的表现。\n实际意义：产品经理可以利用RAG技术来设计更智能的信息检索和内容生成产品。\n\n10. 从媒介角度理解大模型价值\n核心观点：大模型和AIGC在内容生产和媒介转换方面具有革命性的意义。\n实际意义：产品经理可以探索如何通过AI技术改变内容的创作、分发和消费方式。\n\n11. 为什么我们高估了大模型\n核心观点：大模型在某些方面被过度理想化，实际上它们并不能完全替代传统的应用和交互方式。\n实际意义：产品经理需要有现实的期望，并结合AI技术与传统方法，创造出真正有价值的产品。\n\n12. 对产品经理的工作启示\n核心观点：产品经理应该关注实际的业务需求和数据，而不是盲目追求最新的技术趋势。\n实际意义：这要求产品经理具备批判性思维，能够从商业和用户需求的角度评估技术的适用性。\n\n13. AI Agent实践建议\n核心观点：设计AI Agent时，应该考虑任务的细分、成本与效果的平衡，以及如何最有效地利用模型的能力。\n实际意义：这些建议可以帮助产品经理更有效地利用AI技术，提高产品的效率和用户体验。\n\n整体而言，文章强调了产品经理在AI领域的工作中需要具备深入的技术理解、敏锐的商业洞察力和创新的设计思维。通过这些能力，产品经理可以更好地利用AI技术，创造出真正有价值的产品和服务。\n","categories":["大模型"],"tags":["人工智能","大模型","AI产品"]},{"title":"Transformer解析","url":"/2024/09/05/2024-09-05-Transformer%E8%A7%A3%E6%9E%90/","content":"Transformer解析（Attention Is All You Need）【超详细】【原理篇&amp;实战篇】一文读懂Transformer-CSDN博客\nTransformer论文逐段精读【论文精读】_哔哩哔哩_bilibili\n【超详细】【原理篇&amp;实战篇】一文读懂Transformer-CSDN博客\n大模型面试准备（十二）：深入剖析Transformer - 残差连接和层归一化_残差层和归一化层-CSDN博客\nTransformer通俗笔记：从Word2Vec、Seq2Seq逐步理解到GPT、BERT-CSDN博客\n\n“Attention Is All You Need” 是一篇由 Ashish Vaswani 等人撰写的论文，发表于 2017 年的 NeurIPS 会议上。这篇论文提出了 Transformer 模型，Transformer是一种用于自然语言处理（NLP）和其他序列到序列（sequence-to-sequence）任务的深度学习模型架构。Transformer架构引入了自注意力机制（self-attention mechanism），这是一个关键的创新，使其在处理序列数据时表现出色。\nTransformer 模型的主要特点：\n自注意力机制（Self-Attention）：Transformer 模型的核心是自注意力机制，它允许模型在序列的每个位置都计算与其他位置的注意力，从而捕捉序列内部的长距离依赖关系。这种机制使得模型能够更好地理解文本中的上下文信息。\n\n并行化处理：与循环神经网络（RNN）和长短期记忆网络（LSTM）不同，Transformer 模型可以并行处理序列中的所有元素，这大大提高了模型的训练速度。\n\n编码器-解码器架构：Transformer 模型通常由编码器和解码器两部分组成。编码器将输入序列转换为中间表示，解码器则根据这个表示生成输出序列。这种架构特别适用于机器翻译等任务。\n\n位置编码：由于自注意力机制本身不包含序列中的位置信息，Transformer 引入了位置编码来为模型提供序列中单词的位置信息。\n\n多头注意力（Multi-Head Attention）：Transformer 模型使用多头注意力机制来从不同的表示子空间中捕捉信息，这增强了模型的表达能力。\n\n层标准化（Layer Normalization）和残差连接（Residual Connections）：这些技术有助于提高模型的训练稳定性和性能。\n\n\nTransformer重点编码器（Encoder）：编码器：（多头注意力+MLP+残差连接）*N（N&#x3D;6）\n\n2 sub layer: \n\nMulti-Head Attention（多头注意力）\nposition-wise fully connected feed-forward network（一个MLP）\n\n在每一个sub layer中，有一个residual connection（残差连接）和一个Layer Norm（层归一化）。\n残差连接（Residual Connection）-CSDN博客\n【深度学习 | ResNet核心思想】残差连接 &amp; 跳跃连接：让信息自由流动的神奇之道-CSDN博客\nLayer Norm(x+sub layer(x))\n[BatchNorm和LayerNorm——通俗易懂的理解_layernorm和batchnorm-CSDN博客](https://blog.csdn.net/Little_White_9/article/details/123345062?ops_request_misc=%7B%22request%5Fid%22%3A%225650B123-9D57-41CE-A28B-51467C660DDF%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=5650B123-9D57-41CE-A28B-51467C660DDF&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-123345062-null-null.142^v100^pc_search_result_base8&amp;utm_term=Layer Norm&amp;spm&#x3D;1018.2226.3001.4187)\n\nbatchNorm和layerNorm:\n\n在上面的立方体中，可以理解为batch(有多少个句子)，seq（句子里有多少词）,feature（一个词的向量表示，在论文中是长度为512)。均值变为0方差变为1（减去均值再除以标准差）。\nbatchNorm（批归一化）是关注的不同样本和序列的同一feature的切面（蓝色）。\n而layerNorm（层归一化）关注的是一个样本下的东西（黄色）。\n\n\n\n\n编码器的输出作为解码器的输入。\n解码器（Decoder）：解码器：（带掩码的多头注意力+多头注意力+MLP+残差连接）*N（N&#x3D;6）\n\n3 sub layer: \nMasked Multi-Head Attention（带掩码多头注意力）\nMulti-Head Attention（多头注意力)\nposition-wise fully connected feed-forward network（一个MLP）\n\n\n\n在 Transformer 模型中，带掩码的多头注意力机制（Masked Multi-Head Attention）主要用于解码器（Decoder）部分，其作用是确保解码器在生成输出序列时，每一步只能使用之前的时间步的信息，而不能“看到”未来的信息。这种机制对于保持生成序列的自回归特性至关重要，以下是其具体作用和重要性：\n\n自回归特性：在序列生成任务（如语言模型、机器翻译）中，模型在生成当前词的同时，只能依赖于之前已经生成的词，而不能利用未来的词。带掩码的多头注意力机制通过掩码（Masking）操作实现这一点，确保在计算当前位置的注意力权重时，只考虑当前和之前位置的信息。\n避免未来信息泄露：在训练过程中，模型应该只根据给定的输入序列生成输出，而不应该利用未来的信息。如果不使用掩码，模型可能会“作弊”，利用未来的信息来生成当前的输出，这会影响模型的泛化能力和实用性。\n提高模型的鲁棒性：通过限制模型只能使用过去的信息，带掩码的多头注意力机制迫使模型学习如何更好地从已有的信息中提取和利用有用的特征，从而提高了模型的鲁棒性。\n实现并行解码：在解码过程中，由于每个时间步的输出只依赖于之前的输出，这允许模型并行生成整个序列，而不是必须等待前一个词生成完毕。这在某些场景下可以提高解码的效率。\n保持序列生成的连贯性：在生成文本或其他类型的序列数据时，保持序列的连贯性和逻辑性是非常重要的。带掩码的多头注意力机制通过确保每一步生成都只依赖于之前的信息，有助于生成更加连贯和合理的序列。\n\n在 Transformer 模型中，这种掩码通常是通过一个上三角矩阵实现的，其中未来位置的权重被设置为一个非常大的负数（例如负无穷大），这样在应用 softmax 函数时，这些位置的注意力权重会接近于零，从而被忽略。这种掩码也被称为因果掩码（Causal Mask），因为它确保了解码过程中的因果关系。\n编码器和解码器之间的联系作用的几个关键点：\n\n信息传递：编码器将输入序列（如源语言文本）转换为一系列连续的表示，解码器则利用这些表示来生成输出序列（如目标语言文本）。编码器-解码器注意力机制使得解码器能够在每一步生成输出时，都能够参考编码器提供的上下文信息。\n对齐关系：在机器翻译等任务中，编码器-解码器注意力机制有助于识别输入序列和输出序列之间的对齐关系。例如，它可以帮助模型确定在翻译过程中，源语言中的某个词对应于目标语言中的哪个词。\n上下文建模：解码器在生成每个输出词时，不仅要考虑已经生成的输出序列的部分，还要考虑整个输入序列的上下文。编码器-解码器注意力机制使得解码器能够在生成过程中充分利用输入序列的全局上下文信息。\n灵活性：编码器-解码器架构提供了灵活性，使得模型可以处理各种序列到序列的任务，如文本摘要、问答系统、对话系统等，而不仅仅是机器翻译。\n并行处理：在训练阶段，编码器可以并行处理整个输入序列，而解码器则可以并行生成整个输出序列，这大大提高了模型的训练效率。\n自回归特性：尽管解码器可以并行接收编码器的输出，但在生成输出序列时，它仍然保持自回归特性，即在生成当前词时，只能使用之前的时间步信息，而不能使用未来的信息。\n\n在 Transformer 模型的具体实现中，编码器-解码器注意力层通常位于解码器的每个层中。在这一层次上，查询（Queries）来自于解码器的上一层输出，键（Keys）和值（Values）来自于编码器的输出。通过这种方式，解码器可以有效地利用编码器处理过的输入序列信息来生成输出序列。\nAttention：Q、K、V（都是矩阵）：\n\n对于每一个key，有一个value和它对应。\nquery（黄色部分）将进行查询，搜索到与query相似度最大的若干key，并进行权重的分配（相似度越高的权重也就越高），综合value返回结果。\n不同注意力-&gt;不同权重，结果也不同\nScaled Dot-Product AttentionTransformer自己的注意力机制叫做：Scaled Dot-Product Attention。\n$$Attention(Q,K,V)&#x3D;softmax(QK^T&#x2F;\\sqrt{dk})V$$\n这里的query和key的维度是一样的（都是dk），而value的维度是（dv）。\n注意到softmax中的公式，Q乘以K的转置（做一个内积，余弦相似度），再除以根号dk，再softmax（对每一行做softmax）得到n个非负的且加起来和等于1的权重。\n\n这里其实是一个点乘注意力（dot-product attention）+除以根号dk\n为什么除以根号dk？\nScaled dot-product attention 中的缩放因子$$\\sqrt{dk}$$ 是为了调整点积注意力的缩放，以防止在计算注意力分数时出现过大的数值，这可能会导致梯度消失或者梯度爆炸的问题。这里的$$\\sqrt{dk}$$ 是查询（queries）、键（keys）向量的维度。\n当我们计算两个向量的点积时，如果向量的维度$$\\sqrt{dk}$$较大，那么点积的结果可能会变得非常大。由于 softmax 函数的输入值如果过大，会导致输出值接近于 0 或 1，这会使得梯度非常小，从而在反向传播过程中难以有效地更新权重。通过除以$$ \\sqrt{dk}$$，我们可以将点积的结果缩放到一个更合理的范围内，这样 softmax 函数的输出分布会更加平滑，梯度也会更加稳定。\n具体来说，缩放点积注意力的计算步骤如下：\n\n计算查询 Q和所有键 K之间的点积。\n\n将点积结果除以$$\\sqrt{dk}$$，这样做可以防止点积结果过大。\n\n应用 softmax 函数来获取注意力权重，这些权重表示每个值 V在计算加权和时的重要性。\n\n使用注意力权重对值 V进行加权求和，得到最终的注意力输出。\n\n\n数学上，Scaled dot-product attention 可以表示为：$$Attention(Q,K,V)&#x3D;softmax(QK^T&#x2F;\\sqrt{dk})V$$其中 Q是查询矩阵，K 是键矩阵，V是值矩阵，$$\\sqrt{dk}$$是缩放因子。\n这种缩放操作是 Transformer 模型中的一个关键设计，它有助于模型在处理长序列时保持稳定性，并且使得模型能够更有效地学习序列中的长距离依赖关系。\n掩码机制掩码机制：\n\n在 Transformer 模型中，掩码机制（Masking Mechanism）的作用主要是在解码器（Decoder）的自注意力层中防止未来信息的泄露，确保模型在生成当前输出时只能使用之前的时间步信息。这种机制对于保证序列生成任务的正确性和因果关系至关重要。以下是掩码机制的几个主要作用：\n\n因果关系维护：在序列生成任务中，如语言模型或机器翻译，每个输出应该是基于之前输出的因果序列。掩码机制确保解码器在生成当前词时，不会利用到未来词的信息，从而维护了序列的因果性。\n训练稳定性：通过限制自注意力层的计算范围，掩码机制可以防止在训练过程中出现错误的信息流，这有助于提高模型训练的稳定性和效率。\n并行解码：在解码过程中，掩码机制允许模型并行生成整个序列，因为每个输出词的生成只依赖于它之前的词，而不是整个序列。这大大提高了解码速度。\n避免无效计算：在自注意力计算中，掩码机制通过忽略无关的位置（例如填充位置或未来的词），减少了不必要的计算，从而提高了计算效率。\n处理变长序列：在处理不同长度的序列时，掩码机制可以动态地适应序列的实际长度，忽略填充部分，确保模型只关注有效的序列部分。\n\n在 Transformer 模型的解码器中，通常使用两种类型的掩码：\n\n因果掩码（Causal Mask）：这种掩码确保在生成序列的每个时间步时，模型只能看到当前和之前的词，而不能“看到”未来的词。这通常通过一个上三角矩阵实现，其中未来位置的权重被设置为一个非常大的负数（例如负无穷大），使得在应用 softmax 函数时，这些位置的注意力权重接近于零。\n填充掩码（Padding Mask）：在处理包含不同长度序列的批次时，通常会使用填充（Padding）来对齐序列长度。填充掩码用于告诉模型忽略这些填充的位置，因为它们不包含有效信息。\n\n例如，在机器翻译任务中，当模型正在生成英文翻译的第 i 个词时，它只能使用到已经翻译好的前 i-1 个词，而不能使用第 i 个词之后的信息。这样可以确保翻译的连贯性和正确性，因为翻译的每个步骤都是基于当前可用的最完整的上下文信息。\n多头注意力\n其实在Scaled Dot-Product Attention中没有什么要去学的参数，这里直接QKV线性变化低维投影，然后重复h次最后concat再做一次线性投影。\n在 Transformer 模型中的多头注意力机制（Multi-Head Attention）中，进行线性变换（Linear Transformation）和拼接（Concatenation）的步骤是为了增加模型的表达能力，允许它在不同的表示子空间中并行地学习信息。以下是这些步骤的具体作用和原因：\n\n线性变换：\n\n增加非线性：通过线性变换，模型可以学习到输入数据的不同线性组合，这有助于引入非线性特性，使得模型能够捕捉更复杂的特征和模式。\n特征提取：每个“头”（Head）中的线性变换可以看作是一种特征提取过程，它允许模型在不同的表示子空间中捕捉不同的信息。\n减少维度：在拼接之前，通常需要对每个头的输出进行线性变换，以减少维度，使得不同头的输出可以被拼接在一起而不会超过原始的维度限制。\n\n\n拼接：\n\n整合信息：拼接操作将多个头的输出合并成一个单一的表示，这样模型就可以同时考虑到所有头学习到的信息。\n增加宽度：拼接增加了模型的宽度，类似于在卷积神经网络中增加滤波器的数量，这有助于提高模型的容量和学习能力。\n保留多样性：每个头可以学习到不同的特征，拼接这些特征可以保留这种多样性，使得模型能够从多个角度理解数据。\n\n\n多头注意力的优势：\n\n并行处理：多头注意力允许模型并行地在不同的子空间中学习信息，这提高了计算效率。\n捕捉不同尺度的特征：不同的头可以捕捉到不同尺度的特征，例如，一些头可能关注局部细节，而另一些头可能关注更广泛的上下文信息。\n提高鲁棒性：多头机制增加了模型的鲁棒性，即使某些头没有学习到有用的特征，其他头仍然可以提供有用的信息。\n\n\n\n在实际操作中，多头注意力的计算过程通常如下：\n\n将输入 ( X ) 通过三个不同的线性变换得到查询 ( Q )、键 ( K ) 和值 ( V )。\n将 ( Q )、( K ) 和 ( V ) 分别分割成多个头，每个头对应一个子空间。\n对每个头，计算 ( Q ) 和 ( K ) 的点积注意力，然后应用 softmax 函数得到注意力权重，最后用这些权重对 ( V ) 进行加权求和。\n将所有头的输出拼接在一起，并通过另一个线性变换来整合信息，得到最终的多头注意力输出。\n\n这种设计使得 Transformer 模型在处理序列数据时非常有效，尤其是在自然语言处理任务中。\n\n多头注意力的公式理解_multihead attention公式-CSDN博客\nApplication of Attention in Our ModelTransformer中的三个attention是在干什么事情？\n\n在Transformer架构中，有3种不同的注意力层：\n\n解码器中的交叉注意力层（Cross attention layer）（右上角）\n\n在 Transformer 中，交叉注意力层位于字面上的中心位置；它连接了编码器和解码器，是在模型中使用注意力最直接的方式。\n要实现这一点，需要将目标序列作为查询，将上下文序列作为键&#x2F;值传递。\n\nQ &#x3D; 解码器中因果注意力层的输出向量\nK &#x3D; 编码器输出的注意力向量\nV &#x3D; 编码器输出的注意力向量\n\n\n\n\n编码器中的全局自注意力层（Global self attention layer）（左下角）\n\n全局自注意力是Transformer编码器的一部分，它的作用是负责处理整个输入序列。\n它允许每个序列元素直接访问其他所有序列元素，只需将整个序列作为Q，K，V即可，所有输出可以并行计算。\n\nQ &#x3D; 输入序列中的当前位置词向量\n\nK &#x3D; 输入序列中的所有位置词向量\n\nV &#x3D; 输入序列中的所有位置词向量\n\n\n\n\n\n解码器中的因果自注意力层（Casual attention layer）（右下角）\n\n因果注意力层对解码器中输出序列执行类似于全局自注意力层的工作；但与编码器的全局自注意力层有不同的处理方式。\nTransformer是一个“自回归”模型，它逐个标记地生成文本，并将输出反馈到输入中；为了使这个过程高效，这些模型确保每个序列元素的输出只依赖于前面的序列元素；这些模型是“因果”的。\n要构建一个因果自注意力层，在计算注意力分数和求和注意力值时需要使用适当的掩码，因为输出序列也是一次性输入的，但在计算前面分词的时候是不希望它后面的分词也参与计算的。\n\n\n\n\nPosition-wise Feed-Forward Networks$$\\text{FFN}(x) &#x3D; \\max(0, xW_1 + b_1)W_2 + b_2$$一个单隐藏层的MLP，做语义的转换。\n如上图所示：\n\n最下面蓝色的是输入，上面红色的长块就是注意力\n注意力能够提取到有用的序列信息\n这些有用的信息再经过一次MLP\n\n在Transformer模型中，Position-wise Feed-Forward Network（FFN）是编码器和解码器内部的一个关键组件。它的作用主要体现在以下几个方面：\n\n增加模型的表达能力：FFN通过引入非线性变换，使得模型能够捕捉到输入数据中更复杂的特征和模式。这对于处理序列数据尤其重要，因为序列数据往往包含丰富的上下文信息和复杂的依赖关系。\n\n参数效率：尽管Transformer模型的自注意力机制能够处理长距离依赖，但它的参数数量随着输入序列长度的增加而线性增长。FFN通过在每个位置独立地应用相同的权重，使得模型能够在保持参数数量相对固定的同时，处理不同长度的输入序列。\n\n位置不变性：FFN的设计使得它对输入序列中的位置信息不敏感，这有助于模型更好地泛化到不同的输入序列。在自注意力机制中，位置信息是通过位置编码（Positional Encoding）来引入的，而FFN则专注于处理序列中的局部特征。\n\n并行化处理：由于FFN在每个位置独立地应用相同的权重，这使得它可以很容易地在不同的位置上并行处理，从而提高模型的训练效率。\n\n减少过拟合：FFN通过引入额外的参数和非线性变换，增加了模型的复杂度，这有助于模型在面对复杂数据时减少过拟合的风险。\n\n\nFFN通常由两个线性变换和一个非线性激活函数（如ReLU）组成，其结构可以表示为：$$\\text{FFN}(x) &#x3D; \\max(0, xW_1 + b_1)W_2 + b_2$$其中，( x ) 是输入向量，( W_1 ) 和 ( W_2 ) 是权重矩阵，( b_1 ) 和 ( b_2 ) 是偏置向量。\nFFN的结构如下所示：\n\n第一个线性变换：输入数据首先通过一个线性变换，这个变换由权重矩阵 W1 和偏置向量 b1 组成。\nReLU激活函数：经过第一个线性变换后，数据会通过ReLU激活函数，ReLU函数的公式是 max⁡(0,x)max(0,x)，它将所有负值置为0，保留所有正值。这一步的目的是增加模型的非线性，使得模型能够学习到更复杂的函数。\n第二个线性变换：经过ReLU激活后的数据再通过另一个线性变换，这个变换由权重矩阵 W2 和偏置向量 b2 组成。\n\n在Transformer模型中，FFN通常在自注意力层之后应用，它的作用是对自注意力层的输出进行进一步的变换和特征提取。通过这种方式，FFN与自注意力机制协同工作，共同提高了模型的性能和泛化能力。\nRNN：\n\n如何从RNN起步，一步一步通俗理解LSTM_rnn lstm-CSDN博客\nEmbeddings and Softmax\n在RNN中，自然是包含时序信息的：将之前的输出自然的作为输出。\n但注意力机制而言，如果将一个句子顺序打乱，其得到的权重是不变的-&gt;这显然是不符合常理的，因为打乱顺序就意味着语义变化。为了弥补这种缺陷，加入了 位置编码。\ninput-&gt;词嵌入，得到一个向量-&gt;位置编码（正余弦，值在-1到1）-&gt;将向量和位置编码相加。\n在Transformer模型中，”Embedding” 和 “Softmax” 是两个重要的概念，它们在模型的不同部分发挥着关键作用。\nEmbedding\n定义：\n\nEmbedding 是一种将离散数据（如单词、字符或其他符号）映射到连续的向量空间的技术。在自然语言处理（NLP）中，embedding 通常用于将词汇表中的单词转换为固定长度的向量。\n\n\n在Transformer中的应用：\n\n词嵌入（Word Embedding）：在Transformer模型的输入阶段，每个单词首先被转换为一个词嵌入向量。这些向量捕捉了单词的语义信息，并且可以通过训练进一步优化。\n位置编码（Positional Encoding）：由于Transformer模型本身不具备捕捉序列中位置信息的能力，因此需要添加位置编码到词嵌入中。位置编码是一种将位置信息编码到向量中的方法，它与词嵌入向量相加，以确保模型能够理解单词在序列中的位置。\n\n\n\nSoftmax\n定义：\n\nSoftmax 是一种将实数向量转换为概率分布的函数。对于向量中的每个元素，Softmax 函数计算其相对于其他元素的指数，并将其归一化，使得所有输出值的和为1。\n\n\n在Transformer中的应用：\n\n自注意力机制中的输出：在自注意力层中，每个单词的嵌入向量会通过一个线性变换，然后应用Softmax函数。Softmax函数的输出表示每个单词对其他所有单词的关注程度，即注意力权重。\n解码器中的输出：在解码器的最后阶段，模型会预测下一个单词的概率分布。这里也会使用Softmax函数，将最后一个隐藏层的输出转换为词汇表上的概率分布，以便选择下一个最可能的单词。\n\n\n\n具体应用示例\n词嵌入：\n\n假设词汇表大小为10000，每个单词被映射到一个维度为512的向量空间。词嵌入层会将输入的单词索引转换为相应的512维向量。\n\n\n位置编码：\n\n位置编码通常是与词嵌入向量相同维度的向量，它通过正弦和余弦函数生成，以确保模型能够区分不同位置的单词。\n\n\n自注意力层中的Softmax：\n\n在自注意力层中，每个单词的嵌入向量会通过一个线性变换，得到一个未归一化的注意力分数。然后，Softmax函数将这些分数转换为概率分布，即每个单词对其他单词的关注权重。\n\n\n解码器的输出Softmax：\n\n在解码器的最后，模型会将最后一个隐藏层的输出通过一个线性变换，然后应用Softmax函数，得到词汇表上每个单词的概率分布。这个分布用于选择下一个最可能的单词。\n\n\n\n通过这些机制，Transformer模型能够有效地处理序列数据，捕捉单词之间的依赖关系，并在各种NLP任务中取得优异的性能。\nWhy Self-Attention没有说的太清楚\n\nComplexity per Layer（每层的复杂度）\nSequential Operations（序列操作）：\n\nO(1)：这意味着在处理序列时，每个层的操作可以并行化，不需要等待前一个操作完成。\n**O(n)**：并行化程度较差\n\nMaximum Path Length（最大路径长度）\nCNN&#x2F;RNN&#x2F;Transformer对比 - 知乎 (zhihu.com)\nTransformer 的应用：Transformer 模型自提出以来，已经在自然语言处理领域取得了巨大的成功，尤其是在机器翻译、文本摘要、问答系统和文本生成等任务中。此外，它也被用于语音识别和计算机视觉等领域。\n“Attention Is All You Need” 论文的提出标志着 NLP 领域的一个重要转折点，它不仅推动了模型架构的发展，也为后续的研究和应用奠定了基础。\nTransformer和CNN：Transformer 和 CNN 是两种在深度学习领域广泛使用的模型架构，它们各自有着独特的优势和适用场景。\nTransformer：\n\n并行处理能力：Transformer 模型由于不依赖于序列的循环结构，可以并行处理序列中的所有元素，这使得它在训练时能够充分利用现代硬件的并行计算能力，从而加快训练速度。\n自注意力机制：Transformer 通过自注意力机制能够捕捉序列中的长距离依赖关系，这在处理长序列数据时特别有用，如机器翻译和文本生成等任务。\n多头注意力：Transformer 模型中的多头注意力机制可以同时从不同的表示子空间中学习信息，增强了模型的表达能力。\n位置编码：由于 Transformer 本身不包含序列中的位置信息，因此需要引入位置编码来为模型提供序列中单词的位置信息。\n\nCNN：\n\n局部特征提取：CNN 通过卷积层可以有效地提取图像中的局部特征，如边缘、纹理等，这使得它在图像识别和分类任务中表现出色。\n参数共享：CNN 的卷积层通过权重共享减少了模型的参数数量，这不仅减少了计算成本，也使得模型更加高效。\n多层结构：CNN 通常包含多个卷积层和池化层，这有助于模型学习从低级到高级的特征表示。\n平移不变性：CNN 的卷积操作具有平移不变性，这意味着模型对图像中物体的位置变化具有一定的鲁棒性。\n\n在计算机视觉领域，CNN 长期以来一直是主流的模型架构，但近年来 Transformer 也开始在这一领域取得突破。例如，Vision Transformer（ViT）通过将图像分割成多个小块，然后将这些小块作为序列输入到 Transformer 模型中，已经在多个视觉任务中取得了优异的性能。\n在自然语言处理领域，Transformer 已经成为许多任务的首选模型，如机器翻译、文本摘要和问答系统等。它的并行化处理能力和长距离依赖关系的捕捉能力使其在这些任务中超越了传统的 RNN 和 LSTM 模型。\n总的来说，Transformer 和 CNN 各有优势，选择哪种模型取决于具体的任务需求、数据类型和计算资源。在某些情况下，甚至可以将两者结合起来，以利用它们各自的优势。\n","categories":["大模型"],"tags":["人工智能","Transformer"]},{"title":"大模型学习路线","url":"/2024/09/05/2024-09-05-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/","content":"大模型学习路线\n现在门槛降低了，成本也降低了。大模型技术爆发，抓住机会。\n开源大模型（离线，更安全）&#x2F;在线大模型\n\n微调：Lora-&gt;垂类\n\n适用于用户意图识别\n\n\nRAG：检索增强生成（一系列专家，提升表现幅度，降低幻觉）\n\n只要提供了正确答案，大概率就不会答错\n适合私有数据库\n所以依赖于提供的数据库的信息，对数据质量要求比较高\n推理更加缓慢（低于微调）\n对知识库构建&#x2F;信息压缩排名等（并非深度学习方面，需要深度学习算法工程师进行辅助）\n\n\n提示词工程\n【AI大模型】Prompt 提示词工程使用详解_大模型prompt的用法详解-CSDN博客\n\n预训练：创造出属于自己的全新大模型\n\n需要算力最多（微调其次，RAG和提示词工程对于算力的要求就没那么高）\n\n\n\nagent-&gt;担任80%脑力工作\n一些课程NLPFudanNLP&#x2F;nlp-beginner: NLP上手教程 (github.com)\n自然语言处理的入门练习\n深度学习跟李沐学AI的个人空间-跟李沐学AI个人主页-哔哩哔哩视频 (bilibili.com)\n动手学深度学习\n论文精读https://www.bilibili.com/video/BV1H44y1t75x/?spm_id_from=333.999.0.0\nllm-course :star:mlabonne&#x2F;llm-course: Course to get into Large Language Models (LLMs) with roadmaps and Colab notebooks. (github.com)\n课程分为三个部分：\n\nLLM的基础知识，包含数学python神经网络\n理论：专注于使用最新技术构建最好的 LLM\n工程：专注于创建基于 LLM 的应用程序并部署它们\n\n提示词工程https://github.com/Kevin-free/chatgpt-prompt-engineering-for-developers\n一些项目【2024最新】54个大模型实战项目，练完即可就业，从入门到进阶，基础到框架，你想要的全都有，建议码住！超级适合小白入门学习，大模型教程_哔哩哔哩_bilibili\n【李宏毅】2024年公认最好的【LLM大模型】教程！大模型入门到进阶，一套全解决！2024生成式人工智慧-附带课件代码_哔哩哔哩_bilibili\n","categories":["大模型"],"tags":["人工智能","大模型学习路线"]},{"title":"线段树","url":"/2024/09/08/2024-09-08-%E7%BA%BF%E6%AE%B5%E6%A0%91/","content":"线段树线段树是一种二叉树，也就是对于一个线段，我们会用一个二叉树来表示。\n性质：节点 i 的权值 &#x3D; 她的左儿子权值 + 她的右儿子权值。\n1. 建树根据这个思路，我们就可以建树了，我们设一个结构体 tree，tree[i].l 与 tree[i].r 分别表示这个点代表的线段的左右下标，tree[i].sum 表示这个节点表示的线段和。\n我们知道，一颗从1开始编号的二叉树，结点 i 的左儿子和右儿子编号分别是 2×i 和 2×i+1。\n再根据刚才的性质，得到式子：tree[ i ].sum &#x3D; tree[i∗2].sum + tree [i∗2+1].sum ，就可以建一颗线段树了！代码如下（这里以区间求和的查询为例）：\nvoid build(int i,int l,int r)&#123;//递归建树    tree[i].l=l;tree[i].r=r;    if(l==r)&#123;//如果这个节点是叶子节点        tree[i].sum=input[l];        return ;    &#125;    //二分建树    int mid=(l+r)/2;    build(i*2,l,mid);//分别构造左子树和右子树    build(i*2+1,mid+1,r);    tree[i].sum=tree[i*2].sum+tree[i*2+1].sum;//刚才我们发现的性质return ;&#125;\n\n2. 简单（无pushdown）的线段树2.1 单点修改，区间查询线段树的查询方法（范围查询）：\n\n如果这个区间被完全包括在目标区间里面，直接返回这个区间的值\n如果这个区间的左儿子和目标区间有交集，那么搜索左儿子\n如果这个区间的右儿子和目标区间有交集，那么搜索右儿子\n\n这里以区间求和的查询为例：\nint search(int i,int l,int r)&#123;    if(tree[i].l&gt;=l &amp;&amp; tree[i].r&lt;=r)//如果这个区间被完全包括在目标区间里面，直接返回这个区间的值        return tree[i].sum;    if(tree[i].r&lt;l || tree[i].l&gt;r)  return 0;//如果这个区间和目标区间毫不相干，返回0    int s=0;    if(tree[i*2].r&gt;=l)  s+=search(i*2,l,r);//如果这个区间的左儿子和目标区间又交集，那么搜索左儿子    if(tree[i*2+1].l&lt;=r)  s+=search(i*2+1,l,r);//如果这个区间的右儿子和目标区间又交集，那么搜索右儿子    return s;&#125;\n\n注意几个if条件和传参：\n\n传参：节点编号+左范围+右范围\n完全包含-&gt;直接返回sum；\n毫不相干-&gt;返回0；\n左儿子&#x2F;右儿子有交集-&gt;递归搜索下去\n\n单点更新：\n怎么修改这个区间的单点，其实这个相对简单很多，你要把区间的第dis位加上k，那么你从根节点开始，看这个dis是在左儿子还是在右儿子，在哪往哪跑，\n然后返回的时候，还是按照tree[i].sum=tree[i*2].sum+tree[i*2+1].sum的原则，更新所有路过的点。\n整个过程也是递归的\ninline void add(int i,int dis,int k)&#123;    if(tree[i].l==tree[i].r)&#123;//如果是叶子节点，那么说明找到了        tree[i].sum+=k;        return ;    &#125;    if(dis&lt;=tree[i*2].r)  add(i*2,dis,k);//在哪往哪跑    else  add(i*2+1,dis,k);    tree[i].sum=tree[i*2].sum+tree[i*2+1].sum;//返回更新    return ;&#125;\n\n\n\n2.2 区间修改，单点查询区间修改和单点查询，我们的思路就变为：如果把这个区间加上 k ，相当于把这个区间涂上一个 k 的标记，然后单点查询的时候，就从上跑到下，把沿路的标记加起来就好。\n这里面给区间贴标记的方式与上面的区间查找类似，原则还是那三条，只不过第一条：如果这个区间被完全包括在目标区间里面，直接将这个区间的值+k。（lazy标记）\n具体做法很像，这里贴上代码：\nvoid modify(int p, int l, int r, int k) &#123;\tif(tr[p].l &gt;= l &amp;&amp; tr[p].r &lt;= r) &#123;\t\ttr[p].num += k;\t\treturn ;\t&#125;\tint mid = tr[p].l + tr[p].r &gt;&gt; 1;\tif(l &lt;= mid) modify(p &lt;&lt; 1, l, r, k);\tif(r &gt; mid) modify(p &lt;&lt; 1 | 1, l, r, k);&#125;/*inline void add(int i,int l,int r,int k)&#123;    if(tree[i].l&gt;=l &amp;&amp; tree[i].r&lt;=r)&#123;//如果这个区间被完全包括在目标区间里面，讲这个区间标记k        tree[i].sum+=k;        return ;    &#125;    if(tree[i*2].r&gt;=l)        add(i*2,l,r,k);    if(tree[i*2+1].l&lt;=r)        add(i*2+1,l,r,k);&#125;*/\n\n单点查询了，这个更好理解了，就是dis在哪往哪跑，把路径上所有的标记(加上lazy标记)加上就好了：\nvoid query(int p, int x)&#123;\tans += tr[p].num;//一路加起来\tif(tr[p].l == tr[p].r) return;\tint mid = tr[p].l + tr[p].r &gt;&gt; 1;\tif(x &lt;= mid) query(p &lt;&lt; 1, x);\telse query(p &lt;&lt; 1 | 1, x); &#125;/*void search(int i,int dis)&#123;    ans+=tree[i].sum;//一路加起来    if(tree[i].l==tree[i].r)        return ;    if(dis&lt;=tree[i*2].r)        search(i*2,dis);    if(dis&gt;=tree[i*2+1].l)        search(i*2+1,dis);&#125;*/\n\n完整代码：\n#include &lt;bits/stdc++.h&gt;using namespace std;const int maxn = 5e5 + 7;int n, m, s, t;int ans;int a[maxn];struct segment_tree&#123;\t\tstruct node\t&#123;\t\tint l, r;\t\tint num;\t&#125;tr[maxn * 4];\t\tvoid build(int p, int l, int r)\t&#123;\t\ttr[p] = &#123;l, r, 0&#125;;\t\tif(l == r) &#123;\t\t\ttr[p].num = a[l];\t\t\treturn ;\t\t&#125;\t\tint mid = (l + r)/2;\t\tbuild(p*2, l, mid);\t\tbuild(p*2+1, mid + 1, r);\t&#125;\t\t\t//区间修改\tvoid modify(int p, int l, int r, int k) \t&#123;        //完全在区间里面\t\tif(tr[p].l &gt;= l &amp;&amp; tr[p].r &lt;= r) &#123;\t\t\ttr[p].num += k;\t\t\treturn ;\t\t&#125;\t\tint mid = (tr[p].l + tr[p].r)/2;\t\tif(l &lt;= mid) modify(p*2, l, r, k);\t\tif(r &gt; mid) modify(p*2+1, l, r, k);\t&#125;\t//单点查询\tvoid query(int p, int x)\t&#123;\t\tans += tr[p].num;\t\tif(tr[p].l == tr[p].r) return;\t\tint mid = (tr[p].l + tr[p].r)/2;\t\tif(x &lt;= mid) query(p*2, x);\t\telse query(p*2+1, x); \t&#125;&#125;ST;int main()&#123;\tcin &gt;&gt; n &gt;&gt; m;\tfor (int i = 1; i &lt;= n; ++ i) &#123;\t    scanf(&quot;%d&quot;, &amp;a[i]);\t&#125;\tST.build(1, 1, n);    for (int i = 1; i &lt;= m; ++ i) &#123;        int c;        scanf(&quot;%d&quot;, &amp;c);        if(c == 1) &#123;            int x, y, z;            scanf(&quot;%d%d%d&quot;, &amp;x, &amp;y, &amp;z);            ST.modify(1, x, y, z);        &#125;        else &#123;            ans = 0;            int x;            scanf(&quot;%d&quot;, &amp;x);            ST.query(1, x);            printf(&quot;%d\\n&quot;, ans);        &#125;    &#125;\treturn 0;&#125;/*int main()&#123;\tn = 100;\tfor (int i = 1; i &lt;= n; ++ i) &#123;\t\ta[i] = i;\t&#125;\tST.build(1, 1, n);\tm = 10;\tfor (int i = 1; i &lt;= m; ++ i) &#123;\t\tint l = 1, r = 100;\t\tST.modify(1, l, r, 10000);\t\tans = 0;\t\t// query(p, x), p = 1, x 为想要查询的点的下标\t\tST.query(1, 50); // 单点查询 下标为 50 的点的值，ans = 50 + 10000 * i\t\tcout &lt;&lt; i &lt;&lt; &quot; &quot; &lt;&lt; ans &lt;&lt; &#x27;\\n&#x27;;\t\tans = 0;\t\tST.query(1, 100); // 单点查询 ans = 100 + 10000 * i\t\tcout &lt;&lt; i &lt;&lt; &quot; &quot; &lt;&lt; ans &lt;&lt; &#x27;\\n&#x27;; \t&#125;\treturn 0;&#125;*/\n\n","categories":["算法"],"tags":["算法","数据结构","c++","线段树"]},{"title":"残差连接（Residual Connection）","url":"/2024/09/09/2024-09-09-%E6%AE%8B%E5%B7%AE%E8%BF%9E%E6%8E%A5/","content":"残差连接（Residual Connection）【深度学习 | ResNet核心思想】残差连接 &amp; 跳跃连接：让信息自由流动的神奇之道-CSDN博客\n\n背景：在深度神经网络中，随着层数的增加，网络的性能在一定程度上会提高（网格退化 Degradation）。然而，深度网络的训练也面临着一些挑战，其中之一是梯度消失或梯度爆炸的问题。当反向传播过程中的梯度变得非常小或非常大时，网络的参数更新会受到影响，导致训练变得困难。\n梯度消失和梯度爆炸：概念：梯度消失：在深层网络中，梯度需要通过多个层次进行反向传播。根据链式法则，梯度在传播过程中会不断相乘，当层数较多时，梯度值可能会以指数形式衰减并趋近于零，导致梯度消失。\n梯度爆炸：深层网络中的梯度在传播过程中也可能因链式法则的连乘效应而迅速增长，甚至呈指数级增长，导致网络参数更新过大，网络不稳定。\n为什么会梯度消失：在使用激活函数为Sigmoid或Tanh等饱和激活函数时，因为这些函数在输入较大或较小的情况下会饱和并导致梯度变得非常小。当输入接近1时，Sigmoid函数的输出值会接近于1，导数趋近于0。于是在反向传播过程中，梯度的乘积会趋近于零。（为了缓解梯度消失问题，深度神经网络中常常使用其他类型的激活函数，如ReLU）\n深度神经网络中，梯度是通过链式法则进行反向传播的。每一层的梯度都需要与前一层的梯度相乘，然后再传递到前一层，依此类推，直到传递到网络的输入层。如果网络层数较多，那么在反向传播过程中会经过多次连续的乘法操作，从而可能导致梯度的值指数级地减小，最终趋近于零，即梯度消失。\n为什么会梯度爆炸：\n神经网络经过多次的连乘，每次乘法操作都可能将梯度放大，从而导致梯度值变得非常大，从而导致梯度爆炸。\n\n梯度爆炸会导致网络的权重参数更新过大，从而使得模型的训练变得不稳定。\n\n\n\n残差连接的思想：残差连接的核心思想是在网络的一层或多层之间引入直接连接，使得这些层的输出不仅包括经过非线性变换的特征，还包括未经处理的输入特征。这样做的目的是允许网络学习到的是输入和输出之间的残差（即差异），而不是直接学习一个完整的映射。这种方式有助于梯度在训练过程中更有效地回流，减轻深度网络中梯度消失的问题。\n残差连接的核心思想是引入一个“快捷连接”（shortcut connection）或“跳过连接”（skip connection），允许数据绕过一些层直接传播。这样，网络中的一部分可以直接学习到输入与输出之间的残差（即差异），而不是直接学习到映射本身。具体来说，如果我们希望学习的目标映射是 H(x)，我们让网络学习残差映射 F(x)&#x3D;H(x)−x。因此，原始的目标映射可以表示为 F(x)+x。\n补一个跳过连接（skip connections）：\nSkip connections的实现方式通常是将某一层的输出（通常经过一个恒等映射或简单的线性变换）直接加到下一层（或更深层）的输出上。 这样，网络的输出就可以表示为输入的非线性变换与输入的线性叠加，即y &#x3D; F(x) + x，其中F(x)表示输入x经过一系列非线性变换后的输出，x表示直接传递的输入。e.g. :\n\n模型一共56层，若第20层时模型已经充分学习达到测试集最佳效果，则让从21层开始到第56层学习一种恒等变换，在最后一层将第20层的输出恒等映射出来。\n\n残差连接是一种跳过连接。\n\n\n具体实现：在传统的深度神经网络中，每一层的输出是基于前一层的输出进行计算。当网络层次增加时，网络的训练变得困难，因为梯度在反向传播过程中容易消失或爆炸。残差连接通过添加额外的“快捷连接”（shortcut connections）来解决这个问题。这些快捷连接允许一部分输入直接跳过一个或多个层传到更深的层，从而在不增加额外参数或计算复杂度的情况下，促进梯度的直接反向传播。\n具体来说：设想一个简单的网络层，其输入为 𝑥，要通过一个非线性变换 𝐹(𝑥) 来得到输出。在没有残差连接的情况下，这个层的输出就是 𝐹(𝑥)。当引入残差连接后，这个层的输出变为𝐹(𝑥) + 𝑥。这里的𝑥是直接从输入到输出的跳过连接（Skip Connection），𝐹(𝑥) + 𝑥即是考虑了输入本身的残差输出。这样设计允许网络在需要时倾向于学习更简单的函数（例如，当 𝐹(𝑥) 接近0时，输出接近输入），这有助于提高网络的训练速度和准确性。\n优点：\n梯度传播： 梯度能够更容易地通过残差连接传递。在反向传播时，由于直接的跳过连接，梯度不会消失得太快，使得训练更加容易。\n\n信息流动： 残差连接允许信息直接从输入层流向后续层，减轻了深度网络中信息难以传递的问题，有助于保持更加直接的信息流动。\n\n网络深度： 允许构建非常深的网络而不会遇到梯度消失的问题，从而推动了深度学习模型的发展。\nimport torchimport torch.nn as nnimport torch.nn.functional as F # 定义残差块class ResidualBlock(nn.Module):    def __init__(self, in_channels, out_channels, stride=1):        super(ResidualBlock, self).__init__()         # 第一个卷积层        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)        self.bn1 = nn.BatchNorm2d(out_channels)         # 激活函数        self.relu = nn.ReLU(inplace=True)         # 第二个卷积层        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)        self.bn2 = nn.BatchNorm2d(out_channels)         # 如果输入和输出的通道数不一致，需要进行调整，用于残差连接        self.shortcut = nn.Sequential()        if stride != 1 or in_channels != out_channels:            self.shortcut = nn.Sequential(                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),                nn.BatchNorm2d(out_channels)            )     def forward(self, x):        residual = x  # 保存输入，用于残差连接         # 第一个卷积块        out = self.conv1(x)        out = self.bn1(out)        out = self.relu(out)         # 第二个卷积块        out = self.conv2(out)        out = self.bn2(out)         out += self.shortcut(residual)  # 残差连接        out = self.relu(out)         return out # 定义ResNet模型class ResNet(nn.Module):    def __init__(self, block, layers, num_classes=10):        super(ResNet, self).__init__()        self.in_channels = 64  # 输入通道数        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)        self.bn1 = nn.BatchNorm2d(64)        self.relu = nn.ReLU(inplace=True)         # 通过make_layer函数构建ResNet的各层        self.layer1 = self.make_layer(block, 64, layers[0], stride=1)        self.layer2 = self.make_layer(block, 128, layers[1], stride=2)        self.layer3 = self.make_layer(block, 256, layers[2], stride=2)        self.layer4 = self.make_layer(block, 512, layers[3], stride=2)         # 全局平均池化层        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))         # 全连接层        self.fc = nn.Linear(512, num_classes)     # 构建每一层的函数    def make_layer(self, block, out_channels, blocks, stride):        layers = []        layers.append(block(self.in_channels, out_channels, stride))        self.in_channels = out_channels        for _ in range(1, blocks):            layers.append(block(out_channels, out_channels, stride=1))        return nn.Sequential(*layers)     def forward(self, x):        # 第一个卷积块        out = self.conv1(x)        out = self.bn1(out)        out = self.relu(out)         # 后续各层的卷积块        out = self.layer1(out)        out = self.layer2(out)        out = self.layer3(out)        out = self.layer4(out)         # 全局平均池化        out = self.avg_pool(out)        out = out.view(out.size(0), -1)         # 全连接层        out = self.fc(out)         return out # 创建ResNet18模型model = ResNet(ResidualBlock, [2, 2, 2, 2]) # 打印模型结构print(model)\n\n","categories":["深度学习"],"tags":["深度学习"]},{"title":"AlexNet解析","url":"/2024/09/10/2024-09-10-AlexNet%E8%A7%A3%E6%9E%90/","content":"AlexNet解析卷积神经网络经典回顾之AlexNet - 知乎 (zhihu.com)\nAlexNet论文逐段精读【论文精读】_哔哩哔哩_bilibili\n饱和：saturating \n非饱和：non-saturating\n\n\n","categories":["深度学习"],"tags":["人工智能","AlexNet"]},{"title":"常用激活函数","url":"/2024/09/10/2024-09-10-%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/","content":"常用激活函数激活函数汇总_高斯激活函数-CSDN博客\n常用的激活函数合集（详细版）-CSDN博客\n重点关注ReLU(max(0,x))，Sigmoid(0-1)，Softmax（0-1概率）\n神经网络之softmax(作用，工作原理【示例说明】，损失计算)_softmax层-CSDN博客\n预处理直接做原始图片 （224 * 224 * 3）\n","categories":["深度学习"],"tags":["人工智能","激活函数","神经网络"]},{"title":"饱和（saturating）和非饱和（non-saturating）的激活函数","url":"/2024/09/10/2024-09-10-%E9%A5%B1%E5%92%8C%EF%BC%88saturating%EF%BC%89%E5%92%8C%E9%9D%9E%E9%A5%B1%E5%92%8C%EF%BC%88non-saturating%EF%BC%89%E7%9A%84%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/","content":"饱和（saturating）和非饱和（non-saturating）的激活函数在神经网络中，激活函数是决定网络能否学习复杂模式的关键因素之一。激活函数的选择会影响网络的收敛速度、性能以及最终的泛化能力。激活函数可以根据其输出特性被分为“饱和”（saturating）和“非饱和”（non-saturating）两大类：\n饱和激活函数（Saturating Activation Functions）\n定义：\n\n饱和激活函数是指当输入值增大或减小时，函数的输出值会达到一个上限或下限，并在该范围内趋于稳定，不再随输入的增加而显著变化。\n\n\n特点：\n\n输出值存在一个明显的上限和下限。\n当输入值增大到一定程度后，输出值不再显著增加（或减少）。\n\n\n例子：\n\nSigmoid 函数：[ \\sigma(x) &#x3D; \\frac{1}{1 + e^{-x}} ]\nTanh 函数（双曲正切函数）：[ \\tanh(x) &#x3D; \\frac{2}{1 + e^{-2x}} - 1 ]\nReLU 函数（Rectified Linear Unit）在正区间内是非饱和的，但在负区间内是饱和的。\n\n\n影响：\n\n饱和激活函数容易导致梯度消失问题，特别是在深层网络中，因为当输入值远离激活函数的线性区域时，梯度会非常小。\n\n\n\n非饱和激活函数（Non-saturating Activation Functions）\n定义：\n\n非饱和激活函数是指无论输入值如何变化，函数的输出值和梯度都不会趋于一个固定的上限或下限。\n\n\n特点：\n\n输出值和梯度随输入值的增加而持续增加或减少，没有明显的饱和点。\n\n\n例子：\n\nReLU 函数（Rectified Linear Unit）：[ \\text{ReLU}(x) &#x3D; \\max(0, x) ]\nLeaky ReLU：[ \\text{LeakyReLU}(x) &#x3D; \\max(0.01x, x) ]\nParametric ReLU (PReLU) 和其他变种。\n\n\n影响：\n\n非饱和激活函数有助于缓解梯度消失问题，因为它们在整个输入范围内都能保持较大的梯度。\n但是，ReLU等激活函数可能会导致梯度爆炸问题，特别是在训练初期或输入值较大时。\n\n\n\n在实际应用中，选择哪种类型的激活函数取决于具体的任务、网络结构以及训练策略。例如，ReLU及其变种由于计算简单且能有效缓解梯度消失问题，因此在许多现代深度学习模型中被广泛使用。然而，在某些情况下，如输出需要被限制在特定范围内或需要输出概率分布时，饱和激活函数（如Sigmoid或Softmax）可能更为合适。\n","categories":["深度学习"],"tags":["人工智能","激活函数","神经网络"]},{"title":"CNN笔记","url":"/2024/09/11/2024-09-11-CNN%E7%AC%94%E8%AE%B0/","content":"CNN笔记CNN笔记：通俗理解卷积神经网络_cnn卷积神经网络-CSDN博客\nZero Padding（零填充）——在卷积神经网络中的作用？-CSDN博客\n一句话CNN：如何理解padding的作用和算法 - 知乎 (zhihu.com)\n为什么需要随机裁剪：随机裁剪相当于建立每个因子特征与相应类别的权重关系，减弱背景(或噪音)因子的权重，且使模型面对缺失值不敏感，也就可以产生更好的学习效果，增加模型稳定性。\n","categories":["神经网络"],"tags":["人工智能","CNN","卷积神经网络"]},{"title":"KL散度详解","url":"/2024/09/11/2024-09-11-KL%E6%95%A3%E5%BA%A6%E8%AF%A6%E8%A7%A3/","content":"KL散度进阶详解KL散度 - 知乎 (zhihu.com)\n","categories":["概率论"],"tags":["人工智能","KL散度","概率论"]},{"title":"RLHF","url":"/2024/09/11/2024-09-11-RLHF/","content":"RLHF从零实现ChatGPT——RLHF技术笔记 - 知乎 (zhihu.com)\n一文读懂「RLHF」基于人类反馈的进行强化学习-CSDN博客\n大模型 | 通俗理解RLHF基础知识以及完整流程-CSDN博客\n","categories":["强化学习"],"tags":["人工智能","强化学习"]},{"title":"Seq2Seq","url":"/2024/09/11/2024-09-11-Seq2Seq/","content":"Seq2Seq和Word2VecSeq2SeqSeq2Seq模型介绍 - 知乎 (zhihu.com)\nWord2Vec深入浅出Word2Vec原理解析 - 知乎 (zhihu.com)\n一文搞懂One-Hot编码与词嵌入（Embedding）-百度开发者中心 (baidu.com)\n如何通俗理解Word2Vec (23年修订版)-CSDN博客 :star:\n传统的one-hot 编码仅仅只是将词符号化，不包含任何语义信息。而且词的独热表示（one-hot representation）是高维的，且在高维向量中只有一个维度描述了词的语义 (高到什么程度呢？词典有多大就有多少维，一般至少上万的维度)。所以我们需要解决两个问题：\n\n需要赋予词语义信息\n降低维度\n\nWord2Vec:最终词向量的维度(与隐含层结点数一致)一般情况下要远远小于词语总数  的大小，所以 Word2vec 最有价值的是\n\n让不带语义信息的词带上了语义信息\n其次把词语从 one-hot encoder 形式的表示降维到 Word2vec 形式的表示\n\nCBOW（通过上下文推断某个词）\n\n将上下文词进行 one-hot 表征作为输入：I：        [1,0,0,0]drink：     [0,1,0,0]coffee：    ？everyday： [0,0,0,1]\n然后将 one-hot 表征结果[1,0,0,0]、[0,1,0,0]、[0,0,0,1]，分别乘以：3×4的输入层到隐藏层的权重矩阵W「这个矩阵也叫嵌入矩阵，可以随机初始化生成」，比如可以是1 2 3 01 2 1 2-1 1 1 1\n将得到的结果向量求平均作为隐藏层向量：[1, 1.67, 0.33]\n然后将隐藏层[1, 1.67, 0.33]向量乘以：4×3的隐藏层到输出层的权重矩阵W’「这个矩阵也是嵌入矩阵，也可以初始化得到」，得到输出向量：[4.01, 2.01, 5.00, 3.34]\n最后对输出向量[4.01, 2.01, 5.00, 3.34] 做 softmax 激活处理得到实际输出[0.23, 0.03, 0.62, 0.12]，并将其与真实标签[0, 0, 1, 0]做比较，然后基于损失函数做梯度优化训练\n\n","categories":["大模型"],"tags":["人工智能","Seq2Seq","Word2Vec"]},{"title":"强化学习笔记","url":"/2024/09/11/2024-09-11-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","content":"强化学习笔记强化学习极简入门：通俗理解MDP、DP MC TC和Q学习、策略梯度、PPO-CSDN博客\n","categories":["强化学习"],"tags":["人工智能","强化学习"]},{"title":"ResNet","url":"/2024/09/14/2024-09-14-ResNet/","content":"ResNet视频：ResNet论文逐段精读【论文精读】_哔哩哔哩_bilibili\n【深度学习】ResNet网络讲解-CSDN博客\n深度学习基础学习-残差-CSDN博客\n为什么要使用3×3卷积？&amp; 11卷积的作用是什么？&amp; 对ResNet结构的一些理解_33卷积-CSDN博客\n残差、方差、偏差、MSE均方误差、Bagging、Boosting、过拟合欠拟合和交叉验证-CSDN博客\n深度学习——残差网络（ResNet）原理讲解+代码（pytroch）_残差神经网络-CSDN博客 :star:\n快速理解卷积神经网络的输入输出尺寸问题_卷积神经网络输入和输出-CSDN博客\nCNN基础知识——卷积（Convolution）、填充（Padding）、步长(Stride) - 知乎 (zhihu.com)\n正态及标准正态分布-CSDN博客\n[ 图像分类 ] 经典网络模型4——ResNet 详解与复现-CSDN博客\n\n现象：更深的网络结构反而训练误差和测试误差都提升了！（梯度消失&#x2F;梯度爆炸）\n这里和overfiiting的区别是：过拟合是训练集上表现好，但测试集表现差，这里的现象是表现的都差，所以不是overfitting\n加了ResNet之后，解决这个问题\nBatch Normalizazion:具体的过程就是通过方法将该层的特征值分布重新拉回到标准正态分布(均值为0方差为1)，特征值降落在激活函数对于输入较为敏感的区间，输入的小变化可导致损失函数较大的变化，使得梯度变大，避免梯度消失，同时也可加快收敛。\n理解：\n可以转换为学习一个残差函数：F（x） &#x3D; H（x）- x，主要F（x）&#x3D; 0 就构成了一个恒等变换，而且拟合残差肯定更容易。\nF是求和前网络映射，H是从输入到求和后的网络映射。比如把5映射到5.1，那么引入残差前是:\nF(5)′&#x3D;5.1\n引入残差后是：H(5)&#x3D;5.1，H(5.1)&#x3D;F(5)+5，F(5)&#x3D;0.1\n这里的F′和F都表示网络参数映射，引入残差后的映射对输出的变化更敏感。比如S输出从5.1变到5.2，映射的输出F′增加了2%，而对于残差结构输出从5.1到5.2，映射F是从0.1到0.2，增加了100%。明显后者输出变化对权重的调整作用更大，所以效果更好。残差的思想都是去掉相同的主体部分，从而突出微小的变化。\n至于为何shortcut（捷径）的输入是X，而不是X&#x2F;2或是其他形式。作者的另一篇文章中探讨了这个问题，对以下6种结构（图2）的残差结构进行实验比较，shortcut是X&#x2F;2的就是第二种，结果发现还是第一种效果好。(实验得出的结果)\n输入输出：\n\n填零（zero padding）\n\n1*1卷积投影（在不增加感受野的情况下，让网络加深，进行数据的升维和降维）\n深度学习基础学习-1x1卷积核的作用（CNN中）_1*1卷积核的作用-CSDN博客:star\n\n\n","categories":["深度学习"],"tags":["人工智能","ResNet"]},{"title":"Lora大模型微调","url":"/2024/09/11/2024-09-11-Lora%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/","content":"Lora大模型微调LoRA微调方法详解-CSDN博客\n理解Lora微调只需一个公式-CSDN博客\n【LLM】金融场景的大模型Lora微调实战_金融微调数据集-CSDN博客\nLoRA原理很简单， 代码实现也不复杂。 简单地说，在模型实现上， 要在特定的模块上加一个旁路， 这个旁路就是两个矩阵相乘的形式。这些特定的模块理论上可以是任何模块， 目前作者实现的是在Linear, Embeding, Conv, Attention(只改其中的q和v)这些模块上加。\n关键代码：\nclass LoRALayer():    def __init__(        self,         r: int,         lora_alpha: int,         lora_dropout: float,        merge_weights: bool,    ):        self.r = r        self.lora_alpha = lora_alpha        # Optional dropout        if lora_dropout &gt; 0.:            self.lora_dropout = nn.Dropout(p=lora_dropout)        else:            self.lora_dropout = lambda x: x        # Mark the weight as unmerged        self.merged = False        self.merge_weights = merge_weightsclass Linear(nn.Linear, LoRALayer):    # LoRA implemented in a dense layer    def __init__(        self,         in_features: int,         out_features: int,         r: int = 0,         lora_alpha: int = 1,         lora_dropout: float = 0.,        fan_in_fan_out: bool = False, # Set this to True if the layer to replace stores weight like (fan_in, fan_out)        merge_weights: bool = True,        **kwargs    ):        nn.Linear.__init__(self, in_features, out_features, **kwargs)        LoRALayer.__init__(self, r=r, lora_alpha=lora_alpha, lora_dropout=lora_dropout,                           merge_weights=merge_weights)        self.fan_in_fan_out = fan_in_fan_out        # Actual trainable parameters        if r &gt; 0:            self.lora_A = nn.Parameter(self.weight.new_zeros((r, in_features)))            self.lora_B = nn.Parameter(self.weight.new_zeros((out_features, r)))            self.scaling = self.lora_alpha / self.r            # Freezing the pre-trained weight matrix            self.weight.requires_grad = False        self.reset_parameters()        if fan_in_fan_out:            self.weight.data = self.weight.data.transpose(0, 1)    def reset_parameters(self):        nn.Linear.reset_parameters(self)        if hasattr(self, &#x27;lora_A&#x27;):            # initialize A the same way as the default for nn.Linear and B to zero            nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(5))            nn.init.zeros_(self.lora_B)    def train(self, mode: bool = True):        def T(w):            return w.transpose(0, 1) if self.fan_in_fan_out else w        nn.Linear.train(self, mode)        if mode:            if self.merge_weights and self.merged:                # Make sure that the weights are not merged                if self.r &gt; 0:                    self.weight.data -= T(self.lora_B @ self.lora_A) * self.scaling                self.merged = False        else:            if self.merge_weights and not self.merged:                # Merge the weights and mark it                if self.r &gt; 0:                    self.weight.data += T(self.lora_B @ self.lora_A) * self.scaling                self.merged = True           def forward(self, x: torch.Tensor):        def T(w):            return w.transpose(0, 1) if self.fan_in_fan_out else w        if self.r &gt; 0 and not self.merged:            result = F.linear(x, T(self.weight), bias=self.bias)                        result += (self.lora_dropout(x) @ self.lora_A.transpose(0, 1) @ self.lora_B.transpose(0, 1)) * self.scaling            return result        else:            return F.linear(x, T(self.weight), bias=self.bias) \n\n在Linear层的实现上，多继承了一个LoRALayer, LoRALayer中就是设置了一些参数， 最主要的就是上面的讲道的矩阵的秩r了，其他就是一些辅助参数， 如控制训练和推理时主路参数和旁路参数是否合并等等。 在Linear层中， 多定义了A和B两个可训练的参数矩阵， 然后在forward中把主路和旁路输出相加， 基本上就是完全按照原理来的。LoRALayer 类\n\nLoRALayer 是一个基础类，用于定义LoRA层的通用属性和行为。\n\n__init__ \n  方法初始化类实例：  - `r`: LoRA的秩，表示要引入的低秩结构的大小。  - `lora_alpha`: 用于调整LoRA参数影响的缩放因子。  - `lora_dropout`: Dropout概率，用于在训练过程中随机丢弃部分LoRA参数，防止过拟合。  - `merge_weights`: 一个布尔值，用于控制是否将LoRA参数与原始权重合并。  - `lora_dropout`: 如果大于0，则创建一个`nn.Dropout`层；否则，定义一个不改变输入的lambda函数。### Linear 类- `Linear` 类继承自PyTorch的`nn.Linear`类，并集成了`LoRALayer`的功能，实现了LoRA层。  [python中的类class: 继承、覆盖、重写、重载、扩展、多态、封装_python class函数-CSDN博客](https://blog.csdn.net/eylier/article/details/128961571?ops_request_misc=%7B%22request%5Fid%22%3A%22B8F3F5FA-5712-4026-8DB6-DD482BCCC380%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=B8F3F5FA-5712-4026-8DB6-DD482BCCC380&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-2-128961571-null-null.142^v100^pc_search_result_base8&amp;utm_term=python类的继承&amp;spm=1018.2226.3001.4187)- ```  __init__\n\n 方法初始化类实例：\n\n- `in_features` 和 `out_features`: 分别表示输入和输出的特征数量。\n- `r`, `lora_alpha`, `lora_dropout`, `merge_weights`: 与`LoRALayer`中的参数相同。\n- `fan_in_fan_out`: 一个布尔值，用于控制权重矩阵的存储方式。\n- `**kwargs`: 允许传递其他关键字参数给`nn.Linear`。\n- 如果`r`大于0，初始化LoRA参数`lora_A`和`lora_B`，并将原始权重矩阵的梯度设置为False（即冻结预训练权重）。\n- `reset_parameters` 方法用于初始化权重。\n\n\n\n重写的方法\ntrain 方法：根据mode参数（训练或评估模式），合并或分离LoRA参数。\nforward 方法：定义了数据通过LoRA层时的计算过程。如果r大于0且参数未合并，则使用LoRA参数和原始权重计算输出；否则，直接使用原始权重计算输出。\n\n","categories":["大模型"],"tags":["人工智能","大模型微调","Lora"]},{"title":"Golang基础学习","url":"/2024/09/19/2024-09-19-Golang%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/","content":"Golang基础学习Go 语言教程 | 菜鸟教程 (it028.com)\ngoland开发环境搭建及运行第一个go程序HelloWorld_goland helloworld-CSDN博客\n基础语法Go 语言教程 | 菜鸟教程 (it028.com)\n语句后不需要;\n&#123;不能单独一列\nswitch注意switch支持多值匹配：\npackage mainimport (    &quot;fmt&quot;)func main() &#123;    day := &quot;Thursday&quot;    switch day &#123;    case &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;:        fmt.Println(day, &quot;is a weekday.&quot;)    case &quot;Saturday&quot;, &quot;Sunday&quot;:        fmt.Println(day, &quot;is a weekend.&quot;)    default:        fmt.Println(day, &quot;is not a valid day.&quot;)    &#125;&#125;\n\nfallthrough关键字强制执行下一个case的内容，switch不需要break（但java需要）\n注意if和switch没有()的使用\n函数定义：package mainimport &quot;fmt&quot;func add(a int, b int) int &#123; //返回值类型在后面\tvar result int\tresult = a + b\treturn result&#125;func main() &#123;\ta := 2\tb := 3\tans := add(a, b)\tfmt.Printf(&quot;ans is %d&quot;, ans)&#125;//如果有多个返回值func addAndMutiply(a,b int)(int,int)&#123;    var result1 int\tvar result2 int    result1 = a+b    result2 = a*b    return result1,result&#125;\n\n\n\n数组：var nums[5] intvar nums = [5]int&#123;0,1,2,3,4&#125;var nums = []int&#123;1,3,5,7,9,10&#125;\n\n获取数组长度：\n\n指针:var a intvar ptr *intptr = &amp;afmt.Printf(&quot;the num is %d\\n&quot;,a)fmt.Printf(&quot;the address of a is %x\\n&quot;,&amp;a)fmt.Printf(&quot;the address is %x\\n&quot;,ptr)fmt.Printf(&quot;the num of the address is %d\\n&quot;,*ptr)//空指针var nullPtr *intfmt.Printf(&quot;nullPtr的值为%x&quot;,nullPtr) //输出为0//判断是否为空指针if (nullPtr==nil)\n\n\n\n结构体和结构体指针：package mainimport &quot;fmt&quot;type Books struct &#123;   title string   author string   subject string   book_id int&#125;func main() &#123;   var Book1 Books        /* 声明 Book1 为 Books 类型 */   var Book2 Books        /* 声明 Book2 为 Books 类型 */   /* book 1 描述 */   Book1.title = &quot;Go 语言&quot;   Book1.author = &quot;www.runoob.com&quot;   Book1.subject = &quot;Go 语言教程&quot;   Book1.book_id = 6495407   /* book 2 描述 */   Book2.title = &quot;Python 教程&quot;   Book2.author = &quot;www.runoob.com&quot;   Book2.subject = &quot;Python 语言教程&quot;   Book2.book_id = 6495700   /* 打印 Book1 信息 */   fmt.Printf( &quot;Book 1 title : %s\\n&quot;, Book1.title)   fmt.Printf( &quot;Book 1 author : %s\\n&quot;, Book1.author)   fmt.Printf( &quot;Book 1 subject : %s\\n&quot;, Book1.subject)   fmt.Printf( &quot;Book 1 book_id : %d\\n&quot;, Book1.book_id)   /* 打印 Book2 信息 */   fmt.Printf( &quot;Book 2 title : %s\\n&quot;, Book2.title)   fmt.Printf( &quot;Book 2 author : %s\\n&quot;, Book2.author)   fmt.Printf( &quot;Book 2 subject : %s\\n&quot;, Book2.subject)   fmt.Printf( &quot;Book 2 book_id : %d\\n&quot;, Book2.book_id)&#125;//结构体指针package mainimport &quot;fmt&quot;type Books struct &#123;   title string   author string   subject string   book_id int&#125;func main() &#123;   var Book1 Books        /* Declare Book1 of type Book */   var Book2 Books        /* Declare Book2 of type Book */   /* book 1 描述 */   Book1.title = &quot;Go 语言&quot;   Book1.author = &quot;www.runoob.com&quot;   Book1.subject = &quot;Go 语言教程&quot;   Book1.book_id = 6495407   /* book 2 描述 */   Book2.title = &quot;Python 教程&quot;   Book2.author = &quot;www.runoob.com&quot;   Book2.subject = &quot;Python 语言教程&quot;   Book2.book_id = 6495700   /* 打印 Book1 信息 */   printBook(&amp;Book1)   /* 打印 Book2 信息 */   printBook(&amp;Book2)&#125;func printBook( book *Books ) &#123;   fmt.Printf( &quot;Book title : %s\\n&quot;, book.title)   fmt.Printf( &quot;Book author : %s\\n&quot;, book.author)   fmt.Printf( &quot;Book subject : %s\\n&quot;, book.subject)   fmt.Printf( &quot;Book book_id : %d\\n&quot;, book.book_id)&#125;\n\n\n\n切片:len:=3cap:=5var nums[] int = make([]int,len)var nums2[] int = make([]int,len,cap) //length,capacity//切片初始化var arr[] int = []int&#123;5,6,7,1,2&#125;var s[] int = arr[:] //cap=len=5s2[] = arr[0:5] //startIndex = 0,endIndex = 5-1=4\n\n完整的切片例子：\npackage mainimport &quot;fmt&quot;func main() &#123;   /* 创建切片 */   numbers := []int&#123;0,1,2,3,4,5,6,7,8&#125;     printSlice(numbers)   /* 打印原始切片 */   fmt.Println(&quot;numbers ==&quot;, numbers)   /* 打印子切片从索引1(包含) 到索引4(不包含)*/   fmt.Println(&quot;numbers[1:4] ==&quot;, numbers[1:4])   /* 默认下限为 0*/   fmt.Println(&quot;numbers[:3] ==&quot;, numbers[:3])   /* 默认上限为 len(s)*/   fmt.Println(&quot;numbers[4:] ==&quot;, numbers[4:])   numbers1 := make([]int,0,5)   printSlice(numbers1)   /* 打印子切片从索引  0(包含) 到索引 2(不包含) */   number2 := numbers[:2]   printSlice(number2)   /* 打印子切片从索引 2(包含) 到索引 5(不包含) */   number3 := numbers[2:5]   printSlice(number3)&#125;func printSlice(x []int)&#123;   fmt.Printf(&quot;len=%d cap=%d slice=%v\\n&quot;,len(x),cap(x),x)&#125;\n\n切片的append和copy\npackage mainimport &quot;fmt&quot;func main() &#123;   var numbers []int   printSlice(numbers)   /* 允许追加空切片 */   numbers = append(numbers, 0)   printSlice(numbers)   /* 向切片添加一个元素 */   numbers = append(numbers, 1)   printSlice(numbers)   /* 同时添加多个元素 */   numbers = append(numbers, 2,3,4)   printSlice(numbers)   /* 创建切片 numbers1 是之前切片的两倍容量*/   numbers1 := make([]int, len(numbers), (cap(numbers))*2)   /* 拷贝 numbers 的内容到 numbers1 */   copy(numbers1,numbers)   printSlice(numbers1)  &#125;func printSlice(x []int)&#123;   fmt.Printf(&quot;len=%d cap=%d slice=%v\\n&quot;,len(x),cap(x),x)&#125;\n\n\n\nrange：Go 语言中 range 关键字用于 for 循环中迭代数组(array)、切片(slice)、通道(channel)或集合(map)的元素。在数组和切片中它返回元素的索引和索引对应的值，在集合中返回 key-value 对。\npackage mainimport &quot;fmt&quot;func main() &#123;    //这是我们使用range去求一个slice的和。使用数组跟这个很类似    nums := []int&#123;2, 3, 4&#125;    sum := 0    for _, num := range nums &#123;        sum += num    &#125;    fmt.Println(&quot;sum:&quot;, sum)    //在数组上使用range将传入index和值两个变量。上面那个例子我们不需要使用该元素的序号，所以我们使用空白符&quot;_&quot;省略了。有时侯我们确实需要知道它的索引。    for i, num := range nums &#123;        if num == 3 &#123;            fmt.Println(&quot;index:&quot;, i)        &#125;    &#125;    //range也可以用在map的键值对上。    kvs := map[string]string&#123;&quot;a&quot;: &quot;apple&quot;, &quot;b&quot;: &quot;banana&quot;&#125;    for k, v := range kvs &#123;        fmt.Printf(&quot;%s -&gt; %s\\n&quot;, k, v)    &#125;    //range也可以用来枚举Unicode字符串。第一个参数是字符的索引，第二个是字符（Unicode的值）本身。    for i, c := range &quot;go&quot; &#123;        fmt.Println(i, c)    &#125;&#125;\n\n结果：\nsum: 9index: 1a -&gt; appleb -&gt; banana0 1031 111\n\nMap:package mainimport &quot;fmt&quot;func main() &#123;    var countryCapitalMap map[string]string /*创建集合 */    countryCapitalMap = make(map[string]string)    /* map插入key - value对,各个国家对应的首都 */    countryCapitalMap [ &quot;France&quot; ] = &quot;巴黎&quot;    countryCapitalMap [ &quot;Italy&quot; ] = &quot;罗马&quot;    countryCapitalMap [ &quot;Japan&quot; ] = &quot;东京&quot;    countryCapitalMap [ &quot;India &quot; ] = &quot;新德里&quot;    /*使用键输出地图值 */    for country := range countryCapitalMap &#123;        fmt.Println(country, &quot;首都是&quot;, countryCapitalMap [country])    &#125;    /*查看元素在集合中是否存在 */    capital, ok := countryCapitalMap [ &quot;American&quot; ] /*如果确定是真实的,则存在,否则不存在 */    /*fmt.Println(capital) */    /*fmt.Println(ok) */    if (ok) &#123;        fmt.Println(&quot;American 的首都是&quot;, capital)    &#125; else &#123;        fmt.Println(&quot;American 的首都不存在&quot;)    &#125;&#125;\n\ndelete函数\npackage mainimport &quot;fmt&quot;func main() &#123;        /* 创建map */        countryCapitalMap := map[string]string&#123;&quot;France&quot;: &quot;Paris&quot;, &quot;Italy&quot;: &quot;Rome&quot;, &quot;Japan&quot;: &quot;Tokyo&quot;, &quot;India&quot;: &quot;New delhi&quot;&#125;        fmt.Println(&quot;原始地图&quot;)        /* 打印地图 */        for country := range countryCapitalMap &#123;                fmt.Println(country, &quot;首都是&quot;, countryCapitalMap [ country ])        &#125;        /*删除元素*/ delete(countryCapitalMap, &quot;France&quot;)        fmt.Println(&quot;法国条目被删除&quot;)        fmt.Println(&quot;删除元素后地图&quot;)        /*打印地图*/        for country := range countryCapitalMap &#123;                fmt.Println(country, &quot;首都是&quot;, countryCapitalMap [ country ])        &#125;&#125;\n\n原始地图India 首都是 New delhiFrance 首都是 ParisItaly 首都是 RomeJapan 首都是 Tokyo法国条目被删除删除元素后地图Italy 首都是 RomeJapan 首都是 TokyoIndia 首都是 New delhi\n\n接口Go 语言提供了另外一种数据类型即接口，它把所有的具有共性的方法定义在一起，任何其他类型只要实现了这些方法就是实现了这个接口。\n接口-&gt;结构-&gt;func(结构)call(){}\npackage mainimport (    &quot;fmt&quot;)type Phone interface &#123;    call()&#125;type NokiaPhone struct &#123;&#125;func (nokiaPhone NokiaPhone) call() &#123;    fmt.Println(&quot;I am Nokia, I can call you!&quot;)&#125;type IPhone struct &#123;&#125;func (iPhone IPhone) call() &#123;    fmt.Println(&quot;I am iPhone, I can call you!&quot;)&#125;func main() &#123;    var phone Phone    phone = new(NokiaPhone)    phone.call()    phone = new(IPhone)    phone.call()&#125;\n\nI am Nokia, I can call you!I am iPhone, I can call you!\n\n错误处理\n例子：\npackage mainimport (    &quot;fmt&quot;)// 定义一个 DivideError 结构type DivideError struct &#123;    dividee int    divider int&#125;// 实现 `error` 接口func (de *DivideError) Error() string &#123;    strFormat := `    Cannot proceed, the divider is zero.    dividee: %d    divider: 0`    return fmt.Sprintf(strFormat, de.dividee)&#125;// 定义 `int` 类型除法运算的函数func Divide(varDividee int, varDivider int) (result int, errorMsg string) &#123;    if varDivider == 0 &#123;            dData := DivideError&#123;                    dividee: varDividee,                    divider: varDivider,            &#125;            errorMsg = dData.Error()            return    &#125; else &#123;            return varDividee / varDivider, &quot;&quot;    &#125;&#125;func main() &#123;    // 正常情况    if result, errorMsg := Divide(100, 10); errorMsg == &quot;&quot; &#123;            fmt.Println(&quot;100/10 = &quot;, result)    &#125;    // 当除数为零的时候会返回错误信息    if _, errorMsg := Divide(100, 0); errorMsg != &quot;&quot; &#123;            fmt.Println(&quot;errorMsg is: &quot;, errorMsg)    &#125;&#125;\n\n并发&#x2F;协程Go 并发 | 菜鸟教程 (it028.com)\ngolang学习笔记（协程的基础知识）_协程 golang-CSDN博客\n在Go语言中，要创建一个协程，只需在函数调用前加上关键字”go”。下面是一个简单的示例：\ngo 函数名()\n\n\n这样就创建了一个新的协程，并在该协程中执行相应的函数。协程会与主线程并发执行，不会阻塞主线程的执行。\n协程之间可以通过通道（Channel）进行通信。通道是一种在多个协程之间同步和传递数据的机制，它能够保证并发安全。通过通道，协程可以发送和接收数据，实现协程之间的协作。\npackage mainimport (\t&quot;fmt&quot;\t&quot;time&quot;)func longRunningTask() (res int) &#123;\ttime.Sleep(time.Second)\tfor i := 0; i &lt; 10; i++ &#123;\t\tres += i\t&#125;\treturn res&#125;func main() &#123;\tresult := make(chan int)\tgo func() &#123;\t\tresult &lt;- longRunningTask()\t&#125;()\tfmt.Println(&quot;Waiting for result...&quot;)\tfmt.Println(&quot;Result:&quot;, &lt;-result)&#125;\n\nmake和new[深入理解 Golang 中 New() 和 make() 的区别_golang new-CSDN博客](https://blog.csdn.net/qq_53742640/article/details/137696417?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=golang make&amp;utm_medium&#x3D;distribute.pc_search_result.none-task-blog-2allsobaiduweb~default-1-137696417.nonecase&amp;spm&#x3D;1018.2226.3001.4187)\n[golang 中 new 和 make 详解_golang make new-CSDN博客](https://blog.csdn.net/u012730525/article/details/136390719?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=golang make&amp;utm_medium&#x3D;distribute.pc_search_result.none-task-blog-2allsobaiduweb~default-2-136390719.nonecase&amp;spm&#x3D;1018.2226.3001.4187)\n包管理Golang 基础 Go Modules包管理_golang包管理-CSDN博客\ngo怎么引入其他Go package文件（vscode中）_go怎么引入别的文件-CSDN博客\n注意GOPATH和go.mod不能共存，用go.mod好一些\n$GOPATH&#x2F;go.mod exists but should not-CSDN博客\n","categories":["Golang"],"tags":["Golang"]},{"title":"Pytorch框架学习","url":"/2024/09/16/2024-09-16-Pytorch%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/","content":"Pytorch框架学习[conda常用命令汇总_conda info-CSDN博客](https://blog.csdn.net/raelum/article/details/125109819?ops_request_misc=%7B%22request%5Fid%22%3A%22FDEA5F49-A7E0-4BF5-99F9-B75BE8373F14%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=FDEA5F49-A7E0-4BF5-99F9-B75BE8373F14&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-2-125109819-null-null.142^v100^pc_search_result_base8&amp;utm_term=conda 命令&amp;spm&#x3D;1018.2226.3001.4187)\n【Pytorch】2024 Pytorch基础入门教程（完整详细版）-CSDN博客\n[通用的CUDA、cuDNN、anaconda、pytorch环境配置详细过程 - Windows &#x2F; Ubuntu Linux (以YOLOv5模型安装配置为例)_yolo5安装-CSDN博客](https://blog.csdn.net/Wontoner/article/details/115469474?ops_request_misc=%7B%22request%5Fid%22%3A%22D931CBE1-01B4-48A6-A1E1-F59F682F8C60%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=D931CBE1-01B4-48A6-A1E1-F59F682F8C60&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-115469474-null-null.142^v100^pc_search_result_base8&amp;utm_term=anaconda cuda cudnn&amp;spm&#x3D;1018.2226.3001.4187)\n","categories":["深度学习"],"tags":["人工智能","Pytorch"]},{"title":"AI Infra基础","url":"/2024/09/20/2024-09-20-AI-Infra%E5%9F%BA%E7%A1%80/","content":"AI Infra基础AI Infra 基础知识 - 一文介绍并行计算、费林分类法和 CUDA 基本概念 - 大模型知识库|大模型训练|开箱即用的企业大模型应用平台|智能体开发|53AI\n","categories":["AI Infra"],"tags":["人工智能","并行计算"]},{"title":"AI资源调度","url":"/2024/09/20/2024-09-20-AI%E8%B5%84%E6%BA%90%E8%B0%83%E5%BA%A6/","content":"AI资源调度[云原生 AI 的资源调度和 AI 工作流引擎设计分享_paddleflow-CSDN博客](https://blog.csdn.net/lihui49/article/details/129260286?ops_request_misc=%7B%22request%5Fid%22%3A%2281C8FAB8-41BA-4FDC-A5E5-B7EF5F69A9D0%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=81C8FAB8-41BA-4FDC-A5E5-B7EF5F69A9D0&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-3-129260286-null-null.142^v100^pc_search_result_base8&amp;utm_term=AI 资源调度&amp;spm&#x3D;1018.2226.3001.4187)\n解密英伟达NVLink：解锁多GPU计算的无限潜力_nvidia nvlink-CSDN博客\n论文导读：万卡集群训练大模型（by字节跳动）-CSDN博客\nhttps://arxiv.org/pdf/2402.15627.pdf\ny &#x3D; x+MLP(LN(x+Attention(LN(x))))  \n这个公式描述的是Transformer模型中的一个自注意力机制（Self-Attention）和前馈神经网络（Feed-Forward Neural Network, MLP）的组合。Transformer模型是自然语言处理领域中广泛使用的一种模型，它在处理序列数据时非常有效。这个公式可以分解为以下几个部分：\n\n**LN(x)**：这是Layer Normalization（层归一化）的缩写，它是一种归一化技术，用于稳定训练过程并提高模型性能。它对每个样本的特征进行归一化，而不是对整个批次进行归一化。\n\n**Attention(LN(x))**：这是自注意力机制，它允许模型在序列的不同位置关注不同的信息。自注意力机制可以捕捉序列内部的长距离依赖关系，这对于理解文本的上下文非常重要。\n\n**MLP(LN(x+Attention(LN(x))))**：这是一个前馈神经网络，它接收层归一化和自注意力机制的输出作为输入。MLP通常包含两个线性变换，中间可能有一个激活函数，如ReLU。这个MLP可以学习从自注意力机制中提取的复杂特征。\n\n**y &#x3D; x + MLP(LN(x+Attention(LN(x))))**：这是Transformer中的残差连接（Residual Connection）。在Transformer中，每个子层（如自注意力层和MLP层）的输出都会与子层的输入相加，然后进行层归一化。这种残差连接有助于避免在深层网络中出现的梯度消失问题，并且可以提高模型的性能。\n\n\n总结来说，这个公式描述了Transformer模型中的一个关键操作，它结合了层归一化、自注意力机制和前馈神经网络，并通过残差连接来提高模型的稳定性和性能。\n[一次讲清模型并行、数据并行、张量并行、流水线并行区别nn.DataParallel分布式]-CSDN博客\n【云原生 • Kubernetes】认识 k8s、k8s 架构、核心概念点介绍-CSDN博客\nK8S详解(5万字详细教程)-CSDN博客\n","categories":["AI Infra"],"tags":["人工智能","容器化","虚拟化","资源调度","AI Infra"]},{"title":"一种基于经验的动态资源调度：StraightLine:An End-to-End Resource-Aware Scheduler for Machine Learning Application Requests","url":"/2024/09/24/2024-09-24-%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E7%BB%8F%E9%AA%8C%E7%9A%84%E5%8A%A8%E6%80%81%E8%B5%84%E6%BA%90%E8%B0%83%E5%BA%A6%EF%BC%9AStraightLine-An-End-to-End-Resource-Aware-Scheduler-for-Machine-Learning-Application-Requests/","content":"StraightLine: An End-to-End Resource-Aware Scheduler for Machine Learning Application Requests\n摘要：提出了一个端到端的资源感知调度器，用于在混合基础设施中调度机器学习应用请求的最优资源。\n关键词：机器学习部署、异构资源、资源放置、容器化、无服务器计算。\n主要内容：\nML应用的生命周期包括模型开发和模型部署两个阶段。\n传统ML系统通常只关注生命周期中的一个特定阶段或阶段。\nStraightLine通过一个基于经验的动态放置算法，根据请求的独特特征（如请求频率、输入数据大小和数据分布）智能地放置请求。\n包括三个层次：模型开发抽象、多种实现部署、实时资源调度。\n\n模型容器化：\n使用NVIDIA-Docker实现模型开发的容器化。\n\n为模型训练构建了强大的NVIDIA-Docker，为模型验证构建了轻量级的NVIDIA-Docker。\n深度学习docker环境配置之nvidia-docker安装使用_nvidia docker-CSDN博客\n\n\n容器定制：\n根据不同的压缩ML模型，构建相应的RESTful API、无服务器应用程序和Docker容器。\n使用Docker容器适应不同的计算环境。\n\n实时资源感知调度：\n设计了一个基于经验的动态放置算法，以在混合基础设施中智能地放置不同的ML应用请求。\n\n评估：\n在一个混合测试平台（RESTful API、无服务器进程、Docker容器和虚拟机）上进行了实验。\n实验结果表明，StraightLine在适应异构资源方面有效。\n\n具体的算法：在论文 “StraightLine: An End-to-End Resource-Aware Scheduler for Machine Learning Application Requests” 中，提出了一个名为 Empirical Dynamic Placing Algorithm 的算法，用于智能地放置机器学习（ML）应用请求到最优资源上。这个算法是 StraightLine 调度器的关键创新之一。\nEmpirical Dynamic Placing Algorithm 的核心特点：\n基于经验：算法依赖于对过往请求和资源使用情况的经验数据来做出决策。\n\n动态放置：算法实时分析请求的特征，并动态地决定将请求分配到哪种资源（如容器、虚拟机或无服务器进程）。\n\n考虑请求特征：算法考虑了请求的独特特征，例如请求频率、输入数据大小和数据分布。\n\n\n算法的逻辑流程：\n输入：算法接收一组请求 R，每个请求 r 包含请求 ID（rid）、在时间 t 的请求频率（ft）、请求数据大小（rd）。\n\n初始化：定义请求频率阈值（F）和数据大小阈值（D），以及可用资源（Flask SF 和 Docker SD）。\n\n请求分析：\n\n如果请求频率 ft 大于阈值 F 且数据大小 rd 小于阈值 D，则将请求 r 部署到无服务器平台上。\n如果数据大小 rd 大于阈值 D，则将请求 r 部署到 Docker 平台上。\n如果 Flask SF 资源可用且请求频率 ft 适中，则将请求 r 部署到 Flask（本地 web 服务器）上。\n\n\n资源分配：\n\n如果 Flask SF 资源不可用，但 Docker SD 资源可用，则将请求分配到 Docker 平台。\n如果 Flask SF 和 Docker SD 资源都不可用作进一步请求，则将请求分配到无服务器平台上。\n\n\n输出：算法输出请求 R 的放置 K，即每个请求分配到的具体资源。\n\n\n算法的目的：\n最小化延迟：通过智能放置请求，减少 ML 应用部署的响应时间和失败率。\n适应混合基础设施：算法能够适应包含云计算数据中心、本地服务器、容器和无服务器平台的混合基础设施。\n\n算法的效果：\n减少响应时间：通过将请求分配到最适合的资源，算法减少了处理请求所需的时间。\n降低失败率：通过考虑请求的特征和资源的可用性，算法减少了请求处理失败的可能性。\n\nEmpirical Dynamic Placing Algorithm 是 StraightLine 调度器中用于优化 ML 应用请求处理的核心组件，它通过实时分析和智能决策来提高资源利用率和系统性能。\n","categories":["AI Infra"],"tags":["人工智能","容器化","虚拟化","资源调度","AI Infra"]},{"title":"GPU 容器底层实现","url":"/2024/09/28/2024-09-28-GPU-%E5%AE%B9%E5%99%A8%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/","content":"GPU 容器底层实现容器使⽤ GPU – 问题提出在容器环境中使⽤ GPU 是⼀件有趣的事情，以 NVIDIA GPU 为例，常⻅的⼀个使⽤ CUDA 的应⽤程序，其结构图如下：\n\nCUDA Driver API：GPU 设备的抽象层，通过⼀系列 API 直接操作 GPU 设备，性能好，但编程难度⾼ （需要显式进⾏device初始化以及context管理等）\nCUDA Runtime API: 对 CUDA Driver API 进⾏⼀定封装，简化编程过程，降低开发难度； \nCUDA Libraries: 更⾼层的封装，包含⼀些成熟的⾼效函数库。\n 因此要实现 NVIDIA 容器化，也就是要让应⽤程序可以在容器内调⽤ CUDA API 来操作 GPU，⼀般来讲，就要使容器内应⽤程序内可调⽤ CUDA Runtime API 和 CUDA Libraries，容器内可使⽤ CUDA Driver 相关库。 \n\nNVIDIA CONTAINER TOOLKIT 具体结构曾经 NVIDIA Docker 通过 docker 的 volume ⽅法将 CUDA Driver 挂载到容器⾥，应⽤程序需要在 LD_LIBRARY_PATH 环境变量中配置 CUDA Driver 库所在位置。\n⽽到了 NVIDIA Docker2.0，默认 的 Runtime 被修改为了 nvidia-container-runtime，nvidia-container-runtime 会向传⼊的 OCI 规范，添加⼀个 prestart hook，该挂钩为容器调⽤ NVIDIA 容器运⾏时挂钩，从⽽配置 GPU 访问。 NVIDIA 将所有的这些组件打包成了 nvidia container toolkit，其内部组织结构如下：\n\n简单来说，NVIDIA Container Toolkit 是⼀系列软件包的集合，这些软件包将容器运⾏时（如 Docker）与主机上的英伟达驱动程序接⼝相连。\nlibnvidia-container 库负责提供 API 和 CLI， 通过运⾏时包装器⾃动向容器提供系统的 GPU，其内部结构如下： \nnvidia-container-toolkit 组件实现了⼀个容器运⾏ hook。这意味着当⼀个新容器即将启动时，它会收到通知。它会查看要附加的 GPU，并调⽤ libnvidia-container 来处理容器创建。 该 hook 由 nvidia-container-runtime 启⽤。它封装了 “真正的 “容器运⾏时，如 containerd 或 runc，以确保运⾏ prestart hook 。hook 执⾏后，现有运⾏时将继续执⾏容器启动过程。容器⼯具包安装完成后，会看到 Docker 守护进程配置⽂件中选择了 nvidia-container-runtime 。\n补充：[docker基础知识_–runtime&#x3D;runc-CSDN博客](https://blog.csdn.net/o0xgw0o/article/details/124498742?ops_request_misc=%7B%22request%5Fid%22%3A%2243690CB2-A222-4FE8-8DAE-E2A586C5B244%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=43690CB2-A222-4FE8-8DAE-E2A586C5B244&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-124498742-null-null.142^v100^pc_search_result_base8&amp;utm_term=low-level runtime&amp;spm&#x3D;1018.2226.3001.4187)\n挂载流程具体细节NVIDIA Container Runtimenvidia-container-runtime 是⼀个对low-level runtime(底层运⾏时,如 runc）的 shim，其传统模式就是修改 OCI specification。注意：这⾥它与 docker 中的 –gpus ⼲了同样的事情（所以如果是其他模式，就会报错，此时加 –runtime&#x3D;nvidia 即可）。 \nnvidia-container-runtime 其实就是在 runc 基础上多实现了对 nvidia-container-runime-hook 的调⽤。当检测到包含有 create 命令和 NVIDIA_VISIBLE_DEVICES 环境变 量时，就会执⾏默认的 runc。\nfunc newNVIDIAContainerRuntime(logger logger.Interface, cfg *config.Config, argv []string, driver *root.Driver) (oci.Runtime, error) &#123;    lowLevelRuntime, err := oci.NewLowLevelRuntime(logger, cfg.NVIDIAContainerRuntimeConfig.Runtimes)    if err != nil &#123;        return nil, fmt.Errorf(&quot;error constructing low-level runtime: %v&quot;, err)    &#125;    if !oci.HasCreateSubcommand(argv) &#123;        logger.Debugf(&quot;Skipping modifier for non-create subcommand&quot;)        return lowLevelRuntime, nil    &#125;    ociSpec, err := oci.NewSpec(logger, argv)    if err != nil &#123;        return nil, fmt.Errorf(&quot;error constructing OCI specification: %v&quot;, err)    &#125;    specModifier, err := newSpecModifier(logger, cfg, ociSpec, driver)    if err != nil &#123;        return nil, fmt.Errorf(&quot;failed to construct OCI spec modifier: %v&quot;, err)    &#125;    // Create the wrapping runtime with the specified modifier    r := oci.NewModifyingRuntimeWrapper(        logger,        lowLevelRuntime,        ociSpec,        specModifier,    )    return r, nil&#125;\n\n其中需要注意的是，如果命令中不包含 create，也就是说不创建新的 container 时，会直接返回low-level runtime。\n其中 modify 部分就是将输入的 OCI spec 进行修改，添加上 Hook，不同 modify 的功能主要功能如下：\n\nModeModifier: 添加 Hook\nGraphicsModifier: 负责修改 NVIDIA_DRIVER_CAPABILITIES 相关指标\nFeatureModifier: 包括一些可选功能（如 NVSWITCH 等）的修改\n\nModify 的关键代码如下：\nfunc (m stableRuntimeModifier) Modify(spec *specs.Spec) error &#123;    // If an NVIDIA Container Runtime Hook already exists, we don&#x27;t make any modifications to the spec.    if spec.Hooks != nil &#123;        for _, hook := range spec.Hooks.Prestart &#123;            hook := hook            if isNVIDIAContainerRuntimeHook(&amp;hook) &#123;                m.logger.Infof(&quot;Existing nvidia prestart hook (%v) found in OCI spec&quot;, hook.Path)                return nil            &#125;        &#125;    &#125;    path := m.nvidiaContainerRuntimeHookPath    m.logger.Infof(&quot;Using prestart hook path: %v&quot;, path)    args := []string&#123;filepath.Base(path)&#125;    if spec.Hooks == nil &#123;        spec.Hooks = &amp;specs.Hooks&#123;&#125;    &#125;    spec.Hooks.Prestart = append(spec.Hooks.Prestart, specs.Hook&#123;        Path: path,        Args: append(args, &quot;prestart&quot;),    &#125;)    return nil&#125;\n\n其在最后向 spec 中写入了一个 prestart，从而启动 nvidia-container-runtime-hook组件进行对 prestart 的具体修改。\nDocker GPU在 Docker 中，也可以通过指定 –gpus 的方式有和 NVIDIA Container Runtime 类似的效果，相关代码如下：\nconst nvidiaHook = &quot;nvidia-container-runtime-hook&quot;func setNvidiaGPUs(s *specs.Spec, dev *deviceInstance) error &#123;    req := dev.req    if req.Count != 0 &amp;&amp; len(req.DeviceIDs) &gt; 0 &#123;        return errConflictCountDeviceIDs    &#125;    if len(req.DeviceIDs) &gt; 0 &#123;        s.Process.Env = append(s.Process.Env, &quot;NVIDIA_VISIBLE_DEVICES=&quot;+strings.Join(req.DeviceIDs, &quot;,&quot;))    &#125; else if req.Count &gt; 0 &#123;        s.Process.Env = append(s.Process.Env, &quot;NVIDIA_VISIBLE_DEVICES=&quot;+countToDevices(req.Count))    &#125; else if req.Count &lt; 0 &#123;        s.Process.Env = append(s.Process.Env, &quot;NVIDIA_VISIBLE_DEVICES=all&quot;)    &#125;    var nvidiaCaps []string    // req.Capabilities contains device capabilities, some but not all are NVIDIA driver capabilities.    for _, c := range dev.selectedCaps &#123;        nvcap := nvidia.Capability(c)        if _, isNvidiaCap := allNvidiaCaps[nvcap]; isNvidiaCap &#123;            nvidiaCaps = append(nvidiaCaps, c)            continue        &#125;        // TODO: nvidia.WithRequiredCUDAVersion        // for now we let the prestart hook verify cuda versions but errors are not pretty.    &#125;    if nvidiaCaps != nil &#123;        s.Process.Env = append(s.Process.Env, &quot;NVIDIA_DRIVER_CAPABILITIES=&quot;+strings.Join(nvidiaCaps, &quot;,&quot;))    &#125;    path, err := exec.LookPath(nvidiaHook)    if err != nil &#123;        return err    &#125;    if s.Hooks == nil &#123;        s.Hooks = &amp;specs.Hooks&#123;&#125;    &#125;    s.Hooks.Prestart = append(s.Hooks.Prestart, specs.Hook&#123;         Path: path,        Args: []string&#123;            nvidiaHook,            &quot;prestart&quot;,        &#125;,        Env: os.Environ(),    &#125;)    return nil&#125;\n\n这也就印证了之前所说的非传统模式的 nvidia-container-runtime 会和 Docker 产生的冲突\nNVIDIA Container Runtime HookNvidia-container-runtime-hook的作用为根据 config 设置 nvidia-container-cli 的参数，并调用 nvidia-container-cli\nrootfs := getRootfsPath(container)args := []string&#123;getCLIPath(cli)&#125;if cli.Root != &quot;&quot; &#123;    args = append(args, fmt.Sprintf(&quot;--root=%s&quot;, cli.Root))&#125;if cli.LoadKmods &#123;    args = append(args, &quot;--load-kmods&quot;)&#125;if cli.NoPivot &#123;    args = append(args, &quot;--no-pivot&quot;)&#125;if *debugflag &#123;    args = append(args, &quot;--debug=/dev/stderr&quot;)&#125; else if cli.Debug != &quot;&quot; &#123;    args = append(args, fmt.Sprintf(&quot;--debug=%s&quot;, cli.Debug))&#125;if cli.Ldcache != &quot;&quot; &#123;    args = append(args, fmt.Sprintf(&quot;--ldcache=%s&quot;, cli.Ldcache))&#125;if cli.User != &quot;&quot; &#123;    args = append(args, fmt.Sprintf(&quot;--user=%s&quot;, cli.User))&#125;args = append(args, &quot;configure&quot;)if ldconfigPath := cli.NormalizeLDConfigPath(); ldconfigPath != &quot;&quot; &#123;    args = append(args, fmt.Sprintf(&quot;--ldconfig=%s&quot;, ldconfigPath))&#125;if cli.NoCgroups &#123;    args = append(args, &quot;--no-cgroups&quot;)&#125;if len(nvidia.Devices) &gt; 0 &#123;    args = append(args, fmt.Sprintf(&quot;--device=%s&quot;, nvidia.Devices))&#125;if len(nvidia.MigConfigDevices) &gt; 0 &#123;    args = append(args, fmt.Sprintf(&quot;--mig-config=%s&quot;, nvidia.MigConfigDevices))&#125;if len(nvidia.MigMonitorDevices) &gt; 0 &#123;    args = append(args, fmt.Sprintf(&quot;--mig-monitor=%s&quot;, nvidia.MigMonitorDevices))&#125;if len(nvidia.ImexChannels) &gt; 0 &#123;    args = append(args, fmt.Sprintf(&quot;--imex-channel=%s&quot;, nvidia.ImexChannels))&#125;for _, cap := range strings.Split(nvidia.DriverCapabilities, &quot;,&quot;) &#123;    if len(cap) == 0 &#123;        break    &#125;    args = append(args, capabilityToCLI(cap))&#125;for _, req := range nvidia.Requirements &#123;    args = append(args, fmt.Sprintf(&quot;--require=%s&quot;, req))&#125;args = append(args, fmt.Sprintf(&quot;--pid=%s&quot;, strconv.FormatUint(uint64(container.Pid), 10)))args = append(args, rootfs)env := append(os.Environ(), cli.Environment...)//nolint:gosec // TODO: Can we harden this so that there is less risk of command injection?err = syscall.Exec(args[0], args, env)\n\n代码中与 GPU 有关的部分已经加粗标出，其中全部信息都来自由如下代码生成的 image.CUDA（WithDisableRequire 主要用于忽略 startup 时的 CUDA 类型检查，暂时可不用管）\ns := loadSpec(path.Join(b, &quot;config.json&quot;))image, err := image.New(    image.WithEnv(s.Process.Env),    image.WithDisableRequire(hook.DisableRequire),)\n\n上面提到的各种参数(device、mig-config等)均来自 image 中最终所获得的环境变量，直接查询即可获得，image.CUDA 的数据结构如下：\ntype CUDA struct &#123;    env    map[string]string    mounts []specs.Mount&#125;\n\n至此，可以调用 nvidia-container-cli 进行后续操作了\nNVIDIA Container CLInvidia-container-cli 工具包含于 libnvidia-container 中，用于自动配置利用NVIDIA硬件的相关容器。\n该实现依赖于内核原语，其设计与容器运行时无关。\nnvidia-container-cli 通过向容器暴露设备驱动程序，从而配置容器的 GPU 支持，其将进入指定容器的 namespace 中执行部分操作以确保驱动程序的相关功能在容器里可用，注意，此时假定容器已创建但尚未启动，并且主机文件系统是可访问的（即尚未调用 chroot&#x2F;pivot_root）。\n分别支持 configure、info、list 三个功能，在此只分析 configure 功能，也就是让容器能够获取到 GPU Driver 和 Device 信息，从而能够使用 GPU。\n在 configure 功能中，会分别获取 Driver 和 Device 的相关信息并筛选出合适的 GPU 设备，代码如下：\nif ((drv = libnvc.driver_info_new(nvc, NULL)) == NULL ||        (dev = libnvc.device_info_new(nvc, NULL)) == NULL) &#123;        warnx(&quot;detection error: %s&quot;, libnvc.error(nvc));        goto fail;&#125;if (dev-&gt;ngpus &gt; 0) &#123;        if (select_devices(&amp;err, ctx-&gt;devices, dev, &amp;devices) &lt; 0) &#123;                warnx(&quot;device error: %s&quot;, err.msg);                goto fail;        &#125;&#125;\n\n之后就可以将其 mount 到容器中：\n/* Mount the driver, visible devices, mig-configs, mig-monitors, and imex-channels. */if (perm_set_capabilities(&amp;err, CAP_EFFECTIVE, ecaps[NVC_MOUNT], ecaps_size(NVC_MOUNT)) &lt; 0) &#123;        warnx(&quot;permission error: %s&quot;, err.msg);        goto fail;&#125;if (libnvc.driver_mount(nvc, cnt, drv) &lt; 0) &#123;        warnx(&quot;mount error: %s&quot;, libnvc.error(nvc));        goto fail;&#125;for (size_t i = 0; i &lt; devices.ngpus; ++i) &#123;        if (libnvc.device_mount(nvc, cnt, devices.gpus[i]) &lt; 0) &#123;                warnx(&quot;mount error: %s&quot;, libnvc.error(nvc));                goto fail;        &#125;&#125;\n\n其中 driver 的 mount 会根据需要选择宿主机上相关的 binary 和 library，可用 nvidia-container-cli list 查看。\n至此就完成了 GPU 在容器中的使用，可以发现一般情况下，CUDA Libraries 和 CUDA Runtime API 是和应用程序一起打包到镜像中的，而 CUDA Driver 库是在创建容器时从宿主机挂载到容器中的，因此存在版本风险，所以需要保证 CUDA Driver 的版本不低于 CUDA Runtime 版本。\n","categories":["AI Infra"],"tags":["Golang","GPU","Container"]},{"title":"GPU容器相关概念","url":"/2024/09/28/2024-09-28-GPU-%E5%AE%B9%E5%99%A8%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/","content":"GPU容器相关概念CUDA API 体系：要使编写的 GPU 程序能够正常运行，需要借助 CUDA 直接使用 NVIDIA 的 GPU 来执行通用计算任务，从而使 GPU 能够从图形渲染设备转变为一个通用并行处理器，CUDA API 体系结构图如下：\n\n\nCUDA Driver API：GPU 设备的抽象层，通过一系列 API 直接操作 GPU 设备，性能好，但编程难度高（需要显式进行device初始化以及context管理等）。\nCUDA Runtime API: 对 CUDA Driver API 进行一定封装，简化编程过程，降低开发难度。\nCUDA Libraries: 更高层的封装，包含一些成熟的高效函数库。\n\n因此要实现 CUDA 容器化，就要让应用程序可以在容器内调用 CUDA API 来操作 GPU，一般来讲，就要使容器内程序可调用 CUDA Runtime API 和 CUDA Libraries，容器内可使用 CUDA Driver 相关库。\nCUDA 容器化基本思路要将 GPU 设备挂载到容器中，NVIDIA Docker 是通过注入一个 prestart 的 hook 到容器中，在容器自定义命令启动前将 GPU 挂载好。设备挂载好后，也需要使用类似 hook 的方式将宿主机中的 CUDA Driver API 挂载到容器里，需要将 CUDA Runtime API 和 CUDA Libraries 与应用程序一起打包到镜像中。\n具体实现为将 Docker daemon 的启动参数中默认的 Runtime 改为 nvidia-container-runtime 后，nvidia-container-runtime 在 runc 基础上多实现了 nvidia-container-runtime-hook：\n\n该 hook 会在容器启动后（Namespace 已创建完成），在容器自定义命令启动前执行。当检测到 NVIDIA_VISIBLE_DEVICES 环境变量时，会调用 libnvidia-container 挂载 GPU Device 和 CUDA Driver。如果没有检测到 NVIDIA_VISIBLE_DEVICES 就会执行默认的 runc。\n\nCUDA 三层API中，CUDA Libraries和CUDA Runtime API是和应用程序一起打包到镜像中的，所以在应用程序和CUDA Libraries以及CUDA Runtime间通常不会有什么问题。主要问题是在CUDA Runtime和CUDA Driver之间。CUDA Driver库是在创建容器时从宿主机挂载到容器中的，很容易出现版本问题，需要保证CUDA Driver的版本不低于CUDA Runtime版本。\nNvidia Docker 介绍原本的 nvidia-docker 与 docker 运行时高度耦合，缺乏灵活性，因此设计了新的容器运行时设计：nvidia-docker2.0。\n\nnvidia-docker2.0 通过修改 docker 的配置文件&#x2F;etc&#x2F;docker&#x2F;daemon.json 来让 docker 使用 NVIDIA Container runtime。\n\nnvidia-container-runtime 在原有的 docker 容器运行时 runc 的基础上增加一个 prestart hook 用于调用 libnvidia-container 库。\nlibnvidia-container 提供一个库和一个简单的 CLI 程序，使用这个库可以使 NVIDIA GPU 适用 Linux 容器。\n\n其之间的关系可参考下图\n\n正常启动一个容器会通过 containerd 去调用 runc，而 GPU 容器会将 runc 换为 nvidia-container-runtime，如果需要使用 GPU 则调用 libnvidia-container，否则走默认的runc。\n目前 nvidia docker2 已经被 nvidia container toolkits 取代。\nNvidia Container ToolkitNVIDIA Container Toolkit 在实际场景中的位置如下图所示\n\nNVIDIA Container 的组件包括了：\n\nNVIDIA Container Runtime(nvidia-container-runtime)\nNVIDIA Container Runtime Hook(nvidia-container-toolkit&#x2F;nvidia-container-runtime-hook)\nNVIDIA Container Library and CLI(libnvidia-container1, nvidia-container-cli)\n\n这些组件被打包为了 NVIDIA Container Toolkit，对于 Docker 或者 Containerd，NVIDIA Container Runtime（nvidia-container-runtime）被配置为一个符合 OCI 标准的运行时，其结构如下图所示（具体流程就是 prestart-hook 设置好参数，从而调用 nvidia-cli 执行相关挂载）：\n\n\nNVIDIA Container Library and CLI\n\n这些组件被打包为了 libnvidia-container-tools 和 libnvidia-container软件包，其能够自动配置能够利用 GPU 的 Linux 容器，实现只依赖于内核原语，与容器运行时无关。\n\nNVIDIA Container Runtime Hook\n\n该组件被包含于 nvidia-container-toolkit，其包含一个可执行文件，实现了runc prestart hook 所需的接口。脚本在容器创建后、启动前由runc调用并获得与容器关联的config.json的访问权限，然后获取其中的信息并结合一些 flags （如选择哪些 GPU）调用 nvidia-container-cli，其关键部分如下：\nif len(nvidia.Devices) &gt; 0 &#123;       args = append(args, fmt.Sprintf(&quot;--device=%s&quot;, nvidia.Devices))   &#125;   if len(nvidia.MigConfigDevices) &gt; 0 &#123;       args = append(args, fmt.Sprintf(&quot;--mig-config=%s&quot;, nvidia.MigConfigDevices))   &#125;   if len(nvidia.MigMonitorDevices) &gt; 0 &#123;       args = append(args, fmt.Sprintf(&quot;--mig-monitor=%s&quot;, nvidia.MigMonitorDevices))   &#125;   if len(nvidia.ImexChannels) &gt; 0 &#123;       args = append(args, fmt.Sprintf(&quot;--imex-channel=%s&quot;, nvidia.ImexChannels))   &#125;   for _, cap := range strings.Split(nvidia.DriverCapabilities, &quot;,&quot;) &#123;       if len(cap) == 0 &#123;           break       &#125;       args = append(args, capabilityToCLI(cap))   &#125;   for _, req := range nvidia.Requirements &#123;       args = append(args, fmt.Sprintf(&quot;--require=%s&quot;, req))   &#125;\n\n\nNVIDIA Container Runtime\n\n该组件被包含于 nvidia-container-toolkit-base 中，曾经其就只是一个 runC 的复制体，但是现在其变成了一个安装在主机上的对 runC 的封装，其会将 prestart hook 注入 runC 的 spec 中，再用这个新的 spec 作为参数去调用本地的 runC\n\nNVIDIA Container Toolkit CLI\n\n该组件被包含于 nvidia-container-toolkit-base 中，其包含大量用于与 NVIDIA Container Toolkit 交互的实用程序。\n\nLibnvidia-container\n\nlibnvidia-container 用于挂载 GPU Device 和 CUDA Driver，其关键概念如下：\n/* Query the driver and device information. */if (perm_set_capabilities(&amp;err, CAP_EFFECTIVE, ecaps[NVC_INFO], ecaps_size(NVC_INFO)) &lt; 0) &#123;  warnx(&quot;permission error: %s&quot;, err.msg);  goto fail;&#125;if ((drv = nvc_driver_info_new(nvc, NULL)) == NULL ||    (dev = nvc_device_info_new(nvc, NULL)) == NULL) &#123;  warnx(&quot;detection error: %s&quot;, nvc_error(nvc));  goto fail;&#125;/* Select the visible GPU devices. */if (dev-&gt;ngpus &gt; 0) &#123;  gpus = alloca(dev-&gt;ngpus * sizeof(*gpus));  memset(gpus, 0, dev-&gt;ngpus * sizeof(*gpus));  if (select_devices(&amp;err, ctx-&gt;devices, gpus, dev-&gt;gpus, dev-&gt;ngpus) &lt; 0) &#123;    warnx(&quot;device error: %s&quot;, err.msg);    goto fail;  &#125;&#125;\n\nnvc_driver_info_new() 和 nvc_device_info_new() 方法分别获取了 CUDA Driver 和 GPU Device 相关信息，如 driver libraries，driver binaries 路径，cuda version 等。再通过 select_devices() 方法选出容器可用的GPU Device。\n获取到 CUDA Driver Libraries&#x2F;Binaries 路径，以及可用的 GPU 后，将其挂载到容器中。实现如下：\n/* Mount the driver and visible devices. */if (perm_set_capabilities(&amp;err, CAP_EFFECTIVE, ecaps[NVC_MOUNT], ecaps_size(NVC_MOUNT)) &lt; 0) &#123;  warnx(&quot;permission error: %s&quot;, err.msg);  goto fail;&#125;if (nvc_driver_mount(nvc, cnt, drv) &lt; 0) &#123;  warnx(&quot;mount error: %s&quot;, nvc_error(nvc));  goto fail;&#125;for (size_t i = 0; i &lt; dev-&gt;ngpus; ++i) &#123;  if (gpus[i] != NULL &amp;&amp; nvc_device_mount(nvc, cnt, gpus[i]) &lt; 0) &#123;    warnx(&quot;mount error: %s&quot;, nvc_error(nvc));    goto fail;  &#125;&#125;\n\n其是采用 mount --bind 将 CUDA Driver Libraries&#x2F;Binaries 一个个挂载到容器里，而不是将整个目录挂载到容器中。可通过 NVIDIA_DRIVER_CAPABILITIES 环境变量指定要挂载的driver libraries&#x2F;binaries，可通过NVIDIA_DRIVER_CAPABILITIES 环境变量指定要挂载的driver libraries&#x2F;binaries。\n总而言之，NVIDIA Container Toolkit 是一系列软件包的集合，这些软件包将容器运行时（如 Docker）与主机上的英伟达驱动程序接口相连。libnvidia-container库负责提供 API 和 CLI，通过运行时包装器自动向容器提供系统的 GPU，其内部结构如下：\nnvidia-container-toolkit组件实现了一个容器运行钩子。这意味着当一个新容器即将启动时，它会收到通知。它会查看要附加的 GPU，并调用libnvidia-container来处理容器创建。\n该挂钩由nvidia-container-runtime 启用。它封装了 “真正的 “容器运行时，如 containerd 或 runc，以确保运行prestart钩子。钩子执行后，现有运行时将继续执行容器启动过程。容器工具包安装完成后，会看到 Docker 守护进程配置文件中选择了nvidia-container-runtime。\n","categories":["AI Infra"],"tags":["Golang","GPU","Container"]},{"title":"NVIDIA device plugin for Kubernetes原理分析","url":"/2024/09/28/2024-09-28-NVIDIA-device-plugin-for-Kubernetes%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/","content":"NVIDIA device plugin for Kubernetes原理分析什么是 Device Plugin K8s 原生并没有支持第三方设备厂商的物理设备资源，因此 Device Plugins 给第三方设备厂商提供了相关接口，可以让他们的物理设备资源以 Extended Resources 提供给底层的容器。\n当 device plugin 功能启动后，可以令 kubelet 开放 Register 的 gRPC 服务，device plugin 就可以通过这个服务向 kubelet 进行注册，注册成功后 device plugin 就进入了 Serving 模式，提供前面提到的 gRPC 接口调用服务，kubelet 也就可以通过调用 Listandwatch、Allocate 等方法对设备进行操作，可以用下图来描述单一节点上这一过程：\n\n下面以 NVIDIA k8s-device-plugin 为例简单讲讲这一过程。\n注册服务先看 gRPC 注册部分，下面的函数用于启动一个 gRPC 服务器并在 kubelet 中注册\nfunc (plugin *NvidiaDevicePlugin) Start() error &#123;    plugin.initialize()    if err := plugin.waitForMPSDaemon(); err != nil &#123;        return fmt.Errorf(&quot;error waiting for MPS daemon: %w&quot;, err)    &#125;    err := plugin.Serve()    if err != nil &#123;        klog.Infof(&quot;Could not start device plugin for &#x27;%s&#x27;: %s&quot;, plugin.rm.Resource(), err)        plugin.cleanup()        return err    &#125;    klog.Infof(&quot;Starting to serve &#x27;%s&#x27; on %s&quot;, plugin.rm.Resource(), plugin.socket)    err = plugin.Register()    if err != nil &#123;        klog.Infof(&quot;Could not register device plugin: %s&quot;, err)        return errors.Join(err, plugin.Stop())    &#125;    klog.Infof(&quot;Registered device plugin for &#x27;%s&#x27; with Kubelet&quot;, plugin.rm.Resource())    go func() &#123;        // TODO: add MPS health check        err := plugin.rm.CheckHealth(plugin.stop, plugin.health)        if err != nil &#123;            klog.Infof(&quot;Failed to start health check: %v; continuing with health checks disabled&quot;, err)        &#125;    &#125;()    return nil&#125;\n\n其中 Register 就是将资源注册给本机的 kubelet，注册请求包括 版本号、socket 名称、资源名称（如 nvidia.com&#x2F;gpu）以及一些额外参数。注册好以后，kubelet 就可以通过 gRPC 来调用现在启用的 RPC server 中的一些服务，具体 proto 定义如下\nservice DevicePlugin &#123;    rpc GetDevicePluginOptions(Empty) returns (DevicePluginOptions) &#123;&#125;    rpc ListAndWatch(Empty) returns (stream ListAndWatchResponse) &#123;&#125;    rpc GetPreferredAllocation(PreferredAllocationRequest) returns (PreferredAllocationResponse) &#123;&#125;    rpc Allocate(AllocateRequest) returns (AllocateResponse) &#123;&#125;    rpc PreStartContainer(PreStartContainerRequest) returns (PreStartContainerResponse) &#123;&#125;&#125;\n\n下文是的一些重点 rpc。\nListAndWatchfunc (plugin *NvidiaDevicePlugin) ListAndWatch(e *pluginapi.Empty, s pluginapi.DevicePlugin_ListAndWatchServer) error &#123;    if err := s.Send(&amp;pluginapi.ListAndWatchResponse&#123;Devices: plugin.apiDevices()&#125;); err != nil &#123;        return err    &#125;    for &#123;        select &#123;        case &lt;-plugin.stop:            return nil        case d := &lt;-plugin.health:            d.Health = pluginapi.Unhealthy            klog.Infof(&quot;&#x27;%s&#x27; device marked unhealthy: %s&quot;, plugin.rm.Resource(), d.ID)            if err := s.Send(&amp;pluginapi.ListAndWatchResponse&#123;Devices: plugin.apiDevices()&#125;); err != nil &#123;                return nil            &#125;        &#125;    &#125;&#125;\n\nListAndWatch 负责发送 GPU list 信息，同时在 GPU 健康状态发生变化时，再次发送进行更新。\nAllocateallocate 是 kubelet 在创建底层容器时会调用的操作，从而使创建的容器能够使用相应的资源，其代码如下，\nfunc (plugin *NvidiaDevicePlugin) Allocate(ctx context.Context, reqs *pluginapi.AllocateRequest) (*pluginapi.AllocateResponse, error) &#123;    responses := pluginapi.AllocateResponse&#123;&#125;    for _, req := range reqs.ContainerRequests &#123;        if err := plugin.rm.ValidateRequest(req.DevicesIDs); err != nil &#123;            return nil, fmt.Errorf(&quot;invalid allocation request for %q: %w&quot;, plugin.rm.Resource(), err)        &#125;        response, err := plugin.getAllocateResponse(req.DevicesIDs)        if err != nil &#123;            return nil, fmt.Errorf(&quot;failed to get allocate response: %v&quot;, err)        &#125;        responses.ContainerResponses = append(responses.ContainerResponses, response)    &#125;    return &amp;responses, nil&#125;func (plugin *NvidiaDevicePlugin) getAllocateResponse(requestIds []string) (*pluginapi.ContainerAllocateResponse, error) &#123;    deviceIDs := plugin.deviceIDsFromAnnotatedDeviceIDs(requestIds)    // Create an empty response that will be updated as required below.    response := &amp;pluginapi.ContainerAllocateResponse&#123;        Envs: make(map[string]string),    &#125;    if plugin.deviceListStrategies.IsCDIEnabled() &#123;        responseID := uuid.New().String()        if err := plugin.updateResponseForCDI(response, responseID, deviceIDs...); err != nil &#123;            return nil, fmt.Errorf(&quot;failed to get allocate response for CDI: %v&quot;, err)        &#125;    &#125;    if plugin.deviceListStrategies.Includes(spec.DeviceListStrategyEnvvar) &#123;        plugin.updateResponseForDeviceListEnvvar(response, deviceIDs...)    &#125;    if plugin.deviceListStrategies.Includes(spec.DeviceListStrategyVolumeMounts) &#123;        plugin.updateResponseForDeviceMounts(response, deviceIDs...)    &#125;    if plugin.config.Sharing.SharingStrategy() == spec.SharingStrategyMPS &#123;        plugin.updateResponseForMPS(response)    &#125;    if *plugin.config.Flags.Plugin.PassDeviceSpecs &#123;        response.Devices = append(response.Devices, plugin.apiDeviceSpecs(*plugin.config.Flags.NvidiaDriverRoot, requestIds)...)    &#125;    if *plugin.config.Flags.GDSEnabled &#123;        response.Envs[&quot;NVIDIA_GDS&quot;] = &quot;enabled&quot;    &#125;    if *plugin.config.Flags.MOFEDEnabled &#123;        response.Envs[&quot;NVIDIA_MOFED&quot;] = &quot;enabled&quot;    &#125;    return response, nil&#125;// func (plugin *NvidiaDevicePlugin) updateResponseForDeviceListEnvvar(response *pluginapi.ContainerAllocateResponse, deviceIDs ...string) &#123;//     response.Envs[plugin.deviceListEnvvar] = strings.Join(deviceIDs, &quot;,&quot;)// &#125;// plugin := NvidiaDevicePlugin&#123;//         rm:                   resourceManager,//         config:               config,//         deviceListEnvvar:     &quot;NVIDIA_VISIBLE_DEVICES&quot;,//         deviceListStrategies: deviceListStrategies,//         socket:               pluginPath + &quot;.sock&quot;,//         cdiHandler:           cdiHandler,//         cdiAnnotationPrefix:  *config.Flags.Plugin.CDIAnnotationPrefix,//         mpsDaemon:   mpsDaemon,//         mpsHostRoot: mpsHostRoot,//         // These will be reinitialized every//         // time the plugin server is restarted.//         server: nil,//         health: nil,//         stop:   nil,//     &#125;\n\n可以看出，其核心部分就是将请求中的 DeviceID 封装到 Envs:NVIDIA_VISIBLE_DEVICES ，其实就是改环境变量 NVIDIA_VISIBLE_DEVICES，之后结合GPU 容器底层实现即可创建对应的容器。\n总体流程具体来讲，含 GPU 需求的 pod 在包含 GPU 设备的 K8s 集群上的生命周期如下：\n\n各 Node 上的 kubelet 和各设备的 device plugin 交互完成注册，并通过 ListAndWatch 方法获得可用设备的资源信息，并将资源信息同步至集群 apiserver 中；\n含 GPU 需求的 pod 创建后，会根据在 apiserver 中的信息选取合适的节点进行调度至某个节点；\n节点上的 kubelet 获取 pod 信息后，会先根据 kubelet 本身的缓存选取节点上符合 pod 需求的具体设备，再根据设备 id 向 device plugin 发送 Allocate 调用，获得相应的信息并进行存储，kubelet 中有一个专门存储 pod 与设备信息的 map podDevices（在 ManagerImpl 中）；\nKubelet 在创建 pod 的容器时，就会根据这些信息创建出能够使用所需设备的容器。\n\nAllocate 中的相关参数如下所示：\nmessage AllocateResponse &#123;    repeated ContainerAllocateResponse container_responses = 1;&#125;message ContainerAllocateResponse &#123;    map&lt;string, string&gt; envs = 1;    repeated Mount mounts = 2;    repeated DeviceSpec devices = 3;    map&lt;string, string&gt; annotations = 4;    repeated CDIDevice cdi_devices = 5 [(gogoproto.customname) = &quot;CDIDevices&quot;];&#125;message AllocateRequest &#123;    repeated ContainerAllocateRequest container_requests = 1;&#125;message ContainerAllocateRequest &#123;    repeated string devices_ids = 1 [(gogoproto.customname) = &quot;DevicesIDs&quot;];&#125;\n\n这些设备参数主要用于帮助容器启动时能够使用这些设备。\n当 kubelet 要创建 pod 的容器时，就会从中读取这些参数来进行参数指定，最终能够使用这些设备。\n","categories":["AI Infra"],"tags":["Golang","GPU","Container","K8S","NVIDIA"]},{"title":"CUDA容器化&Container runtime相关技术梳理","url":"/2024/10/01/2024-10-01-CUDA%E5%AE%B9%E5%99%A8%E5%8C%96&Container-runtime%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF%E6%A2%B3%E7%90%86/","content":"CUDA容器化&amp;Container runtime相关技术梳理整体结构CUDA API体系\nCUDA Driver API：GPU 设备的抽象层，通过一系列 API 直接操作 GPU 设备，性能好，但编程难度高（需要显式进行device初始化以及context管理等）；\nCUDA Runtime API: 对 CUDA Driver API 进行一定封装，简化编程过程，降低开发难度；\nCUDA Libraries: 更高层的封装，包含一些成熟的高效函数库。\n因此要实现 NVIDIA 容器化，也就是要让应用程序可以在容器内调用 CUDA API 来操作 GPU，一般来讲，就要使容器内应用程序内可调用 CUDA Runtime API 和 CUDA Libraries，容器内可使用 CUDA Driver 相关库。\nNVIDIA CONTAINER TOOLKIT 具体结构\nGPU 容器底层实现\nGPU 容器相关概念\n一些背景知识\n什么是运行时？什么是高级运行时（high-level runtime）和低级运行时(low-level runtime):\n参考：https://blog.csdn.net/easylife206/article/details/135447413?fromshare=blogdetail&amp;sharetype=blogdetail&amp;sharerId=135447413&amp;sharerefer=PC&amp;sharesource=a1150568956&amp;sharefrom=from_link\n\n\ndocker和containerd的区别和联系：\n参考：https://blog.csdn.net/weixin_58519482/article/details/139123290?fromshare=blogdetail&amp;sharetype=blogdetail&amp;sharerId=139123290&amp;sharerefer=PC&amp;sharesource=a1150568956&amp;sharefrom=from_link\n\n\n官方参考：https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/arch-overview.html\n什么是OCI?CRI?\n参考：https://blog.csdn.net/weixin_43539320/article/details/137865618?fromshare=blogdetail&amp;sharetype=blogdetail&amp;sharerId=137865618&amp;sharerefer=PC&amp;sharesource=a1150568956&amp;sharefrom=from_link\n\n\n\n组件介绍在整个container-runtime的组织结构图中，分别对上图进行各个组件的解释：\n\ncontainerd: \n\nCRI 插件 是一个中间层，位于 Kubelet 和具体容器运行时之间。插件实现了 CRI 定义的接口（例如 PodSandboxService 和 RuntimeService），并将 Kubelet 发送的请求翻译成对应容器运行时的 API 调用。而containerd是被调用的其中的一种。\n\n\n​       而docker的如下图所示（其中也包含了containerd）：\n\n\ncontainerd 是一个高级容器运行时（high-level container runtime），它在低级运行时（如 runc）之上构建，提供更丰富的功能和更高层次的抽象。作为高级运行时，containerd 负责容器镜像的传输和管理，以及从镜像运行容器。它通过插件机制实现扩展，包括与 Kubernetes 的 CRI 插件集成、使用 CNI 插件进行网络管理以及使用 CSI 插件进行存储管理。\n\n其设计目标是简单、高效，并且与 Kubernetes 深度集成，使其成为 Kubernetes 的首选容器运行时。它提供了核心的容器管理功能，如镜像管理、容器执行和存储管理，并且通过 gRPC API 与外部客户端通信，提供标准化的接口以执行容器操作。\n\ncontainerd 是 Kubernetes 默认的容器运行时。\n\n\n\nrunc:\n\nrunc是一个轻量级的、符合 Open Container Initiative (OCI) 规范的低级容器运行时（low-level container runtime）工具，它的主要任务是创建和运行容器 。作为一个低级运行时，runc 专注于在 Linux 系统上利用命名空间（namespaces）和控制组（cgroups）等内核特性来提供容器的隔离性。它不涉及镜像管理、网络配置或卷管理等高级功能，这些通常由 Docker、containerd 或 Kubernetes 等更高级的容器管理系统来处理。\nrunc 直接与 Linux 内核交互，创建容器所需的隔离环境，并执行指定的容器进程。它不关心镜像的分发和存储，而是假定已经有一个准备好的文件系统（rootfs）和一个配置文件（config.json）来描述容器的运行配置。runc 的设计哲学是保持简单和专注于容器的生命周期管理，如创建、启动、停止和删除容器。\n在容器技术栈中，runc 作为容器运行的基础，被设计为可以被更高级别的容器管理系统所调用，例如 containerd 或 CRI-O。这些系统在 runc 之上提供了额外的功能，如镜像管理、网络和存储的集成、API 接口等，使得用户可以更方便地使用容器技术。\nrunc 作为低级运行时，提供了容器运行所需的核心功能，而高级运行时（比如containerd）则构建在 runc 这样的低级运行时之上，提供更全面和易用的容器管理服务。\n\n\nNVIDIA Container Runtime和runc的关系\n\nNVIDIA Container Runtime 是一个与 Open Containers Initiative (OCI) 规范兼容的 GPU 感知容器运行时，它在 runc 的基础上增加了对 NVIDIA GPU 的支持。runc 本身是一个遵循 OCI 规范的低级容器运行时，专注于创建和运行容器。\nNVIDIA Container Runtime 通过在 runc 的基础上增加一个 prestart hook（称为 nvidia-container-runtime-hook），在容器启动后（Namespace 已创建完成），容器自定义命令（Entrypoint）启动前执行。这个 hook 会检查容器是否需要使用 GPU（通过环境变量 NVIDIA_VISIBLE_DEVICES 判断），如果需要则调用 libnvidia-container 来挂载 GPU 设备和 CUDA 驱动到容器中。如果检测不到需要 GPU 的环境变量，则会执行默认的 runc 运行时逻辑。\nrunc 是一个低级容器运行时，主要负责容器的生命周期管理，如创建、启动和停止容器。而 NVIDIA Container Runtime 则是在 runc 的基础上增加了 GPU 支持的能力，使得容器可以访问和利用宿主机上的 NVIDIA GPU 资源。这种设计使得 NVIDIA Container Runtime 可以灵活地支持不同的容器运行时，如 Docker、LXC 和 CRI-O，从而在容器中运行 GPU 加速的应用。\n\n\nnvidia-container-runtime-hook\n\nNvidia-container-runtime-hook 的作用为根据 config 设置 nvidia-container-cli 的参数，并调用 nvidia-container-cli。\nnvidia-container-cli 工具包含于 libnvidia-container 中，用于自动配置利用NVIDIA硬件的相关容器。该实现依赖于内核原语，其设计与容器运行时无关。nvidia-container-cli 通过向容器暴露设备驱动程序，从而配置容器的 GPU 支持，其将进入指定容器的 namespace 中执行部分操作以确保驱动程序的相关功能在容器里可用，注意，此时假定容器已创建但尚未启动，并且主机文件系统是可访问的（即尚未调用 chroot&#x2F;pivot_root）。\n\n\nLibnvidia-container:\n\nlibnvidia-container用于挂载 GPU Device 和 CUDA Driver\nlibnvidia-container 是 NVIDIA Container Toolkit 的一部分，它提供了一个库和命令行工具来帮助容器发现和使用宿主机上的 NVIDIA GPU 资源。这个库实现了核心的 GPU 发现和挂载逻辑，使得容器可以利用 NVIDIA GPU 进行加速计算。\nlibnvidia-container 的主要组件包括：\n库文件 (libnvidia-container1): 提供核心功能，供其他程序调用。\n命令行工具 (nvidia-container-cli): 用于配置 Linux 容器对 GPU 硬件的使用。\nNVIDIA device plugin for Kubernetes 原理分析\n\n\n\n\n\n容器启动流程（kubelet、containerd、container-runtime、device-plugin、runc）一些基础背景：\nKubelet\n\n参考：https://blog.csdn.net/ok875161027/article/details/78891733?fromshare=blogdetail&amp;sharetype=blogdetail&amp;sharerId=78891733&amp;sharerefer=PC&amp;sharesource=a1150568956&amp;sharefrom=from_link\n\n\n\n\n\ncontainerd链路:containerd 作为一个 api 服务，提供了一系列的接口供外部调用，比如创建容器、删除容器、创建镜像、删除镜像等等。使用 docker 和 ctr 等工具，都是通过调用 containerd 的 api 来实现的。\n\nDevice plugin &amp; 具体分配example:NVIDIA device plugin for Kubernetes 原理分析\n\ndevice物理设备要作为资源，通过device plugin的grpc向kubelet注册。在之后的pod&#x2F;容器的创建便会首先通过kubelet去进行rpc调用listWatch对所拥有的物理设备资源进行查询，并通过allocate进行具体的操作\n\n对于上图：\n\n首先，对于每一种硬件设备，都需要有它所对应的 Device Plugin 进行管理，这些 Device Plugin，都通过 gRPC 的方式，同 kubelet 连接起来。以 NVIDIA GPU 为例，它对应的插件叫作NVIDIA GPU device plugin。\n这个 Device Plugin 会通过一个叫作 ListAndWatch 的 API，定期向 kubelet 汇报该 Node 上 GPU 的列表。比如，在我们的例子里，一共有三个 GPU（GPU0、GPU1 和 GPU2）。这样，kubelet 在拿到这个列表之后，就可以直接在它向 APIServer 发送的心跳里，以 Extended Resource 的方式，加上这些 GPU 的数量，比如nvidia.com&#x2F;gpu&#x3D;3。所以说，用户在这里是不需要关心 GPU 信息向上的汇报流程的。\n需要注意的是，ListAndWatch 向上汇报的信息，只有本机上 GPU 的 ID 列表，而不会有任何关于 GPU 设备本身的信息。而且 kubelet 在向 API Server 汇报的时候，只会汇报该 GPU 对应的 Extended Resource 的数量。当然，kubelet 本身，会将这个 GPU 的 ID 列表保存在自己的内存里，并通过 ListAndWatch API 定时更新。\n而当一个 Pod 想要使用一个 GPU 的时候，它只需要在 Pod 的 limits 字段声明nvidia.com&#x2F;gpu: 1。那么接下来，Kubernetes 的调度器就会从它的缓存里，寻找 GPU 数量满足条件的 Node，然后将缓存里的 GPU 数量减 1，完成 Pod 与 Node 的绑定。\n这个调度成功后的 Pod 信息，自然就会被对应的 kubelet 拿来进行容器操作。而当 kubelet 发现这个 Pod 的容器请求一个 GPU 的时候，kubelet 就会从自己持有的 GPU 列表里，为这个容器分配一个 GPU。此时，kubelet 就会向本机的 Device Plugin 发起一个 Allocate() 请求。这个请求携带的参数，正是即将分配给该容器的设备 ID 列表。\n当 Device Plugin 收到 Allocate 请求之后，它就会根据 kubelet 传递过来的设备 ID，从 Device Plugin 里找到这些设备对应的设备路径和驱动目录。当然，这些信息，正是 Device Plugin 周期性的从本机查询到的。比如，在 NVIDIA Device Plugin 的实现里，它会定期访问 nvidia-docker 插件，从而获取到本机的 GPU 信息。\n而被分配 GPU 对应的设备路径和驱动目录信息被返回给 kubelet 之后，kubelet 就完成了为一个容器分配 GPU 的操作。接下来，kubelet 会把这些信息追加在创建该容器所对应的 CRI 请求当中。这样，当这个 CRI 请求发给 Docker 之后，Docker 为你创建出来的容器里，就会出现这个 GPU 设备，并把它所需要的驱动目录挂载进去。\n\n至此，Kubernetes 为一个 Pod 分配一个 GPU 的流程就完成了。                   \n参考原文链接：https://blog.csdn.net/qq_37756660/article/details/134523326\ncontainerd 创建容器流程：\n接收到 api 请求，通过调用 containerd-shim-runc-v2 调用 runc 创建容器，主要是做解压文件和准备环境的工作。\n接收到 api 请求，创建一个 task，task 是一个容器的抽象，包含了容器的所有信息，比如容器的 id、容器的状态、容器的配置等等。\ncontainerd 启动一个 containerd-shim-runc-v2 进程。\ncontainerd-shim-runc-v2 进程再启动一个 containerd-shim-runc-v2 进程（相当于这里已经有两个），然后第一个 containerd-shim-runc-v2 进程退出。\ncontainerd 通过 IPC 通信，让第二个 containerd-shim-runc-v2 启动容器。\ncontainerd-shim-runc-v2 进程通过调用 runc start 启动容器。\nrunc 会调用 runc init 启动容器的 init 进程。\nrunc init 进程会调用 unix.Exec 的方式，替换自己的进程，启动容器的第一个进程。这个进程既是容器的启动命令，也是容器的 pid 1 进程。完成之后，runc create 进程退出。\n\n这样 containerd-shim-runc-v2 的父进程就是 init 进程（1），而 容器的init 进程（用户进程）的父进程是 containerd-shim-runc-v2 进程，这样就形成了一个进程树。\n一些问题🙋\n\n为什么要创建两个 containerd-shim 不嫌麻烦吗？\n因为第一个 containerd-shim 会在创建完第二个 containerd-shim 后退出，而作为第一个进程子进程的第二个 containerd-shim 会成为孤儿进程，这样就会被 init 进程接管，而和 containerd 本身脱离了关系。\n\n\n为什么要想方设法把 containerd-shim 挂在 init 进程下面，而不是 containerd？\n为了保证稳定性和独立性。这样做可以确保即使 containerd 崩溃或重启，由 containerd-shim 管理的容器进程仍然可以继续运行，不受影响。此外，这种设计还有助于更好地管理资源和防止资源泄露。\n\n\n为什么 runc start 进程退出了 runc init 进程（用户进程）没有变成 系统init 的子进程 而是containerd-shim的子进程？\n因为 containerd-shim 做了 unix 的 PR_SET_CHILD_SUBREAPER 调用, 这个系统调用大概作用为当这个进程的子子孙孙进程变成孤儿进程的时候，这个进程会接管这个孤儿进程，而不是 init 进程接管。\n\n\n\n\n完整链路流程：下面是一个详细的示意图，展示了包含 GPU 需求的 Pod 在 Kubernetes 集群上的生命周期，包括 Kubelet、containerd、容器运行时（如 runc）、设备插件（如 NVIDIA Device Plugin）之间的交互：\n\n设备注册与资源信息同步：\n每个节点上的 Kubelet 与设备插件（如 NVIDIA GPU Device Plugin）交互，完成设备的注册。\n设备插件通过 ListAndWatch 方法定期向 Kubelet 汇报节点上可用的 GPU 设备列表。\nKubelet 将这些设备资源信息同步至 Kubernetes 集群的 API Server。\n\n\nPod 调度：\n包含 GPU 需求的 Pod 被创建后，Kubernetes 调度器根据 API Server 中的节点资源信息选择合适的节点进行调度。\n\n\n设备分配：\n节点上的 Kubelet 获取到 Pod 信息后，根据 Pod 的资源需求从本地缓存中选择合适的设备。\nKubelet 向设备插件发送 Allocate 调用，请求分配 GPU 设备。\n设备插件根据请求的设备 ID，返回设备路径和驱动目录等信息给 Kubelet。\n\n\nKubelet 存储设备分配信息：\nKubelet 将设备分配信息存储在一个名为 podDevices 的映射（map）中，这个映射位于 ManagerImpl 中。\n\n\n容器创建：\nKubelet 在创建 Pod 的容器时，会根据 podDevices 映射中的信息，通过 CRI (Container Runtime Interface) 请求 containerd 创建容器。\nKubelet 会将 GPU 设备路径和驱动目录作为挂载卷和环境变量传递给容器运行时。\n\n\n容器运行时与设备插件交互：\ncontainerd 接收到 Kubelet 的请求后，创建一个 task，并启动 containerd-shim 进程来管理容器的生命周期。\ncontainerd-shim 调用 NVIDIA Container Runtime，它负责在容器内设置 GPU 环境。\n\n\n容器启动：\nNVIDIA Container Runtime 调用 runc 来实际创建容器，进行解压镜像和准备环境的工作。\nrunc 启动容器的 init 进程（PID 1），容器启动并运行。\n\n\n容器启动完成：\n容器启动并运行，Kubelet 将容器状态更新到 Kubernetes 集群。\n\n\n\n以下是这个过程的示意图：\nKubernetes Cluster    |----&gt; Kubernetes Scheduler ----&gt; Kubelet (Node 1)    |                                     |    |                                     |----&gt; Device Plugin (e.g., NVIDIA)    |                                     |               |    |                                     |               |----&gt; GPU Hardware    |                                     |               |    |                                     |&lt;---- ListAndWatch API ----&lt;     |                                     |               |    |               +-------------------+               |----&gt; containerd    |               |                   |               |    |               |                   |               |----&gt; NVIDIA Container Runtime(shim)    |               |                   |               |               |    |               |                   |               |               |----&gt; runc    |               |                   |               |               |    |               |                   |               |               |----&gt; Container (PID 1)    |               |                   |               |               |    |               |                   |               |&lt;------------+    |               |                   |               |    |               |                   |               |---- Allocate()    |               |                   |               |    |               |                   +-------------&gt;+    |               |                              |    |               |&lt;----------------------------+    +---------------+---------------------------+\n\n在这个过程中，Kubelet 作为 Kubernetes 与容器运行时之间的桥梁，负责协调容器的生命周期管理。containerd 作为容器运行时的守护进程，处理容器的创建、启动和监控。设备插件为容器提供必要的硬件资源，如 GPU。这些组件之间的交互确保了 Pod 能够在节点上顺利创建和运行。\n","categories":["CUDA"],"tags":["人工智能","容器化","虚拟化","AI Infra","CUDA"]},{"title":"k8s中通过pod获取gpu使用进程到pod的映射关系","url":"/2025/02/16/2025-02-16-k8s%E4%B8%AD%E9%80%9A%E8%BF%87pod%E8%8E%B7%E5%8F%96gpu%E4%BD%BF%E7%94%A8%E8%BF%9B%E7%A8%8B%E5%88%B0pod%E7%9A%84%E6%98%A0%E5%B0%84%E5%85%B3%E7%B3%BB%20-%20%E5%89%AF%E6%9C%AC/","content":"k8s中通过pod获取gpu使用进程到pod的映射关系背景该任务的pod为daemonset在集群的每一个节点上，controller pod（只有一个）通过grpc的方式进行调用该daemonset pod获取到该节点上gpu的使用进程到pod的映射关系，传递的参数为使用gpu的pod的id。\n该需求涉及到几个部分内容：\n\n如何通过pod id定位到具体的节点\n通过controller 的cache机制（包含有pod和node cache）获取到daemonset pod id对应的node ip，在daemonset的pod部分新建grpc server端，根据ip:port构建grpc client即可\n\n\n如何获取到节点上的gpu-&gt;process的映射关系\n调用go-nvml即可\n\n\n如何获取到节点上的process-&gt;container的映射关系\n调用taskClient\n\n\ncontainer-&gt;pod的映射关系？\ncontroller cache机制获取到对应的node，然后可以获取到该node上的pod和container，做一层映射，随着请求发送给daemonset pod即可，daemonset pod进行调用\n\n\n\n解决节点上调用nvml正确获取宿主机上的gpu和pid信息\n\n涉及到两个目标\n\n正确的将gpu挂载进去 且 不需要对gpu资源的具体请求：\ndaemonset.yaml做如下修改：\nhostPID: trueenv:...- name: NVIDIA_DRIVER_CAPABILITIES  value: all- name: NVIDIA_VISIBLE_DEVICES  value: all  \n\n这部分的原理就是nvidia-container-toolkit 会根据该 Env 拿到要分配给该容器的 GPU 及相关驱动的能力，最终把相关文件挂载到容器里，此时能够正确使用nvml的功能。参考：https://blog.csdn.net/java_1996/article/details/144586459?fromshare=blogdetail&amp;sharetype=blogdetail&amp;sharerId=144586459&amp;sharerefer=PC&amp;sharesource=a1150568956&amp;sharefrom=from_link\n\npid信息要与宿主机一致：\n具体的修改在daemonset.yaml中:\nhostPID: true\n\n\n\ndaemonset pod部分代码：\nfunc (s *Server) GetGpuPidPods(req *v1alpha1.GetGpuPodsRequest) (map[string]*v1alpha1.Pods, map[string]*v1alpha1.GpuInfo, error) &#123;        if ret := nvml.Init(); ret.String() == &quot;ERROR_LIBRARY_NOT_FOUND&quot; &#123;                s.logger.Errorf(&quot;return error: %s \\n&quot;, ret.String())                return nil, nil, fmt.Errorf(ret.String())        &#125;        defer nvml.Shutdown()        containerIdPidMap := make(map[string][]int)        pidContainerIdMap := make(map[int]string)        // response        GpuPods := make(map[string]*v1alpha1.Pods)        GpuInfos := make(map[string]*v1alpha1.GpuInfo)        // list tasks        ctx := namespaces.WithNamespace(context.Background(), s.ContainerdNamespace)        tasks, err := s.taskClient.List(ctx, &amp;tasksapi.ListTasksRequest&#123;                Filter: &quot;status==running&quot;,        &#125;)        if err != nil &#123;                return nil, nil, err        &#125;        s.logger.Infof(&quot;task=container num:%d&quot;, len(tasks.Tasks))        for _, process := range tasks.Tasks &#123;                var pids []int                s.logger.Infof(&quot;pid:%d,containerID:%s,ID:%s&quot;, process.Pid, process.GetContainerID(), process.GetID())                // List pids in container                containerProcesses, err := s.taskClient.ListPids(ctx, &amp;tasksapi.ListPidsRequest&#123;                        ContainerID: process.GetID(),                &#125;)                if err != nil &#123;                        continue                &#125;                for _, p := range containerProcesses.Processes &#123;                        pids = append(pids, int(p.Pid))                        pidContainerIdMap[int(p.Pid)] = process.GetID()                        s.logger.Infof(&quot;pid:%d, containerID:%s&quot;, p.Pid, process.GetID())                &#125;                containerIdPidMap[process.GetID()] = pids        &#125;        // get GPU Num        gpuNum, ret := nvml.DeviceGetCount()        s.logger.Infof(&quot;get count ret : %s&quot;, ret.String())        if ret != nvml.SUCCESS &#123;                s.logger.Errorf(&quot;Failed to get GPU count: %s&quot;, ret.String())                return nil, nil, fmt.Errorf(ret.String())        &#125;        fmt.Printf(&quot;gpu num:%d\\n&quot;, gpuNum)        // get containerpid-&gt;podname        containerPods, err := s.getContainerPodsFromController(req.WorkerId)        if err != nil &#123;                return nil, nil, err        &#125;        for i := 0; i &lt; gpuNum; i++ &#123;                device, ret := nvml.DeviceGetHandleByIndex(i)                s.logger.Infof(&quot;getbyindex: %s&quot;, ret.String())                if ret != nvml.SUCCESS &#123;                        continue // Skip to the next device if there&#x27;s an error                &#125;                uuid, ret := device.GetUUID()                if ret != nvml.SUCCESS &#123;                        continue // Skip to the next device if there&#x27;s an error                &#125;                s.logger.Infof(&quot;get UUID: %s&quot;, uuid)                process, ret := device.GetComputeRunningProcesses()                if ret != nvml.SUCCESS &#123;                        continue // Skip to the next device if there&#x27;s an error                &#125;                name, ret := device.GetName()                if ret != nvml.SUCCESS &#123;                        continue // Skip to the next device if there&#x27;s an error                &#125;                usage, ret := device.GetUtilizationRates()                if ret != nvml.SUCCESS &#123;                        continue // Skip to the next device if there&#x27;s an error                &#125;                // response: gpu-&gt;gpuinfo                gpuInfo := v1alpha1.GpuInfo&#123;                        GpuName:  name,                        Uuid:     uuid,                        UsageGpu: usage.Gpu,                &#125;                GpuInfos[uuid] = &amp;gpuInfo                for _, p := range process &#123;                        pidName, _ := nvml.SystemGetProcessName(int(p.Pid))                        s.logger.Infof(&quot;Process ID: %d, Process name: %s, UUID: %s, Name: %s, GPUusage:%v MiB, GPUInstanceID:%v. &quot;, p.Pid, pidName, uuid, name, p.UsedGpuMemory/(1024*1024), p.GpuInstanceId)                        if containerID, exist := pidContainerIdMap[int(p.Pid)]; exist &#123;                                s.logger.Infof(&quot;pid: %v,containerID: %v&quot;, p.Pid, containerID)                                if podName, exist := containerPods[containerID]; exist &#123;                                        //              |-&gt;pod                                        // response: gpu--&gt;pod                                        //              |-&gt;pod                                        s.logger.Infof(&quot;containerID: %v，podName:%v&quot;, containerID, podName)                                        gpuPods := v1alpha1.PidPods&#123;                                                Pid:           p.Pid,                                                ProcessName:   pidName,                                                UsedGpuMemory: p.UsedGpuMemory / (1024 * 1024), //MiB                                                Pod:           podName,                                        &#125;                                        if _, exists := GpuPods[uuid]; !exists &#123;                                                var pidpod v1alpha1.Pods                                                GpuPods[uuid] = &amp;pidpod                                        &#125;                                        GpuPods[uuid].PidPods = append(GpuPods[uuid].PidPods, &amp;gpuPods)                                &#125;                        &#125;                &#125;        &#125;        return GpuPods, GpuInfos, nil&#125;func (s *Server) GetGpuPods(ctx context.Context, req *v1alpha1.GetGpuPodsRequest) (*v1alpha1.GetGpuPodsResponse, error) &#123;        GpuPods, GpuInfos, err := s.GetGpuPidPods(req)        if err != nil &#123;                return nil, err        &#125;        return &amp;v1alpha1.GetGpuPodsResponse&#123;                GpuPods:  GpuPods,                GpuInfos: GpuInfos,        &#125;, nil&#125;func (s *Server) getContainerPodsFromController(containerIDPodName string) (map[string]string, error) &#123;        // 创建一个空的map来存储解析后的数据        containerPods := make(map[string]string)        // 使用json.Unmarshal将JSON字符串解析到map中        err := json.Unmarshal([]byte(containerIDPodName), &amp;containerPods)        if err != nil &#123;                return nil, fmt.Errorf(&quot;failed to unmarshal JSON: %w&quot;, err)        &#125;        return containerPods, nil&#125;type PidContainerID struct &#123;        Pid         int        ContainerID string&#125;\n\nproto相关代码\nservice Server &#123;   ...    // gpu-&gt;pid-&gt;pod    rpc GetGpuPods(GetGpuPodsRequest)returns(GetGpuPodsResponse)&#123;        option (google.api.http) = &#123;            get: &quot;/gpu-pods&quot;        &#125;;    &#125;&#125;message GetGpuPodsRequest &#123;    string worker_id = 1;&#125;message GetGpuPodsResponse &#123;    map&lt;string,Pods&gt;GpuPods =1;    map&lt;string,GpuInfo&gt;GpuInfos =2;&#125;message Pods&#123;    repeated PidPods pidPods =1;&#125;message PidPods&#123;    uint32 pid = 1;    string processName = 2;    uint64 UsedGpuMemory = 3;    string pod = 4;&#125;message GpuInfo&#123;    // gpu-&gt;gpuInfo    string uuid = 1;    string gpuName = 2;    uint32 usageGpu =3;&#125;\n\ncontroller相关代码\nfunc (s *Controller) GetGpuPods(ctx context.Context, req *v1alpha1.GetGpuPodsRequest) (*v1alpha1.GetGpuPodsResponse, error) &#123;        // from workerId get         // podName-&gt;nodeName-&gt;Client        podName := req.WorkerId        nodeName, err := s.getNodeName(podName)        if err != nil &#123;                return nil, err        &#125;        // nodeName-&gt; client        if Client, exist := s.cache.NodeConn[nodeName]; !exist &#123;                var Target string                // ip:port                ip, err := s.getNodeIP(podName)                if err != nil &#123;                        return nil, err                &#125;                port := config.DefaultConfig().Port                Target = ip + &quot;:&quot; + port                Conn, err := grpc.NewClient(Target, grpc.WithTransportCredentials(insecure.NewCredentials()))                if err != nil &#123;                        return nil, err                &#125;                Client = v1alpha1.NewClient(Conn)                s.cache.NodeConn[nodeName] = Client        &#125;        // send request        // get container-&gt;pod info        containerPods := s.getContainerPodsByNodeName(nodeName)        jsonData, err := json.Marshal(containerPods)        if err != nil &#123;                fmt.Println(&quot;Error marshaling map:&quot;, err)                return nil, err        &#125;        containerPodMap := string(jsonData)        s.logger.Infof(&quot;marshall workerid: %v&quot;, containerPodMap)        ssReq := &amp;v1alpha1.GetGpuPodsRequest&#123;                // containerId-&gt;podName                WorkerId: containerPodMap,        &#125;        res, err := s.cache.NodeConn[nodeName].GetGpuPods(ctx, ssReq)        if err != nil &#123;                delete(s.cache.NodeConn, nodeName)                return nil, err        &#125;        return res, nil&#125;func (s *Controller) getContainerPods() map[string]string &#123;        containerPods := make(map[string]string)        for _, pi := range s.cache.Snapshot().Pods &#123;                for _, c := range pi.Pod.Status.ContainerStatuses &#123;                        containerPods[c.ContainerID] = pi.Pod.GetName()                &#125;        &#125;        return containerPods&#125;func (s *Controller) getContainerPodsByNodeName(nodeName string) map[string]string &#123;        containerPods := make(map[string]string)        for _, pi := range s.cache.Snapshot().Pods &#123;                if pi.Pod.Spec.NodeName != nodeName &#123;                        continue                &#125;                for _, c := range pi.Pod.Status.ContainerStatuses &#123;                        containerId := strings.TrimPrefix(c.ContainerID, &quot;containerd://&quot;)                        containerPods[containerId] = pi.Pod.GetName()                &#125;        &#125;        return containerPods&#125;func (s *Controller) getNodeName(podName string) (string, error) &#123;        s.logger.Infof(&quot;start getting node name by pod name: %s, num of pods:%d&quot;, podName, len(s.cache.Snapshot().Pods))        for _, pi := range s.cache.Snapshot().Pods &#123;                s.logger.Infof(&quot;wanted:%s, getted:%s&quot;, podName, pi.Name)                if pi.Name == podName &#123;                        if len(pi.Pod.Spec.NodeName) &gt; 0 &#123;                                s.logger.Infof(&quot;get node name by pod name: %s, nodeName: %s&quot;, podName, pi.Pod.Spec.NodeName)                                return pi.Pod.Spec.NodeName, nil                        &#125; else &#123;                                return &quot;&quot;, fmt.Errorf(&quot;this pod is not on a specific node&quot;)                        &#125;                &#125;        &#125;        return &quot;&quot;, fmt.Errorf(&quot;no match pod name&quot;)&#125;func (s *Controller) getNodeIP(podName string) (string, error) &#123;        s.logger.Infof(&quot;start getting node ip by pod name: %s, num of pods:%d&quot;, podName, len(s.cache.Snapshot().Pods))        for _, pi := range s.cache.Snapshot().Pods &#123;                if pi.Name == podName &#123;                        ni := s.cache.GetNodeInfo(pi.Pod.Spec.NodeName)                        if ni == nil &#123;                                return &quot;&quot;, fmt.Errorf(&quot;node info not found for pod %s&quot;, podName)                        &#125;                        for _, addr := range ni.Node.Status.Addresses &#123;                                s.logger.Infof(&quot;podName: %s, addType: %s, addAddress: %s&quot;, podName, addr.Type, addr.Address)                                if addr.Type == v1.NodeInternalIP &#123;                                        s.logger.Infof(&quot;find address:%s&quot;, addr.Address)                                        return addr.Address, nil                                &#125;                        &#125;                        return &quot;&quot;, fmt.Errorf(&quot;no internal IP found for node %s&quot;, pi.Pod.Spec.NodeName)                &#125;        &#125;        return &quot;&quot;, fmt.Errorf(&quot;no match pod name: %s&quot;, podName)&#125;\n\n效果\n其他猜的坑在裸机上，go-nvml能正常运行；但在进行镜像的制作时，报错：\n\n用mindprince-gonvml替代go-nvml：https://github.com/mindprince/gonvml\n但这个库能获取到的信息非常有限，拿不到进程相关的信息，无法满足需求。\n参考解决方案：\nhttps://github.com/NVIDIA/go-nvml/issues/49\nhttps://github.com/NVIDIA/go-nvml/issues/8\n其需要cgo，故令CGO_ENABLED&#x3D;1后，遇到该问题\n\ngithub上有人遇到了相同的问题：\n\n解决方案：\nhttps://blog.csdn.net/sun007700/article/details/120487881?fromshare=blogdetail&amp;sharetype=blogdetail&amp;sharerId=120487881&amp;sharerefer=PC&amp;sharesource=a1150568956&amp;sharefrom=from_link\nhttps://www.jianshu.com/p/e0ad27fe4e2d\nsudo apt-get updatesudo apt-get install gcc-aarch64-linux-gnu g++-aarch64-linux-gnu\n\n.mak\n\n后续能正常编译\n另外Base镜像要用Ubuntu\n","categories":["k8s"],"tags":["GPU","NVIDIA","k8s","pod","nvml"]},{"title":"KL散度","url":"/2025/06/25/2025-06-25KL%E6%95%A3%E5%BA%A6/","content":"KL散度🧩 KL散度公式解析图片中的KL散度公式为：$$D_{KL}(\\pi_{\\theta}||\\pi_{ref})&#x3D;\\sum_{\\theta}\\pi_{\\theta}(y|x)\\log\\frac{\\pi_{\\theta}(y|x)}{\\pi_{ref}(y|x)} &#x3D; E_{y\\sim \\pi_{\\theta}(y|x)}\\log\\frac{\\pi_{\\theta}(y|x)}{\\pi_{ref}(y|x)}$$\n🔍 关键参数解释\n**π_θ 和 π_ref**（核心参数）\n\nπ_θ: 当前策略模型\n带参数θ的神经网络（例如PPO正在训练的策略）\n策略的数学表示：π_θ(y|x) &#x3D; 在状态x下选择动作y的概率\n动态更新：通过梯度下降不断优化\n\n\nπ_ref: 参考策略模型\n通常表示旧的或冻结的策略版本\n在PPO中，通常指上次参数更新前的策略\n保持固定：在每次训练迭代中不变\n\n\n物理意义：KL散度衡量的是 当前策略(π_θ) 相对于参考策略(π_ref) 的变化程度\n\n\n**(y|x)**（策略条件）\n\nx: 当前状态&#x2F;观察输入\n例如：机器人传感器数据，游戏画面像素等\n\n\ny: 要选择的动作\n例如：机器人的关节控制指令，游戏中的按键操作\n\n\n整体含义：表示在给定状态x下采取动作y的概率分布\n\n\n**D_KL(π_θ||π_ref)**（核心概念）\n\n非对称性：D_KL(P||Q) ≠ D_KL(Q||P)\n在PPO中的物理意义：$$D_{KL}(\\pi_{\\theta}||\\pi_{ref}) &#x3D; \\begin{cases} 0 &amp; \\text{完全一致} \\\n\n0 &amp; \\text{存在差异} \\ \\infty &amp; \\text{分布无重叠}\\end{cases}$$\n\n\n计算值表示：用π_ref的编码系统描述π_θ时，平均需要的额外信息量（单位为nats）\n\n\n\n期望形式（右半部分）\n\nE_&#123;y∼π_θ&#125;: 表示从当前策略π_θ采样动作y的期望\n物理意义：在当前策略产生的动作分布上，评估新旧策略的概率比值的对数期望\n\n\n\n⚙️ 在PPO中的具体作用\n\n\n方面\n解释\n\n\n\n目标\n防止策略更新过大导致崩溃\n\n\n实现方式\n在损失函数中加入KL惩罚项：\n\n\n\nL_total = L_policy - β * D_KL(π_θ‖π_ref)\n\n\nβ (beta)\n调节KL惩罚强度的超参数\n\n\n\n过大→策略更新保守，过小→可能更新过度\n\n\n工作流程\n1. 收集经验 2. 冻结π_ref&#x3D;当前策略 3. 多次更新π_θ 4. 当KL&gt;阈值时停止更新\n\n\n\n📊 直观理解：KL散度就像给策略更新加了一个”安全带”，确保新策略不会突然偏离旧策略太远，导致训练不稳定。在微调语言模型时（如RLHF），这相当于约束新模型不要过度偏离原始基础模型的行为特征。\n\n需要进一步说明的是：PPO中的实际实现通常用概率比值的裁剪(Clipped Surrogate Objective)替代直接的KL惩罚，但KL散度仍是理解策略约束的核心数学基础。\n均方差和均方误差：https://zhuanlan.zhihu.com/p/673342488\nKL散度恒大于0，靠琴生不等式来推\n","categories":["人工智能"],"tags":["人工智能","机器学习"]},{"title":"github博客换机无缝迁移教程","url":"/2025/07/27/2025-07-27-github%E5%8D%9A%E5%AE%A2%E6%8D%A2%E6%9C%BA%E6%97%A0%E7%BC%9D%E8%BF%81%E7%A7%BB%E6%95%99%E7%A8%8B/","content":"github博客换机无缝迁移教程博客从零搭建教程：\nhttps://yangcheneee.github.io/categories/%E5%8D%9A%E5%AE%A2/\n迁移参考：https://blog.csdn.net/qq_35956041/article/details/108552563?fromshare=blogdetail&amp;sharetype=blogdetail&amp;sharerId=108552563&amp;sharerefer=PC&amp;sharesource=&amp;sharefrom=from_link\n这个教程是不全的\n旧电脑如下操作：git clone $原仓库cd到目录下git checkout -b hexogit push origin hexo:hexo# 在hexo分支删掉除了.git文件之外的其他文件# 将原来main分支的下面六个东西复制到下来：1. _config.yml2. package.json3. scaffolds/4. source/5. themes/6. .gitignore# 接着git add .git commit -m &#x27;提交仓库所需资源&#x27;git push origin hexo:hexo\n\n同时，假如安装了butterfly主题或其他主题，注意保留其下的_config.yml，之后会用到\n同时注意在main分支的public目录下的资源（图片），如果后续发现没有这些东西，也要手动迁移一发到新电脑上\n新电脑如下操作：git clone $原仓库cd到目录下git checkout hexonpm install hexo-cli -gnpm install# 假如用的是butterfly主题git clone -b master https://github.com/jerryc127/hexo-theme-butterfly.git themes/butterfly# 安装依赖npm install hexo-renderer-pug hexo-renderer-stylus --savenpm install hexo-generator-search --save# 同时记得替换/theme/butterfly 下的_config.yml(旧电脑上的迁移过来)hexo ghexo d# 注意如果这里发现图片不对劲，可能是public下面的图片没有迁移过来，从旧电脑上完全迁移下来即可\n\n","categories":["博客"],"tags":["博客","nodejs","hexo"]},{"title":"Shall We Pretrain Autoregressive Language Models with Retrieval","url":"/2025/08/13/2025-08-13-Shall-We-Pretrain-Autoregressive-Language-Models-with-Retrieval/","content":"Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study解析论文《Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study》的主要内容本文由 Boxin Wang 等人（主要来自 NVIDIA）撰写，旨在解决一个核心问题：在预训练自回归语言模型（如 GPT）时，是否应融入检索机制？ 通过全面研究检索增强模型 RETRO 及其变体 RETRO++，论文比较了 RETRO 与标准 GPT、微调阶段融入检索的 GPT（如 RAG）和推理阶段融入检索的 GPT（如 KNN-LM）的性能差异。研究基于大规模预训练（参数规模从 148M 到 9.5B，检索数据库包含 330B tokens），并覆盖文本生成质量(text generation quality)、下游任务准确性和毒性等多个维度。以下是详细解析，结构分为六个部分，确保内容逻辑清晰、层次丰富。\n\n1. 研究背景与核心问题\n问题动机：大型自回归语言模型（如 GPT-3&#x2F;4）虽在文本生成和下游任务上表现优异，但存在显著缺陷：\n高参数需求导致部署成本高。\n事实准确性差（易产生幻觉）。\n知识更新困难（预训练后无法轻松融入新事实）。\n检索增强（如 RETRO）可降低困惑度（perplexity），但其对文本生成质量（如流畅性、事实性）和下游任务的影响尚不明确。\n\n\n研究目标：通过复现和扩展 RETRO 模型，系统评估检索在预训练阶段的价值，回答“是否应在预训练自回归 LM 时默认融入检索？”。\n方法概述：公平比较 RETRO 与 GPT（相同架构、超参数、预训练语料），并引入新变体 RETRO++。\n\n\n2. 模型设计与实现细节\nRETRO 核心机制：\n\n分块检索（Chunk-wise Retrieval）：输入序列被分为固定大小块（chunk size&#x3D;64），每个块基于前一块检索最近邻（k-nearest neighbors），并通过双向编码器融合检索信息，指导下一个块的生成。这确保了因果性（causality）和可扩展性。\n\n检索数据库：使用整个预训练语料（330B tokens）构建 Faiss 索引，支持高效近似最近邻搜索（查询延迟约 4ms&#x2F;chunk）。\n\n推理优化：提出“左填充规则”（left padding rule），解决短上下文下的检索对齐问题（图1展示填充设计）。\n\n\n检索频率策略：支持灵活检索步长（retrieval step），平衡生成准确性和计算开销（小步长用于短答案任务，大步长用于长文本生成）。图3 示意不同步长的影响。\n\n\n\n\nRETRO++ 变体：针对开放域 QA 任务优化，将最相关证据（top-1 检索结果）输入解码器作为上下文，其余证据输入编码器。这显著提升 QA 准确性。\n\n预训练设置：RETRO 和 GPT 使用相同配置（层数、隐藏大小等），预训练语料为 330B tokens（包括 Wikipedia 和 CommonCrawl）。RETRO 预训练开销比 GPT 高约 25%（表11），但收益显著。\n\n\n\n3. 关键发现：文本生成质量评估论文全面评估了开放端文本生成（open-ended generation），涵盖质量、事实性和毒性：\n\n文本质量：\n\n自动评估（基于 5000 个提示）：RETRO 显著减少重复（repetition% 平均降低 21%），同时在多样性（Self-BLEU）和词汇使用（Zipf 系数）上与 GPT 持平（表3）。\n\n人工评估（200 个样本）：RETRO 在流畅性（fluency）和连贯性（coherence）上略优于 GPT（平均分数：RETRO 3.826 vs. GPT 3.818），图4 显示人类投票分布。\n\n\n\n\n事实准确性：\n\n在 FACTUALITYPROMPTS 基准上：RETRO 通过贪婪解码（greedy decoding）减少幻觉（hallucination），命名实体错误率（NEER）降低 2.45%，蕴涵率（EntailR）提高 3.75%（表4a）。\n在 TruthfulQA 基准上：RETRO 在对抗性问题上表现更稳健，但改进幅度较小（因问题涉及逻辑谬误，检索帮助有限）。\n\n\n毒性控制：\n\n使用预训练数据库时，RETRO 毒性略高于 GPT（因检索可能放大有害内容）。\n但切换到 Wikipedia 数据库后，毒性概率（toxicity probability）从 37% 降至 35%（表5），证明检索数据库质量是关键。\n\n\n\n\n4. 下游任务性能：LM 评估基准与开放域 QA\nLM 评估基准（Zero-Shot）：\n\n知识密集型任务：RETRO 在 Hellaswag（常识推理）和 BoolQ（是&#x2F;否问答）上显著优于 GPT（平均提升 2-6%），因检索提供额外事实支持（表6）。\n非知识密集型任务：如 Lambada（词预测）和 RACE（阅读理解），RETRO 与 GPT 持平（平均差异 &lt;1%）。\n微调后性能：在 Hellaswag 和 Lambada 上微调后，RETRO 改进幅度更大（表15），表明其更易适应新领域。\n对比检索增强 GPT：在推理阶段直接添加检索证据会损害 GPT 性能（准确率降至 ~24.5%），因噪声证据干扰上下文（表16）。\n\n\n开放域 QA 任务：\n\nRETRO++ 的突破：在 Natural Questions（NQ）和 TriviaQA 上，RETRO++ 的 EM 分数显著提升（NQ：54.1% vs. 原始 RETRO 40.9%），超越 RAGGPT（微调阶段融入检索的 GPT）和 FiD 等基线（表7）。\n\n模型规模扩展：图2 显示 RETRO++ 随参数增加（Small 到 XXL）性能单调提升，且始终优于 RAGGPT。\n\n\n指令微调（Instruction Tuning）：在 RETRO++ 上应用指令微调后，零样本 QA 准确率进一步提升（NQ EM 从 24.43% 升至 29.75%），凸显检索增强模型的兼容性（表8）。\n\n\n\n\n\n5. 创新贡献与结论\n核心创新：\n成功复现并扩展 RETRO（至 9.5B 参数），提供可扩展预训练配方。\n提出 RETRO++，通过优化证据融合机制，大幅提升 QA 性能。\n首次全面证明：预训练阶段融入检索，能系统改善文本生成质量、事实性、毒性控制及下游任务（尤其知识密集型任务）。\n\n\n结论：预训练自回归 LM 时融入检索（如 RETRO）是值得推广的方向，因其：\n降低模型退化（如重复生成）。\n提升事实准确性（通过检索实时知识）。\n在相同困惑度下，用更少参数匹配或超越 GPT 性能。\n\n\n实践意义：论文开源代码和模型（GitHub 链接），推动未来基础模型发展，尤其是在检索增强架构上结合指令微调等高级技术。\n\n\n6. 局限性与未来方向\n局限性：\n检索数据库依赖：模型事实性和毒性高度依赖数据库质量（如 Wikipedia 优于预训练语料）。若数据库含偏见或错误信息，性能会下降。\n计算成本：RETRO 预训练开销比 GPT 高 25%（表11），大规模扩展（如 &gt;10B 参数）尚未探索。\n任务特定性：RETRO++ 主要优化 QA，其他任务（如对话）需进一步适配。\n\n\n未来工作：\n探索更大规模模型（如 48B 参数 RETRO）。\n结合强化学习人类反馈（RLHF）进一步降低毒性。\n开发动态数据库更新机制，避免预训练后知识过时。\n\n\n\n此研究为检索增强语言模型提供了实证基础，证明其在构建高效、可信赖的基础模型中的潜力。如需深入细节，可参考论文中的完整实验数据（如附录中的配置表）或访问开源代码库。\n","categories":["大模型"],"tags":["人工智能"]},{"title":"P4&SRV6","url":"/2024/06/24/B-EP2/","content":"B-EP2背景：互联网变得臃肿，网络管理员迫切需要一种快速高效的网络遥测方案，能够利用采集到的实时准确的网络状态信息来快速检测和定位常见网络故障，然后需要一个有效的网络控制和管理（NC&amp;M）方案，以实现只能及时决策以在网络路径上梳理和路由流量，以同时实现高效的利用和高质量的服务（QoS）。\n\n采集网络信息，定位故障\n有效的网络控制和管理方案\n\n(465条消息) P4学习笔记（一）初识P4_p4接口是干嘛的_程序员学编程的博客-CSDN博客\n\n基于P4的主动遥测\n\n探针代替数据分组进行遥测，降低了遥测开销（因为数组分组比如INT即带内网络遥测(460条消息) 带内网络遥测INT–In-band Network Telemetry_袁冬至的博客-CSDN博客\n\nhttps://www.sdnlab.com/23822.html\n(465条消息) Telemetry 技术概述_LeocenaY的博客-CSDN博客\n，在转发数据分组时能够在数据在网络结构流动的过程中，通过在路径中间节点插入元数据，监控系统可以通过这些元数据进行收集网络状态，但这样载荷比就大)，INT之类的带内网络遥测也存在一些局限性，难以获取全局网络试图。这样就加入了探针进行主动遥测，提高数据分组的有效载荷比。\n一文读懂带内网络遥测技术 | SDNLAB | 专注网络创新技术\n\n\n\n基于段路由（基于IPV6的一向技术）\n\n(460条消息) 广域网技术——SRv6 SID讲解_静下心来敲木鱼的博客-CSDN博客\n(465条消息) 1.2、SRv6(Segment Routing Over IPv6) 介绍_srv6技术是什么_Ether_Dzh的博客-CSDN博客\n\n\n改变SR标签和排列顺序指定探测路径\n探针加入SR标签栈获取全面的网络视图，环形探测路径，单个探测点具备探针发送端和接收端功能，减少多个探测点之间同步协调探针等复杂操作。\n减少遥测冗余，探针分组中加入遥测指示域，指定需要采集的遥测数据\n将可编程设备的内部状态的状态信息嵌入到探针中，通过可编程设备的定制化能力自定义数据分组处理逻辑来是实现。\n\n\n\nSDN控制面：可编程环境\n可集中控制网络：SDN域由集中统一的控制单元实施管理\n转发和控制分离\nP4：\n\n可以对网络设备芯片逻辑进行编程\n\n可重配置性：支持转发逻辑代码经过编译部署到具体平台上之后动态修改报文\n\n不绑定某个具体的网络协议\n\n平台无关性：独立于特定的底层运行平台来编写数据报文处理逻辑\n\n需要特定交换机的支持\n\n数据采集与感知：\n\n通过ONOS（一体化的网络操作系统）的Restful北向接口查询得到的ONOS特有数据库内的全局网络信息（但忽略细节）(460条消息) ONOS预热篇之ONOS简介_weixin_34384681的博客-CSDN博客\n数据层交换机中的数据流，插入探针，数据采集服务链，提取各个包的特征进行统计\n基于段路由机制，进行INT主动遥测（INT本身是有局限性的，探测路径需要提前指定，而借助段路由机制进行主动网络遥测，降低成本提高了灵活性），流量包中插入探针，快速获取探测包路径上的第一手数据平面遥测数据\n\n\n这里的智能分析与决策采用深度学习相关的东西\n\n可编程动态管控（P4）：仅管理数据平面如何处理数据包，定义控制平面与数据平面通信的接口，但不描述控制平面功能\n\n传统交换机和P4交换机\n在传统交换机中，制造商定义了数据平面的功能，控制平面通过一些管理表（如路由表）中的条目以及处理控制数据包（如路由协议数据包）或异步事件（如链路状态更改或学习通知）来控制数据平面。\nP4可编程交换机与传统交换机的区别主要体现在两个方面：\n\n数据平面功能不是预先固定的，而是由 P4 程序定义的。数据平面在初始化时配置为实现 P4 程序描述的功能（由红色长箭头显示），并且没有现有网络协议的内置知识。\n控制平面使用与固定功能设备中相同的通道与数据平面进行通信，但数据平面中的表集合和其他对象不再是固定的，因为它们由 P4 程序定义。P4 编译器生成控制平面用于与数据平面通信的 API。\n\n\n控制平面（SDN控制器）如何与P4的设备进行通信？\n\nP4Runtime（基于gRPC框架）\n\nOpenFlow协议中，控制器和设备是由控制器开放端口，设备才能连接上控制器；而P4Runtime是设备上开始gRPC,控制器连接设备，因此，在支持P4的设备上也会有一个代理的Agent去处理控制器来的连接\n\n\n\n\n鉴于基于P4的被动网络遥测可扩展性不足的缺点，首先要保证的就是主动遥测的探测路径在运行时是灵活可控的，我们采用段路由机制来灵活控制探针的探测路径（这里的路径生成采用了Hierholzer 算法，欧拉回路）。段路由机制简单易用，不需要额外的协议支持，通过组合一系列简单的网络操作指令就可以完全控制数据分组的转发路径。在降低了网络成本的同时也提高了灵活性。最后段路由能够支持增量部署，降低了部署难度，可行性好。该系统下可以灵活定义遥测路径，按需探测可能或已经出现问题的路径，快速定位故障位置。同时，可以在探针格式中加入探测遥测数据类型的字段来支持按需获取遥测数据。同时要保证能够采集到网络设备内部的状态信息等细粒度准确的遥测数据，我们可以通过修改可编程设备的数据平面处理逻辑来区分正常数据分组和探针数据分组，对于正常数据分组直接正常转发，而对于探针数据分组匹配其中的路径转发标签以及遥测指令字段，将实时的网络状态信息封装在探针数据分组中。\n","categories":["SDN"],"tags":["SDN","P4","SRV6"]},{"title":"CoRE-learning：Learnability with Time-Sharing Computational Resource Concerns","url":"/2024/07/01/CoRE-learning%EF%BC%9A%E5%B8%A6%E6%9C%89%E5%88%86%E6%97%B6%E8%AE%A1%E7%AE%97%E8%B5%84%E6%BA%90%E8%80%83%E8%99%91%E7%9A%84%E5%8F%AF%E5%AD%A6%E4%B9%A0%E6%80%A7%E7%90%86%E8%AE%BA/","content":"CoRE-learning：Learnability with Time-Sharing Computational Resource Concerns‍https://doi.org/10.1093/nsr/nwae204‍\n一般认为，人工智能机器学习技术应用涉及算法、数据、算力“三要素”。经典机器学习理论关注算法与数据对学习性能的影响，推导出的机器学习泛化误差界所包含的重要项通常涉及假设类复杂度和样本复杂度，两者分别与算法和数据有关，而对“三要素”中的算力缺乏考虑，尽管现实场景中算力资源的供给分配直接影响到最终学习性能。\n在近期发表于《国家科学评论》（National Science Review, NSR）的Perspective文章中，南京大学周志华教授提出了“计算资源高效学习（CoRE-learning）”理论框架，这是第一个考虑了算力资源供给调度对机器学习性能影响的学习理论框架。\nCoRE理论框架：\n\n作者定义了“机器学习吞吐率”并引入了对资源动态分配调度策略的考虑，使得算力资源的供给分配对机器学习泛化性能的影响可以被抽象地在学习理论中进行研究，不仅有助于指导设计出高效使用算力资源的算法，还可望引导“智算中心”在为机器学习模型训练提供资源服务时从“独占式”转变为“分时式”，为能源的高效利用提供一个机器学习理论视角。\n动机（Motivation）：\n传统机器学习理论通常假设有足够的甚至无限供应的计算资源来处理所有接收到的数据。然而，在实际应用中，如流学习，数据流可能是无限的，且数据量巨大，不可能及时处理所有数据。（这个问题通常不是机器学习领域考虑的问题）\n现代“智能超级计算”设施通常以独占方式运行，用户被分配固定数量的资源来运行机器学习任务。这种方式可能过于乐观或悲观，导致资源分配不合理。这就有点像早期的计算机系统了。\n机器学习理论应该考虑时间共享计算资源的问题，以提高用户效率和硬件效率，这一关键技术就是分时（time-sharing）。\n目标：\n用户效率角度：在一定时间预算内得到理想的模型结果。\n硬件效率角度：计算资源被合理地利用。\n\n\n\n工作内容（Work）：基于motivation，提出了“计算资源高效学习”（CoRE learning）的概念，并建立了一个理论框架。\n定义\n吞吐量：每秒可以传输的数据量&#x2F;数据库中平均事务处理数量。\n\n引入了机器学习吞吐量的概念，用于在抽象层面上理论化计算资源和调度的影响。：\n\n数据吞吐量：表示每个时间单位内可以学习的数据百分比。\n\n线程吞吐量：线程吞吐量表示在一段时间内可以很好地学习的线程的百分比。\n\n图1(a)为数据吞吐量，将这个概念引入机器学习研究：\n\n数据量和计算资源预算的影响可以被涉及。\n但并未考虑到从数据中学习的难度可能会发生变化的事实。\n\n线程：计算设备接收到的机器学习任务。\n\n生命周期：开始时间和截止&#x2F;死亡时间（这里的截止时间是人为设置的）。\n成功线程：时间跨度内能很好地学习，达到用户的要求。\n失败线程：时间跨度内不能很好地学习，不能达到用户的要求。\n\n线程吞吐量：由该时间段内所有线程中的成功线程百分比计算，如图1(b)线程吞吐量即为3&#x2F;5&#x3D;60%。\n任务束（task bundle）：相关时间段内的一组任务线程。\n\n\n其中，Dk表示具有数据分布的线程，bk表示起始时间，dk是截止时间，Nt是在给定计算资源前提下在时间t时可以处理的数据量，K是任务束中的总线程数（总的任务数)，T是总的**时隙（time slots)数量。如果bi&#x3D;bj (所有i≠j)**，则所有任务线程同时到达。\n\n\n\n\n\nLearning algorithm学习算法：\n输入：\n输出：\n\nsk为算法确定的切换时间。\nMk为第k个线程的learned model。\n\n用At表示在时间t时存活线程的集合：\n\n学习过程如下：\n\nfor循环:时间t&#x3D;1,…,T，the learner \ndo：\n\n最多收集 k,t，Nt 在 k ∈ At条件下的样本 , 其中 ηk,t为线程k在时间t的数据吞吐量。\n为线程k更新模型Mk。\n如果线程k完成，将sk设为t。\n\n\n终止循环。\n\n\nDefinition 1 ((η, κ,L)-CoRE learnability)：现在引入CoRE learnability，其中为数据吞吐量，为线程吞吐量。\n\n条件（1）涉及整个数据吞吐量，约束所有在当前时刻的alive set中的线程的总体资源配额永远不会超过最大资源预算。\n条件（2）涉及线程吞吐量，要求调度策略ψ使L能够尽可能多地学习：\n\n线程的学习应在截止时间前完成，如条件（2a）所示；\n并且线程的学习性能应当在如条件（2b）所指示的小误差水平内。学习性能由来衡量，当算法利用时隙（bk，sk）中接收到的数据并在时间点sk之前完成学习时，根据预定的来评估学习性能是否可接受。\n\n注意，条件（1）与用户效率有关，而条件（2)与硬件效率有关；调度策略应该谨慎地平衡这两个方面。\nCoRE learnability定义使用了一种类似可能近似正确的PAC学习理论。与PAC不同的是，CoRE learnability考虑了资源调度策略ψ的影响，并且对于具有（η，κ）吞吐量问题的学习算法L，仅要求可接受的。\n\n算法流程举例说明：图1(c)给出了一个图示，其中任务包由K&#x3D;5个线程组成。为简单起见，假设在每个时间单位个数据单位可以处理。请注意，CoRE学习允许任务线程的开始时间sk和截止时间dk,为任何实际值，而在此图中，我们假设它们是四舍五入的，以便更好地说明。对于给定的算法L，任务束是**(0.5,0.6,L)-CoRE learnable的，因为存在一种调度策略ψ，使得在给定数据吞吐量η&#x3D;50%**的情况下，工能够成功地学习5个线程中的3个。\n如图1c所示：\n\nψ将能够处型ηN&#x3D;32个数据单元的资源平等地在time slot处于t0-t1时分配给线程1和线程3，线程1继续接收可以处理16个数据单元的资源，直到在t3完成；剩余可以处理16个数据单元的资源在t1-t3中平均分配给线程2和线程3。\n在t3-t4时，因为线程1不再需要任何资源，线程2和3每个都将分配到可以处理8个以上数据单元的资源。\n线程4在t4到来，ψ对线程2感到悲观，所以把所有资源分配给线程3和线程4。\n线程5在t5到来，由于线程5寿命很短，所以ψ给它分配了尽可能多的资源，直到在t7学习失败。\n在t6，ψ对线程3非常乐观，因此决定暂时牺牲线程4将所有剩余的资源给线程3。\n在t7，只有线程2和线程4还活着。\n线程2和线程5失败的原因：线程2因为学习表现不理想，违反了条件2(b)，而线程5没有在截止时间前完成，违反了条件2(a)。\n\n关于调度策略ψ：资源调度策略ψ能够根据对学习状态的感知和对线程学习进度的预测，自适应地分配资源。\n直观地说，如果L是基于梯度计算的，那么为一个任务分配更多的计算资源意味着可以为该任务执行更多的梯度计算\n\n资源分配的动态性：在梯度下降算法中，如果一个任务线程（thread）进入了平坦的收敛区域，即错误率在过去几轮梯度计算中没有显著下降，而另一个线程进入了斜率区域，错误率下降更快，资源调度策略ψ会根据这些信息来调整资源分配。例如，在迭代τ1时，如果线程1进入了一个平坦的收敛区域，而线程2进入了斜率区域，ψ就会减少线程1的资源并重新分配给线程2。\n\n资源调度的优化：资源调度策略ψ的目标是提高整体的吞吐量（throughput）。在图1(d)的示例中，假设两个任务线程最初被分配了相同数量的资源。通过动态调整资源分配，线程2可以在最终迭代τ3达到更好的状态b，而不是b’，而线程1则牺牲了达到a’的机会，达到了a。这导致整体吞吐量从0.0提高到0.5，即线程2根据阈值ϵ0被判定为成功。\n\n\n资源调度的平衡：资源调度策略需要在探索和利用之间找到平衡。在机器学习过程中，可能需要在继续分配资源给当前表现不佳的任务线程（探索）和将资源重新分配给表现更好的任务线程（利用）之间做出选择。\n\n资源调度的复杂性：机器学习中的资源调度与计算机系统和数据库中的资源调度不同。在计算机系统和数据库中，一旦任务接收到，完成该任务所需的资源量通常是已知的，而在机器学习中，这个信息是未知的，只能通过在线监视学习过程来估计。\n\n在线治理和状态估计：在线治理和状态估计需要通信和计算资源，这增加了资源调度的复杂性。CoRE学习理论自然涉及到资源调度的探索-利用平衡。\n\nCoRE学习理论的目标：CoRE学习理论的一个基本目标是通过引入调度，使机器学习的计算资源能够以时间共享的方式使用，而不是当前的难以捉摸的方式。这有助于减少资源浪费，并提高资源利用效率。\n\nCoRE学习算法的证明：一旦开发出具体的CoRE学习算法，就可以证明其CoRE可学习性。\n\n\n成果（Results）：\n论文提出了CoRE学习理论，该理论考虑了计算资源的调度策略，允许机器学习任务像计算机系统和数据库的时间共享技术一样运行。\n通过定义CoRE可学习性，作者提供了一种评估学习算法在有限资源下性能的方法，包括数据吞吐量和线程吞吐量的限制条件。\n\n结论（Conclusion）：\nCoRE学习理论强调了在机器学习中考虑时间共享计算资源的重要性，目标是实现计算资源的高效利用，类似于计算机系统的时间共享技术。\n通过引入调度策略，CoRE学习可以更好地平衡用户效率和硬件效率，提高机器学习任务的整体吞吐量。\n论文指出，CoRE学习理论为机器学习中的资源调度提供了新的研究方向，包括如何在线有效地管理和估计机器学习过程的状态和进度。\n\n","categories":["机器学习"],"tags":["机器学习","分时计算","系统优化"]},{"title":"漫谈 LLM 解码策略-采样策略 贪心解码、随机采样、Top-K 采样、Top-P 采样、核采样 和搜索策略Beam Search","url":"/2025/08/13/2025-08-13-%E6%BC%AB%E8%B0%88%20LLM%20%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5%EF%BC%9A%E9%87%87%E6%A0%B7%E7%AD%96%E7%95%A5%EF%BC%88%E8%B4%AA%E5%BF%83%E8%A7%A3%E7%A0%81%E3%80%81%E9%9A%8F%E6%9C%BA%E9%87%87%E6%A0%B7%E3%80%81Top-K%20%E9%87%87%E6%A0%B7%E3%80%81Top-P%20%E9%87%87%E6%A0%B7%E3%80%81%E6%A0%B8%E9%87%87%E6%A0%B7%EF%BC%89%E5%92%8C%E6%90%9C%E7%B4%A2%E7%AD%96%E7%95%A5%EF%BC%88%20Beam%20Search%EF%BC%89/","content":"漫谈 LLM 解码策略：采样策略（贪心解码、随机采样、Top-K 采样、Top-P 采样、核采样）和搜索策略（ Beam Search）转载：https://zhuanlan.zhihu.com/p/29031912458\n","categories":["大模型"],"tags":["人工智能","贪婪解码"]},{"title":"Docker命令_各种参数简介","url":"/2024/07/27/Docker%E5%91%BD%E4%BB%A4_%E5%90%84%E7%A7%8D%E5%8F%82%E6%95%B0%E7%AE%80%E4%BB%8B/","content":"Docker命令_各种参数简介rundocker run [OPTIONS] IMAGE [COMMOND] [ARGS...] # OPTIONS 说明\t--name=&quot;容器新名字&quot;: 为容器指定一个名称；\t-d: 后台运行容器，并返回容器ID，也即启动守护式容器；\t-i：以交互模式运行容器，通常与 -t 同时使用；\t-t：为容器重新分配一个伪输入终端，通常与 -i 同时使用；\t-P: 随机端口映射；\t-p: 指定端口映射，有以下四种格式\t      ip:hostPort:containerPort\t      ip::containerPort\t      hostPort:containerPort\t      containerPort    -w: 指定命令执行时，所在的路径  # IMAGEXXX_IMAGE_NAME:XXX_IMAGE_VER  # COMAND例：mvn -Duser.home=xxx -B clean package -Dmaven.test.skip=true # 常用OPTIONS补足：--name：容器名字--network：指定网络--rm：容器停止自动删除容器 -i：--interactive,交互式启动-t：--tty，分配终端-v：--volume,挂在数据卷-d：--detach，后台运行# 在已运行的容器中运行命令docker exec [OPTIONS] CONTAINER COMMAND [ARG…]常用选项：  -d：--detach ，后台运行命令  -e, --env list             设置env  -i, --interactive         启用交互式  -t, --tty                     启用终端  -u, --user string        指定用户 (格式: &lt;name|uid&gt;[:&lt;group|gid&gt;])  -w, --workdir string       指定工作目录\n\ndocker -v 挂载#譬如我要启动一个centos容器，宿主机的/test目录挂载到容器的/soft目录，可通过以下方式指定： docker run -it -v /test:/soft centos /bin/bash #冒号&quot;:&quot;前面的目录是宿主机目录，后面的目录是容器内目录。\n\n其他常用================================#查看docker服务运行状况ps -el | grep -i docker-#停止Docker服务service docker stop-#启动docker服务service docker start================================#查看有哪些镜像docker search yourAppName-#获取镜像docker pull imageName-#查看安装了的镜像docker images-#查看运行的容器docker ps-#查看所有的容器docker ps -a-#停止容器运行docker stop &lt;container_id&gt;-#重新启动容器docker resatart &lt;container_id&gt;-#删除容器docker rm yourContainerID -#删除镜像docker rmi yourImageName-#查看容器开启时的logdocker logs -f yourContainerName-#进入容器内部执行命令docker exec -it yourContainerID bash＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝#查看Logdocker logs -f &lt;image_name&gt;\n\n","categories":["Docker"],"tags":["Docker"]},{"title":"利用ollama一键式部署HuatuoGPT2和使用","url":"/2024/07/26/HuatuoGPT2/","content":"利用ollama一键式部署HuatuoGPT2和使用killgfat&#x2F;huatuogpt2 (ollama.com)\n部署过程采用ollama进行一键式部署：\nssh bjtc@162.105.16.236password: 000000curl -fsSL https://ollama.com/install.sh | sh //下载ollmaollama run killgfat/huatuogpt2 //利用ollma下载huatuogpt2\n\n运行和对比将离线状态下成功部署的huatuogpt2与Kimi（月之暗面大模型）各自询问五个医学领域的问题，各自的回答对比结果如下。\n\n从20年元旦发烧好了以后，小孩每天晚上喊双膝盖好累到现在，应该是酸痛，白天基本没事，目前走路正常，无肿胀。已到人民医院检查核磁共振检查显示关节有少许积液，请问这是什么病，怎么治疗，能不能给我开药？\nHuatuoGPT2:\n\n根据您的描述和医院的检查结果，这可能是孩子的膝关节出现了一些问题。具体的原因可能是多种多样的，比如过度使用、受伤或者是某种疾病的表现。但是，具体的诊断还需要由医生根据详细的病史和其他相关的医学信息来做出。关于关节积液的问题，这可能是由于炎症或者其他原因导致的。如果是由于炎症的话，那么可能是由于某种疾病的症状，比如说类风湿关节炎或者是因为其他的一些疾病引起的。如果是由于其他的原因，比如过度使用或者是受伤的话，那么治疗的方法也会有所不同。治疗方法可能包括物理疗法、药物治疗以及其他的治疗方法。具体的治疗方案需要由医生根据孩子的具体情况来制定。药物治疗可能会包括非处方药物，比如用来缓解疼痛和炎症的药物，也可能会包括处方药物，比如说如果需要控制炎症或者是为了治疗某种疾病的话。但是，我必须强调，以上的所有的信息都是基于您提供的信息和我所了解的医学知识，具体的诊断和治疗还需要由医生来决定。我建议您尽快带孩子去看医生，由专业的医生来进行详细的检查和评估，以便能够得到最准确的诊断和最适合的治疗方案。\n\nKimi:\n\n根据您描述的情况，孩子晚上双膝盖感到酸痛，但白天走路正常且无肿胀，核磁共振检查显示关节有少许积液。这可能是由多种原因引起的，例如过度疲劳、轻微的关节损伤或是早期的关节炎症等。不过，具体的诊断需要由专业医生根据详细的病史、体检和辅助检查结果来确定。对于膝盖的酸痛，一些常见的治疗方法包括：1. 休息和减少活动量，尤其是减少可能加大膝关节负担的活动，如跑跳、长时间行走或爬楼梯 。2. 冰敷可以减轻疼痛和肿胀，建议在疼痛的第一天每小时冰敷15分钟，之后几天每天4次 。3. 使用护膝来保护和辅助膝关节运动 。4. 如果疼痛较为严重，可以在医生的指导下使用非甾体抗炎药物（如布洛芬、塞来昔布等）来缓解疼痛 。5. 在某些情况下，医生可能会建议进行物理治疗或康复训练，以增强膝关节周围的肌肉并改善关节功能 。重要的是，如果孩子的膝盖疼痛持续存在或有加重的趋势，应该及时带孩子去医院就诊，明确病因，并根据医生的建议进行针对性治疗。此外，如果核磁共振检查显示关节有积液，医生可能会建议进一步的检查或治疗，如关节穿刺抽液等，以排除其他潜在的疾病 。请注意，我不能为您开药，因为我不是医生，也无法进行面对面的诊断。上述建议仅供参考，具体治疗方案还需咨询专业医生。\n\n您好，我患有大拇指腱鞘炎已经有13年了，症状包括右手大拇指明显比左手粗大，伸不直，使劲伸直有响声，不灵活。这个病严重影响了我的工作和生活。我想知道宿州这边有没有看这个病的医院，能否推荐一个好一点的医院给我？如果需要手术，我也愿意尝试，只希望能尽快解决这个痛苦。谢谢！\nHuatuoGPT2:\n\n很抱歉听到您的病情。大拇指腱鞘炎是一种常见的疾病，主要是由于长期过度使用或者受伤导致的大拇指屈伸肌腱发炎引起的。这种病症可能会导致手指功能障碍，严重的话可能会影响日常生活和工作。在宿州地区，我建议您可以考虑去宿州市人民医院的骨科进行咨询和治疗。他们有专业的医生和设备可以进行相关的检查和治疗。如果您需要手术，他们也可以为您提供相应的服务。同时，您也可以在在线医疗平台上咨询一些医生，看看他们对您的病情有什么建议。在治疗方面，除了手术之外，还有一些非手术的治疗方法，比如物理疗法、药物治疗等。具体的治疗方案还需要根据您的具体病情来确定。希望您能早日康复！\n\nKimi:\n\n您好，根据搜索结果，宿州市立医院是宿州地区治疗腱鞘炎排名靠前的医院，它是一家三级甲等综合医院，具有悠久的历史和良好的口碑 。医院有多位擅长骨科疾病的主任医师，例如程银树主任医师，他擅长脊柱常见病、多发病及疑难杂症的诊治，熟练操作人工全髋关节置换术、人工全膝关节置换术以及各类骨科创伤整复内固定手术 。此外，吴健生主任医师和刘体彬主任医师也都在骨科领域有丰富的经验，擅长脊柱、四肢、人工关节置换及小儿畸形的矫正治疗等 。如果您考虑手术治疗腱鞘炎，宿州市立医院是一个值得考虑的选择。建议您根据自己的健康需求，选择合适的医生进行进一步的咨询和治疗。您可以通过医院的预约挂号服务或图文问诊、电话咨询服务来了解更多信息和安排就诊 。祝您早日康复。\n\n我最近出现了一些症状，想向您咨询一下。我站姿或坐姿时脖子后侧感到涨痛，头也涨痛，但是平躺时就没事了。这种情况是怎么回事呢？\nHuatuoGPT2:\n\n首先，我要澄清一点，我是一个人工智能模型，虽然我可以提供医学知识和建议，但我不能进行实际的诊断和治疗。您的症状可能由多种原因引起，我会尽力帮助您理解可能的解释和可能的原因。根据您的描述，您在站立或坐着时感到脖子后部涨痛，头部也有类似的感觉。这种情况可能是由于颈椎肌肉紧张引起的，这在长时间保持不良姿势（如坐立不动或使用电脑）的情况下很常见。这可能导致颈部和上背部肌肉的紧张，从而引起疼痛和不适。此外，某些疾病和状况，如颈椎病、颈部劳损、肌肉痉挛或其他神经系统问题也可能导致类似的症状。我建议您：1. 尝试改变您的坐姿或站姿，避免长时间保持同一姿势；2. 定期休息和活动身体，以帮助缓解肌肉的紧张；3. 使用冷热敷疗法来缓解疼痛和不适；4. 如果症状持续或加重，或者伴有其他严重症状（如麻木、无力等），请尽快就医进行专业评估和治疗。\n\nKimi:\n\n您描述的症状可能与多种因素有关，包括但不限于以下几种情况：1. **颈椎病**：长时间保持不良姿势，如长时间低头看手机或电脑，可能导致颈椎压力增加，引起脖子和头部的不适。2. **肌肉紧张**：颈部和肩部肌肉长时间紧张或疲劳，可能导致肌肉僵硬和疼痛。3. **姿势不良**：不正确的坐姿或站姿可能导致颈部和背部肌肉承受额外压力。4. **压力或焦虑**：心理压力和焦虑有时会导致肌肉紧张，包括颈部和肩部肌肉。5. **眼睛疲劳**：长时间注视屏幕或阅读可能导致眼睛疲劳，进而引起头痛。6. **脱水**：脱水有时也会导致头痛。7. **睡眠不足**：睡眠不足或睡眠质量差也可能导致头痛和颈部不适。8. **其他健康问题**：如高血压、贫血等也可能引起头痛。由于我无法提供诊断，建议您咨询医生或专业的医疗人员以获得准确的诊断和治疗建议。在此之前，您可以尝试以下一些缓解措施：- 保持良好的姿势，避免长时间保持同一姿势。- 定期休息并做一些颈部和肩部的伸展运动。- 确保充足的睡眠。- 保持适当的水分摄入。- 如果是眼睛疲劳，尝试每隔一段时间远离屏幕，让眼睛休息。- 如果症状持续或加重，请及时就医。如果您需要更多帮助，比如寻找附近的医疗机构或专家，请随时告诉我。\n\n我最近出现了尿中有些血的情况，已经持续三天了。我之前做过前列腺增生手术，现在不想再去医院，想在家里保守治疗。您能给我一些建议吗？\nHuatuoGPT2:\n\n首先，我要提醒您的是，尿液异常可能是身体内部问题的信号，特别是如果伴随其他症状如疼痛、发热等，应及时就医以获得正确的诊断和治疗。对于您的尿中情况，以下是一些可能的建议：1. 多喝水：保持充足的水分摄入有助于稀释尿液，减少刺激尿路的可能性。2. 饮食调整：避免摄入刺激性食物和饮料，如咖啡、酒精、辛辣食物等，这些可能会加重症状。同时增加摄入纤维丰富的水果和蔬菜，有助于预防便秘（如果存在）及降低尿路感染的风险。3. 尿中血尿可能是泌尿系统疾病的表现，例如膀胱炎、肾脏病或前列腺问题。虽然您已经做过前列腺手术，但仍有可能发生复发或其他问题。因此，我强烈建议您尽快咨询医生以获取专业意见和必要的检查。4. 在等待就医期间，您可以尝试一些自我护理措施来缓解症状。例如，避免长时间坐立不动，经常进行适量的运动有助于促进血液循环；注意个人卫生，保持外阴清洁干燥，以减少细菌感染的可能性等。然而，这些只能作为临时缓解的方法，不能替代医生的诊断和治疗建议。请记住，我提供的建议仅供参考，并不能替代专业医疗意见。如果您的尿中血的情况持续存在或加重，或者您有其他不适症状，请尽快就医寻求专业的医疗帮助。\n\nKimi:\n\n尿液中出现血迹（医学上称为血尿）可能是由多种原因引起的，包括但不限于泌尿系统感染、结石、肾脏疾病、前列腺问题等。考虑到您之前做过前列腺增生手术，血尿可能与此有关，但也可能是其他原因引起的。**重要提示**：血尿是一个需要医生评估的症状，因为它可能是一些严重疾病的早期信号。尽管您不想去医院，但我强烈建议您至少通过电话或在线咨询的方式联系医生，以确保得到正确的诊断和治疗。在您能够联系医生之前，以下是一些建议，可能有助于缓解症状或减少潜在的风险：1. **增加水分摄入**：喝足够的水可以帮助冲洗泌尿系统，减少感染的风险，并可能帮助排出小的结石。2. **避免刺激性食物和饮料**：咖啡、酒精和辛辣食物可能会刺激泌尿道，应适量减少。3. **适当休息**：避免剧烈运动和重体力劳动，减少对泌尿系统的压力。4. **观察症状**：记录血尿的情况，包括颜色、频率和任何伴随症状，这有助于医生进行诊断。5. **使用非处方止痛药**：如果感到疼痛，可以考虑使用非处方的止痛药，如布洛芬，但请遵循药物说明，并注意不要长期过量使用。6. **保持良好的个人卫生**：这有助于减少泌尿系统感染的风险。7. **避免性行为**：如果血尿与前列腺有关，性行为可能会加重症状。然而，我必须再次强调，血尿是一个需要专业医疗评估的症状。如果血尿持续或伴有其他症状（如发热、腰痛、排尿困难等），您应该尽快就医。请不要忽视这些症状，因为及时的诊断和治疗对于预防并发症非常重要。\n\n医生您好。我想咨询一下关于我孩子的病情。她现在2岁3个月，几个月前我发现她的膝关节前方出现了一块硬痂，开始以为是皮纹，但是后来越来越硬，并且有凸起的感觉。她没有疼痛或者痒的感觉，也没有外伤史。我想知道这是什么病，是否会扩大，是否需要去医院。谢谢您的帮助！\nHuatuoGPT2:\n\n您好，根据您的描述，孩子的膝盖部位出现的硬性凸起可能是由于几种情况引起的：1. 骨疣（又称为骨瘤或骨质增生）：这是一种常见的良性骨肿瘤，通常在骨骼生长的地方出现，尤其是在膝关节周围。它们通常是无痛的，可以移动，并且随着时间的推移可能会变大或者变硬。2. 滑膜囊肿：这是由于关节内部的液体积聚形成的囊肿。这些囊肿通常不痛，但是可能会导致肿胀和硬度。3. 肌腱鞘囊肿：这是一种在肌腱附近出现的肿块，通常是由于滑液积聚引起的。4. 骨刺或骨质增生：这可能是由于骨骼的过度使用或者磨损引起的。要确定具体的病因，最好的做法是带孩子去医院进行检查。医生可能会建议进行X光检查或者其他影像学检查来确定肿块的性质和大小。如果需要的话，可能还会建议进行活检以进一步确定诊断。如果肿块没有引起任何症状（如疼痛、肿胀或活动受限）并且没有继续增大，那么可能不需要立即进行治疗。但是，我建议您带孩子去医院进行检查，以确保没有其他潜在的问题。同时，也可以让孩子避免在肿块上施加过多的压力或者摩擦，以防止进一步的损伤或者炎症。\n\nKimi:\n\n您好，根据您描述的情况，孩子膝关节前方出现的硬痂可能有多种原因，包括但不限于以下几种可能性：1. **骨软骨瘤**：这是一种良性骨肿瘤，通常表现为骨表面出现的硬性突起，可能随着时间慢慢增大。2. **骨质增生**：在某些情况下，骨质可能异常增生，形成硬结。3. **皮肤病变**：某些皮肤病也可能在关节附近形成硬痂或结节。4. **囊肿**：如腱鞘囊肿，可能在关节附近形成肿块。5. **其他原因**：包括某些感染或炎症性疾病。由于硬痂没有疼痛或瘙痒，孩子可能不会表现出不适，但这并不意味着不需要关注。随着时间的推移，如果硬痂继续增大或出现其他症状，可能需要进一步的评估。**建议**：- **观察**：注意硬痂是否有变化，如大小、形状、颜色或是否出现疼痛、红肿等症状。- **记录**：记录硬痂的变化情况，包括任何新出现的症状。- **咨询医生**：尽管您可能不想立即去医院，但考虑到硬痂的性质和可能的增长，建议您至少通过电话或在线咨询的方式联系儿科医生或骨科医生，以获得专业意见。- **必要时就医**：如果硬痂有任何变化或您感到担忧，应该带孩子去医院进行进一步的检查，可能包括X光、超声或其他影像学检查，以确定硬痂的性质。请记住，我提供的信息不能代替专业医疗建议。孩子的健康非常重要，因此及时的评估和适当的医疗干预是非常关键的。希望孩子能够尽快得到正确的诊断和治疗。\n\n","categories":["大模型"],"tags":["HuatuoGPT2","Ollama"]},{"title":"Faiss入门及应用经验记录","url":"/2025/08/13/FAISS/","content":"Faiss入门及应用经验记录转载：https://zhuanlan.zhihu.com/p/357414033\n1. 什么是Faiss？Faiss的全称是Facebook AI Similarity Search，是FaceBook的AI团队针对大规模相似度检索问题开发的一个工具，使用C++编写，有python接口，对10亿量级的索引可以做到毫秒级检索的性能。\n简单来说，Faiss的工作，就是把我们自己的候选向量集封装成一个index数据库，它可以加速我们检索相似向量TopK的过程，其中有些索引还支持GPU构建，可谓是强上加强。\n2. Faiss简单上手首先，Faiss检索相似向量TopK的工程基本都能分为三步：\n\n得到向量库；\n用faiss 构建index，并将向量添加到index中；\n用faiss index 检索。\n\n好吧……这貌似和废话没啥区别，参考把大象装冰箱需要几个步骤。本段代码摘自Faiss官方文档，很清晰，基本所有的index构建流程都遵循这个步骤。\n\n第一步，得到向量：\n\nimport numpy as npd = 64                                           # 向量维度nb = 100000                                      # index向量库的数据量nq = 10000                                       # 待检索query的数目np.random.seed(1234)             xb = np.random.random((nb, d)).astype(&#x27;float32&#x27;)xb[:, 0] += np.arange(nb) / 1000.                # index向量库的向量xq = np.random.random((nq, d)).astype(&#x27;float32&#x27;)xq[:, 0] += np.arange(nq) / 1000.                # 待检索的query向量\n\n\n第二步，构建索引，这里我们选用暴力检索的方法FlatL2，L2代表构建的index采用的相似度度量方法为L2范数，即欧氏距离：\n\nimport faiss          index = faiss.IndexFlatL2(d)             print(index.is_trained)         # 输出为True，代表该类index不需要训练，只需要add向量进去即可index.add(xb)                   # 将向量库中的向量加入到index中print(index.ntotal)             # 输出index中包含的向量总数，为100000 \n\n\n第三步，检索TopK相似query：\n\nk = 4                     # topK的K值D, I = index.search(xq, k)# xq为待检索向量，返回的I为每个待检索query最相似TopK的索引list，D为其对应的距离print(I[:5])print(D[-5:])\n\n\n打印输出为：\n\n&gt;&gt;&gt; [[  0 393 363  78]  [  1 555 277 364]  [  2 304 101  13]  [  3 173  18 182]  [  4 288 370 531]]  [[ 0.          7.17517328  7.2076292   7.25116253]   [ 0.          6.32356453  6.6845808   6.79994535]   [ 0.          5.79640865  6.39173603  7.28151226]   [ 0.          7.27790546  7.52798653  7.66284657]   [ 0.          6.76380348  7.29512024  7.36881447]]\n\n3. Faiss常用index优缺点及使用场景Faiss之所以能加速，是因为它用的检索方式并非精确检索，而是模糊检索。既然是模糊检索，那么必定有所损失，我们用召回率来表示模糊检索相对于精确检索的损失。\n在我们实际的工程中，候选向量的数量级、index所占内存的大小、检索所需时间（是离线检索还是在线检索）、index构建时间、检索的召回率等都是我们选择index时常常需要考虑的地方。\n首先，我建议关于Faiss的所有索引的构建，都统一使用faiss.index_factory，基本所有的index都支持这种构建索引方法。\n以第二章的代码为例，构建index方法和传参方法建议修改为：\ndim, measure = 64, faiss.METRIC_L2param = &#x27;Flat&#x27;index = faiss.index_factory(dim, param, measure)\n\n\n三个参数中，dim为向量维数；\n最重要的是param参数，它是传入index的参数，代表需要构建什么类型的索引；\nmeasure为度量方法，目前支持两种，欧氏距离和inner product，即内积。因此，要计算余弦相似度，只需要将vecs归一化后，使用内积度量即可。\n20220102更新，现在faiss官方支持八种度量方式，分别是：\nMETRIC_INNER_PRODUCT（内积）\nMETRIC_L1（曼哈顿距离）\nMETRIC_L2（欧氏距离）\nMETRIC_Linf（无穷范数）\nMETRIC_Lp（p范数）\nMETRIC_BrayCurtis（BC相异度）\nMETRIC_Canberra（兰氏距离&#x2F;堪培拉距离）\nMETRIC_JensenShannon（JS散度）\n\n\n\n接下来笔者将介绍几种最核心的index类型的用法及优缺点，当然faiss支持的index类型非常多，但是以下这些index属于faiss最核心的几种基本index，大部分其他index是在这些核心index思想上的扩展、补充和改进，比如在PQ思想基础上的改进有SQ、OPQ、LOPQ，基于LSH的改进有ALSH等等，使用方法和下面介绍的类似。\n3.1 Flat ：暴力检索\n\n优点：该方法是Faiss所有index中最准确的，召回率最高的方法，没有之一；\n缺点：速度慢，占内存大。\n使用情况：向量候选集很少，在50万以内，并且内存不紧张。\n注：虽然都是暴力检索，faiss的暴力检索速度比一般程序猿自己写的暴力检索要快上不少，所以并不代表其无用武之地，建议有暴力检索需求的同学还是用下faiss。\n构建方法：\n\ndim, measure = 64, faiss.METRIC_L2param = &#x27;Flat&#x27;index = faiss.index_factory(dim, param, measure)index.is_trained                                   # 输出为Trueindex.add(xb)                                      # 向index中添加向量\n\n3.2 IVFx Flat ：倒排暴力检索\n\n优点：IVF主要利用倒排的思想，在文档检索场景下的倒排技术是指，一个kw后面挂上很多个包含该词的doc，由于kw数量远远小于doc，因此会大大减少了检索的时间。在向量中如何使用倒排呢？可以拿出每个聚类中心下的向量ID，每个中心ID后面挂上一堆非中心向量，每次查询向量的时候找到最近的几个中心ID，分别搜索这几个中心下的非中心向量。通过减小搜索范围，提升搜索效率。\n缺点：速度也还不是很快。\n使用情况：相比Flat会大大增加检索的速度，建议百万级别向量可以使用。\n参数：IVFx中的x是k-means聚类中心的个数\n构建方法：\n\ndim, measure = 64, faiss.METRIC_L2 param = &#x27;IVF100,Flat&#x27;                           # 代表k-means聚类中心为100,   index = faiss.index_factory(dim, param, measure)print(index.is_trained)                          # 此时输出为False，因为倒排索引需要训练k-means，index.train(xb)                                  # 因此需要先训练index，再add向量index.add(xb)                                     \n\n3.3 PQx ：乘积量化\n\n优点：利用乘积量化的方法，改进了普通检索，将一个向量的维度切成x段，每段分别进行检索，每段向量的检索结果取交集后得出最后的TopK。因为PQ算法把原来的向量空间分解为若干个低维向量空间的笛卡尔积，并对分解得到的低维向量空间分别做量化（quantization）。这样每个向量就能由多个低维空间的量化code组合表示，因此速度很快，而且占用内存较小，召回效果也还可以。\n缺点：召回率相较于暴力检索，下降较多。\n使用情况：内存及其稀缺，并且需要较快的检索速度，不那么在意召回率\n参数：PQx中的x为将向量切分的段数，因此，x需要能被向量维度整除，且x越大，切分越细致，时间复杂度越高\n构建方法：\n\ndim, measure = 64, faiss.METRIC_L2 param =  &#x27;PQ16&#x27; index = faiss.index_factory(dim, param, measure)print(index.is_trained)                          # 此时输出为False，因为倒排索引需要训练k-means，index.train(xb)                                  # 因此需要先训练index，再add向量index.add(xb)          \n\n3.4 IVFxPQy 倒排乘积量化\n\n优点：工业界大量使用此方法，各项指标都均可以接受，利用乘积量化的方法，改进了IVF的k-means，将一个向量的维度切成x段，每段分别进行k-means再检索。\n缺点：集百家之长，自然也集百家之短\n使用情况：一般来说，超大规模数据的情况下，各方面没啥特殊的极端要求的话，最推荐使用该方法！\n参数：IVFx，PQy，其中的x和y同上\n构建方法：\n\ndim, measure = 64, faiss.METRIC_L2  param =  &#x27;IVF100,PQ16&#x27;index = faiss.index_factory(dim, param, measure) print(index.is_trained)                          # 此时输出为False，因为倒排索引需要训练k-means， index.train(xb)                                  # 因此需要先训练index，再add向量 index.add(xb)       \n\n3.5 LSH 局部敏感哈希\n\n原理：哈希对大家再熟悉不过，向量也可以采用哈希来加速查找，我们这里说的哈希指的是局部敏感哈希（Locality Sensitive Hashing，LSH），不同于传统哈希尽量不产生碰撞，局部敏感哈希依赖碰撞来查找近邻。高维空间的两点若距离很近，那么设计一种哈希函数对这两点进行哈希计算后分桶，使得他们哈希分桶值有很大的概率是一样的，若两点之间的距离较远，则他们哈希分桶值相同的概率会很小。\n优点：训练非常快，支持分批导入，index占内存很小，检索也比较快\n缺点：召回率非常拉垮。\n使用情况：候选向量库非常大，离线检索，内存资源比较稀缺的情况\n构建方法：\n\ndim, measure = 64, faiss.METRIC_L2  param =  &#x27;LSH&#x27;index = faiss.index_factory(dim, param, measure) print(index.is_trained)                          # 此时输出为Trueindex.add(xb)       \n\n3.6 HNSWx （最重要的放在最后说）\n\n优点：该方法为基于图检索的改进方法，检索速度极快，10亿级别秒出检索结果，而且召回率几乎可以媲美Flat，最高能达到惊人的97%。检索的时间复杂度为loglogn，几乎可以无视候选向量的量级了。并且支持分批导入，极其适合线上任务，毫秒级别体验。\n缺点：构建索引极慢，占用内存极大（是Faiss中最大的，大于原向量占用的内存大小）\n参数：HNSWx中的x为构建图时每个点最多连接多少个节点，x越大，构图越复杂，查询越精确，当然构建index时间也就越慢，x取4~64中的任何一个整数。\n使用情况：不在乎内存，并且有充裕的时间来构建index\n构建方法：\n\ndim, measure = 64, faiss.METRIC_L2   param =  &#x27;HNSW64&#x27; index = faiss.index_factory(dim, param, measure)  print(index.is_trained)                          # 此时输出为True index.add(xb)\n\n4. 使用Faiss时踩过的坑和一些经验4.1 以下是我的同事对不同index做过的一些对比实验结果：\n\n召回率、搜索时间对比\n\n召回率、检索时间、内存消耗、构建时间对比\n4.2 Faiss可以组合传参\nFaiss内部支持先将向量PCA降维后再构建index，param设置如下：\nparam = &#x27;PCA32,IVF100,PQ16&#x27;\n\n代表将向量先降维成32维，再用IVF100 PQ16的方法构建索引。\n同理可以使用：\nparam = &#x27;PCA32,HNSW32&#x27;\n\n可以用来处理HNSW内存占用过大的问题。\n4.3 Faiss在构建索引时，有时生成的vecs会很大，向index中添加的向量很有可能无法一次性放入内存中，怎么办呢？\n\n这时候，索引的可分批导入index的性质就起了大作用了；\n如何来知道一种index是否可以分批add呢？一般来说在未对index进行train操作前，如果一个index.is_trained &#x3D; True，那么它就是可以分批add的；\n如果是index.is_trained &#x3D; False，就不能分批导入，当然，其实强行对index.is_trained &#x3D; False的索引分批add向量是不会报错的，只不过内部构建索引的逻辑和模型都在第一个batch数据的基础上构建的，比如PCA降维，其实是拿第一个batch训练了一个PCA模型，后续add进入的新向量都用这个模型降维，这样会导致后续batch的向量失真，影响精度，当然如果不在意这点精度损失那也可以直接add；\n由上可得，只要一个index的param中包含PCA，那他就不能分批add；\n可以分批导入的index为：HNSW、Flat、LSH。\n\n4.4 如果我们的需求，既想PCA降维减小index占用内存，还想分批add向量，该怎么办？\n可以使用sklean中的增量pca方法，先把数据降维成低维的，再将降维后的向量分批add进索引中，增量pca使用方法和pca一致：\nfrom sklearn.decomposition import IncrementalPCA\n\n4.5 关于HNSW\nHNSW虽好，可不要贪杯哦，这里坑还是蛮多的：\n\nHNSW的构建过程有时很短，有时却又很长，500万量级的向量快时可以15分钟构建完毕，慢则有可能花费两小时，这和HNSW构建多层图结构时的生成函数有关。\n老版本faiss的HNSW在使用以下这种构建索引方式时，有一个bug，这个bug会导致如果measure选用内积的方法度量，但最后构建的索引的度量方式仍然是欧氏距离：\n\nindex = faiss.index_factory(dim, param, measure)  \n\n如果想构建以内积（余弦相似度）为基准的HNSW索引，可以这样构建：\nindex = faiss.IndexHNSWFlat(dim, x,measure)  # measure 选为内积，x为4~64之间的整数\n\n\n所以直接建议使用新版本faiss，版本最好 &gt; 1.7，无此bug。\nHNSW占用内存真的很大，500万条768维的向量构建的索引占用内存17G，而同样数据下LSH仅占用500M，emmm所以自行体会吧。\nHNSW的检索候选可能不会很多，笔者的经验是一般500w的候选集，用HNSW64构建索引，检索top1000的时候就开始出现尾部重复现象，这其实就是HNSW在他的构建图中搜索不到近邻向量了，所以最后会用一个重复的id将尾部padding，让输出list补满至1000个，虽然IVF、PQ都会出现这个问题，但是HNSW会特别明显，这个和算法本身的原理有关。\n\n4.6 Faiss所有的index仅支持浮点数为float32格式\nFaiss仅支持浮点数为np.float32格式，其余一律不支持，所以用Faiss前需要将向量数据转化为float32，否则会报错！这也告诉大家，想用降低精度来实现降低index内存占用是不可能的！\n5.Faiss构建索引时，如何权衡数据量级和内存占用来选择index呢？这里有一份Faiss的官方文档，里面写的很清楚：\nFaiss官网，如何选择index类型github.com&#x2F;facebookresearch&#x2F;faiss&#x2F;wiki&#x2F;Guidelines-to-choose-an-index\n关于Faiss中index的更多详细信息，请参考官网：\nFaiss index factory介绍github.com&#x2F;facebookresearch&#x2F;faiss&#x2F;wiki&#x2F;The-index-factory\n","categories":["大模型"],"tags":["人工智能","向量检索"]},{"title":"Linux中读取文件,软硬件分别发生什么","url":"/2025/08/13/Linux%E4%B8%AD%E8%AF%BB%E5%8F%96%E6%96%87%E4%BB%B6%EF%BC%8C%E8%BD%AF%E7%A1%AC%E4%BB%B6%E5%88%86%E5%88%AB%E5%8F%91%E7%94%9F%E4%BB%80%E4%B9%88%EF%BC%9F/","content":"Linux中读取文件，软硬件分别发生什么？当你在Linux终端输入一个相对路径（例如 ./script.sh 或 ../data/file.txt）并执行时，操作系统会触发一系列硬件、内核与软件的协同操作。以下是按执行顺序的全流程解析：\n\n一、用户输入与Shell解析（软件层）\nShell解析路径\n\nShell（如Bash）将路径字符串拆解为目录分量（例如 ../data/file.txt → [&quot;..&quot;, &quot;data&quot;, &quot;file.txt&quot;]）。\n解析依赖当前工作目录（Current Working Directory, CWD），通过系统调用 getcwd() 获取（CWD存储于进程的 fs_struct 内核结构体中）。\n\n\n路径拼接逻辑\n\n相对路径会被拼接为绝对路径：\nCWD: /home/user/project → 输入 `../data/file.txt` → 最终路径: /home/user/data/file.txt\n\n\n\n\n二、操作系统内核处理（内核层）⚙️ 步骤1：路径遍历（Path Lookup）\n调用 openat() 系统调用 内核通过 openat() 接收路径（需指定起点目录的文件描述符 AT_FDCWD 表示当前目录）。\n\n逐级解析目录项（Directory Entry, dentry）\n内核执行 \npath_lookupat()\n\n 函数（源码位置：\nlinux/fs/namei.c\n\n）：\n\n从当前进程的 fs_struct-&gt;pwd 获取起点目录的 dentry缓存。\n遍历每个分量：\n若分量为 .. → 跳转到父目录的dentry。\n若分量为 . → 保持当前dentry。\n若为普通目录名 → 在dentry子项中查找匹配项。\n\n\n\n\ndentry缓存加速 内核使用 ​​dentry缓存（dcache）​​ 哈希表加速查找（避免重复磁盘访问）。\n\n\n⚙️ 步骤2：文件系统与磁盘交互\n查找Inode 找到目标dentry后，获取其关联的 ​​inode编号​​（如ext4文件系统中inode编号存储于目录项）。\n\n读取Inode元数据\n内核通过文件系统驱动（如ext4）从磁盘读取inode：\n\n硬件交互：\n若文件在SSD上：NVMe控制器将逻辑块地址（LBA）映射到物理闪存页。\n若在机械硬盘：磁头移动到inode表的柱面位置（寻道时间约3-15ms）。\n\n\ninode包含：文件大小、权限、数据块指针等。\n\n\n权限检查 内核比对进程的​​用户ID&#x2F;组ID​​与inode权限位（如 rw-r--r--），失败则返回 EACCES 错误。\n\n\n⚙️ 步骤3：数据读取\n对于 \ncat ../data/file.txt\n\n：\n\n根据inode中的数据块指针，计算磁盘位置。\n发起磁盘I&#x2F;O请求（内核调用块设备层 submit_bio()）。\n\n\n硬件执行：\n\nSSD：通过FTL（闪存转换层）将逻辑块转为物理地址，从NAND闪存读取数据。\n硬盘：磁头读取目标磁道的扇区数据。\n\n\n\n\n三、关键内核数据结构graph TD    A[进程 task_struct] --&gt; B[fs_struct]    B --&gt; C[当前目录 dentry缓存]    C --&gt; D[inode元数据]    D --&gt; E[文件数据块磁盘地址]\n\n\ndentry缓存：缓存目录结构，减少磁盘访问。\ninode：文件的元数据核心（存储于磁盘，使用时加载到内存）。\nPage Cache：文件内容的内存缓存（由内核管理，减少磁盘I&#x2F;O）。\n\n\n四、文件系统差异案例\next4文件系统\ninode表存储在固定磁盘区域。\n目录项存储文件名与inode号的映射。\n\n\nBtrfs文件系统\n使用B树管理目录项，支持子卷（Subvolume）隔离路径解析。\n\n\n\n\n五、硬件协作流程图sequenceDiagram    participant 用户进程    participant Linux内核    participant 文件系统驱动    participant 磁盘控制器    participant SSD/NVMe    用户进程 -&gt;&gt; Linux内核： 调用 openat(AT_FDCWD, &quot;../data/file.txt&quot;)    Linux内核 -&gt;&gt; Linux内核： 路径解析（dentry缓存→inode）    Linux内核 -&gt;&gt; 文件系统驱动： 请求inode读取（ext4/btrfs）    文件系统驱动 -&gt;&gt; 磁盘控制器： 发送LBA逻辑地址    disk 磁盘控制器 -&gt;&gt; SSD/NVMe： 物理地址读写指令    SSD/NVMe --&gt;&gt; 磁盘控制器： 返回数据（或错误）    磁盘控制器 --&gt;&gt; 文件系统驱动： 数据块内容    文件系统驱动 --&gt;&gt; Linux内核： 构造file对象    Linux内核 --&gt;&gt; 用户进程： 返回文件描述符（fd）\n\n\n六、性能关键点\ndentry缓存命中率：直接影响路径解析速度。\nPage Cache：文件内容的热数据缓存。\n磁盘响应时间：\nNVMe SSD：延迟约100µs\nSATA SSD：延迟约500µs\nHDD：延迟约10ms（受寻道时间主导）\n\n\n\n\n💡 总结：相对路径的访问是 硬件（磁盘寻址）→ 内核（路径解析&#x2F;权限&#x2F;缓存）→ 软件（Shell&#x2F;应用） 的深度协作过程，理解流程可帮助优化I&#x2F;O密集型应用性能。\n\nLinux 内核中关键组件及其与硬件协作的深度解析：\n🧩 一、核心数据结构：进程与文件系统1. task_struct（进程描述符）\n作用：描述进程的所有信息（相当于进程的”身份证”），内核通过 task_struct 管理进程。\n\n关键字段：\nstruct task_struct &#123;    pid_t pid;                     // 进程ID    struct mm_struct *mm;          // 内存管理结构（虚拟内存布局）    struct files_struct *files;    // 打开文件表    struct fs_struct *fs;           // 文件系统状态 ← 关联 fs_struct&#125;;\n\n典型场景：当进程执行 open(&quot;../file.txt&quot;) 时，内核从当前进程的 task_struct 中获取 fs-&gt;pwd（当前工作目录）。\n\n\n\n2. fs_struct（文件系统状态）\n作用：存储进程的文件系统上下文。\n\n关键字段：\nstruct fs_struct &#123;    struct path root;   // 根目录路径（通常为 &quot;/&quot;）    struct path pwd;    // 当前工作目录路径 → 指向 dentry&#125;;\n\n动态更新：执行 cd /data 时，内核更新当前进程的 pwd，指向 /data 目录的 dentry。\n\n\n\n3. dentry（目录项缓存）\n作用：缓存目录结构，加速路径查找（避免重复访问磁盘）。\n关键特性：\n内存缓存：在 RAM 中维护树状结构（d_parent 指向父目录，d_subdirs 链表存储子目录）。\n磁盘关联：通过 d_inode 指向磁盘上的 inode 元数据。\n\n\n生命周期：\n初次访问目录时创建 dentry（如 ls /data）。\n通过 dcache 哈希表管理，内存不足时自动回收。\n\n\n\n\n4. inode（索引节点）\n作用：文件的元数据核心（物理存储在磁盘，使用时加载到内存）。\n\n关键字段：\nstruct inode &#123;    unsigned long i_ino;      // inode 编号（磁盘唯一标识）    struct super_block *i_sb; // 所属文件系统（如 ext4）    loff_t i_size;            // 文件大小    struct address_space *i_mapping; // 关联 page cache&#125;;\n\n磁盘存储（以 ext4 为例）：\n\n\n\n磁盘区域\n内容\n\n\n\nSuperblock\n文件系统全局信息（如 inode 表位置）\n\n\nInode Table\n存储所有 inode（固定大小结构体）\n\n\nData Blocks\n文件实际内容\n\n\n\n\n\n5. Page Cache（页缓存）\n作用：将磁盘文件内容缓存到内存，减少 I&#x2F;O 延迟。\n工作原理：\n内核将文件按 4KB 页 缓存（通过 address_space 管理）。\n读操作：若数据在缓存中命中（find_get_page()），直接返回；否则触发磁盘读取。\n写操作：数据先写入缓存，标记为”脏页”，由内核线程定期刷盘（pdflush）。\n\n\n性能影响：缓存命中时读取速度 ≈ 内存访问速度（100ns），未命中时 ≈ 磁盘读取速度（SSD: 100µs, HDD: 10ms）。\n\n\n⚡ 二、硬件协作：NVMe SSD 的工作流程1. SSD 架构graph LR    A[Host] --&gt; B[NVMe 控制器]    B --&gt; C[闪存转换层 FTL]    C --&gt; D[闪存颗粒 NAND]\n\n\nNVMe 控制器：\n通过 PCIe 总线与 CPU 通信（并行队列，低延迟）。\n\n\nFTL（Flash Translation Layer）：\n关键功能：逻辑块地址（LBA）→ 物理闪存页地址（PBA）的映射。\n隐藏特性：磨损均衡（Wear Leveling）、垃圾回收（GC）。\n\n\nNAND 闪存：\n数据存储单元：页（Page，4KB16KB）→ 块（Block，128256 页）。\n\n\n\n2. 读文件时的硬件交互\n进程调用 \nread()\n\n → 内核检查 \npage cache：\n\n若命中 → 返回内存数据。\n若未命中 → 触发磁盘 I&#x2F;O。\n\n\n内核提交 I&#x2F;O 请求：\n\n构造 bio 结构体（Block I&#x2F;O 请求）。\n通过 NVMe 驱动发送命令队列到 SSD。\n\n\nSSD 执行：\n\nNVMe 控制器解析命令 → FTL 转换 LBA 为物理地址 → NAND 读取数据 → 通过 DMA 写入主机内存。\n\n\n\n3. 关键延迟对比\n\n\n操作\n延迟（纳秒级）\n\n\n\nCPU 访问 L1 Cache\n1 ns\n\n\n访问内存\n100 ns\n\n\nNVMe SSD 读延迟\n100 µs（0.1ms）\n\n\nSATA SSD 读延迟\n500 µs\n\n\n机械硬盘随机读\n10 ms\n\n\n\n🔄 三、全链路协作流程示例：打开文件 /home/user/test.txtsequenceDiagram    participant 用户进程    participant 内核    participant SSD    用户进程-&gt;&gt;内核: open(&quot;/home/user/test.txt&quot;)    内核-&gt;&gt;内核: 1. 从 task_struct 获取当前进程的 fs_struct    内核-&gt;&gt;内核: 2. 通过 dentry 缓存逐级查找路径    alt 目录项在缓存中        内核-&gt;&gt;内核: 直接获取目标 dentry    else 缓存未命中        内核-&gt;&gt;SSD: 读取目录 inode 数据（如 /home/user）        SSD--&gt;&gt;内核: 返回目录项数据        内核-&gt;&gt;内核: 创建 dentry 并加入缓存    end    内核-&gt;&gt;内核: 3. 加载目标文件 inode → 权限检查    内核-&gt;&gt;内核: 4. 创建 file 对象（关联 inode 和操作函数）    内核-&gt;&gt;用户进程: 返回文件描述符（fd）    用户进程-&gt;&gt;内核: read(fd, buf, size)    内核-&gt;&gt;内核: 检查 page cache    alt 数据在缓存        内核-&gt;&gt;用户进程: 直接返回数据    else         内核-&gt;&gt;SSD: 提交 I/O 请求（NVMe 命令）        SSD-&gt;&gt;SSD: FTL 转换 LBA → PBA        SSD-&gt;&gt;内核: DMA 传输数据到 page cache        内核-&gt;&gt;用户进程: 返回数据    end\n\n\n💎 四、性能优化关键点\n最大化缓存命中：\n调整 dcache 和 page cache 大小（通过 /proc/sys/vm/ 参数）。\n\n\n减少 I&#x2F;O 路径深度：\n使用 O_DIRECT 绕过 page cache（需应用自己管理缓存）。\n\n\nSSD 最佳实践：\n4KB 对齐写入（避免”写放大”）。\n启用 TRIM（通知 SSD 释放已删文件空间）。\n\n\n\n\n🔍 深度理解：Linux 文件访问是 软件（进程）→ 内核（VFS&#x2F;Page Cache）→ 硬件（SSD&#x2F;NVMe） 的精密协作，优化需综合考虑各层级特性。\n\n","categories":["操作系统"],"tags":["操作系统"]},{"title":"Java刷题","url":"/2024/06/24/Java%20algo/","content":"Java2024年 Java 面试八股文（20w字）_java八股文2023-CSDN博客\nSQLSQL 50 题（MySQL 版，包括建库建表、插入数据等完整过程，适合复习 SQL 知识点）_sql50题-CSDN博客\nSQL常见语句及用法_sql语句大全及用法-CSDN博客\nSQL中的 聚合函数 ,where ,having_where后面可以跟聚合函数吗-CSDN博客\nSpring面试被问了几百遍的 IOC 和 AOP ，一篇文章带你搞清楚！！！_ioc和aop的原理面试-CSDN博客\nSentinelsentinel （史上最全）-CSDN博客\nGradle&amp;Mavengradle中的build script详解_gradle buildscript-CSDN博客\n[Gradle和Maven的区别-CSDN博客](https://blog.csdn.net/weixin_45626288/article/details/131973787?ops_request_misc=%7B%22request%5Fid%22%3A%22172024305816800185819613%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172024305816800185819613&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-131973787-null-null.142^v100^pc_search_result_base8&amp;utm_term=gradle maven&amp;spm&#x3D;1018.2226.3001.4187)\n线程池和锁面试+基础—–详细解读多线程（线程池、锁、死锁…）_多线程井发、死锁问题、线程池原理等-CSDN博客\nJava 多线程：彻底搞懂线程池_java线程池-CSDN博客\nNetty【硬核】肝了一月的Netty知识点-CSDN博客\n超详细Netty入门，看这篇就够了！_netty框架-CSDN博客\nJUnitJUnit详解-CSDN博客\nPytestPython测试框架之pytest详解_pytest框架详解-CSDN博客\nDockerdocker入门，这一篇就够了。-CSDN博客\n\ndocker run [可选参数] image 命令 #启动容器（无镜像会先下载镜像）#参数说明–name &#x3D; “Name”   容器名字-c   后面跟待完成的命令-d   以后台方式运行并且返回ID，启动守护进程式容器-i   使用交互方式运行容器，通常与t同时使用-t   为容器重新分配一个伪输入终端。也即启动交互式容器-p   指定容器端口    -p 容器端口:物理机端口  映射端口-P   随机指定端口-v   给容器挂载存储卷\n\nJVM[JAVA内存分配原理解析–栈、堆、常量池_堆,栈,常量池详解-CSDN博客](https://blog.csdn.net/gb702250823/article/details/92801716?ops_request_misc=%7B%22request%5Fid%22%3A%22171151029816800225558425%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=171151029816800225558425&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-92801716-null-null.142^v100^pc_search_result_base2&amp;utm_term=java 常量池 栈 堆&amp;spm&#x3D;1018.2226.3001.4187)\njava的垃圾回收(GC)详解_java gc-CSDN博客\nJava - 类加载器_java类加载器-CSDN博客\n常用数据结构和库java刷题前常用的数据结构及方法_java刷题常用方法-CSDN博客\nACM模式import java.util.Scanner;// 注意类名必须为 Main, 不要有任何 package xxx 信息public class Main &#123;    public static void main(String[] args) &#123;        &#125;&#125;\n\n输入输出1、输入整数、字符串数组第一行输入n, m\n第二行输入n个整数\n第三行输入m个字符串\n//导入包import java.util.Scanner;import java.util.Arrays;public class MyScanner &#123;public static void main(String[] args) &#123;\t\t//创建对象\tScanner sc = new Scanner(System.in);\t\t\tSystem.out.println(&quot;输入数据:&quot;);\t\t//多行输入\tint n = sc.nextInt();\tint m = sc.nextInt();\tint[] arr = new int[n];\t\tString[] str = new String[m];\t\t//int等基本数据类型的数组,用nextInt()，同行或不同都可以\tfor(int i=0; i&lt;n; i++) &#123;\t\tarr[i] = sc.nextInt();\t&#125;\t//String字符串数组, 读取用next()，以空格划分\tfor(int i=0; i&lt;m; i++) &#123;\t\tstr[i] = sc.next();\t&#125;\t    //调用方法进行操作\tTestSc(n, m, arr);\tTestStr(str);\t\tSystem.out.println(&quot;Test01 End&quot;);\t\t//关闭\tsc.close();&#125;public static void TestSc(int n, int m, int[] arr) &#123;\tSystem.out.println(&quot;数据n：&quot; + n + &quot;, 数据m：&quot; + m);\tSystem.out.println(Arrays.toString(arr));&#125;public static void TestStr(String[] str) &#123;\tSystem.out.println(Arrays.toString(str));&#125;&#125;\n\n\n若输入的字符串中想要包含空格，使用scanner.nextLine()换行后用scanner.nextLine()进行读入，见情形7.\n2、输入二维数组第一行输入n, m\n第二行开始输入二维数组。\nimport java.util.Arrays;import java.util.Scanner;public class MyScanner2 &#123;public static void main(String[] args) &#123;\t\tScanner sc = new Scanner(System.in);\t\t\tSystem.out.println(&quot;输入数据:&quot;);\t \t//二维数组\tint n = sc.nextInt();\tint m = sc.nextInt();\tint[][] arr2 = new int[n][m];\t\tSystem.out.println(&quot;Test02 输入二维数组数据：&quot;); \t//可以直接读入\tfor(int i=0; i&lt;n; i++) &#123;\t\tfor(int j=0; j&lt;m; j++) &#123;\t\t\tarr2[i][j] = sc.nextInt();\t\t&#125;\t&#125; \tTestSc(n, m, arr2);\t//关闭\tsc.close();&#125;public static void TestSc(int n, int m, int[][] arr) &#123;\tSystem.out.println(&quot;数据n：&quot; + n + &quot;, 数据m：&quot; + m);\tfor(int i=0; i&lt;n; i++) &#123;\t\tSystem.out.println(Arrays.toString(arr[i]));\t&#125;\tSystem.out.println(&quot;数组行数： arr.length= &quot;+ arr.length);\tSystem.out.println(&quot;数组列数： arr[0].length= &quot;+ arr[0].length);&#125;&#125;\n\n\n3、输入字符串输入字符串，用空格隔开。\nnext()和nextLine()区别。\nimport java.util.Scanner;&#x2F;* *next()读取到空白停止，在读取输入后将光标放在同一行中。 *nextLine()读取到回车停止 ，在读取输入后将光标放在下一行。 *&#x2F;\npublic class MyScanner3 &#123;public static void main(String[] args) &#123;\t\tScanner sc = new Scanner(System.in);\t\t\tSystem.out.println(&quot;输入字符串:&quot;);\t\t\t\t//next():只读取输入直到空格。\tString str = sc.next(); \t//nextLine():读取输入，包括单词之间的空格和除回车以外的所有符号\tString str2 = sc.nextLine(); \tSystem.out.println(&quot;str：&quot; + str);\tSystem.out.println(&quot;str2：&quot; + str2);\t\t//关闭\tsc.close();&#125;&#125;\n\n\n4、输入字符串分割为数组先用scanner.nextLine()读入字符串，再将字符串分割为字符数组或字符串数组。\nimport java.util.*;public class MyScanner4 &#123;public static void main(String[] args) &#123;\t\tScanner sc = new Scanner(System.in);\t\tSystem.out.println(&quot;输入字符串数组：&quot;);\t\tString str;\tstr = sc.nextLine();\t\tchar[] ch = new char[str.length()];\tfor(int i=0; i&lt;str.length(); i++) &#123;\t\t//用charAt();进行定位分隔\t\tch[i] = str.charAt(i);\t\tSystem.out.println(ch[i] + &quot; &quot;);\t&#125;\tSystem.out.println(&quot;END&quot;);\t\t//读入字符串后,用空格分隔为数组\tString[] strs = str.split(&quot; &quot;);\tSystem.out.println(Arrays.toString(strs)); &#125;&#125;\n\n5、连续输入数字和字符串区别于情形1，对于不能采用for循环的方式获取String。采用情形5,6用来处理。\n采用while(scanner.hasNext()) 循环，实现连续输入。\n格式：数字，空格，字符串。\n或： 数字，回车，字符串\nimport java.util.Scanner;public class MyScanner5 &#123;public static void main(String[] args) &#123;\t\tScanner sc = new Scanner(System.in);\t\twhile(sc.hasNext()) &#123;\t\t\t\t\t\t\tint n = sc.nextInt();\t\tString str = sc.next();\t\tTes(n, str);\t&#125;\t\t\tsc.close();&#125;public static void Tes(int n, String str) &#123;\tSystem.out.println(&quot;n = &quot; + n);\tSystem.out.println(&quot;str = &quot; + str);\t\tSystem.out.println(&quot;str.length = &quot; + str.length());&#125;&#125;\n\n\n6、换行输入数字和字符串也采用scanner.nextLine()，将光标移到下一行。再继续读入字符串。\n第一行输入整数n，m，第二行开始输入字符串。或\n第一行输入整数n，第二行输入m，第三行开始输入字符串。\nimport java.util.*;public class MyScanner6 &#123;public static void main(String[] args) &#123;\tScanner sc = new Scanner(System.in);\tint n = sc.nextInt();\tint m = sc.nextInt();\t\t//注意！！！光标换到下一行\tsc.nextLine();\t\tString s = sc.nextLine();\tString str = sc.nextLine();\t\tSystem.out.println(&quot;n = &quot; + n + &quot; , m = &quot; + m);\tSystem.out.println(&quot;s = &quot; + s);\tSystem.out.println(&quot;str = &quot; + str);\t\t\t\tsc.close();&#125;&#125;\n\n\n7、换行输入数字和字符串(需要包含空格)采用scanner.nextLine()，将光标移到下一行。再继续读入字符串。\n第一行输入n，\n第二行开始输入n行字符串，字符串中包含空格。\nimport java.util.Scanner;public class MyScanner7 &#123;public static void main(String[] args) &#123;\t\tScanner sc = new Scanner(System.in);\t\tint n = sc.nextInt();\tString[] strs = new String[n]; \t\tsc.nextLine();\t\tfor(int i=0; i&lt;n; i++) &#123;\t\tString str = sc.nextLine();\t\tstrs[i] = str;\t\t\t\t&#125;\t\tTes2(strs);\tSystem.out.println(&quot;End&quot;);\t\t\tsc.close();&#125;public static void Tes2(String[] strs) &#123;\tfor(int i=0; i&lt;strs.length; i++) &#123;\t\tString str = strs[i];\t\tSystem.out.println(str);\t&#125;&#125;&#125;\n\nint 转Integerint num=1;Integer i = Integer.valueOf(num);\n\nInteger转intint num = integer.intValue();\n\nint到String数据类型的转换int num;Integer.toString(num);\n\n或者String.valueOf(num);\npublic class HelloWorld &#123;  public static void main(String[] args) &#123;   // 引号带上数据    int num=100;    String a=&quot;&quot;+num;    System.out.println(a);   // 直接类型转换    Integer num2=100;    String b=Integer.toString(num2);    System.out.println(b);            // 字符串定义    String c=String.valueOf(num2);    System.out.println(c);&#125;&#125;\n\n\nString到int类型的转换String s = &quot;100&quot;int d = Integer.parseInt(s);    // parseInt    // 加上static的方法，方法属于类，需要使用类名进行调用，没有加上static的，方法属于对象，可以new一个对象再调用    int e=Integer.parseInt(s);    System.out.println(e);\n\nArrayList动态转换为Array数组String [] array=list.toArray(new String[size]);\n\n除此之外，ArrayList还有以下的常用的方法：\nvoid add(int index, E element) 将指定元素插入此列表中的指定位置。boolean add(E e)将指定的元素追加到此列表的末尾。boolean contains(Object o)如果此列表包含指定的元素，则返回 true 。E get(int index) 返回此列表中指定位置的元素。int indexOf(Object o) 返回此列表中第一次出现的指定元素的索引，如果此列表不包含该元素，则返回-1。boolean isEmpty() 如果此列表不包含任何元素，则返回 true 。int lastIndexOf(Object o)返回此列表中指定元素最后一次出现的索引，如果此列表不包含该元素，则返回-1。E remove(int index) 删除此列表中指定位置的元素。boolean remove(Object o)从该列表中删除指定元素的第一个匹配项（如果存在）E set(int index, E element) 用指定的元素替换此列表中指定位置的元素。int size() 返回此列表中的元素数。\n\nArray数组转为ArrayListList&lt;String&gt;list= Arrays.asList(array)\n\nArrays的常用方法//创建数组int nums[]=new int[100];//获取长度nums.length;Arrays.toString(nums)Arrays.sort(nums)//升序Arrays.fill(nums)//初始化数组的时候会用到（比如全部给-1）Arrays.equal(nums)Arrays.copyof(nums)Arrays.compare(nums)Arrays.binarySearch(nums)\n\nArrays.sort()重写Comparator:\n//合并区间的例子Arrays.sort(nums,new Comparator&lt;int []&gt;()&#123;    public int compare(int[]nums1, int[]nums2)&#123;        return nums1[0]-nums2[0];    &#125;&#125;);\n\n\n\nArrayList的常用用法Array：只可存储基本数据类型和对象。被设置为固定大小。所包含的方法没有ArrayList多ArrayList：只能存储对象。是一个可变数组，大小可自动调整。有很多操作方法：addAll、removeAll、iteration等。\n//添加元素ArrayList list = new ArrayList();list.add(&quot;迪丽热巴&quot;);ArrayList&lt;String&gt; sites = new ArrayList&lt;String&gt;();        sites.add(&quot;Google&quot;);        sites.add(&quot;Runoob&quot;);        sites.add(&quot;Taobao&quot;);        sites.add(&quot;Weibo&quot;);        sites.remove(3); // 删除第四个元素//计算大小sites.size();//排序Collections.sort(sites);//是否包含sites.contains();//addAll()这个方法括号中类型是list，拼接    void add(int index, E element) 将指定元素插入此列表中的指定位置。boolean add(E e)将指定的元素追加到此列表的末尾。boolean contains(Object o)如果此列表包含指定的元素，则返回 true 。E get(int index) 返回此列表中指定位置的元素。int indexOf(Object o) 返回此列表中第一次出现的指定元素的索引，如果此列表不包含该元素，则返回-1。boolean isEmpty() 如果此列表不包含任何元素，则返回 true 。int lastIndexOf(Object o)返回此列表中指定元素最后一次出现的索引，如果此列表不包含该元素，则返回-1。E remove(int index) 删除此列表中指定位置的元素。boolean remove(Object o)从该列表中删除指定元素的第一个匹配项（如果存在）E set(int index, E element) 用指定的元素替换此列表中指定位置的元素。int size() 返回此列表中的元素数。\n\n\n\nCollections类对list进行反转\nCollections.reverse(list)Collections.sort(numbers); //List列表按照升序排列Collections.binarySearch(numbers, 3); //numbers是List且按升序排列Collections.swap(numbers, 2,4); //交换numbers的list的Index为2、4的数字\n\nString类String获取长度是.length()（要加括号）\nString、StringBuilder类超详细笔记_stringbuilder可以用equalsignorecase-CSDN博客\n重要：char charAt​(int index) 返回指定索引处的 char值。int indexOf​(String ch) 返回指定字符第一次出现的字符串中的索引。    String s = String.valueOf(&#x27;c&#x27;); //效率最高的方法- boolean isEmpty() ，当且仅当， length()是 0 返回 trueint lastIndexOf​(int ch) 返回指定字符最后一次出现的字符串中的索引。int length() 返回此字符串的长度。    String trim() 去除两端的空格String replace​(CharSequence target, CharSequence replacement) 将此字符串中与文字目标序列匹配的每个子字符串替换为指定的文字替换序列。String replaceAll​(String regex, String replacement) 将给定替换的给定 regular expression匹配的此字符串的每个子字符串替换。String[] split​(String regex) //将此字符串拆分为给定 regular expression的匹配 项 。（如果有多个空格，则会在Arrays中有空的&quot;&quot;出现）boolean startsWith​(String prefix) 测试此字符串是否以指定的前缀开头。String substring​(int beginIndex) 返回一个字符串，该字符串是此字符串的子字符串。char[] toCharArray() 将此字符串转换为新的字符数组。String toLowerCase() 使用默认语言环境的规则将此 String所有字符转换为小写。String toUpperCase() 使用默认语言环境的规则将此 String所有字符转换为大写。比较大小的话    String c= &quot;123&quot;;\tString b = &quot;123&quot;;\tc.compareTo(b);或者    c.equals(b);\n\n字符类Chracter//char转CharacterCharacter.valueOf(&#x27;I&#x27;);Character.compare(char x, char y) 以数字方式比较两个 char值。Character.equals(Object obj) 将此对象与指定的对象进行比较。Character.isDigit(char ch) 确定指定的字符是否为数字。Character.isLetter(char ch) 确定指定的字符是否为字母。Character.isLowerCase(char ch) 确定指定的字符是否为小写字符。Character.isUpperCase(char ch) 确定指定的字符是否为大写字符。Character.toString(char c) 返回表示指定的 char的 String对象。Character.valueOf(char c) 返回表示指定的 char值的 Character实例。Character.toLowerCase(&quot;A&quot;); 转为小写Character.toUpperCase(&quot;a&quot;); 转为大写//char数组转Stringchar[] data = new char[] &#123;&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;&#125;;String str = new String(data);System.out.println(str);  //输出abc\n\n字符串构造器StringBuilderJava-修改 String 指定位置的字符最全方法总结（StringBuilder 和 StringBuffer 的使用以及区别）_string替换指定位置字符-CSDN博客\nString、StringBuffer与StringBuilder之间区别_string stringbuffer stringbuilder区别-CSDN博客\n可变字符串，StringBuilder对象的内容可以修改。\n\nStringBuilder类的常用方法\n\nappend()方法使用append()方法可实现字符串的拼接操作，返回拼接后的StringBuilder对象。\n\nreverse()方法使用reverse()方法可实现StringBuilder字符串的反转操作。\n\ndelete(int start, int end)方法删除字符串中指定索引范围为 [start,end) 的所有内容。\nJava中大多数范围均为左闭右开区间。\nStringBuilder sb = new StringBuilder(&quot;hello&quot;);sb.append(&quot;world&quot;);sb.delete(5,8);  //删除索引范围为[5,8)内的所有内容，即从w开始删除到l之前System.out.println(sb);  //输出hellold\n\ninsert(int start, 任意数据类型)方法在索引start处开始插入任意数据类型的内容。插入内容的起始索引是start。\nStringBuilder sb1 = new StringBuilder(&quot;hello&quot;);sb1.insert(2,77);System.out.println(sb1);  //输出he77llosb1.insert(3,&quot;ooo&quot;);System.out.println(sb1);  //输出he7ooo7llo\n\nsetCharAt(index,character)\nsb.setCharAt(j,Character.toUpperCase(sb.charAt(j)));\n\n\nStringBuilder与String的相互转换 1）String转为StringBuilder ① 构造方法StringBuilder(String str)\n\n\nStringBuilder sb = new StringBuilder(&quot;hello&quot;); \n\n② 字符串拼接方法append(String str)\nStringBuilder sb = new StringBuilder();sb.append(&quot;123&quot;);\n\n\n2）StringBuilder转为String通过StringBuilder对象调用toString()方法\nString str = sb.toString();String、StringBuilder、StringBuffer的区别String为不可变字符串类，StringBuilder、StringBuffer为可变字符串类。StringBuilder类性能较高，但存在线程安全问题; StringBuffer类线程安全，但性能较差。\n\n双链表LinkedListboolean isEmpty()int size()boolean contains(Object o) // 判断链表中是否存在元素o 复杂度O(N)void addFirst(E e)E removeFirst() //删除，返回的是删除的元素E getFirst/Last()int indexOf( E e)Collections.reverse(link); // 翻转链表\n\n哈希表Hashmapboolean containsKey(Object key)如果这个映射包含指定键映射，则返回trueboolean containsValue(Object value) 如果此映射将一个或多个键映射到指定值，则返回 true 。V get(Object key) 返回指定键映射到的值，如果此映射不包含键的映射，则返回 null 。V put(K key, V value) 将指定的值与此映射中的指定键相关联。V remove(Object key) 从此映射中删除指定键的映射（如果存在）。int size() 返回此映射中键 - 值映射的数量。Collection&lt;V&gt; values() 返回此映射中包含的值的Collection视图。Set&lt;K&gt; keySet() 返回此映射中包含的键的Set视图。default V getOrDefault(Object key, V defaultValue) 返回指定键映射到的值，如果此映射不包含键的映射，则返回 defaultValue 。这个方法继承自Map接口default V putIfAbsent(K key, V value) 如果key存在则什么都不做，否则put()，并且返回当前值Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() 返回此映射中包含的映射的Set视图。    /* 初始化哈希表 */Map&lt;Integer, String&gt; map = new HashMap&lt;&gt;();/* 添加操作 */// 在哈希表中添加键值对 (key, value)map.put(12836, &quot;小哈&quot;);   map.put(15937, &quot;小啰&quot;);   map.put(16750, &quot;小算&quot;);   map.put(13276, &quot;小法&quot;);map.put(10583, &quot;小鸭&quot;);/* 查询操作 */// 向哈希表中输入键 key ，得到值 valueString name = map.get(15937);/* 删除操作 */// 在哈希表中删除键值对 (key, value)map.remove(10583);/* 遍历哈希表 */// 遍历键值对 key-&gt;valuefor (Map.Entry &lt;Integer, String&gt; kv: map.entrySet()) &#123;    System.out.println(kv.getKey() + &quot; -&gt; &quot; + kv.getValue());&#125;// 单独遍历键 keyfor (int key: map.keySet()) &#123;    System.out.println(key);&#125;// 单独遍历值 valuefor (String val: map.values()) &#123;    System.out.println(val);&#125;\n\n哈希集合HashSet[【Java 基础篇】Java Set 详解-CSDN博客](https://blog.csdn.net/qq_21484461/article/details/131383848?ops_request_misc=%7B%22request%5Fid%22%3A%22171015290416800180682690%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=171015290416800180682690&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-131383848-null-null.142^v99^pc_search_result_base2&amp;utm_term=Java set&amp;spm&#x3D;1018.2226.3001.4187)\n不能保证集合迭代的顺序\nboolean add(E e) 如果指定的元素尚不存在，则将其添加到此集合中。boolean remove(Object o) 如果存在，则从该集合中移除指定的元素。boolean contains(Object o) 如果此set包含指定的元素，则返回 true 。\n\n栈 Stack栈，后进先出\n/* 初始化栈 */Stack&lt;Integer&gt; stack = new Stack&lt;&gt;();/* 元素入栈 */stack.push(1);stack.push(3);stack.push(2);stack.push(5);stack.push(4);/* 访问栈顶元素 */int peek = stack.peek();/* 元素出栈 */int pop = stack.pop();/* 获取栈的长度 */int size = stack.size();/* 判断是否为空 */boolean isEmpty = stack.isEmpty();\n\n队列Queue、双端队列Deque（都可用LinkedList来实例化，因为二者都是接口）队列，先进先出，Queue和Deque都是接口，而LinkedList类继承了这两个队列，可以是用LinkedList来实例化Queue或者Deque，可以作为单向队列或者双向队列来使用。\nQueue q = new LinkedList&lt;&gt;();void add(int index, E element) 将指定元素插入此列表中的指定位置。E element() 检索但不删除此列表的头部（第一个元素）。E get(int index) 返回此列表中指定位置的元素。int indexOf(Object o) 返回此列表中第一次出现的指定元素的索引，如果此列表不包含该元素，则返回-1。int lastIndexOf(Object o) 返回此列表中指定元素最后一次出现的索引，如果此列表不包含该元素，则返回-1。boolean offer(E e) 将指定的元素添加为此列表的尾部（最后一个元素）。E peek() 检索但不删除此列表的头部（第一个元素）E poll() 检索并删除此列表的头部（第一个元素）。E set(int index, E element) 用指定的元素替换此列表中指定位置的元素。/* 翻转队列 */Collections.reverse(queue) /* 获取队列的长度 */int size = queue.size();/* 判断队列是否为空 */boolean isEmpty = queue.isEmpty();\n\n双端队列\n/* 初始化双向队列 */Deque&lt;Integer&gt; deque = new LinkedList&lt;&gt;();/* 元素入队 */deque.offerLast(2);   // 添加至队尾deque.offerLast(5);deque.offerLast(4);deque.offerFirst(3);  // 添加至队首deque.offerFirst(1);/* 访问元素 */int peekFirst = deque.peekFirst();  // 队首元素int peekLast = deque.peekLast();    // 队尾元素/* 元素出队 */int popFirst = deque.pollFirst();  // 队首元素出队int popLast = deque.pollLast();    // 队尾元素出队/* 获取双向队列的长度 */int size = deque.size();/* 判断双向队列是否为空 */boolean isEmpty = deque.isEmpty();\n\n…\nLinkedList可以作为堆栈使用，并且在类中实现了对应的方法E pop() 弹出此列表所代表的堆栈中的元素。void push(E e) 将元素推送到此列表所表示的堆栈上。\n\n优先队列(作为堆来用)默认小顶堆，但如果是数据结构就还是要重写comparator\nimport java.util.PriorityQueue;PriorityQueue&lt;Integer&gt; minHeap = new PriorityQueue&lt;&gt;();//读minHeap.peek();minHeap.poll();(会弹出)//添加minHeap.add();minHeap.offer();//优先队列自然排序示例Queue&lt;Integer&gt; integerPriorityQueue = new PriorityQueue&lt;&gt;(7);//容量为7//优先队列使用示例Queue&lt;Customer&gt; customerPriorityQueue = new PriorityQueue&lt;&gt;(idComparator);//匿名Comparator实现public static Comparator&lt;Customer&gt; idComparator = new Comparator&lt;Customer&gt;()&#123;    public int compare(Customer c1, Customer c2) &#123;        return (int) (c1.getId() - c2.getId());//这是小顶堆，反着写就是大顶堆        &#125;    &#125;;//或者实现Comparator接口也行class idComparator implements Comparator&#123;    @Override    public int compare(Customer c1, Customer c2)&#123;        return (int)(c1.getId()-c2.getId)());    &#125;&#125;\n\n/* 初始化堆 */// 初始化小顶堆Queue&lt;Integer&gt; minHeap = new PriorityQueue&lt;&gt;();// 初始化大顶堆（使用 lambda 表达式修改 Comparator 即可）Queue&lt;Integer&gt; maxHeap = new PriorityQueue&lt;&gt;((a, b) -&gt; b - a);/* 元素入堆 */maxHeap.offer(1);maxHeap.offer(3);maxHeap.offer(2);maxHeap.offer(5);maxHeap.offer(4);/* 获取堆顶元素 */int peek = maxHeap.peek(); // 5/* 堆顶元素出堆 */// 出堆元素会形成一个从大到小的序列peek = maxHeap.poll(); // 5peek = maxHeap.poll(); // 4peek = maxHeap.poll(); // 3peek = maxHeap.poll(); // 2peek = maxHeap.poll(); // 1/* 获取堆大小 */int size = maxHeap.size();/* 判断堆是否为空 */boolean isEmpty = maxHeap.isEmpty();/* 输入列表并建堆 */minHeap = new PriorityQueue&lt;&gt;(Arrays.asList(1, 3, 2, 5, 4));\n\n数学库Math.ceil(3.3); //向上取整Math.floor(3.3); //向下取整Math.round(3.4); //四舍五入Math.pow(3,2) //幂运算Math.abs(-1); //绝对值 Math.max(9999,10000);Math.min(9999,10000);Math.ramdom(); //返回0-1的随机数，左闭右开Math.sqrt(3.644); //开方\n\n算法排序import java.util.Arrays;public class MergeSort&#123;    public static void mergeSort(int[]arr, int l, int r)&#123;        if (l&gt;=r)return ;        int mid = l+(r-l)/2;        mergeSort(arr,l,mid);        mergeSort(arr,mid+1,r);        merge(arr,l,mid,r);    &#125;    public static void merge(int[] arr, int l ,int mid,int r)&#123;        int temp[] = new int[r-l+1];        int left = l;        int right = mid+1;        int start = 0;        while(left&lt;=mid&amp;&amp; right&lt;=r)&#123;            if (arr[left]&lt;arr[right])&#123;                temp[start++] = arr[left++];            &#125;else&#123;                temp[start++] = arr[right++];            &#125;        &#125;        while(left&lt;=mid)&#123;            temp[start++] = arr[left++];        &#125;        while(right&lt;=r)&#123;            temp[start++] = arr[right++];        &#125;        for(int i=0;i&lt;temp.length;i++)&#123;                arr[l+i] = temp[i];        &#125;     &#125;     public static void main(String[] args)&#123;        int nums[] = new int[]&#123;            1,4,2,6,9,3,5,8,7        &#125;;        mergeSort(nums,0,nums.length-1);        System        .out.println(Arrays.toString(nums));     &#125;&#125;\n\n图邻接矩阵\n/* 基于邻接矩阵实现的无向图类 */class GraphAdjMat &#123;    List&lt;Integer&gt; vertices; // 顶点列表，元素代表“顶点值”，索引代表“顶点索引”    List&lt;List&lt;Integer&gt;&gt; adjMat; // 邻接矩阵，行列索引对应“顶点索引”    /* 构造方法 */    public GraphAdjMat(int[] vertices, int[][] edges) &#123;        this.vertices = new ArrayList&lt;&gt;();        this.adjMat = new ArrayList&lt;&gt;();        // 添加顶点        for (int val : vertices) &#123;            addVertex(val);        &#125;        // 添加边        // 请注意，edges 元素代表顶点索引，即对应 vertices 元素索引        for (int[] e : edges) &#123;            addEdge(e[0], e[1]);        &#125;    &#125;    /* 获取顶点数量 */    public int size() &#123;        return vertices.size();    &#125;    /* 添加顶点 */    public void addVertex(int val) &#123;        int n = size();        // 向顶点列表中添加新顶点的值        vertices.add(val);        // 在邻接矩阵中添加一行        List&lt;Integer&gt; newRow = new ArrayList&lt;&gt;(n);        for (int j = 0; j &lt; n; j++) &#123;            newRow.add(0);        &#125;        adjMat.add(newRow);        // 在邻接矩阵中添加一列        for (List&lt;Integer&gt; row : adjMat) &#123;            row.add(0);        &#125;    &#125;    /* 删除顶点 */    public void removeVertex(int index) &#123;        if (index &gt;= size())            throw new IndexOutOfBoundsException();        // 在顶点列表中移除索引 index 的顶点        vertices.remove(index);        // 在邻接矩阵中删除索引 index 的行        adjMat.remove(index);        // 在邻接矩阵中删除索引 index 的列        for (List&lt;Integer&gt; row : adjMat) &#123;            row.remove(index);        &#125;    &#125;    /* 添加边 */    // 参数 i, j 对应 vertices 元素索引    public void addEdge(int i, int j) &#123;        // 索引越界与相等处理        if (i &lt; 0 || j &lt; 0 || i &gt;= size() || j &gt;= size() || i == j)            throw new IndexOutOfBoundsException();        // 在无向图中，邻接矩阵关于主对角线对称，即满足 (i, j) == (j, i)        adjMat.get(i).set(j, 1);        adjMat.get(j).set(i, 1);    &#125;    /* 删除边 */    // 参数 i, j 对应 vertices 元素索引    public void removeEdge(int i, int j) &#123;        // 索引越界与相等处理        if (i &lt; 0 || j &lt; 0 || i &gt;= size() || j &gt;= size() || i == j)            throw new IndexOutOfBoundsException();        adjMat.get(i).set(j, 0);        adjMat.get(j).set(i, 0);    &#125;    /* 打印邻接矩阵 */    public void print() &#123;        System.out.print(&quot;顶点列表 = &quot;);        System.out.println(vertices);        System.out.println(&quot;邻接矩阵 =&quot;);        PrintUtil.printMatrix(adjMat);    &#125;&#125;\n\n邻接表的BFS\n/* 广度优先遍历 */// 使用邻接表来表示图，以便获取指定顶点的所有邻接顶点List&lt;Vertex&gt; graphBFS(GraphAdjList graph, Vertex startVet) &#123;    // 顶点遍历序列    List&lt;Vertex&gt; res = new ArrayList&lt;&gt;();    // 哈希表，用于记录已被访问过的顶点    Set&lt;Vertex&gt; visited = new HashSet&lt;&gt;();    visited.add(startVet);    // 队列用于实现 BFS    Queue&lt;Vertex&gt; que = new LinkedList&lt;&gt;();    que.offer(startVet);    // 以顶点 vet 为起点，循环直至访问完所有顶点    while (!que.isEmpty()) &#123;        Vertex vet = que.poll(); // 队首顶点出队        res.add(vet);            // 记录访问顶点        // 遍历该顶点的所有邻接顶点        for (Vertex adjVet : graph.adjList.get(vet)) &#123;            if (visited.contains(adjVet))                continue;        // 跳过已被访问的顶点            que.offer(adjVet);   // 只入队未访问的顶点            visited.add(adjVet); // 标记该顶点已被访问        &#125;    &#125;    // 返回顶点遍历序列    return res;&#125;\n\n邻接表的DFS\n/* 深度优先遍历辅助函数 */void dfs(GraphAdjList graph, Set&lt;Vertex&gt; visited, List&lt;Vertex&gt; res, Vertex vet) &#123;    res.add(vet);     // 记录访问顶点    visited.add(vet); // 标记该顶点已被访问    // 遍历该顶点的所有邻接顶点    for (Vertex adjVet : graph.adjList.get(vet)) &#123;        if (visited.contains(adjVet))            continue; // 跳过已被访问的顶点        // 递归访问邻接顶点        dfs(graph, visited, res, adjVet);    &#125;&#125;/* 深度优先遍历 */// 使用邻接表来表示图，以便获取指定顶点的所有邻接顶点List&lt;Vertex&gt; graphDFS(GraphAdjList graph, Vertex startVet) &#123;    // 顶点遍历序列    List&lt;Vertex&gt; res = new ArrayList&lt;&gt;();    // 哈希表，用于记录已被访问过的顶点    Set&lt;Vertex&gt; visited = new HashSet&lt;&gt;();    dfs(graph, visited, res, startVet);    return res;&#125;\n\nFloydpublic class MatrixUDG &#123;    private int mEdgNum;        // 边的数量    private char[] mVexs;       // 顶点集合    private int[][] mMatrix;    // 邻接矩阵    private static final int INF = Integer.MAX_VALUE;   // 最大值    ...&#125;/* * floyd最短路径。 * 即，统计图中各个顶点间的最短路径。 * * 参数说明： *     path -- 路径。path[i][j]=k表示，&quot;顶点i&quot;到&quot;顶点j&quot;的最短路径会经过顶点k。 *     dist -- 长度数组。即，dist[i][j]=sum表示，&quot;顶点i&quot;到&quot;顶点j&quot;的最短路径的长度是sum。 */public void floyd(int[][] path, int[][] dist) &#123;    // 初始化    for (int i = 0; i &lt; mVexs.length; i++) &#123;        for (int j = 0; j &lt; mVexs.length; j++) &#123;            dist[i][j] = mMatrix[i][j];    // &quot;顶点i&quot;到&quot;顶点j&quot;的路径长度为&quot;i到j的权值&quot;。            path[i][j] = j;                // &quot;顶点i&quot;到&quot;顶点j&quot;的最短路径是经过顶点j。        &#125;    &#125;    // 计算最短路径    for (int k = 0; k &lt; mVexs.length; k++) &#123;        for (int i = 0; i &lt; mVexs.length; i++) &#123;            for (int j = 0; j &lt; mVexs.length; j++) &#123;                // 如果经过下标为k顶点路径比原两点间路径更短，则更新dist[i][j]和path[i][j]                int tmp = (dist[i][k]==INF || dist[k][j]==INF) ? INF : (dist[i][k] + dist[k][j]);                if (dist[i][j] &gt; tmp) &#123;                    // &quot;i到j最短路径&quot;对应的值设，为更小的一个(即经过k)                    dist[i][j] = tmp;                    // &quot;i到j最短路径&quot;对应的路径，经过k                    path[i][j] = path[i][k];                &#125;            &#125;        &#125;    &#125;    // 打印floyd最短路径的结果    System.out.printf(&quot;floyd: \\n&quot;);    for (int i = 0; i &lt; mVexs.length; i++) &#123;        for (int j = 0; j &lt; mVexs.length; j++)            System.out.printf(&quot;%2d  &quot;, dist[i][j]);        System.out.printf(&quot;\\n&quot;);    &#125;&#125;\n\n迪杰斯特拉public class MatrixUDG &#123;     private int mEdgNum;        // 边的数量    private char[] mVexs;       // 顶点集合    private int[][] mMatrix;    // 邻接矩阵    private static final int INF = Integer.MAX_VALUE;   // 最大值     ...&#125;/* * Dijkstra最短路径。 * 即，统计图中&quot;顶点vs&quot;到其它各个顶点的最短路径。 * * 参数说明： *       vs -- 起始顶点(start vertex)。即计算&quot;顶点vs&quot;到其它顶点的最短路径。 *     prev -- 前驱顶点数组。即，prev[i]的值是&quot;顶点vs&quot;到&quot;顶点i&quot;的最短路径所经历的全部顶点中，位于&quot;顶点i&quot;之前的那个顶点。 *     dist -- 长度数组。即，dist[i]是&quot;顶点vs&quot;到&quot;顶点i&quot;的最短路径的长度。 */public void dijkstra(int vs, int[] prev, int[] dist) &#123;    // flag[i]=true表示&quot;顶点vs&quot;到&quot;顶点i&quot;的最短路径已成功获取    boolean[] flag = new boolean[mVexs.length];     // 初始化    for (int i = 0; i &lt; mVexs.length; i++) &#123;        flag[i] = false;          // 顶点i的最短路径还没获取到。        prev[i] = 0;              // 顶点i的前驱顶点为0。        dist[i] = mMatrix[vs][i];  // 顶点i的最短路径为&quot;顶点vs&quot;到&quot;顶点i&quot;的权。    &#125;     // 对&quot;顶点vs&quot;自身进行初始化    flag[vs] = true;    dist[vs] = 0;     // 遍历mVexs.length-1次；每次找出一个顶点的最短路径。    int k=0;    for (int i = 1; i &lt; mVexs.length; i++) &#123;        // 寻找当前最小的路径；        // 即，在未获取最短路径的顶点中，找到离vs最近的顶点(k)。        int min = INF;        for (int j = 0; j &lt; mVexs.length; j++) &#123;            if (flag[j]==false &amp;&amp; dist[j]&lt;min) &#123;                min = dist[j];                k = j;            &#125;        &#125;        // 标记&quot;顶点k&quot;为已经获取到最短路径        flag[k] = true;         // 修正当前最短路径和前驱顶点        // 即，当已经&quot;顶点k的最短路径&quot;之后，更新&quot;未获取最短路径的顶点的最短路径和前驱顶点&quot;。        for (int j = 0; j &lt; mVexs.length; j++) &#123;            int tmp = (mMatrix[k][j]==INF ? INF : (min + mMatrix[k][j]));            if (flag[j]==false &amp;&amp; (tmp&lt;dist[j]) ) &#123;                dist[j] = tmp;                prev[j] = k;            &#125;        &#125;    &#125;     // 打印dijkstra最短路径的结果    System.out.printf(&quot;dijkstra(%c): \\n&quot;, mVexs[vs]);    for (int i=0; i &lt; mVexs.length; i++)        System.out.printf(&quot;  shortest(%c, %c)=%d\\n&quot;, mVexs[vs], mVexs[i], dist[i]);&#125;\n\nLeetcode 133.克隆图/*// Definition for a Node.class Node &#123;    public int val;    public List&lt;Node&gt; neighbors;    public Node() &#123;        val = 0;        neighbors = new ArrayList&lt;Node&gt;();    &#125;    public Node(int _val) &#123;        val = _val;        neighbors = new ArrayList&lt;Node&gt;();    &#125;    public Node(int _val, ArrayList&lt;Node&gt; _neighbors) &#123;        val = _val;        neighbors = _neighbors;    &#125;&#125;*/class Solution &#123;    Map&lt;Node,Node&gt;visitedMap=new HashMap();    public Node cloneGraph(Node node) &#123;        if (node==null)return null;        if (!visitedMap.containsKey(node))&#123;            int val = node.val;            Node temp = new Node(val,new ArrayList());            visitedMap.put(node,temp);        &#125;else&#123;            return visitedMap.get(node);        &#125;        Node ans = visitedMap.get(node);        for (Node node1:node.neighbors)&#123;            ans.neighbors.add(cloneGraph(node1));        &#125;        return ans;    &#125;&#125;\n\nLeetcode 399.除法求值(并查集，一遍查询一边修改)import java.util.HashMap;import java.util.List;import java.util.Map;public class Solution &#123;    public double[] calcEquation(List&lt;List&lt;String&gt;&gt; equations, double[] values, List&lt;List&lt;String&gt;&gt; queries) &#123;        int equationsSize = equations.size();        UnionFind unionFind = new UnionFind(2 * equationsSize);        // 第 1 步：预处理，将变量的值与 id 进行映射，使得并查集的底层使用数组实现，方便编码        Map&lt;String, Integer&gt; hashMap = new HashMap&lt;&gt;(2 * equationsSize);        int id = 0;        for (int i = 0; i &lt; equationsSize; i++) &#123;            List&lt;String&gt; equation = equations.get(i);            String var1 = equation.get(0);            String var2 = equation.get(1);            if (!hashMap.containsKey(var1)) &#123;                hashMap.put(var1, id);                id++;            &#125;            if (!hashMap.containsKey(var2)) &#123;                hashMap.put(var2, id);                id++;            &#125;            unionFind.union(hashMap.get(var1), hashMap.get(var2), values[i]);        &#125;        // 第 2 步：做查询        int queriesSize = queries.size();        double[] res = new double[queriesSize];        for (int i = 0; i &lt; queriesSize; i++) &#123;            String var1 = queries.get(i).get(0);            String var2 = queries.get(i).get(1);            Integer id1 = hashMap.get(var1);            Integer id2 = hashMap.get(var2);            if (id1 == null || id2 == null) &#123;                res[i] = -1.0d;            &#125; else &#123;                res[i] = unionFind.isConnected(id1, id2);            &#125;        &#125;        return res;    &#125;    private class UnionFind &#123;        private int[] parent;        /**         * 指向的父结点的权值         */        private double[] weight;        public UnionFind(int n) &#123;            this.parent = new int[n];            this.weight = new double[n];            for (int i = 0; i &lt; n; i++) &#123;                parent[i] = i;                weight[i] = 1.0d;            &#125;        &#125;        public void union(int x, int y, double value) &#123;            int rootX = find(x);            int rootY = find(y);            if (rootX == rootY) &#123;                return;            &#125;            parent[rootX] = rootY;          \t// 关系式的推导请见「参考代码」下方的示意图            weight[rootX] = weight[y] * value / weight[x];        &#125;        /**         * 路径压缩         *         * @param x         * @return 根结点的 id         */        public int find(int x) &#123;            if (x != parent[x]) &#123;                int origin = parent[x];                parent[x] = find(parent[x]);                weight[x] *= weight[origin];            &#125;            return parent[x];        &#125;        public double isConnected(int x, int y) &#123;            int rootX = find(x);            int rootY = find(y);            if (rootX == rootY) &#123;                return weight[x] / weight[y];            &#125; else &#123;                return -1.0d;            &#125;        &#125;    &#125;&#125;\n\nLeetcode 207.课程表class Solution &#123;    public boolean canFinish(int numCourses, int[][] prerequisites) &#123;        int numOfRelations = prerequisites.length;        int inDegree[] = new int[numCourses];        Map&lt;Integer,List&lt;Integer&gt;&gt;map = new HashMap();        for (int i=0;i&lt;numOfRelations;i++)&#123;            int pre = prerequisites[i][0];            int after = prerequisites[i][1];            inDegree[after]++;            List&lt;Integer&gt;list = map.getOrDefault(pre,new ArrayList&lt;Integer&gt;());            list.add(after);            map.put(pre,list);        &#125;        Queue&lt;Integer&gt;q = new LinkedList();        for (int i=0;i&lt;numCourses;i++)&#123;            if (inDegree[i]==0)q.add(i);        &#125;        while(!q.isEmpty())&#123;            int pre = q.poll();            List&lt;Integer&gt;after = map.get(pre);            if (after!=null)            for (int num:after)&#123;                inDegree[num]--;                if (inDegree[num]==0)q.add(num);            &#125;        &#125;        for (int i=0;i&lt;numCourses;i++)&#123;            if (inDegree[i]!=0)return false;        &#125;        return true;    &#125;&#125;\n\nLeetcode 210.课程表2class Solution &#123;    public int[] findOrder(int numCourses, int[][] prerequisites) &#123;        int numOfRelations = prerequisites.length;        int inDegree[] = new int[numCourses];        Map&lt;Integer,List&lt;Integer&gt;&gt;map = new HashMap();        for (int i=0;i&lt;numOfRelations;i++)&#123;            int after = prerequisites[i][0];            int pre = prerequisites[i][1];            inDegree[after]++;            List&lt;Integer&gt;list = map.getOrDefault(pre,new ArrayList&lt;Integer&gt;());            list.add(after);            map.put(pre,list);        &#125;        Queue&lt;Integer&gt;q = new LinkedList();        for (int i=0;i&lt;numCourses;i++)&#123;            if (inDegree[i]==0)q.add(i);        &#125;        int ans[]=new int[numCourses];        int start = 0;        while(!q.isEmpty())&#123;            int pre = q.poll();            ans[start] = pre;            start++;            List&lt;Integer&gt;after = map.get(pre);            if (after!=null)&#123;                    for (int num:after)&#123;                inDegree[num]--;                if (inDegree[num]==0)q.add(num);                &#125;            &#125;                    &#125;        for (int i=0;i&lt;numCourses;i++)&#123;            if (inDegree[i]!=0)return new int[]&#123;&#125;;        &#125;        return ans;    &#125;    &#125;\n\nLeetcode 909.蛇梯棋class Solution &#123;    public int snakesAndLadders(int[][] board) &#123;        // edge condition        if(board == null || board.length == 0 || board[0] == null || board[0].length == 0)&#123;            return 0;        &#125;        // Preparation        int rowNum = board.length;        int colNum = board[0].length;        boolean isRight = true;        // 扁平化        int[] nums = new int[rowNum * rowNum + 1];        int index = 1;        for(int i = rowNum - 1; i &gt;= 0; i--)&#123;            if(isRight)&#123;                for(int j = 0; j &lt; colNum; j++)&#123;                    nums[index++] = board[i][j];                &#125;            &#125;            else&#123;                for(int j = colNum - 1; j &gt;= 0; j--)&#123;                    nums[index++] = board[i][j];                &#125;            &#125;            isRight = !isRight;        &#125;        // Queue        Queue&lt;Integer&gt; queue = new LinkedList&lt;&gt;();        queue.offer(1);        // &lt;Index, steps&gt;        Map&lt;Integer, Integer&gt; distanceMap = new HashMap&lt;&gt;();        distanceMap.put(1, 0);        while(!queue.isEmpty())&#123;            int curIndex = queue.poll();            int step = distanceMap.get(curIndex);            // 走到左上角：答案            if(curIndex == rowNum * rowNum)&#123;                return step;            &#125;            for(int i = 1; i &lt;= 6; i++)&#123;                int newIndex = curIndex + i;                // isValid                if(newIndex &lt;= 0 || newIndex &gt; rowNum * rowNum)&#123;                    continue;                &#125;                // 遇到蛇 或 梯子                if(nums[newIndex] != -1)&#123;                    newIndex = nums[newIndex];                &#125;                // visited                if(distanceMap.containsKey(newIndex))&#123;                    continue;                &#125;                // 入 queue                queue.offer(newIndex);                                // 当前点走过的距离                distanceMap.put(newIndex, step + 1);            &#125;        &#125;        return -1;    &#125;&#125;\n\n\n\n回溯问题/* 回溯算法框架 */void backtrack(State state, List&lt;Choice&gt; choices, List&lt;State&gt; res) &#123;    // 判断是否为解    if (isSolution(state)) &#123;        // 记录解        recordSolution(state, res);        // 不再继续搜索        return;    &#125;    // 遍历所有选择    for (Choice choice : choices) &#123;        // 剪枝：判断选择是否合法        if (isValid(state, choice)) &#123;            // 尝试：做出选择，更新状态            makeChoice(state, choice);            backtrack(state, choices, res);            // 回退：撤销选择，恢复到之前的状态            undoChoice(state, choice);        &#125;    &#125;&#125;\n\n全排列问题class Solution &#123;    public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) &#123;        List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;List&lt;Integer&gt;&gt;();        List&lt;Integer&gt; output = new ArrayList&lt;Integer&gt;();        for (int num : nums) &#123;            output.add(num);        &#125;        int n = nums.length;        backtrack(n, output, res, 0);        return res;    &#125;    public void backtrack(int n, List&lt;Integer&gt; output, List&lt;List&lt;Integer&gt;&gt; res, int first) &#123;        // 所有数都填完了        if (first == n) &#123;            res.add(new ArrayList&lt;Integer&gt;(output));        &#125;        for (int i = first; i &lt; n; i++) &#123;            // 动态维护数组            Collections.swap(output, first, i);            // 继续递归填下一个数            backtrack(n, output, res, first + 1);            // 撤销操作            Collections.swap(output, first, i);        &#125;    &#125;&#125;\n\n子集和问题类似于全排列问题，我们可以把子集的生成过程想象成一系列选择的结果，并在选择过程中实时更新“元素和”，当元素和等于 target 时，就将子集记录至结果列表。\n而与全排列问题不同的是，本题集合中的元素可以被无限次选取，因此无须借助 selected 布尔列表来记录元素是否已被选择。我们可以对全排列代码进行小幅修改，初步得到解题代码：\n/* 回溯算法：子集和 I */void backtrack(List&lt;Integer&gt; state, int target, int total, int[] choices, List&lt;List&lt;Integer&gt;&gt; res) &#123;    // 子集和等于 target 时，记录解    if (total == target) &#123;        res.add(new ArrayList&lt;&gt;(state));        return;    &#125;    // 遍历所有选择    for (int i = 0; i &lt; choices.length; i++) &#123;        // 剪枝：若子集和超过 target ，则跳过该选择        if (total + choices[i] &gt; target) &#123;            continue;        &#125;        // 尝试：做出选择，更新元素和 total        state.add(choices[i]);        // 进行下一轮选择        backtrack(state, target, total + choices[i], choices, res);        // 回退：撤销选择，恢复到之前的状态        state.remove(state.size() - 1);    &#125;&#125;/* 求解子集和 I（包含重复子集） */List&lt;List&lt;Integer&gt;&gt; subsetSumINaive(int[] nums, int target) &#123;    List&lt;Integer&gt; state = new ArrayList&lt;&gt;(); // 状态（子集）    int total = 0; // 子集和    List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); // 结果列表（子集列表）    backtrack(state, target, total, nums, res);    return res;&#125;\n\n但这样的问题是，其在进行选取的时候，会造成重复，解决办法是先排序\n\n在开启搜索前，先将数组 nums 排序。在遍历所有选择时，当子集和超过 target 时直接结束循环，因为后边的元素更大，其子集和一定超过 target 。\n省去元素和变量 total ，通过在 target 上执行减法来统计元素和，当 target 等于 0 时记录解。\n\n/* 回溯算法：子集和 I */void backtrack(List&lt;Integer&gt; state, int target, int[] choices, int start, List&lt;List&lt;Integer&gt;&gt; res) &#123;    // 子集和等于 target 时，记录解    if (target == 0) &#123;        res.add(new ArrayList&lt;&gt;(state));        return;    &#125;    // 遍历所有选择    // 剪枝二：从 start 开始遍历，避免生成重复子集    for (int i = start; i &lt; choices.length; i++) &#123;        // 剪枝一：若子集和超过 target ，则直接结束循环        // 这是因为数组已排序，后边元素更大，子集和一定超过 target        if (target - choices[i] &lt; 0) &#123;            break;        &#125;        // 尝试：做出选择，更新 target, start        state.add(choices[i]);        // 进行下一轮选择        backtrack(state, target - choices[i], choices, i, res);        // 回退：撤销选择，恢复到之前的状态        state.remove(state.size() - 1);    &#125;&#125;/* 求解子集和 I */List&lt;List&lt;Integer&gt;&gt; subsetSumI(int[] nums, int target) &#123;    List&lt;Integer&gt; state = new ArrayList&lt;&gt;(); // 状态（子集）    Arrays.sort(nums); // 对 nums 进行排序    int start = 0; // 遍历起始点    List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); // 结果列表（子集列表）    backtrack(state, target, nums, start, res);    return res;&#125;\n\nN皇后问题（经典）13.4  N 皇后问题 - Hello 算法 (hello-algo.com)\n/* 回溯算法：n 皇后 */void backtrack(int row, int n, List&lt;List&lt;String&gt;&gt; state, List&lt;List&lt;List&lt;String&gt;&gt;&gt; res,        boolean[] cols, boolean[] diags1, boolean[] diags2) &#123;    // 当放置完所有行时，记录解    if (row == n) &#123;        List&lt;List&lt;String&gt;&gt; copyState = new ArrayList&lt;&gt;();        for (List&lt;String&gt; sRow : state) &#123;            copyState.add(new ArrayList&lt;&gt;(sRow));        &#125;        res.add(copyState);        return;    &#125;    // 遍历所有列    for (int col = 0; col &lt; n; col++) &#123;        // 计算该格子对应的主对角线和次对角线        int diag1 = row - col + n - 1;        int diag2 = row + col;        // 剪枝：不允许该格子所在列、主对角线、次对角线上存在皇后        if (!cols[col] &amp;&amp; !diags1[diag1] &amp;&amp; !diags2[diag2]) &#123;            // 尝试：将皇后放置在该格子            state.get(row).set(col, &quot;Q&quot;);            cols[col] = diags1[diag1] = diags2[diag2] = true;            // 放置下一行            backtrack(row + 1, n, state, res, cols, diags1, diags2);            // 回退：将该格子恢复为空位            state.get(row).set(col, &quot;#&quot;);            cols[col] = diags1[diag1] = diags2[diag2] = false;        &#125;    &#125;&#125;/* 求解 n 皇后 */List&lt;List&lt;List&lt;String&gt;&gt;&gt; nQueens(int n) &#123;    // 初始化 n*n 大小的棋盘，其中 &#x27;Q&#x27; 代表皇后，&#x27;#&#x27; 代表空位    List&lt;List&lt;String&gt;&gt; state = new ArrayList&lt;&gt;();    for (int i = 0; i &lt; n; i++) &#123;        List&lt;String&gt; row = new ArrayList&lt;&gt;();        for (int j = 0; j &lt; n; j++) &#123;            row.add(&quot;#&quot;);        &#125;        state.add(row);    &#125;    boolean[] cols = new boolean[n]; // 记录列是否有皇后    boolean[] diags1 = new boolean[2 * n - 1]; // 记录主对角线上是否有皇后    boolean[] diags2 = new boolean[2 * n - 1]; // 记录次对角线上是否有皇后    List&lt;List&lt;List&lt;String&gt;&gt;&gt; res = new ArrayList&lt;&gt;();    backtrack(0, n, state, res, cols, diags1, diags2);    return res;&#125;\n\n2024.09.04蔚来import java.util.Scanner;public class Main &#123;    public static boolean getAns(int[][] matrix, int[][] ans, boolean flag) &#123;        int m = matrix.length;        int n = matrix[0].length;                int currentX = 0;        int currentY = 0;        int steps[][] = new int[4][2];        steps[0][0] = 0; steps[0][1] = 1;        steps[1][0] = 1; steps[1][1] = 0;        steps[2][0] = 0; steps[2][1] = -1;        steps[3][0] = -1; steps[3][1] = 0;                if (matrix[0][0] == 1) return false;        ans[0][0] = 1;                boolean visited[][] = new boolean[m][n];        for (int i = 0; i &lt; m; i++) &#123;            for (int j = 0; j &lt; n; j++) &#123;                visited[i][j] = false;            &#125;        &#125;        return backtrace(matrix, visited, currentX, currentY, m, n, flag, steps, ans);    &#125;    public static boolean backtrace(int[][] matrix, boolean[][] visited, int currentX, int currentY, int m, int n, boolean flag, int[][] steps, int[][] ans) &#123;        if (currentY &lt; 0 || currentY &gt;= n || currentX &lt; 0 || currentX &gt;= m) return false;        for (int j = 0; j &lt; 4; j++) &#123;            int tempCurrentX = currentX + steps[j][0];            int tempCurrentY = currentY + steps[j][1];            if (tempCurrentX &lt; 0 || tempCurrentX &gt;= m || tempCurrentY &lt; 0 || tempCurrentY &gt;= n || visited[tempCurrentX][tempCurrentY] || matrix[tempCurrentX][tempCurrentY] == 1) &#123;                continue;            &#125; else &#123;                if (tempCurrentX == m - 1 &amp;&amp; tempCurrentY == n - 1) &#123;                    flag = true;                    ans[tempCurrentX][tempCurrentY] = 1;                    return true;                &#125;                visited[tempCurrentX][tempCurrentY] = true;                ans[tempCurrentX][tempCurrentY] = 1;                if (backtrace(matrix, visited, tempCurrentX, tempCurrentY, m, n, flag, steps, ans)) &#123;                    return true;                &#125;                ans[tempCurrentX][tempCurrentY] = 0;                visited[tempCurrentX][tempCurrentY] = false;            &#125;        &#125;        return false;    &#125;    public static void main(String[] args) &#123;        boolean flag = false;        int matrix[][] = new int[3][3];        matrix[0][1] = 1;        matrix[0][2] = 1;        int ans[][] = new int[3][3];        flag = getAns(matrix, ans, flag);        if (flag) &#123;            for (int i = 0; i &lt; 3; i++) &#123;                for (int j = 0; j &lt; 3; j++) &#123;                    System.out.print(ans[i][j] + &quot; &quot;);                &#125;                System.out.println();            &#125;        &#125; else &#123;            System.out.println(&quot;No path found.&quot;);        &#125;    &#125;&#125;\n\nLeetcode 77.组合class Solution &#123;    List&lt;Integer&gt; temp = new ArrayList&lt;Integer&gt;();    List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;List&lt;Integer&gt;&gt;();    public List&lt;List&lt;Integer&gt;&gt; combine(int n, int k) &#123;        dfs(1, n, k);        return ans;    &#125;    public void dfs(int cur, int n, int k) &#123;        // 剪枝：temp 长度加上区间 [cur, n] 的长度小于 k，不可能构造出长度为 k 的 temp        if (temp.size() + (n - cur + 1) &lt; k) &#123;            return;        &#125;        // 记录合法的答案        if (temp.size() == k) &#123;            ans.add(new ArrayList&lt;Integer&gt;(temp));            return;        &#125;        // 考虑选择当前位置        temp.add(cur);        dfs(cur + 1, n, k);        temp.remove(temp.size() - 1);        // 考虑不选择当前位置        dfs(cur + 1, n, k);    &#125;&#125;\n\n\n\n动态规划记忆化搜索/* 记忆化搜索 */int dfs(int i, int[] mem) &#123;    // 已知 dp[1] 和 dp[2] ，返回之    if (i == 1 || i == 2)        return i;    // 若存在记录 dp[i] ，则直接返回之    if (mem[i] != -1)        return mem[i];    // dp[i] = dp[i-1] + dp[i-2]    int count = dfs(i - 1, mem) + dfs(i - 2, mem);    // 记录 dp[i]    mem[i] = count;    return count;&#125;/* 爬楼梯：记忆化搜索 */int climbingStairsDFSMem(int n) &#123;    // mem[i] 记录爬到第 i 阶的方案总数，-1 代表无记录    int[] mem = new int[n + 1];    Arrays.fill(mem, -1);    return dfs(n, mem);&#125;\n\n01背包暴力搜索 O(2^n)\n/* 0-1 背包：暴力搜索 */int knapsackDFS(int[] wgt, int[] val, int i, int c) &#123;    // 若已选完所有物品或背包无剩余容量，则返回价值 0    if (i == 0 || c == 0) &#123;        return 0;    &#125;    // 若超过背包容量，则只能选择不放入背包    if (wgt[i - 1] &gt; c) &#123;        return knapsackDFS(wgt, val, i - 1, c);    &#125;    // 计算不放入和放入物品 i 的最大价值    int no = knapsackDFS(wgt, val, i - 1, c);    int yes = knapsackDFS(wgt, val, i - 1, c - wgt[i - 1]) + val[i - 1];    // 返回两种方案中价值更大的那一个    return Math.max(no, yes);&#125;\n\n空间优化加动态规划\n/* 0-1 背包：空间优化后的动态规划 */int knapsackDPComp(int[] wgt, int[] val, int cap) &#123;    int n = wgt.length;    // 初始化 dp 表    int[] dp = new int[cap + 1];    // 状态转移    for (int i = 1; i &lt;= n; i++) &#123;        // 倒序遍历        for (int c = cap; c &gt;= 1; c--) &#123;            if (wgt[i - 1] &lt;= c) &#123;                // 不选和选物品 i 这两种方案的较大值                dp[c] = Math.max(dp[c], dp[c - wgt[i - 1]] + val[i - 1]);            &#125;        &#125;    &#125;    return dp[cap];&#125;\n\n完全背包空间优化加动态规划\n/* 完全背包：空间优化后的动态规划 */int unboundedKnapsackDPComp(int[] wgt, int[] val, int cap) &#123;    int n = wgt.length;    // 初始化 dp 表    int[] dp = new int[cap + 1];    // 状态转移    for (int i = 1; i &lt;= n; i++) &#123;        for (int c = 1; c &lt;= cap; c++) &#123;            if (wgt[i - 1] &gt; c) &#123;                // 若超过背包容量，则不选物品 i                dp[c] = dp[c];            &#125; else &#123;                // 不选和选物品 i 这两种方案的较大值                dp[c] = Math.max(dp[c], dp[c - wgt[i - 1]] + val[i - 1]);            &#125;        &#125;    &#125;    return dp[cap];&#125;\n\nLeetcode 322.零钱兑换class Solution &#123;    public int coinChange(int[] coins, int amount) &#123;        int types = coins.length;        int dp[] = new int[amount+1];        for (int i = 0;i&lt;=amount;i++)&#123;            dp[i]=amount+1;        &#125;        dp[0]=0;        for (int i = 0;i&lt;types;i++)&#123;            for (int j=0;j&lt;=amount;j++)&#123;                if (j&gt;=coins[i])&#123; //会用到这个硬币                    if(dp[j-coins[i]]+1&lt;dp[j])&#123;                        dp[j] = dp[j-coins[i]]+1;                    &#125;                &#125;else&#123;                    continue;                &#125;            &#125;        &#125;        if (dp[amount]==amount+1)return -1;        return dp[amount];    &#125;&#125;\n\n零钱兑换问题2凑硬币\n/* 零钱兑换 II：动态规划 */int coinChangeIIDP(int[] coins, int amt) &#123;    int n = coins.length;    // 初始化 dp 表    int[][] dp = new int[n + 1][amt + 1];    // 初始化首列    for (int i = 0; i &lt;= n; i++) &#123;        dp[i][0] = 1;    &#125;    // 状态转移    for (int i = 1; i &lt;= n; i++) &#123;        for (int a = 1; a &lt;= amt; a++) &#123;            if (coins[i - 1] &gt; a) &#123;                // 若超过目标金额，则不选硬币 i                dp[i][a] = dp[i - 1][a];            &#125; else &#123;                // 不选和选硬币 i 这两种方案之和                dp[i][a] = dp[i - 1][a] + dp[i][a - coins[i - 1]];            &#125;        &#125;    &#125;    return dp[n][amt];&#125;\n\n加空间优化\n/* 零钱兑换 II：空间优化后的动态规划 */int coinChangeIIDPComp(int[] coins, int amt) &#123;    int n = coins.length;    // 初始化 dp 表    int[] dp = new int[amt + 1];    dp[0] = 1;    // 状态转移    for (int i = 1; i &lt;= n; i++) &#123;        for (int a = 1; a &lt;= amt; a++) &#123;            if (coins[i - 1] &gt; a) &#123;                // 若超过目标金额，则不选硬币 i                dp[a] = dp[a];            &#125; else &#123;                // 不选和选硬币 i 这两种方案之和                dp[a] = dp[a] + dp[a - coins[i - 1]];            &#125;        &#125;    &#125;    return dp[amt];&#125;\n\n编辑距离问题14.6  编辑距离问题 - Hello 算法 (hello-algo.com)\npackage datastructure.dp;public class Levenshtein &#123;    public static int distance(String a, String b) &#123;         int length1 = a.length();         int length2 = b.length();         int dp[][] = new int[length1+1][length2+1];         for (int i=1;i&lt;=length1;i++)&#123;             dp[i][0]=i;         &#125;         for (int j=1;j&lt;=length2;j++)&#123;             dp[0][j]=j;         &#125;         for (int i = 1 ;i&lt;=length1;i++)&#123;             for (int j=1;j&lt;=length2;j++)&#123;                 if (a.charAt(i-1)==b.charAt(j-1))&#123;                    dp[i][j]=dp[i-1][j-1];                 &#125;else&#123;                     dp[i][j]=Math.min(dp[i-1][j-1],Math.min(dp[i-1][j],dp[i][j-1]))+1;                 &#125;             &#125;         &#125;         return dp[length1][length2];     &#125;     public static void main(String[] args) &#123;          String s1 = &quot;kitten&quot;;          String s2 = &quot;sitting&quot;;          int ans = distance(s1,s2);          System.out.println(ans);      &#125;&#125;\n\nLeetcode 198.打家劫舍class Solution &#123;    public int rob(int[] nums) &#123;        int length = nums.length;        if (length == 1)return nums[0];        int dp [] = new int [length];        dp[0] = nums[0];        for (int i=1; i&lt; length;i++)&#123;            int before = i-2;            if (i==1)&#123;                dp[i]=Math.max(nums[i],nums[i-1]);                continue;            &#125;            else&#123;                dp[i]=Math.max(dp[i-1],dp[i-2]+nums[i]);            &#125;        &#125;        return dp[length-1];    &#125;&#125;\n\nLeetcode 139.单词拆分class Solution &#123;    public boolean wordBreak(String s, List&lt;String&gt; wordDict) &#123;        int length = s.length();        boolean dp[] = new boolean[length+1];        dp[0]=true;        for(int i = 0;i&lt;length;i++)&#123;            for (int j=i+1;j&lt;length+1;j++)&#123;                if (dp[i]&amp;&amp;wordDict.contains(s.substring(i,j)))&#123;                    dp[j]=true;                &#125;            &#125;        &#125;        return dp[length];    &#125;&#125;\n\nLeetcode 300.最长递增子序列解法1：一种特殊思想\nclass Solution &#123;    public int lengthOfLIS(int[] nums) &#123;        List&lt;Integer&gt; ans = new ArrayList();        int length = nums.length;        for (int i=0;i&lt;length;i++)&#123;            if (ans.size()==0||nums[i]&gt;ans.get(ans.size()-1))&#123;                ans.add(nums[i]);            &#125;else&#123;                int index = findSmallIndex(ans,nums[i]);                if (index!=-1)&#123;                    ans.set(index,nums[i]);                &#125;            &#125;        &#125;        return ans.size();    &#125;    public int findSmallIndex(List&lt;Integer&gt; ans,int num)&#123;        int length  = ans.size();        for (int i=0;i&lt;length;i++)&#123;            if (ans.get(i)&gt;=num)&#123;                return i;            &#125;        &#125;        return -1;    &#125;&#125;\n\n解法2：动态规划\nclass Solution &#123;    public int lengthOfLIS(int[] nums) &#123;        int length = nums.length;        if (length==1)return 1;        int dp[]= new int[length];        for (int i=0;i&lt;length;i++)&#123;            dp[i]=1;        &#125;        int ans=1;        for (int i=1;i&lt;length;i++)&#123;            for (int j=0;j&lt;i;j++)&#123;                if(nums[i]&gt;nums[j])&#123;                    dp[i]=Math.max(dp[i],dp[j]+1);                                    &#125;            &#125;            ans = Math.max(dp[i],ans);        &#125;        return ans;    &#125;&#125;\n\nLeetcode 120.三角形最小路径和class Solution &#123;    public int minimumTotal(List&lt;List&lt;Integer&gt;&gt; triangle) &#123;        int depth = triangle.size();        int dp[][]=new int[depth][depth];        dp[0][0]=triangle.get(0).get(0);        if (depth==1)&#123;            return dp[0][0];        &#125;        for (int i=1;i&lt;depth;i++)&#123;            dp[i][0]=dp[i-1][0]+triangle.get(i).get(0);            for (int j=1;j&lt;triangle.get(i).size()-1;j++)&#123;                dp[i][j]=Math.min(dp[i-1][j-1]+triangle.get(i).get(j),dp[i-1][j]+triangle.get(i).get(j));            &#125;            dp[i][triangle.get(i).size()-1]=dp[i-1][triangle.get(i-1).size()-1]+triangle.get(i).get(triangle.get(i).size()-1);        &#125;        int ans = Integer.MAX_VALUE;        for(int i=0;i&lt;triangle.get(depth-1).size();i++)&#123;            ans = Math.min(dp[depth-1][i],ans);        &#125;        return ans;    &#125;&#125;\n\nLeetcode 221.最大正方形class Solution &#123;    public int maximalSquare(char[][] matrix) &#123;        int length = matrix.length;        int length2 = matrix[0].length;        int ans = 0;        int dp[][] = new int [length][length2];        for (int i=0;i&lt;length;i++)&#123;            for(int j=0;j&lt;length2;j++)&#123;                if (matrix[i][j]==&#x27;1&#x27;)&#123;                    if (i==0||j==0)&#123;                        dp[i][j]=1;                        ans = Math.max(ans,dp[i][j]);                    &#125;else&#123;                        dp[i][j]=1+getSmallest(dp[i-1][j],dp[i-1][j-1],dp[i][j-1]);                        ans = Math.max(ans,dp[i][j]);                    &#125;                  &#125;else&#123;                    dp[i][j]=0;                &#125;            &#125;        &#125;        return ans*ans;    &#125;    public int getSmallest(int a,int b,int c)&#123;        if (a&gt;b)&#123;            if (b&gt;c)return c;            else return b;        &#125;else&#123;            if (a&gt;c)return c;            else return a;        &#125;    &#125;&#125;\n\nLeetcode 72.编辑距离class Solution &#123;    public int minDistance(String word1, String word2) &#123;        int length1 = word1.length();        int length2 = word2.length();        int dp[][] = new int[length1+1][length2+1];        dp[0][0]=0;        if (length1*length2==0)return length1+length2;        if (length1&gt;1)&#123;            for (int i=1;i&lt;=length1;i++)&#123;            dp[i][0]=dp[i-1][0]+1;            &#125;        &#125;        if (length2&gt;1)&#123;            for (int j=1;j&lt;=length2;j++)&#123;            dp[0][j]=dp[0][j-1]+1;            &#125;        &#125;                for (int i=1;i&lt;=length1;i++)&#123;            for (int j=1;j&lt;=length2;j++)&#123;                if (word1.charAt(i-1)==word2.charAt(j-1))&#123;                    // dp[i][j]= getSmallest(dp[i-1][j-1],dp[i-1][j]+1,dp[i][j-1]+1);                    dp[i][j]= getSmallest(dp[i-1][j-1]-1,dp[i-1][j],dp[i][j-1])+1;                &#125;else&#123;                    dp[i][j]= 1+getSmallest(dp[i-1][j-1],dp[i][j-1],dp[i-1][j]);                &#125;            &#125;        &#125;        return dp[length1][length2];    &#125;    public int getSmallest(int a,int b,int c)&#123;        if (a&gt;b)&#123;            if (b&gt;c)return c;            return b;        &#125;else&#123;            if (a&gt;c)return c;            return a;        &#125;    &#125;&#125;\n\n\n\n贪心一般情况下，贪心算法的适用情况分以下两种。\n\n可以保证找到最优解：贪心算法在这种情况下往往是最优选择，因为它往往比回溯、动态规划更高效。\n可以找到近似最优解：贪心算法在这种情况下也是可用的。对于很多复杂问题来说，寻找全局最优解非常困难，能以较高效率找到次优解也是非常不错的。\n\n贪心问题的解决流程大体可分为以下三步。\n\n问题分析：梳理与理解问题特性，包括状态定义、优化目标和约束条件等。这一步在回溯和动态规划中都有涉及。\n确定贪心策略：确定如何在每一步中做出贪心选择。这个策略能够在每一步减小问题的规模，并最终解决整个问题。\n正确性证明：通常需要证明问题具有贪心选择性质和最优子结构。这个步骤可能需要用到数学证明，例如归纳法或反证法等。\n\n加油站class Solution &#123;    public int canCompleteCircuit(int[] gas, int[] cost) &#123;        int n = gas.length;        int sumGas = 0;        int sumCost = 0;        for (int i = 0; i &lt; n; i++) &#123;            sumCost += cost[i];            sumGas += gas[i];        &#125;        if (sumCost &gt; sumGas)            return -1;        for (int i = 0; i &lt; n; i++) &#123;            int rest = 0;            int hasPassed = 0;            for (int j = i; hasPassed &lt; n; j++) &#123;                if (j == n)                    j = 0;                rest += gas[j];                if (rest &gt;= cost[j]) &#123;                    rest -= cost[j];                    hasPassed++;                &#125; else &#123;                    i = j;                    break;                &#125;            &#125;            if (hasPassed == n)                return i;        &#125;        return 1;    &#125;&#125;\n\nLCP 03. 机器人大冒险class Solution &#123;    public boolean robot(String cmd, int[][] obstacles, int x, int y) &#123;        int n = cmd.length();        int sx = 0, sy = 0;        // 记录走完一轮后机器人的位置        for (int i = 0; i &lt; n; ++ i) &#123;            char c = cmd.charAt(i);            if (c == &#x27;U&#x27;) ++ sy;            else ++ sx;        &#125;        // 先计算能否到达终点 不考虑障碍物        // 若不能直接返回false        boolean canFinish = canReach(cmd, x, y, sx, sy);        if (!canFinish) return false;        // 判断在终点前会不会遇到障碍物         // 若遇到则返回false        for (int[] o : obstacles) &#123;            if (o[0] &gt; x || o[1] &gt; y)                continue;            if (canReach(cmd, o[0], o[1], sx, sy)) return false;        &#125;        return true;    &#125;    // 判断能否从坐标(x, y)到达(tx, ty)    public boolean canReach(String cmd, int tx, int ty, int x, int y) &#123;        // round记录走到目标点至少要走多少轮        int round = Math.min(tx/x, ty/y);        int nx = round*x, ny = round*y;        if (nx == tx &amp;&amp; ny == ty) return true;        int n = cmd.length();        for (int i = 0; i &lt; n; ++ i) &#123;            char c = cmd.charAt(i);            if (c == &#x27;U&#x27;) ++ ny;            else ++ nx;            if (nx &gt; tx || ny &gt; ty) return false;            if (nx == tx &amp;&amp; ny == ty) return true;        &#125;        return true;    &#125;&#125;\n\nLeetcode 135.分发糖果class Solution &#123;    public int candy(int[] ratings) &#123;        int n = ratings.length;        int ret = 1;        int inc = 1, dec = 0, pre = 1;        for (int i = 1; i &lt; n; i++) &#123;            if (ratings[i] &gt;= ratings[i - 1]) &#123;                dec = 0;                pre = ratings[i] == ratings[i - 1] ? 1 : pre + 1;                ret += pre;                inc = pre;            &#125; else &#123;                dec++;                if (dec == inc) &#123;                    dec++;                &#125;                ret += dec;                pre = 1;            &#125;        &#125;        return ret;    &#125;&#125;\n\nLeetcode 42.接雨水class Solution &#123;    public int trap(int[] height) &#123;        int length = height.length;        int ans = 0;        for (int i =1;i&lt;length-1;i++)&#123;            int max_left = 0;            for (int j = i-1;j&gt;=0;j--)&#123;                if (height[j]&gt;max_left)                max_left = height[j];            &#125;            int max_right = 0;            for (int j = i+1;j&lt;length;j++)&#123;                if (height[j]&gt;max_right)                max_right = height[j];            &#125;            if (height[i]&lt;Math.min(max_left,max_right))&#123;                ans+=Math.min(max_left,max_right)- height[i];            &#125;        &#125;        return ans;    &#125;&#125;\n\nLeetcode 13.罗马数字转整形class Solution &#123;    public int romanToInt(String s) &#123;        HashMap&lt;Character,Integer&gt; romanMap = new HashMap();        romanMap.put(&#x27;I&#x27;,1);        romanMap.put(&#x27;V&#x27;,5);        romanMap.put(&#x27;X&#x27;,10);        romanMap.put(&#x27;L&#x27;,50);        romanMap.put(&#x27;C&#x27;,100);        romanMap.put(&#x27;D&#x27;,500);        romanMap.put(&#x27;M&#x27;,1000);        int length = s.length();        int ans = 0;        for (int i = 0;i&lt;length;i++)&#123;            if (i==length-1)ans+=romanMap.get(s.charAt(i));            else&#123;                if (romanMap.get(s.charAt(i))&lt;romanMap.get(s.charAt(i+1)))&#123;                    ans-=romanMap.get(s.charAt(i));                &#125;else&#123;                    ans+=romanMap.get(s.charAt(i));                &#125;            &#125;                    &#125;        return ans;    &#125;&#125;\n\nLeetcode 12.整数转罗马数字class Solution &#123;    int[] values = &#123;1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1&#125;;    String[] symbols = &#123;&quot;M&quot;, &quot;CM&quot;, &quot;D&quot;, &quot;CD&quot;, &quot;C&quot;, &quot;XC&quot;, &quot;L&quot;, &quot;XL&quot;, &quot;X&quot;, &quot;IX&quot;, &quot;V&quot;, &quot;IV&quot;, &quot;I&quot;&#125;;    public String intToRoman(int num) &#123;        StringBuffer roman = new StringBuffer();        for (int i = 0; i &lt; values.length; ++i) &#123;            int value = values[i];            String symbol = symbols[i];            while (num &gt;= value) &#123;                num -= value;                roman.append(symbol);            &#125;            if (num == 0) &#123;                break;            &#125;        &#125;        return roman.toString();    &#125;&#125;\n\nLeetcode 63.不同路径2动态规划\nclass Solution &#123;    public int uniquePathsWithObstacles(int[][] obstacleGrid) &#123;        if (obstacleGrid == null || obstacleGrid.length == 0 || obstacleGrid[0].length == 0) return 0;        int m = obstacleGrid.length;        int n = obstacleGrid[0].length;        // dp[i][j] 表示到达 (i, j) 的路径数        int[][] dp = new int[m][n];        // 初始化第一行        for (int j = 0; j &lt; n; j++) &#123;            if (obstacleGrid[0][j] == 1) break; // 遇到障碍物，之后的格子路径数为0            dp[0][j] = 1;        &#125;        // 初始化第一列        for (int i = 0; i &lt; m; i++) &#123;            if (obstacleGrid[i][0] == 1) break; // 遇到障碍物，之后的格子路径数为0            dp[i][0] = 1;        &#125;        // 填充 dp 表        for (int i = 1; i &lt; m; i++) &#123;            for (int j = 1; j &lt; n; j++) &#123;                if (obstacleGrid[i][j] == 0) &#123;                    dp[i][j] = dp[i - 1][j] + dp[i][j - 1];                &#125; else &#123;                    dp[i][j] = 0; // 遇到障碍物，路径数为0                &#125;            &#125;        &#125;        return dp[m - 1][n - 1]; // 返回右下角的路径数    &#125;&#125;\n\nLeetcode 68.文本左右对齐class Solution &#123;    public List&lt;String&gt; fullJustify(String[] words, int maxWidth) &#123;        List&lt;String&gt; ans = new ArrayList&lt;String&gt;();        int right = 0, n = words.length;        while (true) &#123;            int left = right; // 当前行的第一个单词在 words 的位置            int sumLen = 0; // 统计这一行单词长度之和            // 循环确定当前行可以放多少单词，注意单词之间应至少有一个空格            while (right &lt; n &amp;&amp; sumLen + words[right].length() + right - left &lt;= maxWidth) &#123;                sumLen += words[right++].length();            &#125;            // 当前行是最后一行：单词左对齐，且单词之间应只有一个空格，在行末填充剩余空格            if (right == n) &#123;                StringBuffer sb = join(words, left, n, &quot; &quot;);                sb.append(blank(maxWidth - sb.length()));                ans.add(sb.toString());                return ans;            &#125;            int numWords = right - left;            int numSpaces = maxWidth - sumLen;            // 当前行只有一个单词：该单词左对齐，在行末填充剩余空格            if (numWords == 1) &#123;                StringBuffer sb = new StringBuffer(words[left]);                sb.append(blank(numSpaces));                ans.add(sb.toString());                continue;            &#125;            // 当前行不只一个单词            int avgSpaces = numSpaces / (numWords - 1);            int extraSpaces = numSpaces % (numWords - 1);            StringBuffer sb = new StringBuffer();            sb.append(join(words, left, left + extraSpaces + 1, blank(avgSpaces + 1))); // 拼接额外加一个空格的单词            sb.append(blank(avgSpaces));            sb.append(join(words, left + extraSpaces + 1, right, blank(avgSpaces))); // 拼接其余单词            ans.add(sb.toString());        &#125;    &#125;    // blank 返回长度为 n 的由空格组成的字符串    public String blank(int n) &#123;        StringBuffer sb = new StringBuffer();        for (int i = 0; i &lt; n; ++i) &#123;            sb.append(&#x27; &#x27;);        &#125;        return sb.toString();    &#125;    // join 返回用 sep 拼接 [left, right) 范围内的 words 组成的字符串    public StringBuffer join(String[] words, int left, int right, String sep) &#123;        StringBuffer sb = new StringBuffer(words[left]);        for (int i = left + 1; i &lt; right; ++i) &#123;            sb.append(sep);            sb.append(words[i]);        &#125;        return sb;    &#125;&#125;\n\nLeetcode 125.验证回文串class Solution &#123;    public boolean isPalindrome(String s) &#123;        String s2 = s.toLowerCase();        Stack stack = new Stack();        Queue queue = new LinkedList();        int length = s2.length();        for (int i=0;i&lt;length;i++)&#123;            if (Character.isLetter(s2.charAt(i))||Character.isDigit(s2.charAt(i)))&#123;                stack.push(s2.charAt(i));                queue.offer(s2.charAt(i));            &#125;        &#125;        boolean ans = true;        while (!stack.isEmpty())&#123;            if (stack.peek()==queue.peek())&#123;                stack.pop();                queue.poll();            &#125;else&#123;                ans = false;                break;            &#125;        &#125;        return ans;    &#125;&#125;\n\nLeetcode 167.两数之和 II - 输入有序数组//双指针class Solution &#123;    public int[] twoSum(int[] numbers, int target) &#123;        int low = 0, high = numbers.length - 1;        while (low &lt; high) &#123;            int sum = numbers[low] + numbers[high];            if (sum == target) &#123;                return new int[]&#123;low + 1, high + 1&#125;;            &#125; else if (sum &lt; target) &#123;                ++low;            &#125; else &#123;                --high;            &#125;        &#125;        return new int[]&#123;-1, -1&#125;;    &#125;&#125;\n\nLeetcode 11.盛最多水的容器//这个方法会超时class Solution &#123;    public int maxArea(int[] height) &#123;        int length = height.length;        int ans = -1;        for (int i =0;i&lt;length-1;i++)&#123;            for (int j=i+1;j&lt;length;j++)&#123;                if ((j-i)*Math.min(height[i],height[j])&gt;ans)&#123;                    ans = (j-i)*Math.min(height[i],height[j]);                &#125;            &#125;        &#125;        return ans;    &#125;&#125;//双指针，正确性可以用反证法：如果高度更高的反而改变了，那么能装的水肯定是变小的，所以这种策略一定是让能装的水变多的class Solution &#123;    public int maxArea(int[] height) &#123;        int length = height.length;        int ans = 0;        int start = 0;        int end = length-1;        while(start&lt;end)&#123;            int minHeight = Math.min(height[start],height[end]);            if ((end-start)*minHeight&gt;ans)&#123;                ans = (end-start)*minHeight;            &#125;            if (minHeight==height[start])start++;            else end--;        &#125;        return ans;    &#125;&#125;\n\nLeetcode 15.三数之和class Solution &#123;    public List&lt;List&lt;Integer&gt;&gt; threeSum(int[] nums) &#123;        Arrays.sort(nums);        int n = nums.length;        List&lt;List&lt;Integer&gt;&gt;ans = new ArrayList&lt;List&lt;Integer&gt;&gt;();        for (int i =0;i&lt;n;i++)&#123;            if (i&gt;0&amp;&amp;nums[i]==nums[i-1])&#123;                continue;            &#125;            int k = n-1;            int t = -nums[i];            for (int j = i+1;j&lt;n;j++)&#123;                if (j&gt;i+1&amp;&amp;nums[j]==nums[j-1])&#123;                    continue;                &#125;                while (j&lt;k&amp;&amp;nums[j]+nums[k]&gt;t)&#123;                    k--;                &#125;                if (j==k)break;                if (nums[j]+nums[k]==t)&#123;                    List&lt;Integer&gt;list = new ArrayList&lt;Integer&gt;();                    list.add(nums[i]);                    list.add(nums[j]);                    list.add(nums[k]);                    ans.add(list);                &#125;            &#125;        &#125;        return ans;    &#125;&#125;\n\n\n\nLeetcode 209.长度最小的子数组//暴力 会超时class Solution &#123;    public int minSubArrayLen(int target, int[] nums) &#123;        int length = nums.length;        int presum[]=new int[length+1];        int ans = 100000;        for (int i=1;i&lt;=length;i++)&#123;                presum[i]=presum[i-1]+nums[i-1];        &#125;        if (presum[length]&lt;target)return 0;        for (int i=0;i&lt;length;i++)&#123;            for (int j=length;j&gt;=i;j--)&#123;                    if (presum[j]-presum[i]&gt;=target)&#123;                        if (j-i&lt;ans)ans = j-i;                    &#125;            &#125;        &#125;        return ans;    &#125;&#125;//滑动窗口class Solution &#123;    public int minSubArrayLen(int target, int[] nums) &#123;        int length = nums.length;        int sum = 0;        int start = 0;        int end = 0;        int ans = 100000;        boolean flag =false;        for (int i=0;i&lt;length;i++)&#123;            sum+=nums[i];            end++;            if (sum&gt;=target)&#123;                while (sum&gt;=target)&#123;                    if (end-start&lt;ans)ans = end -start;                    flag = true;                    sum-=nums[start];                    start++;                &#125;             &#125;        &#125;        if (!flag)return 0;        return ans;&#125;&#125;\n\nLeetcode 3.无重复字符的最长子串class Solution &#123;    public int lengthOfLongestSubstring(String s) &#123;        HashMap&lt;Character,Integer&gt; map= new HashMap();        int start = 0;        int ans = 0;        for (int i = 0;i&lt;s.length();i++)&#123;            if (map.get(Character.valueOf(s.charAt(i)))!=null&amp;&amp;start&lt;map.get(Character.valueOf(s.charAt(i)))+1)&#123; //发现有重复的了                start=map.get(Character.valueOf(s.charAt(i)))+1; //跳到没有重复的地方            &#125;            map.put(Character.valueOf(s.charAt(i)),i);            if (i-start+1&gt;ans)ans = i-start+1;        &#125;        return ans;    &#125;&#125;\n\nLeetcode 36.有效的数独暴力解法\nclass Solution &#123;    public boolean isValidSudoku(char[][] board) &#123;        for(int i = 0; i &lt; board.length; i++)&#123;            for(int j = 0; j &lt; board[0].length; j++)&#123;                if(board[i][j] &gt;= &#x27;0&#x27; &amp;&amp; board[i][j] &lt;= &#x27;9&#x27;)&#123;                    if(!getEffective(i, j, board))&#123;                        return false;                    &#125;                &#125;            &#125;        &#125;        return true;    &#125;    public boolean getEffective(int i, int j, char[][] board)&#123;        // 验证一行        for(int k = 0; k &lt; board[i].length; k++)&#123;            if(board[i][k] == board[i][j] &amp;&amp; k != j)&#123;                return false;            &#125;        &#125;        // 验证一列        for(int k = 0; k &lt; board.length; k++)&#123;            if(board[k][j] == board[i][j] &amp;&amp; k != i)&#123;                return false;            &#125;        &#125;        // 验证当前 3 * 3 数组        int heng = (i / 3) * 3;        int zhong = (j / 3) * 3;        for(int k1 = heng; k1 &lt; heng + 3; k1++)&#123;            for(int k2 = zhong; k2 &lt; zhong + 3; k2++)&#123;                if((board[k1][k2] == board[i][j]) &amp;&amp; (k1 != i &amp;&amp; k2 != j))&#123;                    return false;                &#125;            &#125;        &#125;        return true;    &#125;&#125;\n\nLeetcode 54.螺旋矩阵class Solution &#123;    public List&lt;Integer&gt; spiralOrder(int[][] matrix) &#123;        List&lt;Integer&gt; order = new ArrayList&lt;Integer&gt;();        if (matrix == null || matrix.length == 0 || matrix[0].length == 0) &#123;            return order;        &#125;        int rows = matrix.length, columns = matrix[0].length;        boolean[][] visited = new boolean[rows][columns];        int total = rows * columns;        int row = 0, column = 0;        int[][] directions = &#123;&#123;0, 1&#125;, &#123;1, 0&#125;, &#123;0, -1&#125;, &#123;-1, 0&#125;&#125;;        int directionIndex = 0;        for (int i = 0; i &lt; total; i++) &#123;            order.add(matrix[row][column]);            visited[row][column] = true;            int nextRow = row + directions[directionIndex][0], nextColumn = column + directions[directionIndex][1];            if (nextRow &lt; 0 || nextRow &gt;= rows || nextColumn &lt; 0 || nextColumn &gt;= columns || visited[nextRow][nextColumn]) &#123;                directionIndex = (directionIndex + 1) % 4;            &#125;            row += directions[directionIndex][0];            column += directions[directionIndex][1];        &#125;        return order;    &#125;&#125;\n\nLeetcode 48.旋转图像这种旋转的题就注意位置映射关系就好\nclass Solution &#123;    public void rotate(int[][] matrix) &#123;        int n = matrix.length;        for (int i = 0; i &lt; n / 2; ++i) &#123;            for (int j = 0; j &lt; (n + 1) / 2; ++j) &#123;                int temp = matrix[i][j];                matrix[i][j] = matrix[n - j - 1][i];                matrix[n - j - 1][i] = matrix[n - i - 1][n - j - 1];                matrix[n - i - 1][n - j - 1] = matrix[j][n - i - 1];                matrix[j][n - i - 1] = temp;            &#125;        &#125;    &#125;&#125;\n\nLeetcode 289.生命游戏class Solution &#123;    public void gameOfLife(int[][] board) &#123;        int m = board.length;        int n = board[0].length;        boolean isAlive[][]=new boolean[m][n];        for (int i =0;i&lt;m;i++)&#123;            for (int j =0;j&lt;n;j++)&#123;                int num = getNum(board,i,j,m,n);                if (board[i][j]==1)&#123;                    if (num&lt;2||num&gt;3)isAlive[i][j]=false;                    if (num==2||num==3)isAlive[i][j]=true;                &#125;else&#123;                    if (num==3)isAlive[i][j]=true;                &#125;            &#125;        &#125;        for (int i=0;i&lt;m;i++)&#123;            for (int j =0;j&lt;n;j++)&#123;                if (isAlive[i][j])board[i][j]=1;                else&#123;                    board[i][j]=0;                &#125;            &#125;        &#125;    &#125;    public int getNum(int[][] board,int x,int y,int m, int n)&#123;        int num = 0;        for (int i=x-1;i&lt;=x+1;i++)&#123;            if (i&lt;0||i&gt;=m)continue;            for (int j= y-1;j&lt;=y+1;j++)&#123;                if (j&lt;0||j&gt;=n||i==x&amp;&amp;j==y)continue;                if (board[i][j]==1)num++;            &#125;        &#125;        return num;    &#125;&#125;\n\n哈希表Leetcode 383.赎金信class Solution &#123;    public boolean canConstruct(String ransomNote, String magazine) &#123;        int nums[]=new int[26];        int size = magazine.length();        for (int i=0;i&lt;size;i++)&#123;            nums[magazine.charAt(i)-&#x27;a&#x27;]+=1;        &#125;        int rSize= ransomNote.length();        for (int i =0;i&lt;rSize;i++)&#123;            if (nums[ransomNote.charAt(i)-&#x27;a&#x27;]&lt;=0)return false;            nums[ransomNote.charAt(i)-&#x27;a&#x27;]-=1;        &#125;        return true;    &#125;&#125;\n\nLeetcode 205.同构字符串class Solution &#123;    public boolean isIsomorphic(String s, String t) &#123;        Map&lt;Character,Character&gt; cMap = new HashMap&lt;Character,Character&gt;();        Map&lt;Character,Character&gt; cMap2 = new HashMap&lt;Character,Character&gt;();        int length = s.length();        for (int i = 0;i&lt;length;i++)&#123;            if (cMap.containsKey(Character.valueOf(s.charAt(i)))||cMap2.containsKey(Character.valueOf(t.charAt(i))))&#123;                if (cMap.get(Character.valueOf(s.charAt(i)))!=Character.valueOf(t.charAt(i)))                return false;            &#125;else&#123;                cMap.put(Character.valueOf(s.charAt(i)),Character.valueOf(t.charAt(i)));                cMap2.put(Character.valueOf(t.charAt(i)),Character.valueOf(s.charAt(i)));            &#125;        &#125;        return true;    &#125;&#125;\n\n\n\nLeetcode 290.单词规律class Solution &#123;    public boolean wordPattern(String pattern, String s) &#123;        Map&lt;Character,String&gt; cMap = new HashMap&lt;Character,String&gt;();                Map&lt;String,Character&gt; cMap2 = new HashMap&lt;String,Character&gt;();        int length = pattern.length();        String words[]=s.split(&quot; &quot;);        if (words.length!=length)return false;        for (int i = 0;i&lt;length;i++)&#123;            if (cMap.containsKey(Character.valueOf(pattern.charAt(i))))&#123;                if (!cMap.get(Character.valueOf(pattern.charAt(i))).equals(words[i]))&#123;                return false;&#125;            &#125;            else if (cMap2.containsKey(words[i]))&#123;                return false;            &#125;                        else&#123;                cMap.put(Character.valueOf(pattern.charAt(i)),words[i]);                cMap2.put(words[i],Character.valueOf(pattern.charAt(i)));            &#125;        &#125;        return true;    &#125;&#125;\n\nLeetcode 49.字母异位词分组//错误解法,没考虑到次数，但注意keySet的使用class Solution &#123;    public List&lt;List&lt;String&gt;&gt; groupAnagrams(String[] strs) &#123;        HashMap&lt;HashSet&lt;Character&gt;,ArrayList&lt;String&gt;&gt; map = new HashMap();        int length = strs.length;        for (int i = 0; i&lt;length; i++)&#123;            int length2=strs[i].length();            HashSet&lt;Character&gt;set = new HashSet();            for (int j = 0 ;j&lt;length2;j++)&#123;                set.add(Character.valueOf(strs[i].charAt(j)));            &#125;            if (!map.containsKey(set))&#123;                ArrayList&lt;String&gt;list = new ArrayList();                list.add(strs[i]);                map.put(set,list);            &#125;else&#123;                map.get(set).add(strs[i]);            &#125;        &#125;        List&lt;List&lt;String&gt;&gt; ans = new ArrayList&lt;List&lt;String&gt;&gt;();        for (HashSet&lt;Character&gt; key: map.keySet())&#123;            ans.add(map.get(key));        &#125;        return ans;    &#125;&#125;\n\n//正确解法，注意char的数组可以直接new String转为String类class Solution &#123;    public List&lt;List&lt;String&gt;&gt; groupAnagrams(String[] strs) &#123;       Map&lt;String,List&lt;String&gt;&gt;map = new HashMap();        int length = strs.length;        for (int i = 0; i&lt;length; i++)&#123;            int length2=strs[i].length();            char word[]=new char[length2];            for (int j = 0;j&lt;length2;j++)&#123;                word[j]=strs[i].charAt(j) ;            &#125;            Arrays.sort(word);            String key = new String(word);            if (!map.containsKey(key))&#123;                List&lt;String&gt; list = new ArrayList();                list.add(strs[i]);                map.put(key,list);            &#125;else&#123;                map.get(key).add(strs[i]);            &#125;              &#125;        List&lt;List&lt;String&gt;&gt; ans = new ArrayList&lt;List&lt;String&gt;&gt;();        for (String key: map.keySet())&#123;            ans.add(map.get(key));        &#125;        return ans;    &#125;&#125;\n\n\n\nLeetcode 128.最长连续序列class Solution &#123;    public int longestConsecutive(int[] nums) &#123;        Arrays.sort(nums);        int length = nums.length;        if (length==0||length==1)return length;        int num = 1;        int ans = 1;        for (int i = 1;i&lt;length;i++)&#123;            if (nums[i-1]+1==nums[i])&#123;                num++;                ans=Math.max(num,ans);            &#125;else if(nums[i-1]==nums[i])&#123;                continue;            &#125;else&#123;                num=1;            &#125;              &#125;        return ans;    &#125;&#125;\n\nLeetcode 76.最小覆盖子串class Solution &#123;    Map&lt;Character, Integer&gt; ori = new HashMap&lt;Character, Integer&gt;();    Map&lt;Character, Integer&gt; cnt = new HashMap&lt;Character, Integer&gt;();    public String minWindow(String s, String t) &#123;        int tLen = t.length();        for (int i = 0; i &lt; tLen; i++) &#123;            char c = t.charAt(i);            ori.put(c, ori.getOrDefault(c, 0) + 1);        &#125;        int l = 0, r = -1;        int len = Integer.MAX_VALUE, ansL = -1, ansR = -1;        int sLen = s.length();        while (r &lt; sLen) &#123;            ++r;            if (r &lt; sLen &amp;&amp; ori.containsKey(s.charAt(r))) &#123;                cnt.put(s.charAt(r), cnt.getOrDefault(s.charAt(r), 0) + 1);            &#125;            while (check() &amp;&amp; l &lt;= r) &#123;                if (r - l + 1 &lt; len) &#123;                    len = r - l + 1;                    ansL = l;                    ansR = l + len;                &#125;                if (ori.containsKey(s.charAt(l))) &#123;                    cnt.put(s.charAt(l), cnt.getOrDefault(s.charAt(l), 0) - 1);                &#125;                ++l;            &#125;        &#125;        return ansL == -1 ? &quot;&quot; : s.substring(ansL, ansR);    &#125;    public boolean check() &#123;        Iterator iter = ori.entrySet().iterator();         while (iter.hasNext()) &#123;             Map.Entry entry = (Map.Entry) iter.next();             Character key = (Character) entry.getKey();             Integer val = (Integer) entry.getValue();             if (cnt.getOrDefault(key, 0) &lt; val) &#123;                return false;            &#125;        &#125;         return true;    &#125;&#125;\n\n\n\n区间Leetcode 228.汇总区间注意Integer.toString（）和StringBuilder的用法\nclass Solution &#123;    public List&lt;String&gt; summaryRanges(int[] nums) &#123;        List&lt;String&gt; ret = new ArrayList&lt;String&gt;();        int i = 0;        int n = nums.length;        while (i &lt; n) &#123;            int low = i;            i++;            while (i &lt; n &amp;&amp; nums[i] == nums[i - 1] + 1) &#123;                i++;            &#125;            int high = i - 1;            StringBuffer temp = new StringBuffer(Integer.toString(nums[low]));            if (low &lt; high) &#123;                temp.append(&quot;-&gt;&quot;);                temp.append(Integer.toString(nums[high]));            &#125;            ret.add(temp.toString());        &#125;        return ret;    &#125;&#125;\n\nLeetcode 56.合并区间class Solution &#123;    public int[][] merge(int[][] intervals) &#123;        if (intervals.length == 0) &#123;            return new int[0][2];        &#125;        Arrays.sort(intervals, new Comparator&lt;int[]&gt;() &#123;            public int compare(int[] interval1, int[] interval2) &#123;                return interval1[0] - interval2[0];            &#125;        &#125;);        List&lt;int[]&gt; merged = new ArrayList&lt;int[]&gt;();        for (int i = 0; i &lt; intervals.length; ++i) &#123;            int L = intervals[i][0], R = intervals[i][1];            if (merged.size() == 0 || merged.get(merged.size() - 1)[1] &lt; L) &#123;                merged.add(new int[]&#123;L, R&#125;);            &#125; else &#123;                merged.get(merged.size() - 1)[1] = Math.max(merged.get(merged.size() - 1)[1], R);            &#125;        &#125;        return merged.toArray(new int[merged.size()][]); //List.toArray(array)，注意array是新开辟的未分配的空间    &#125;&#125;\n\nLeetcode 57.插入区间class Solution &#123;    public int[][] insert(int[][] intervals, int[] newInterval) &#123;        int length1 = intervals.length;        int length2 = length1+1;        int [][]ans = new int[length2][2];        for (int i = 0;i&lt;length1;i++)&#123;            ans[i][0]=intervals[i][0];            ans[i][1]=intervals[i][1];        &#125;        ans[length1][0]=newInterval[0];        ans[length1][1]=newInterval[1];        Arrays.sort(ans,new Comparator&lt;int[]&gt;()&#123;            public int compare(int[]nums1,int[] nums2)&#123;                return nums1[0]-nums2[0];            &#125;        &#125;);        List&lt;int[]&gt;ans2 = new ArrayList&lt;int[]&gt;();        for (int i=0;i&lt;length2;i++)&#123;            if (ans2.size()==0||ans2.get(ans2.size()-1)[1]&lt;ans[i][0])&#123;                ans2.add(new int[]&#123;ans[i][0],ans[i][1]&#125;);            &#125;else&#123;                ans2.get(ans2.size()-1)[1]=Math.max(ans[i][1],ans2.get(ans2.size()-1)[1]);            &#125;        &#125;        return ans2.toArray(new int[ans2.size()][]);    &#125;&#125;\n\nLeetcode 452.用最少数量的箭引爆气球注意贪心\nclass Solution &#123;    public int findMinArrowShots(int[][] points) &#123;        int length = points.length;        Arrays.sort(points,(a,b)-&gt;Integer.compare(a[1],b[1]));        List&lt;int[]&gt; ans = new ArrayList();        for (int i =0;i&lt;length;i++)&#123;            if (ans.size()==0||ans.get(ans.size()-1)[1]&lt;points[i][0])&#123;                ans.add(new int[]&#123;points[i][0],points[i][1]&#125;);            &#125;else&#123;               continue;            &#125;        &#125;        return ans.size();    &#125;&#125;\n\n栈Leetcode 71.简化路径注意双端队列Deque用LinkedList来实现，StringBuilder.tostring()转为字符串。\nclass Solution &#123;    public String simplifyPath(String path) &#123;        String []strs = path.split(&quot;/&quot;);        Deque&lt;String&gt;stack = new LinkedList();        for (String str:strs)&#123;            if (&quot;..&quot;.equals(str))&#123;                if (!stack.isEmpty())&#123;                    stack.pollLast();                &#125;            &#125;else if (str.length()&gt;0&amp;&amp;!&quot;.&quot;.equals(str))&#123;                stack.offerLast(str);            &#125;        &#125;        StringBuilder sb = new StringBuilder();        if (stack.isEmpty())&#123;            sb.append(&quot;/&quot;);        &#125;else&#123;            while (!stack.isEmpty())&#123;                sb.append(&quot;/&quot;);                sb.append(stack.pollFirst());            &#125;        &#125;        return sb.toString();    &#125;&#125;\n\nLeetcode 155.最小栈class MinStack &#123;    ArrayList&lt;Integer&gt; stack;    public MinStack() &#123;        this. stack =  new ArrayList();    &#125;        public void push(int val) &#123;        stack.add(val);    &#125;        public void pop() &#123;        stack.remove(stack.size()-1);    &#125;        public int top() &#123;        return stack.get(stack.size()-1).intValue();    &#125;        public int getMin() &#123;          int ans = Integer.MAX_VALUE;        for (Integer num:stack)&#123;            if (num&lt;ans)ans = num;        &#125;        return ans;    &#125;&#125;\n\nLeetcode 150.逆波兰表达式class Solution &#123;    public int evalRPN(String[] tokens) &#123;        Stack&lt;String&gt;stack = new Stack();        for (String str:tokens)&#123;            if (!&quot;+&quot;.equals(str)&amp;&amp;!&quot;-&quot;.equals(str)&amp;&amp;!&quot;*&quot;.equals(str)&amp;&amp;!&quot;/&quot;.equals(str))&#123;                stack.push(str);            &#125;else &#123;                int b = Integer.parseInt(stack.pop());                int a = Integer.parseInt(stack.pop());                if (&quot;+&quot;.equals(str))&#123;                    stack.push(String.valueOf(a+b));                &#125;else if (&quot;-&quot;.equals(str))&#123;                    stack.push(String.valueOf(a-b));                &#125;else if (&quot;*&quot;.equals(str))&#123;                    stack.push(String.valueOf(a*b));                &#125;else if (&quot;/&quot;.equals(str))&#123;                    stack.push(String.valueOf(a/b));                &#125;            &#125;        &#125;        return Integer.parseInt(stack.pop());    &#125;&#125;\n\n链表注意哑结点的构造，很方便！！！\nLeetcode 21.合并两个有序链表class Solution &#123;    public ListNode mergeTwoLists(ListNode l1, ListNode l2) &#123;        ListNode prehead = new ListNode(-1);        ListNode prev = prehead;        while (l1 != null &amp;&amp; l2 != null) &#123;            if (l1.val &lt;= l2.val) &#123;                prev.next = l1;                l1 = l1.next;            &#125; else &#123;                prev.next = l2;                l2 = l2.next;            &#125;            prev = prev.next;        &#125;        // 合并后 l1 和 l2 最多只有一个还未被合并完，我们直接将链表末尾指向未合并完的链表即可        prev.next = l1 == null ? l2 : l1;        return prehead.next;    &#125;&#125;\n\nLeetcode 141.环形链表/** * Definition for singly-linked list. * class ListNode &#123; *     int val; *     ListNode next; *     ListNode(int x) &#123; *         val = x; *         next = null; *     &#125; * &#125; */public class Solution &#123;    public boolean hasCycle(ListNode head) &#123;        ListNode slow =head;        ListNode fast = head;        while(fast!=null&amp;&amp;slow!=null)&#123;            slow=slow.next;            fast = fast.next;            if (fast==null)return false;            fast = fast.next;            if (fast == slow)return true;        &#125;        return false;    &#125;&#125;\n\nLeetcode 2.两数相加class Solution &#123;    public ListNode addTwoNumbers(ListNode l1, ListNode l2) &#123;        ListNode head = null, tail = null;        int carry = 0;        while (l1 != null || l2 != null) &#123;            int n1 = l1 != null ? l1.val : 0;            int n2 = l2 != null ? l2.val : 0;            int sum = n1 + n2 + carry;            if (head == null) &#123;                head = tail = new ListNode(sum % 10);            &#125; else &#123;                tail.next = new ListNode(sum % 10);                tail = tail.next;            &#125;            carry = sum / 10;            if (l1 != null) &#123;                l1 = l1.next;            &#125;            if (l2 != null) &#123;                l2 = l2.next;            &#125;        &#125;        if (carry &gt; 0) &#123;            tail.next = new ListNode(carry);        &#125;        return head;    &#125;&#125;\n\nLeetcode 206.反转链表递归做法\n/** * Definition for singly-linked list. * public class ListNode &#123; *     int val; *     ListNode next; *     ListNode() &#123;&#125; *     ListNode(int val) &#123; this.val = val; &#125; *     ListNode(int val, ListNode next) &#123; this.val = val; this.next = next; &#125; * &#125; */class Solution &#123;    public ListNode reverseList(ListNode head) &#123;        if (head==null||head.next==null)return head;        ListNode newHead = reverseList(head.next);        head.next.next = head;        head.next=null;        return newHead;    &#125;&#125;\n\nLeetcode 92.反转链表2class Solution &#123;    public ListNode reverseBetween(ListNode head, int left, int right) &#123;        // 因为头节点有可能发生变化，使用虚拟头节点可以避免复杂的分类讨论        ListNode dummyNode = new ListNode(-1);        dummyNode.next = head;        ListNode pre = dummyNode;        // 第 1 步：从虚拟头节点走 left - 1 步，来到 left 节点的前一个节点        // 建议写在 for 循环里，语义清晰        for (int i = 0; i &lt; left - 1; i++) &#123;            pre = pre.next;        &#125;        // 第 2 步：从 pre 再走 right - left + 1 步，来到 right 节点        ListNode rightNode = pre;        for (int i = 0; i &lt; right - left + 1; i++) &#123;            rightNode = rightNode.next;        &#125;        // 第 3 步：切断出一个子链表（截取链表）        ListNode leftNode = pre.next;        ListNode curr = rightNode.next;        // 注意：切断链接        pre.next = null;        rightNode.next = null;        // 第 4 步：同第 206 题，反转链表的子区间        reverseLinkedList(leftNode);        // 第 5 步：接回到原来的链表中        pre.next = rightNode;        leftNode.next = curr;        return dummyNode.next;    &#125;    private void reverseLinkedList(ListNode head) &#123;        // 也可以使用递归反转一个链表        ListNode pre = null;        ListNode cur = head;        while (cur != null) &#123;            ListNode next = cur.next;            cur.next = pre;            pre = cur;            cur = next;        &#125;    &#125;&#125;\n\nLeetcode 138.随机链表的复制/*// Definition for a Node.class Node &#123;    int val;    Node next;    Node random;    public Node(int val) &#123;        this.val = val;        this.next = null;        this.random = null;    &#125;&#125;*/class Solution &#123;    Map&lt;Node,Node&gt;map = new HashMap();    public Node copyRandomList(Node head) &#123;        if (head == null)return null;        if (!map.containsKey(head))&#123;            Node newNode = new Node(head.val);            map.put(head,newNode);            newNode.next = copyRandomList(head.next);            newNode.random = copyRandomList(head.random);        &#125;        return map.get(head);    &#125;&#125;\n\nLeetcode 19.删除链表的倒数第N个节点/** * Definition for singly-linked list. * public class ListNode &#123; *     int val; *     ListNode next; *     ListNode() &#123;&#125; *     ListNode(int val) &#123; this.val = val; &#125; *     ListNode(int val, ListNode next) &#123; this.val = val; this.next = next; &#125; * &#125; */class Solution &#123;    public ListNode removeNthFromEnd(ListNode head, int n) &#123;                ListNode currentNode = head;        ArrayList&lt;ListNode&gt; nodes = new ArrayList();         while(currentNode!=null)&#123;            nodes.add(currentNode);            currentNode = currentNode.next;        &#125;        int num = nodes.size();        if (num == 1)return null;        ListNode pre = new ListNode(-1,head);        currentNode = pre;        for (int i=1;i&lt;num-n+1;i++)&#123;            currentNode = currentNode.next;        &#125;        currentNode.next=currentNode.next.next;        return pre.next;    &#125;&#125;\n\nLeetcode 82.删除排序链表中的重复元素2class Solution &#123;    public ListNode deleteDuplicates(ListNode head) &#123;        if (head == null) &#123;            return head;        &#125;                ListNode dummy = new ListNode(0, head);        ListNode cur = dummy;        while (cur.next != null &amp;&amp; cur.next.next != null) &#123;            if (cur.next.val == cur.next.next.val) &#123;                int x = cur.next.val;                while (cur.next != null &amp;&amp; cur.next.val == x) &#123;                    cur.next = cur.next.next;                &#125;            &#125; else &#123;                cur = cur.next;            &#125;        &#125;        return dummy.next;    &#125;&#125;\n\nLeetcode 61.旋转链表/** * Definition for singly-linked list. * public class ListNode &#123; *     int val; *     ListNode next; *     ListNode() &#123;&#125; *     ListNode(int val) &#123; this.val = val; &#125; *     ListNode(int val, ListNode next) &#123; this.val = val; this.next = next; &#125; * &#125; */class Solution &#123;    public ListNode rotateRight(ListNode head, int k) &#123;        ArrayList&lt;ListNode&gt; nodes = new ArrayList();        ListNode dumbNode = new ListNode(-111,head);        ListNode cur = head;        while(cur!=null)&#123;            nodes.add(cur);            cur=cur.next;        &#125;        int num = nodes.size();        if (num==0)return head;        k = k%num;        if (k==0)return head;        int preOrder = num-k-1;        cur = dumbNode;        for (int i = 0;i&lt;=preOrder;i++)&#123;            cur = cur.next;        &#125;        ListNode preNode = cur;        ListNode next =preNode.next;        ListNode last = next;        while(last!=null)&#123;            if (last.next==null)break;            last = last.next;        &#125;        dumbNode.next = next;        last.next = head;        preNode.next = null;        return dumbNode.next;    &#125;&#125;\n\nLeetcode 146.LRU缓存直接继承LinkedHashMap\nclass LRUCache extends LinkedHashMap&lt;Integer, Integer&gt;&#123;    private int capacity;        public LRUCache(int capacity) &#123;        super(capacity, 0.75F, true);        this.capacity = capacity;    &#125;    public int get(int key) &#123;        return super.getOrDefault(key, -1);    &#125;    public void put(int key, int value) &#123;        super.put(key, value);    &#125;    @Override    protected boolean removeEldestEntry(Map.Entry&lt;Integer, Integer&gt; eldest) &#123;        return size() &gt; capacity;     &#125;&#125;\n\n哈希+双链表\npublic class LRUCache &#123;    class DLinkedNode &#123;        int key;        int value;        DLinkedNode prev;        DLinkedNode next;        public DLinkedNode() &#123;&#125;        public DLinkedNode(int _key, int _value) &#123;key = _key; value = _value;&#125;    &#125;    private Map&lt;Integer, DLinkedNode&gt; cache = new HashMap&lt;Integer, DLinkedNode&gt;();    private int size;    private int capacity;    private DLinkedNode head, tail;    public LRUCache(int capacity) &#123;        this.size = 0;        this.capacity = capacity;        // 使用伪头部和伪尾部节点        head = new DLinkedNode();        tail = new DLinkedNode();        head.next = tail;        tail.prev = head;    &#125;    public int get(int key) &#123;        DLinkedNode node = cache.get(key);        if (node == null) &#123;            return -1;        &#125;        // 如果 key 存在，先通过哈希表定位，再移到头部        moveToHead(node);        return node.value;    &#125;    public void put(int key, int value) &#123;        DLinkedNode node = cache.get(key);        if (node == null) &#123;            // 如果 key 不存在，创建一个新的节点            DLinkedNode newNode = new DLinkedNode(key, value);            // 添加进哈希表            cache.put(key, newNode);            // 添加至双向链表的头部            addToHead(newNode);            ++size;            if (size &gt; capacity) &#123;                // 如果超出容量，删除双向链表的尾部节点                DLinkedNode tail = removeTail();                // 删除哈希表中对应的项                cache.remove(tail.key);                --size;            &#125;        &#125;        else &#123;            // 如果 key 存在，先通过哈希表定位，再修改 value，并移到头部            node.value = value;            moveToHead(node);        &#125;    &#125;    private void addToHead(DLinkedNode node) &#123;        node.prev = head;        node.next = head.next;        head.next.prev = node;        head.next = node;    &#125;    private void removeNode(DLinkedNode node) &#123;        node.prev.next = node.next;        node.next.prev = node.prev;    &#125;    private void moveToHead(DLinkedNode node) &#123;        removeNode(node);        addToHead(node);    &#125;    private DLinkedNode removeTail() &#123;        DLinkedNode res = tail.prev;        removeNode(res);        return res;    &#125;&#125;\n\n二分查找Leetcode 35.搜索插入位置class Solution &#123;    public int searchInsert(int[] nums, int target) &#123;        int start = 0;        int end = nums.length-1;        int ans=nums.length;        if (nums[0]&gt;=target)return 0;        while(start&lt;=end)&#123;            int mid = (end-start)/2+start;            if (nums[mid]&gt;=target)&#123;                end =mid-1;                ans =mid;            &#125;else&#123;                start =mid+1;            &#125;        &#125;        return ans;    &#125;&#125;\n\nLeetcode 74.搜索二维矩阵class Solution &#123;    public boolean searchMatrix(int[][] matrix, int target) &#123;        int m = matrix.length;        int n = matrix[0].length;        for (int i=0;i&lt;m;i++)&#123;            if (target&gt;matrix[i][n-1])continue;            for (int j=0;j&lt;n;j++)&#123;                if (matrix[i][j]==target)return true;            &#125;            return false;        &#125;        return false;    &#125; &#125;\n\nLeetcode 200.岛屿数量常规的dfs,甚至不用回溯\nclass Solution &#123;    void dfs(char[][] grid, int r, int c) &#123;        int nr = grid.length;        int nc = grid[0].length;        if (r &lt; 0 || c &lt; 0 || r &gt;= nr || c &gt;= nc || grid[r][c] == &#x27;0&#x27;) &#123;            return;        &#125;        grid[r][c] = &#x27;0&#x27;;        dfs(grid, r - 1, c);        dfs(grid, r + 1, c);        dfs(grid, r, c - 1);        dfs(grid, r, c + 1);    &#125;    public int numIslands(char[][] grid) &#123;        if (grid == null || grid.length == 0) &#123;            return 0;        &#125;        int nr = grid.length;        int nc = grid[0].length;        int num_islands = 0;        for (int r = 0; r &lt; nr; ++r) &#123;            for (int c = 0; c &lt; nc; ++c) &#123;                if (grid[r][c] == &#x27;1&#x27;) &#123;                    ++num_islands;                    dfs(grid, r, c);                &#125;            &#125;        &#125;        return num_islands;    &#125;&#125;\n\nLeetcode 130.被围绕的区域class Solution &#123;    public void solve(char[][] board) &#123;        int m = board.length;        int n = board[0].length;        for (int i=0;i&lt;m;i++)&#123;            dfs(board,i,0);            dfs(board,i,n-1);        &#125;        for (int i=0;i&lt;n;i++)&#123;            dfs(board,0,i);            dfs(board,m-1,i);        &#125;        for (int i=0;i&lt;m;i++)&#123;            for(int j=0;j&lt;n;j++)&#123;                if (board[i][j]==&#x27;V&#x27;)board[i][j]=&#x27;O&#x27;;                  else if(board[i][j]==&#x27;O&#x27;)&#123;                    board[i][j]=&#x27;X&#x27;;                &#125;              &#125;        &#125;    &#125;    public void dfs(char[][]board,int x, int y)&#123;        if (x&lt;0||y&lt;0||x&gt;=board.length||y&gt;=board[0].length||board[x][y]!=&#x27;O&#x27;)return;        board[x][y]=&#x27;V&#x27;;        dfs(board,x+1,y);        dfs(board,x,y+1);        dfs(board,x-1,y);        dfs(board,x,y-1);    &#125;&#125;\n\nLeetcode 2576.求出最多标记下标class Solution &#123;public:    int maxNumOfMarkedIndices(vector&lt;int&gt;&amp; nums) &#123;        sort(nums.begin(), nums.end());        int n = nums.size();        int m = n / 2;        int res = 0;        for (int i = 0, j = m; i &lt; m &amp;&amp; j &lt; n; i++) &#123;            while (j &lt; n &amp;&amp; 2 * nums[i] &gt; nums[j]) &#123;                j++;            &#125;            if (j &lt; n) &#123;                res += 2;                j++;            &#125;        &#125;        return res;    &#125;&#125;;\n\nLeetcode 300.最长递增子序列会用到二分查找,nlogn复杂度\nclass Solution &#123;    public int lengthOfLIS(int[] nums) &#123;        int len = 1, n = nums.length;        if (n == 0) &#123;            return 0;        &#125;        int[] d = new int[n + 1];        d[len] = nums[0];        for (int i = 1; i &lt; n; ++i) &#123;            if (nums[i] &gt; d[len]) &#123;                d[++len] = nums[i];            &#125; else &#123;                int l = 1, r = len, pos = 0; // 如果找不到说明所有的数都比 nums[i] 大，此时要更新 d[1]，所以这里将 pos 设为 0                while (l &lt;= r) &#123;                    int mid = (l + r) &gt;&gt; 1;                    if (d[mid] &lt; nums[i]) &#123;                        pos = mid;                        l = mid + 1;                    &#125; else &#123;                        r = mid - 1;                    &#125;                &#125;                d[pos + 1] = nums[i];            &#125;        &#125;        return len;    &#125;&#125;\n\n\n\n拓扑排序Leetcode 115.序列重建证明挺精彩的\nclass Solution &#123;    public boolean sequenceReconstruction(int[] nums, int[][] sequences) &#123;        int n = nums.length;        int[] indegrees = new int[n + 1];        Set&lt;Integer&gt;[] graph = new Set[n + 1];        for (int i = 1; i &lt;= n; i++) &#123;            graph[i] = new HashSet&lt;Integer&gt;();        &#125;        for (int[] sequence : sequences) &#123;            int size = sequence.length;            for (int i = 1; i &lt; size; i++) &#123;                int prev = sequence[i - 1], next = sequence[i];                if (graph[prev].add(next)) &#123;                    indegrees[next]++;                &#125;            &#125;        &#125;        Queue&lt;Integer&gt; queue = new ArrayDeque&lt;Integer&gt;();        for (int i = 1; i &lt;= n; i++) &#123;            if (indegrees[i] == 0) &#123;                queue.offer(i);            &#125;        &#125;        while (!queue.isEmpty()) &#123;            if (queue.size() &gt; 1) &#123;                return false;            &#125;            int num = queue.poll();            Set&lt;Integer&gt; set = graph[num];            for (int next : set) &#123;                indegrees[next]--;                if (indegrees[next] == 0) &#123;                    queue.offer(next);                &#125;            &#125;        &#125;        return true;    &#125;&#125;\n\n二叉树Leetcode 226.翻转二叉树class Solution &#123;    public TreeNode invertTree(TreeNode root) &#123;        if (root==null)return root;        TreeNode temp=root.left;        root.left = root.right;        root.right = temp;        invertTree(root.left);        invertTree(root.right);        return root;    &#125;&#125;\n\nLeetcode 104.二叉树的最大深度class Solution &#123;    public TreeNode invertTree(TreeNode root) &#123;        if (root==null)return root;        TreeNode temp=root.left;        root.left = root.right;        root.right = temp;        invertTree(root.left);        invertTree(root.right);        return root;    &#125;&#125;\n\nLeetcode 100.相同的树class Solution &#123;    boolean flag =true;    public boolean isSameTree(TreeNode p, TreeNode q) &#123;        findIsSameTree(p,q);        return flag;    &#125;    public void findIsSameTree(TreeNode p,  TreeNode q)&#123;        if (p!=null&amp;&amp;q!=null)&#123;            findIsSameTree(p.left,q.left);            findIsSameTree(p.right,q.right);        &#125;            if (p!=null&amp;&amp;q!=null)&#123;            if (p.val==q.val)&#123;                return;            &#125;else&#123;                flag =false;            &#125;        &#125;else if(p==null&amp;&amp;q==null)&#123;            return;        &#125;else&#123;            flag =false;        &#125;    &#125;&#125;\n\nLeetcode 101.对称二叉树/** * Definition for a binary tree node. * public class TreeNode &#123; *     int val; *     TreeNode left; *     TreeNode right; *     TreeNode() &#123;&#125; *     TreeNode(int val) &#123; this.val = val; &#125; *     TreeNode(int val, TreeNode left, TreeNode right) &#123; *         this.val = val; *         this.left = left; *         this.right = right; *     &#125; * &#125; */class Solution &#123;    boolean flag =true;    public boolean isSymmetric(TreeNode root) &#123;        findIsSymmetric(root,root);        return flag;    &#125;    public void findIsSymmetric(TreeNode a,TreeNode b)&#123;        if (a==null&amp;&amp;b==null)&#123;            return;        &#125;else if (a!=null&amp;&amp;b!=null)&#123;            if (a.val!=b.val)flag =false;            findIsSymmetric(a.left,b.right);            findIsSymmetric(a.right,b.left);        &#125;else&#123;            flag=false;        &#125;    &#125;&#125;\n\nLeetcode 105.从前序和中序遍历序列构造二叉树/* 构建二叉树：分治 */TreeNode dfs(int[] preorder, Map&lt;Integer, Integer&gt; inorderMap, int i, int l, int r) &#123;    // 子树区间为空时终止    if (r - l &lt; 0)        return null;    // 初始化根节点    TreeNode root = new TreeNode(preorder[i]);    // 查询 m ，从而划分左右子树    int m = inorderMap.get(preorder[i]);    // 子问题：构建左子树    root.left = dfs(preorder, inorderMap, i + 1, l, m - 1);    // 子问题：构建右子树    root.right = dfs(preorder, inorderMap, i + 1 + m - l, m + 1, r);    //构建右子树稍微复杂一些。首先，需要确定右子树的根节点在前序遍历中的位置。由于左子树的根节点之后的所有元素都属于右子树，所以右子树的根节点在前序遍历中的位置是 i + 1 + (m - l)。这里的 m - l 表示左子树的大小，即左子树有多少个节点。    // 返回根节点    return root;&#125;/* 构建二叉树 */TreeNode buildTree(int[] preorder, int[] inorder) &#123;    // 初始化哈希表，存储 inorder 元素到索引的映射    Map&lt;Integer, Integer&gt; inorderMap = new HashMap&lt;&gt;();    for (int i = 0; i &lt; inorder.length; i++) &#123;        inorderMap.put(inorder[i], i);    &#125;    TreeNode root = dfs(preorder, inorderMap, 0, 0, inorder.length - 1);    return root;&#125;\n\n\n\nLeetcode 106.从中序和后序遍历序列构造二叉树class Solution &#123;    public TreeNode buildTree(int[] inorder, int[] postorder) &#123;        Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;();        int length = inorder.length;        for (int i = 0; i &lt; length; i++) &#123;            map.put(inorder[i], i);        &#125;        return dfs(inorder, postorder, map, 0, length - 1, length - 1);    &#125;    public TreeNode dfs(int[] inorder, int[] postorder, Map&lt;Integer, Integer&gt; map, int left, int right, int index) &#123;        if (left &gt; right) &#123;            return null;        &#125;        int val = postorder[index];        int mid = map.get(val);        TreeNode node = new TreeNode(val);        node.right = dfs(inorder, postorder, map, mid + 1, right, index-1);        node.left = dfs(inorder, postorder, map, left, mid - 1, index-1-(right-mid));        return node;    &#125;&#125;\n\n判断是不是二叉平衡树/** * Definition for a binary tree node. * public class TreeNode &#123; *     int val; *     TreeNode left; *     TreeNode right; *     TreeNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123;    public boolean isBalanced(TreeNode root) &#123;        if(root == null)    return true;        //求左子树的深度        int left = deepFind(root.left);        //求右子树的深度        int right = deepFind(root.right);        //判断每个节点是否满足平衡二叉树的定义，全部都是，才是真正的平衡二叉树        return (Math.abs(left - right) &lt; 2 ? true : false) &amp;&amp; isBalanced(root.left) &amp;&amp; isBalanced(root.right);    &#125;\t\t//判断一棵树的深度    public int deepFind(TreeNode node)&#123;        if(node == null)    return 0;        return Math.max(deepFind(node.left), deepFind(node.right))+1;    &#125;&#125;\n\nLeetcode 129.求根节点到叶节点数字之和class Solution &#123;    int sum = 0;    public int sumNumbers(TreeNode root) &#123;        StringBuilder sb = new StringBuilder(&quot;&quot;);        getSum(root,sb);        return sum;    &#125;    public void getSum(TreeNode node,StringBuilder sb)&#123;        if (node==null)return;        //不为空        StringBuilder sb2 = new StringBuilder();        String num = String.valueOf(node.val);        sb2.append(sb.toString());        sb2.append(num);        if (node.left==null&amp;&amp;node.right==null)&#123;            System.out.println(sb2.toString());            sum+=Integer.parseInt(sb2.toString());        &#125;        getSum(node.left,sb2);        getSum(node.right,sb2);    &#125;&#125;\n\nLeetcode 199.二叉树的右视图class Solution &#123;    public List&lt;Integer&gt; rightSideView(TreeNode root) &#123;        List&lt;Integer&gt;ans = new ArrayList&lt;Integer&gt;();        Queue&lt;TreeNode&gt;tq = new LinkedList();        Queue&lt;Integer&gt;depthQueue = new LinkedList();        Map&lt;Integer,Integer&gt;map = new HashMap();        tq.add(root);        depthQueue.add(0);        int maxDepth = -1;        while(!tq.isEmpty())&#123;            TreeNode node = tq.poll();            int depth = depthQueue.poll();            if (node!=null)&#123;                maxDepth = Math.max(maxDepth,depth);                map.put(depth,node.val);                tq.add(node.left);                tq.add(node.right);                depthQueue.add(depth+1);                depthQueue.add(depth+1);            &#125;        &#125;        for (int i=0;i&lt;=maxDepth;i++)&#123;            ans.add(map.get(i));        &#125;        return ans;    &#125;&#125;\n\nLeetcode 117.填充每个节点的下一个右侧节点指针2class Solution &#123;    public Node connect(Node root) &#123;        Map&lt;Integer,List&lt;Node&gt;&gt;map = new HashMap();        Queue&lt;Node&gt; nodeQueue = new LinkedList();        Queue&lt;Integer&gt; depthQueue = new LinkedList();        int maxDepth = -1;        nodeQueue.add(root);        depthQueue.add(0);        while(!nodeQueue.isEmpty())&#123;            Node node = nodeQueue.poll();            int depth = depthQueue.poll();            if (node !=null)&#123;                maxDepth = Math.max(depth,maxDepth);                if (!map.containsKey(depth))&#123;                    List&lt;Node&gt;nodeList = new LinkedList();                    nodeList.add(node);                    map.put(depth,nodeList);                &#125;else&#123;                    map.get(depth).add(node);                &#125;                nodeQueue.add(node.left);                nodeQueue.add(node.right);                depthQueue.add(depth+1);                depthQueue.add(depth+1);            &#125;        &#125;        for (int depth=0;depth&lt;=maxDepth;depth++)&#123;            if (map.get(depth).size()==1)continue;            int size=map.get(depth).size();            for (int index=0;index&lt;size-1;index++)&#123;                map.get(depth).get(index).next=map.get(depth).get(index+1);            &#125;        &#125;        return root;    &#125;&#125;\n\nLeetcode 114.二叉树展开为链表class Solution &#123;    public void flatten(TreeNode root) &#123;        Queue&lt;TreeNode&gt; q = new LinkedList();        q=getPreQueue(root,q);        while(!q.isEmpty())&#123;            TreeNode node = q.poll();            if (q.size()==0)break;            node.left = null;            node.right = q.peek();        &#125;    &#125;    public Queue&lt;TreeNode&gt; getPreQueue(TreeNode node,Queue&lt;TreeNode&gt; q)&#123;        if (node!=null)&#123;            q.add(node);            getPreQueue(node.left,q);            getPreQueue(node.right,q);        &#125;                return q;    &#125;&#125;\n\nLeetcode 230.二叉搜索树中第K小的元素class Solution &#123;    public int kthSmallest(TreeNode root, int k) &#123;        Queue&lt;TreeNode&gt;q = new LinkedList();        q = addToQueue(root,q);        while(k--&gt;0)&#123;            if (k==0)return q.peek().val;            q.poll();        &#125;        return -1;    &#125;    public Queue&lt;TreeNode&gt; addToQueue(TreeNode node,Queue&lt;TreeNode&gt;q)&#123;        if (node!=null)&#123;            addToQueue(node.left,q);            q.add(node);            addToQueue(node.right,q);        &#125;        return q;    &#125;&#125;\n\nLeetcode 98.验证二叉搜索树class Solution &#123;    public boolean isValidBST(TreeNode root) &#123;        Queue&lt;TreeNode&gt;q = new LinkedList();        q = addToQueue(root,q);        while(!q.isEmpty())&#123;            TreeNode node = q.poll();            if (q.size()==0)return true;            if (node.val&gt;=q.peek().val)return false;        &#125;        return true;    &#125;    public Queue&lt;TreeNode&gt; addToQueue(TreeNode node,Queue&lt;TreeNode&gt;q)&#123;        if (node!=null)&#123;            addToQueue(node.left,q);            q.add(node);            addToQueue(node.right,q);        &#125;        return q;    &#125;&#125;\n\nLeetcode 112.路径总和/** * Definition for a binary tree node. * public class TreeNode &#123; *     int val; *     TreeNode left; *     TreeNode right; *     TreeNode() &#123;&#125; *     TreeNode(int val) &#123; this.val = val; &#125; *     TreeNode(int val, TreeNode left, TreeNode right) &#123; *         this.val = val; *         this.left = left; *         this.right = right; *     &#125; * &#125; */class Solution &#123;    boolean flag = false;    public boolean hasPathSum(TreeNode root, int targetSum) &#123;        judgeDFS(root,0,targetSum);        return flag;    &#125;    public void judgeDFS(TreeNode node,int currentNum,int targetSum)&#123;        if (node!=null)&#123;            currentNum+=node.val;            if (currentNum==targetSum&amp;&amp;node.left==null&amp;&amp;node.right==null)flag = true;            judgeDFS(node.left,currentNum,targetSum);            judgeDFS(node.right,currentNum,targetSum);        &#125;    &#125;&#125;\n\nLeetcode 173.二叉搜索树迭代器class BSTIterator &#123;    int currentIndex = -1;    List&lt;TreeNode&gt; nodeList = new ArrayList();     public BSTIterator(TreeNode root) &#123;        midOrder(root);    &#125;    public void midOrder(TreeNode node)&#123;        if (node==null)return;        midOrder(node.left);        nodeList.add(node);        midOrder(node.right);    &#125;        public int next() &#123;        currentIndex++;        return nodeList.get(currentIndex).val;    &#125;        public boolean hasNext() &#123;        int nextIndex = currentIndex+1;        return nextIndex&lt;nodeList.size();    &#125;&#125;\n\nLeetcode 222.完全二叉树的节点个数class Solution &#123;    int count=0;    public int countNodes(TreeNode root) &#123;        getCount(root);        return count;    &#125;    public void getCount(TreeNode node)&#123;        if (node==null)return;        count++;        getCount(node.left);        getCount(node.right);    &#125;&#125;\n\nLeetcode 236.二叉树的最近公共祖先class Solution &#123;    Map&lt;TreeNode,TreeNode&gt;fatherMap = new HashMap();    Map&lt;TreeNode,Integer&gt;depthMap = new HashMap();    int depth=0;    public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) &#123;        getMap(root);        Queue&lt;TreeNode&gt;queue = new LinkedList();        Queue&lt;Integer&gt;queue2 = new LinkedList();        queue.add(root);        queue2.add(depth);        while(!queue.isEmpty())&#123;            TreeNode node = queue.poll();            int depth = queue2.poll();            if (node!=null)&#123;                depthMap.put(node,depth);                queue.add(node.left);                queue.add(node.right);                queue2.add(depth+1);                queue2.add(depth+1);            &#125;        &#125;        int depth1 = depthMap.get(p);        int depth2 = depthMap.get(q);        TreeNode ans = null;        TreeNode p1 = p;        TreeNode q1 = q;        if (depth1==depth2)&#123;            while(true)&#123;                TreeNode father1 = fatherMap.get(p1);                TreeNode father2 = fatherMap.get(q1);                if (father1==father2)&#123;                    ans = father1;                    return ans;                &#125;                p1 = father1;                q1 = father2;            &#125;        &#125;else &#123;            int gap = Math.abs(depth1-depth2);            if (depth1&gt;depth2)&#123;                for (int i=0;i&lt;gap;i++)&#123;                    p1=fatherMap.get(p1);                &#125;                //此时depth相等;                //若已经相同                if (p1==q1)return p1;                while(true)&#123;                TreeNode father1 = fatherMap.get(p1);                TreeNode father2 = fatherMap.get(q1);                if (father1==father2)&#123;                    ans = father1;                    return ans;                    &#125;                p1 = father1;                q1 = father2;                &#125;            &#125;else&#123;                for (int i=0;i&lt;gap;i++)&#123;                    q1=fatherMap.get(q1);                &#125;                //此时depth相等;                //若已经相同                if (p1==q1)return p1;                while(true)&#123;                TreeNode father1 = fatherMap.get(p1);                TreeNode father2 = fatherMap.get(q1);                if (father1==father2)&#123;                    ans = father1;                    return ans;                    &#125;                p1 = father1;                q1 = father2;                &#125;            &#125;        &#125;            // return ans;        &#125;        public void getMap(TreeNode node)&#123;        if (node ==null)return;        if (node.left!=null)fatherMap.put(node.left,node);        if (node.right!=null)fatherMap.put(node.right,node);        getMap(node.left);        getMap(node.right);    &#125;    &#125;\n\n递归的做法\nclass Solution &#123;    private TreeNode ans;    public Solution() &#123;        this.ans = null;    &#125;    private boolean dfs(TreeNode root, TreeNode p, TreeNode q) &#123;        if (root == null) return false;        boolean lson = dfs(root.left, p, q);        boolean rson = dfs(root.right, p, q);        if ((lson &amp;&amp; rson) || ((root.val == p.val || root.val == q.val) &amp;&amp; (lson || rson))) &#123;            ans = root;        &#125;         return lson || rson || (root.val == p.val || root.val == q.val);    &#125;    public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) &#123;        this.dfs(root, p, q);        return this.ans;    &#125;&#125;\n\n\n\nLeetcode 102.二叉树的层序遍历class Solution &#123;        public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123;        Map&lt;Integer,List&lt;Integer&gt;&gt; depthNodeListMap = new HashMap();        Queue&lt;TreeNode&gt; nodeQueue = new LinkedList();        Queue&lt;Integer&gt; depthQueue = new LinkedList();        List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;List&lt;Integer&gt;&gt;();        if (root==null)return ans;        int firstDepth = 0;        nodeQueue.add(root);        depthQueue.add(firstDepth);        int maxDepth = -1;        while(!nodeQueue.isEmpty())&#123;            TreeNode node =nodeQueue.poll();            int depth  = depthQueue.poll();            if (node!=null)&#123;                maxDepth = Math.max(depth,maxDepth);                if (!depthNodeListMap.containsKey(depth))&#123;                    List&lt;Integer&gt; list= new ArrayList();                    depthNodeListMap.put(depth,list);                &#125;                depthNodeListMap.get(depth).add(node.val);                nodeQueue.add(node.left);                nodeQueue.add(node.right);                depthQueue.add(depth+1);                depthQueue.add(depth+1);            &#125;        &#125;                for (int depth=0;depth&lt;=maxDepth;depth++)&#123;            ans.add(depthNodeListMap.get(depth));        &#125;        return ans;    &#125;&#125;\n\nLeetcode 427.建立四叉树官方题解\n/*// Definition for a QuadTree node.class Node &#123;    public boolean val;    public boolean isLeaf;    public Node topLeft;    public Node topRight;    public Node bottomLeft;    public Node bottomRight;        public Node() &#123;        this.val = false;        this.isLeaf = false;        this.topLeft = null;        this.topRight = null;        this.bottomLeft = null;        this.bottomRight = null;    &#125;        public Node(boolean val, boolean isLeaf) &#123;        this.val = val;        this.isLeaf = isLeaf;        this.topLeft = null;        this.topRight = null;        this.bottomLeft = null;        this.bottomRight = null;    &#125;        public Node(boolean val, boolean isLeaf, Node topLeft, Node topRight, Node bottomLeft, Node bottomRight) &#123;        this.val = val;        this.isLeaf = isLeaf;        this.topLeft = topLeft;        this.topRight = topRight;        this.bottomLeft = bottomLeft;        this.bottomRight = bottomRight;    &#125;&#125;*/class Solution &#123;    public Node construct(int[][] grid) &#123;        return dfs(grid, 0, 0, grid.length, grid.length);    &#125;    public Node dfs(int[][] grid, int r0, int c0, int r1, int c1) &#123;        boolean same = true;        for (int i = r0; i &lt; r1; ++i) &#123;            for (int j = c0; j &lt; c1; ++j) &#123;                if (grid[i][j] != grid[r0][c0]) &#123;                    same = false;                    break;                &#125;            &#125;            if (!same) &#123;                break;            &#125;        &#125;\t\t//全相同即为叶子结点        if (same) &#123;            return new Node(grid[r0][c0] == 1, true);        &#125;\t\t//否则递归返回        Node ret = new Node(            true,            false,            dfs(grid, r0, c0, (r0 + r1) / 2, (c0 + c1) / 2),            dfs(grid, r0, (c0 + c1) / 2, (r0 + r1) / 2, c1),            dfs(grid, (r0 + r1) / 2, c0, r1, (c0 + c1) / 2),            dfs(grid, (r0 + r1) / 2, (c0 + c1) / 2, r1, c1)        );        return ret;    &#125;&#125;\n\nLeetcode 124.二叉树中的最大路径和/** * Definition for a binary tree node. * public class TreeNode &#123; *     int val; *     TreeNode left; *     TreeNode right; *     TreeNode() &#123;&#125; *     TreeNode(int val) &#123; this.val = val; &#125; *     TreeNode(int val, TreeNode left, TreeNode right) &#123; *         this.val = val; *         this.left = left; *         this.right = right; *     &#125; * &#125; */class Solution &#123;    public int ans = Integer.MIN_VALUE;    public int maxPathSum(TreeNode root) &#123;        getAns(root);        return ans;    &#125;    public int getAns(TreeNode node)&#123;        if (node==null)return 0;        int leftMax = Math.max(getAns(node.left),0);        int rightMax = Math.max(getAns(node.right),0);        int currentNum = node.val + leftMax + rightMax;        ans = Math.max(ans,currentNum);        //返回最大的子节点        return node.val+Math.max(rightMax,leftMax);    &#125;&#125;\n\nLeetcode 637.二叉树的层平均值/** * Definition for a binary tree node. * public class TreeNode &#123; *     int val; *     TreeNode left; *     TreeNode right; *     TreeNode() &#123;&#125; *     TreeNode(int val) &#123; this.val = val; &#125; *     TreeNode(int val, TreeNode left, TreeNode right) &#123; *         this.val = val; *         this.left = left; *         this.right = right; *     &#125; * &#125; */class Solution &#123;    int maxDepth = -1;    public List&lt;Double&gt; averageOfLevels(TreeNode root) &#123;        List&lt;Double&gt;ans = new ArrayList();        Queue&lt;TreeNode&gt;q = new LinkedList();        Queue&lt;Integer&gt; depthQ = new LinkedList();        Map&lt;Integer,List&lt;TreeNode&gt;&gt; map = new HashMap();        q.add(root);        depthQ.add(0);        while(!q.isEmpty())&#123;            TreeNode node = q.poll();            int depth = depthQ.poll();            if (node!=null)&#123;                maxDepth = Math.max(maxDepth,depth);                List&lt;TreeNode&gt; nodeList = map.getOrDefault(depth,new  ArrayList&lt;TreeNode&gt;());                nodeList.add(node);                map.put(depth,nodeList);                q.add(node.left);                q.add(node.right);                depthQ.add(depth+1);                depthQ.add(depth+1);            &#125;        &#125;        for (int i =0;i&lt;=maxDepth;i++)&#123;            List&lt;TreeNode&gt; nodeList = map.get(i);            if (nodeList!=null)            ans.add(getAverage(nodeList));        &#125;        return ans;    &#125;    public double getAverage(List&lt;TreeNode&gt; nodeList)&#123;        int size= nodeList.size();        double sum = 0;        for (TreeNode node:nodeList)&#123;            sum =sum+node.val;        &#125;        return sum/size;    &#125;&#125;\n\nLeetcode 103.二叉树的锯齿形层序遍历/** * Definition for a binary tree node. * public class TreeNode &#123; *     int val; *     TreeNode left; *     TreeNode right; *     TreeNode() &#123;&#125; *     TreeNode(int val) &#123; this.val = val; &#125; *     TreeNode(int val, TreeNode left, TreeNode right) &#123; *         this.val = val; *         this.left = left; *         this.right = right; *     &#125; * &#125; */class Solution &#123;    int maxDepth =-1;    public List&lt;List&lt;Integer&gt;&gt; zigzagLevelOrder(TreeNode root) &#123;        List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;List&lt;Integer&gt;&gt;();        Queue&lt;TreeNode&gt;q = new LinkedList();        Map&lt;Integer,List&lt;Integer&gt;&gt;map = new HashMap();        Queue&lt;Integer&gt; depthQ = new LinkedList();        q.add(root);        depthQ.add(0);        while(!q.isEmpty())&#123;            TreeNode node = q.poll();            int depth = depthQ.poll();            if (node!=null)&#123;                maxDepth = Math.max(depth,maxDepth);                List&lt;Integer&gt;list = map.getOrDefault(depth,new ArrayList&lt;Integer&gt;());                list.add(node.val);                map.put(depth,list);                q.add(node.left);                q.add(node.right);                depthQ.add(depth+1);                depthQ.add(depth+1);            &#125;        &#125;        for (int i=0;i&lt;=maxDepth;i++)&#123;            List&lt;Integer&gt;list = map.get(i);            if (i%2==0)&#123;                ans.add(list);            &#125;else&#123;                Collections.reverse(list);                ans.add(list);            &#125;        &#125;        return ans;    &#125;&#125;\n\nLeetcode 530.二叉搜索树的最小绝对差/** * Definition for a binary tree node. * public class TreeNode &#123; *     int val; *     TreeNode left; *     TreeNode right; *     TreeNode() &#123;&#125; *     TreeNode(int val) &#123; this.val = val; &#125; *     TreeNode(int val, TreeNode left, TreeNode right) &#123; *         this.val = val; *         this.left = left; *         this.right = right; *     &#125; * &#125; */class Solution &#123;    Queue&lt;Integer&gt;q = new PriorityQueue&lt;Integer&gt;((a,b)-&gt;a-b);    public int getMinimumDifference(TreeNode root) &#123;        preOrder(root);        int ans = Integer.MAX_VALUE;        while (!q.isEmpty())&#123;            int a = q.poll();            if (q.isEmpty())break;            int b = q.peek();            ans = Math.min(ans,Math.abs(a-b));        &#125;        return ans;    &#125;    public void preOrder(TreeNode node)&#123;        if (node==null)return;        q.add(node.val);        preOrder(node.left);        preOrder(node.right);    &#125;&#125;\n\n\n\n堆Leetcode 373.查找和最小的K对数字class Solution &#123;    public List&lt;List&lt;Integer&gt;&gt; kSmallestPairs(int[] nums1, int[] nums2, int k) &#123;        PriorityQueue&lt;int[]&gt; pq = new PriorityQueue&lt;&gt;(k, (o1, o2)-&gt;&#123;            return nums1[o1[0]] + nums2[o1[1]] - nums1[o2[0]] - nums2[o2[1]];        &#125;);        List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;();        int m = nums1.length;        int n = nums2.length;        for (int i = 0; i &lt; Math.min(m, k); i++) &#123;            pq.offer(new int[]&#123;i,0&#125;);        &#125;        while (k-- &gt; 0 &amp;&amp; !pq.isEmpty()) &#123;            int[] idxPair = pq.poll();            List&lt;Integer&gt; list = new ArrayList&lt;&gt;();            list.add(nums1[idxPair[0]]);            list.add(nums2[idxPair[1]]);            ans.add(list);            if (idxPair[1] + 1 &lt; n) &#123;                pq.offer(new int[]&#123;idxPair[0], idxPair[1] + 1&#125;);            &#125;        &#125;                return ans;    &#125;&#125;\n\nLeetcode 215.数组中的第K个最大元素class Solution &#123;    public int findKthLargest(int[] nums, int k) &#123;        Queue&lt;Integer&gt;q = new PriorityQueue(new Comparator&lt;Integer&gt;()&#123;            public int compare(Integer a,Integer b)&#123;                return b-a;            &#125;        &#125;);        for (int num:nums)&#123;            q.add(num);        &#125;        while(k--&gt;0)&#123;            if (k==0)return q.poll();            q.poll();        &#125;        return 0;    &#125;&#125;\n\n\n\n数学Leetcode 201.数字范围按位与class Solution &#123;    public int rangeBitwiseAnd(int left, int right) &#123;        int move = 0;        int m=left;        int n=right;        while (m!=n)&#123;            m=m&gt;&gt;1;            n=n&gt;&gt;1;            move++;        &#125;        return m&lt;&lt;move;    &#125;&#125;\n\nKadane算法Leetcode 53.最大子数组和常规用前缀和会超时\n//超时class Solution &#123;    public int maxSubArray(int[] nums) &#123;        int length = nums.length;        int prefixSum[] = new int[length+1];        prefixSum[0]=0;        for (int i=0;i&lt;length;i++)&#123;            prefixSum[i+1]=prefixSum[i]+nums[i];        &#125;        int ans = Integer.MIN_VALUE;        for (int i=0;i&lt;length;i++)&#123;            for (int j=i+1;j&lt;=length;j++)&#123;                int gap = prefixSum[j]-prefixSum[i];                ans = Math.max(gap,ans);            &#125;        &#125;        return ans;    &#125;&#125;\n\n优化后的前缀和\nclass Solution &#123;    public int maxSubArray(int[] nums) &#123;        int length = nums.length;        int prefixSum[] = new int[length+1];        prefixSum[0]=0;        for (int i=0;i&lt;length;i++)&#123;            prefixSum[i+1]=prefixSum[i]+nums[i];        &#125;        int ans = Integer.MIN_VALUE;        int p=0;        for (int i=1;i&lt;=length;i++)&#123;            if (prefixSum[p]&gt;=prefixSum[i])&#123;                ans = Math.max(ans, prefixSum[i]-prefixSum[i-1]);                p=i;            &#125;else&#123;                ans = Math.max(ans, prefixSum[i]-prefixSum[p]);            &#125;        &#125;        return ans;    &#125;&#125;\n\n","categories":["博客"],"tags":["Java","算法","数据结构"]},{"title":"MIT 6.824 Lecture 1-Introduction","url":"/2024/07/01/MIT%206.824%20Lecture%201-Introduction/","content":"MIT 6.824: Lecture 1-IntroductionLecture 1-Introdunction1.1为什么分布式：\n连接不同物理实体\n通过隔离实现安全\n通过复制实现容错\n并行的cpu、mem、disk、net实现扩展\n\n1.2分布式系统：Hadoop（ hdfs , yarn , MapReduce )Spark 批处理Storm ， Flink 流处理Hbase K&#x2F;V分布式数据库Kafka 消息队列\n1.3Lab:1-MapReduce\n2-Raft:管理复制和剔除\n3-k&#x2F;v server\n4-shard k&#x2F;v service\n1.4 Infrastructure-Abstraction\nstorage :star:\ncommunications\ncomputation-MapReduce\n\n1.5 Implementation:examples: RPC, Threads,Lock\n1.6Performance:scalability-&gt; 2 * computers-&gt; 2 * throughput\n1.7 Fault Tolerance:Availability\nRecoverability\ntools:\nNV storage\nReplication\nConsistency\nput(k,v)\nget(k)-&gt;v\nstrong?weak?\n1.8MapReduceMap Function &amp; Reduce Function写好mapreduce程序，无需关心具体分布式实现WordCount例子\nINPUT1-&gt;MAP\t\t a,1 b,1\nINPUT2-&gt;MAP \t\t\t  b,1\nINPUT3-&gt;MAP \t   a,1         c,1\nget intermediate output\nThen Reduces(分治思想)\nMap(k,v):\nsplit v into words\nfor each word \nemit(w,”1)\nReduce(k,v):\nemit(len(v))\n简述：\nmap&#x2F;shuffle&#x2F;reduce\nmaster给workers分配任务，输入被分成M份（M个map task，M比worker多），每份有3个备份；对每份输入调用Map()，产出(k2,v2)的中间结果，在本地Hash成R份，传递给R个Reduce()，每个Reduce task写一个结果文件\n隐藏的细节：\n跟踪task的完成情况、数据移动、错误恢复\n好的负载均衡：\ntasks比workers多，workers完成task后master继续给它分配\n容错：\n某个服务器在运行MR任务时崩溃，只需重新运行相应的Map和Reduce而不用整个任务重新运行；\n这依赖Map和Reduce是纯函数，即：\n不保存状态、\n不读写额外的文件、\n没有task间隐藏的通信\n崩溃恢复：\nMap worker崩溃：\n重新给包含该输入的副本的worker分配该task（可能一些Reduce worker已经读取了该Map的部分输入，不要紧，Map是纯函数）；\n如果该Map的中间结果都已被读取，则不用重新运行\nReduce worker崩溃：\n该worker已运行完的task不用重新运行（结果已存到GFS）\n只需重新运行未完成的task\n如果Reduce worker写数据中途崩溃，不要紧，GFS会在写入完成时才重命名文件，所以相当于原子操作，未写入完成可重新运行\n其他问题：\n给两个worker分配了同样的Map task — 只会告诉Reduce worker其中的一个；\n给两个worker分配了同意的Reduce task — GFS的原子写入操作可解决\n详解MapReduce流程MapReduce 编程模型开发简单且功能强大，专门为并行处理大规模数据量而设计，接下来，通过一张图来描述 MapReduce 的工作过程，如图所示\n\n整体流程（5步）在上图中， MapReduce 的工作流程大致可以分为5步，具体如下:\n\n1.分片、格式化数据源：输入 Map 阶段的数据源，必须经过分片和格式化操作。\n分片操作：指的是将源文件划分为大小相等的小数据块( Hadoop 2.x 中默认 128MB )，也就是分片( split )，Hadoop 会为每一个分片构建一个 Map 任务，并由该任务运行自定义的 map() 函数，从而处理分片里的每一条记录;格式化操作：将划分好的分片( split )格式化为键值对&lt;key,value&gt;形式的数据，其中， key 代表偏移量， value 代表每一行内容。\n2.执行 MapTask每个 Map 任务都有一个内存缓冲区(缓冲区大小 100MB )，输入的分片( split )数据经过 Map 任务处理后的中间结果会写入内存缓冲区中。如果写入的数据达到内存缓冲的阈值( 80MB )，会启动一个线程将内存中的溢出数据写入磁盘，同时不影响 Map 中间结果继续写入缓冲区。在溢写过程中， MapReduce 框架会对 key 进行排序，如果中间结果比较大，会形成多个溢写文件，最后的缓冲区数据也会全部溢写入磁盘形成一个溢写文件，如果是多个溢写文件，则最后合并所有的溢写文件为一个文件。\n\n\nRead 阶段： MapTask 通过用户编写的 RecordReader ，从输入的 InputSplit 中解析出一个个 key &#x2F; value 。\nMap 阶段：将解析出的 key &#x2F; value 交给用户编写的 Map ()函数处理，并产生一系列新的 key &#x2F; value 。\nCollect 阶段：在用户编写的 map() 函数中，数据处理完成后，一般会调用 outputCollector.collect() 输出结果，在该函数内部，它会将生成的 key &#x2F; value 分片(通过调用 partitioner )，并写入一个环形内存缓冲区中(该缓冲区默认大小是 100MB )。\nSpill 阶段：即“溢写”，当缓冲区快要溢出时(默认达到缓冲区大小的 80 %)，会在本地文件系统创建一个溢出文件，将该缓冲区的数据写入这个文件。\n\n\n将数据写入本地磁盘前，先要对数据进行一次本地排序，并在必要时对数据进行合并、压缩等操作。写入磁盘之前，线程会根据 ReduceTask 的数量，将数据分区，一个 Reduce 任务对应一个分区的数据。\n这样做的目的是为了避免有些 Reduce 任务分配到大量数据，而有些 Reduce 任务分到很少的数据，甚至没有分到数据的尴尬局面。\n如果此时设置了 Combiner ，将排序后的结果进行 Combine 操作，这样做的目的是尽可能少地执行数据写入磁盘的操作。\n\n\n\nCombine 阶段：当所有数据处理完成以后， MapTask 会对所有临时文件进行一次合并，以确保最终只会生成一个数据文件\n\n\n合并的过程中会不断地进行排序和 Combine 操作，\n其目的有两个：一是尽量减少每次写入磁盘的数据量;二是尽量减少下一复制阶段网络传输的数据量。\n最后合并成了一个已分区且已排序的文件。\n\n3.执行 Shuffle 过程MapReduce 工作过程中， Map 阶段处理的数据如何传递给 Reduce 阶段，这是 MapReduce 框架中关键的一个过程，这个过程叫作 Shuffle 。Shuffle 会将 MapTask 输出的处理结果数据分发给 ReduceTask ，并在分发的过程中，对数据按 key 进行分区和排序。\n4.执行 ReduceTask输入 ReduceTask 的数据流是&lt;key, {value list}&gt;形式，用户可以自定义 reduce()方法进行逻辑处理，最终以&lt;key, value&gt;的形式输出。\n\n\nCopy 阶段： Reduce 会从各个 MapTask 上远程复制一片数据（每个 MapTask 传来的数据都是有序的），并针对某一片数据，如果其大小超过一定國值，则写到磁盘上，否则直接放到内存中\n\nMerge 阶段：在远程复制数据的同时， ReduceTask 会启动两个后台线程，分别对内存和磁盘上的文件进行合并，以防止内存使用过多或者磁盘文件过多。\n\nSort 阶段：用户编写 reduce() 方法输入数据是按 key 进行聚集的一组数据。为了将 key 相同的数据聚在一起， Hadoop 采用了基于排序的策略。由于各个 MapTask 已经实现对自己的处理结果进行了局部排序，因此， ReduceTask 只需对所有数据进行一次归并排序即可。\n\nReduce 阶段：对排序后的键值对调用 reduce() 方法，键相等的键值对调用一次 reduce()方法，每次调用会产生零个或者多个键值对，最后把这些输出的键值对写入到 HDFS 中\n\nWrite 阶段： reduce() 函数将计算结果写到 HDFS 上。合并的过程中会产生许多的中间文件(写入磁盘了)，但 MapReduce 会让写入磁盘的数据尽可能地少，并且最后一次合并的结果并没有写入磁盘，而是直接输入到 Reduce 函数。\n\n\n5.写入文件MapReduce 框架会自动把 ReduceTask 生成的&lt;key, value&gt;传入 OutputFormat 的 write 方法，实现文件的写入操作。\nMapReduce论文阅读前言MapReduce，是 Google 早年提出了一种软件架构模型，支持大规模数据集的并行运算。现在这个概念被运用在大量分布式系统中。\n相关的理论由 Google 在 2004 年发表在论文《MapReduce: Simplified Data Processing on Large Clusters》中，可以在这里阅读全文。13 页的小论文，信息密度比某些小论文不知道高到哪里去了。\n由于本文是边阅读论文边记录下来的笔记，所以内容可能比较混乱。\n编程模型MapReduce 是一个很简单的并行处理模型，使用 MapReduce 框架，用户只需要指定两个函数：\nMap 函数，负责将一个键值对处理成一系列中间键值对Reduce 函数，负责将所有具有相同 key 的中间值合并剩下的，就由框架自行处理，包括数据分发、任务分发、错误处理、负载均衡等等细节。用户无需掌握这些细节，更能关注于业务逻辑。\n一个大致的处理流程是这样的：\nMap 接受一个输入键值对，产生一系列中间键值对。MapReduce 框架将所有具有相同的中间 key 的中间值组织到一起，传递给 Reduce 函数。Reduce 函数，接收一个中间 key 和一系列中间值，函数通常将这些值聚合成一个较小的集合，有时每次 Reduce 函数调用只会产生一个结果值，甚至不产生结果。\n以大规模文本单词计数为例：\nmap(String key, String value):    // key：文章名称    // value：文章内容    for 单词 w in value:        增加中间计数(w, &quot;1&quot;)reduce(String key, Iterator values):    // key：一个单词    // value：一系列计数    int result = 0;    for v in values:        result += ParseInt(v);    输出(ToString(result))\n\n实现执行流程MapReduce 作为一种编程模型或者说编程思想，实现方式可以有很多。Google 在论文中给出了一种实现方法，用于局域网内互相连接的大量机器。执行流程如下图：\n\nMapReduce 框架首先将输入文件划分为 M 片，每片通常为 16MB 到 64MB 大小。随后会启动集群中的机器（进程）。集群中的一个进程是一个特殊的 master 进程。剩余的 worker 进程都由 master 分配任务。一共有 M 个 map 任务和 R 个 reduce 任务需要分配。master 会挑选空闲的 worker，一次分配一个 map 任务或者一个 reduce 任务。被分配到 map 任务的 worker 读入对应分片的输入，从输入中解析出键值对，并分别将其传给用户定义的 map 函数。map 函数返回的中间键值对会被暂时缓存在内存里。worker 内存中缓存的键值对，会被分片函数分成 R 个分片，并周期性地写进本地磁盘。这些键值对在磁盘上的位置会被发生给 master，master 负责将位置发送给被分配到 reduce 任务的 worker。当一个 reduce worker 接收到 master 发送的这些位置，它会向保存这些内容的 map worker 发送 RPC 请求来读取这些内容。当一个 reducer worker 读取完所有的中间数据，就会将其根据 key 进行排序，这样所有相同 key 的数据就会聚合在一起。这种排序是必要的，因为通常许多不同的 key 会由同一个 reduce 任务处理。如果数据过大，可能会使用外部排序。reduce worker 遍历有序的中间数据，对遇到的所有 key，都会将 key 和对应的值集合传给用户定义的 reduce 函数。reduce 函数的输出会被追加到一个最终的输出文件（每个 reduce 分片一个）。当所有的 map 任务和 reduce 任务都完成后，MapReduce 的任务也就完成了。运行结束后，MapReduce 的运行结果保存在 R 个输出文件中，通常这些文件会被用作下一个 mapreduce 任务的输入。\n容错这里只考虑 worker 挂掉的情况，不考虑 master 挂掉的情况，因为这可能涉及选举共识等复杂情况。\nmaster 和 worker 会维持一个心跳，如果一段时间没有收到 worker 的回应，就会认为这个 worker 挂掉了。所有由这个 worker 完成的 map 任务都会被重新变成未开始状态，会被重新分配给其他 worker 执行。所有挂掉时正在进行的 map 或者 reduce 任务会被标记为未开始。\n已完成的 map 任务需要重新执行是因为它们的结果存储在已经挂掉机器的本地硬盘上，而已经完成的 reduce 任务无需重新执行，reduce 任务的结果被放在全局的文件系统上。\n如果一个 map 任务最初由 A 执行，后来 A 挂掉了，被重新分配给 B 执行，这个消息会被通知到所有执行 reduce 任务的 worker。所有还没有从 A 中读取数据的 reduce 任务会转而选择从 B 读取数据。\n有时，会出现这种情况：部分机器的性能很低，但是由于网络通畅，不会被判定为挂掉，这种机器就会成为整个系统的短板，整个系统不得不等待慢速机器慢吞吞地执行完他们的任务。对于这种情况，Google 的实现采用的一种机制来提升：在整体 MapReduce 操作快要结束时，master 会将所有仍然在进行的任务分配给其他空闲的 worker 执行。无论是原来的 worker，还是二次分配的 worker 完成了任务，这个任务都算是成功完成。\n性能提升与小优化小扩展略去。\nGFS\nGFS（google file system）\t\n\n大数据存储难点：容错能力（分片副本）、数据一致性、性能（快捷）\n\n特点：大文件（分为64Mb的多个chunk块存储）、速度快、通用存储系统、chunk server副本、自动恢复、顺序读取、成本低\n\nGFS架构：client结点master结点（保存元数据）：文件名—数据块列表映射、版本、主数据块、作为master的时限、log、checkpoint，磁盘存储来容错块handle（句柄）块server结点：默认副本数为3来容错，顺序存储数据\n\n\nGFS读：\n1.client将想读的文件名，偏移量发送到master服务器\n2.master发送块handle和块服务器号等元数据给client\n3.client缓存master发回的数据\n4.client将请求根据元数据发送到最近的副本\n5.副本返回数据给client\n\nGFS写：（追加写）\n没有主数据块：找到更新到最新的副本们，master选取一个作为主数据块，写入磁盘，设置主数据块的时效增加版本号，写入磁盘主数据块写入，再同步所有副本返回给client 插入成功 or 插入失败\n\n\n\n\nGFS详解是什么？GFS是一个可扩展的分布式文件系统，用于大型的、分布式的、对大量数据进行访问的应用。它运行于廉价的普通硬件上，并提供容错功能。它可以给大量的用户提供总体性能较高的服务。\n为什么要用GFS?大量数据的存储会面临很多的难点：\n大数据下需要良好的表现就需要分片和容错。在具体操作过程中，涉及到容错一般使用副本来解决，然而副本的使用会面临不一致问题。如果有一致性的要求，就会导致表现降低。\n所谓的一致性，就是在集群中表现的像与一台机器或一个副本进行交互那样\n因为GFS不但是一个理论成熟的框架结构，更是一种通过长期实际使用证明了其优秀性能的分布式架构。GFS是一种松散一致性模型，这是其具有优越的性能主要原因之一。\n松散一致性模型关键：\n依靠添加而不是重写检查点自我验证（校验和）自我认证记录\n组成？一个GFS集群通常由1个Master，多个ChunkServer组成，并同时接受多个Client的访问。\n交互概要图\n\n流程介绍：\n\nclient发送请求给Master，寻找存储了对应副本的chunkserver。\n\nMaster通过遍历本地记录获取chunkserver的信息，包括处理信息和地址信息\nMaster不但会在启动时获取集群中所有chunkserver的信息，还会在后续的周期性的获取chunkserver信息。所有的信息都是存在Master的RAM里\n\nMaster将信息返回给client\n\nclient之后直接通过地址信息与chunkserver交互\n\n\nGFS交互流程图：\n\nSecondary Replica:辅助副本\n要点：\n\nMaster通过lease(租约)和Primary Replica(主副本)本来构建交互的流程。\nMaster是做出决策、创建新的块和赋值，并协调各种系统范围的活动，以保证块完全复制，平衡所有chunkserver的负载，同时还负责垃圾回收。\nMaster的操作通过锁来保证命名空间范围内的序列化\n\n主副本是从众多chunkserver中选出的唯一特殊副本，该副本的特殊性在于其维护了一个定时的租约列表。\n\n租约指的是一组由用户发来的有顺序的指令集合\n\n主副本之外的副本都需要通过主副本中的这个列表来执行指令，以保证每个副本执行的最终结果相同。\n\n\nMaster失效怎么办有副本master，拥有master状态的完整副本；GFS论文中设计需要人工干预才能切换到其中一种主故障后的副本。\n如何保障副本记录的正确性使用原子记录至少追加一次的方法。\n为什么不使用完全追加？\n如果在其中一个写入失败时客户端重新尝试写入，这将导致数据在未失败的副本上多次附加。不同的设计可能会检测到重复的客户端请求，例如，原始故障之间的主要故障请求和客户端的重试。\n应用程序如何知道哪些部分组成填充，哪些是重复记录？为了检测填充，应用程序可以放置一个可预测的幻数在有效记录的开头，或包含一个校验和，该校验和可能仅当记录有效时才有效。该应用程序可以检测通过在记录中包含唯一 ID 来复制。然后，如果它读取与先前记录具有相同 ID 的记录，它知道它们是彼此的重复。GFS 为应用程序提供了一个库处理这些情况。\n什么是校验和？校验和算法将一个字节块作为输入并返回一个单个数字，它是所有输入字节的函数。例如，一个简单校验和可能是输入中所有字节的总和（mod一些大数字）。GFS 存储每个块的校验和以及块。当一个chunkserver在它的磁盘上写一chunk时，它首先计算新块的校验和，并将校验和保存在磁盘上以及块。当一个chunkserver从磁盘读取一个chunk时，它还读取先前保存的校验和，从磁盘读取的块，并检查两个校验和是否匹配。如果数据已被磁盘损坏，校验和不匹配，并且chunkserver 会知道返回错误。另外，一些 GFS应用程序存储自己的校验和，而不是应用程序定义的记录，在 GFS 文件中，以区分正确的记录和填充。\nGFS 以正确性换取性能在多大程度上可以接受这是分布式系统中反复出现的主题。强一致性通常出现在需要复杂且需要交互的协议机器之间。经过利用特定应用程序类可以容忍的放松方式一致性，可以设计出具有良好性能和足够的一致性。例如，GFS 针对 MapReduce 进行了优化对大文件需要高读取性能的应用程序可以在文件中有漏洞，记录显示多次，并且不一致的读取。\nGoogle 是否仍使用 GFS？有传言说 GFS 已经被一个叫做Colossus，总体目标相同，但在 master 方面有所改进性能和容错性。\n","categories":["分布式系统"],"tags":["分布式系统","MapReduce","6.824","GFS"]},{"title":"MIT 6.824 Lecture2-RPC and Threads","url":"/2024/07/03/MIT-6.824-Lecture2-RPC-and-Threads/","content":"Lecture2-RPC and Threads2.1 GO语言❓ why we use go in this class\n1️⃣ go提供类许多便捷的工具，如threads、锁以及线程间同步。此外，还有RPC包也十分重要。\n2️⃣ go是type safe 以及memory safe的，其垃圾回收机制（garbage collected）十分有效\n3️⃣ threads + GC 是十分具有吸引力的\n2.2 threads2.2.1 为什么要关注多线程📖 多线程是在本课程中实现并发的一个重要工具，在分布式系统中，并发十分有趣。比较常见的情况是：一个程序需要同时和多台计算机（a bunch of other computers）通信，客户端可能会同时和多台服务器通信，一台服务器可能会同时响应来自不同客户端的多条请求。假如我的程序同时有 7 件不同的事情在进行，我想要一种简单的方式实现它能同时做 7 件不同的事情，多线程就能很好的解决它。\n在 Go 的文档中，它把线程称为 goroutine，goroutine 真的很像大家所说的线程。\n2.2.2 如何理解多线程假设有一个程序，用一个小盒子表示地址空间，在这个地址空间里，串行执行的程序（serial program）是没有多个线程的，你只有一个线程。它在这个地址空间中执行代码，它只有一个程序计数器（PC），只有一套寄存器(register），一个栈（stack)，这些东西就能描述当前的执行状态。\n在一个多线程程序中，比方说 Go 程序，你可以拥有多个线程，如果这些线程同时执行，那它们就分别有一个属于自己的程序计数器，一套寄存器和一个栈，每个线程都有自己的一套线程控制，他们可以在程序中不同的部分执行每个线程。需要注意的是，每一个独立的线程都有一个栈，这些栈都在程序中的同一个地址空间中，知道地址的话不同的线程之间是可以互相访问他们的栈的。\n多线程的一个重要作用就是允许程序中不同的部分都能独立的执行不同的动作。\n并发的关键是你有处理多个任务的能力，不一定要同时。\n并行的关键是你有同时处理多个任务的能力。\n2.2.3 使用多线程的原因\nI&#x2F;O Concurrency——I&#x2F;O并发IO并发：一个线程正在等待从磁盘上读数据，当它在等待的时候，你又想要另一个线程，可能用来做计算或是从某个磁盘的地方读取数据或是向网络发送一条消息并等待回复，所以 IO 并发是使用多线程的地方之一。\n比如说，我们有一个程序，已经启动并且通过 RPC 请求网络上不同的服务器，然后同时在等待多个回复。具体做法是，需要为每个 RPC 调用创建一个线程，每个线程都会通过 RPC 发送 request 消息，然后等待。当响应回复时，这个线程将会继续执行，使用多线程可以让我们同时发起多个网络请求，所有线程都会等待回复，也不是非得在同一时间去发请求，只要它愿意，这些线程总可以做不同的事情。\n不同 IO 并发活动（activity）可能会有互相重叠（overlapping）的部分，也允许一个活动正在等待，另一个活动可以继续执行\nParallelism——并行化使用多线程的另一个重要原因是多核并行（multi-core parallelism），我们想通过线程来达到并行化的目的。并行化就是如果你有个多核机器，如果你有一个计算繁重的工作，它需要消耗许多 CPU 时钟周期（CPU cycles），这是一件不太好的事情。假设你的程序能使用机器上所有的 CPU 核，比方说它是用 Go 写的多线程程序，你启动了多个 goroutine，这些 goroutine 执行一些计算密集型的任务，比如一直在那执行一个循环，计算 pi（圆周率)的值，直到达到机器上 cpu 核的极限，你的线程将会真正的以并行的方式运行。如果你启动 2 个线程代替 1 个线程，你就能获得 2 倍的性能，就能使用 2 倍数量的 CPU 时钟周期\n在本次课程中，我们不会把过多的精力放在此类并行化上。所以并行化是使用多线程的第二个原因\nConvenience——易用性有时候你只是想在后台做一些事情，比如你就想周期性的去执行它，但你又不愿意在主线程插入一些检查。比如有一个 master 服务需要周期性的检查它的 worker 服务是否一直存活，因为这些 worker 之一宕机的话，就需要把工作扔到另一台机器上去执行，就像 MapReduce 那样。你可以每秒、每分钟通过发送一条“你还活着吗？”这样的消息到 worker 服务上，你能启动一个 goroutine，然后执行一个死循环，sleep 1 秒后，然后做需要周期执行的动作，然后又 sleep 1 秒。\n❓ 开启goroutine的开销大吗\n📖 这个开销是值得的，而且这种开销非常少，取决于创建的线程的多少。但是，这种方法可以节省非常多的时间\n❓ 不使用多线程如何追踪不同活动的状态\n📖 使用另一种风格——异步编程（asynchronous programing），也称为事件驱动编程（event-driven programming）。\n事件驱动编程的一般结构，通常它有一个线程，同时有一个循环，这个循环等待输入或者是其它任何事件，这些事件能触发程序继续进行，事件可能是一个来自客户端的请求，可能是定时器到期。如果你在编写windows 系统程序，你电脑上的许多 windows 系统程序都是通过事件驱动的风格来编写的，它们等待的东西是像键盘击键或者是鼠标移动这样的事件。因此你可能会有一个单一的只有一个控制线程的程序，这个线程有一个循环一直等待输入，无论何时有输入进来，比如收到报文，它能够找出来是哪个客户端发送的这个报文。它有一张表格记录这个客户端到底处于什么样的活动状态。\n使用线程的话通常会变的更加方便，因为线程能让你更容易把把程序写的连贯有序。在事件驱动循环里，你一次只能执行一个活动，这种编程模式的问题在于它实现起来有点痛苦，另一个潜在的缺陷在于当你用这种方法获取了 IO 并发后你就没法利用 CPU 的并行化机制。\n所以当你写一个负载很高的服务，你得想方设法把一台大型机器的 32 核都用上，使用一个单一循环的话，它相当的不自然，也很难获得多核的性能。另一方面，冒这样的风险编程通常换来的性能提升相比多线程来说并不会太多。\n而且线程相对来说也很廉价，每个线程都有一个栈，栈通常是 1kb 或数千字节，如果你有 20 个线程，这些消耗根本不用在意。但是你若有 100 万个线程，那它就会消耗大量的内存。\n另外，线程调度，它是指下一步应该选择哪个线程运行，通常有一个调度列表，上面记录了 1000 个线程，这时候切换线程执行将付出相当昂贵的代价。\n所以，当你只有一个服务器的时候，你的服务器需要为 100 万个客户端提供服务，你需要为这 100 万个客户端记录一些状态，这个代价还是挺高的。如果使用事件驱动编程，花点时间的话，应该容易写一个简单的而又五脏俱全高性能的服务，就是你需要多做点工作。\n[(288条消息) 解读I&#x2F;O多路复用及其技术，让你彻底了解I&#x2F;O多路复用(内含图形讲解)【建议新手收藏】_Linux情报站的博客-CSDN博客](https://blog.csdn.net/m0_50662680/article/details/111273308?ops_request_misc=%7B%22request%5Fid%22%3A%22166315159916782390556461%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&amp;request_id=166315159916782390556461&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~pc_rank_34-1-111273308-null-null.142^v47^pc_rank_34_ctr25,201^v3^add_ask&amp;utm_term=异步 多路复用 图解&amp;spm&#x3D;1018.2226.3001.4187)\n❓ 多线程(threads)和多进程(processes)的区别\n📖 通常，对于类 UNIX 系统的机器来说，一个进程就是一个单独运行的程序，只有一个地址空间，一大片可供进程使用的内存，在这个进程里你可能同时会有好多个线程。当你准备好一个 go 程序并运行，将会创建一个 unix 进程和一块内存区，当你的 Go 进程创建 goroutine 时，它们实际上都是在同一个进程里的。\n实际上这也取决于操作系统的实现，确实有个别或一些操作系统，并不关心你的进程内部到底发生了什么事情，也不关心你使用什么语言，不关心操作系统内部的业务逻辑，在进程内部能运行多个线程就行了。\n如果在你的机器上运行了不止一个进程，比如一个编辑器或是编译器，操作系统需要让它们彼此分开，你的编辑器和你的编译器都有自己的内存空间，他们之间无法看到彼此的内存，不同的进程之间不会有交集。你的编辑器可能有多个线程，你的编译器也可能有多个线程，但是他们都处于各自的世界。但是在同一个进程中，线程与线程之间可以共享内存，可以使用 channel(Go语言中的概念) 进行同步，也可以使用 mutex 等。但进程之间是没有交集的，这类软件的传统结构就是这样。\n❓ 当上下文切换时，是所有线程都在切换吗(when a context switch happens does it happened for all threads)\n你只有一个单核机器，这意味着在同一个时刻你只能做一件事情。你打算在你的机器上运行多进程，操作系统把 CPU 时间片反复的分配给这两个程序，当硬件时钟到期时，操作系统就判断是时候把 CPU 从当前正在运行的进程剥夺，然后把 CPU 分配给另一个进程，这件事件是在进程级别上做的。\n我们使用的线程最终是由是操作系统线程所提供的，当操作系统上下文切换时，就是不同的线程之间产生切换时，操作系统是知道这一切的，所以操作系统可能会清楚这儿有两个线程在这个进程中，有三个线程在那个进程，当时钟到期时操作系统会基于一些调度算法选择一个不同的线程来运行。在这个进程中的线程和另一进程中的线程可能是不同的，另外，Go 会聪明复用一个操作系统线程，在上面运行尽可能多的 goroutine 以节省开支，所以这可能需要两个阶段去调度。\n首先操作系统选择一个线程去运行，然后在这个进程中，Go 会再去选择哪个 goroutine 去运行。\n2.2.4 sharing memory——共享内存事实上写多线程程序是有些挑战的，其中一个是共享数据，关于线程模型，酷的地方在于这些线程共享地址空间，共享内存，如果某个线程在内存中创建了一个对象，在其它线程中你也能使用它。你可以创建个数组或是别的什么东西，所有不同的线程都能读写。这就存在一些临界情况，如果你持有一些你关注的状态，可能你会缓存一些数据：你的 server，你的缓存，你的内存。当其中一个线程正处理一个客户端的请求的时候，首先它会先查一下缓存中的数据，但是这个共享缓存，每个线程都能读。当线程里有新的信息时，线程可能会向缓存里写入数据进行更新。\n但是事实也表明如果你不关心多线程之间共享内存的话，很容易出现bug。\n问题举例假设你有一个全局变量 N 在不同的线程之间共享，其中一个线程只是对 N 做自增，这可能就是造成 bug 的原因。\nn=n+1\t\n\n\n在同一时刻，总有其它的线程可能也正在查看，所以这里有个很明显的问题。线程 1 正在执行，但是另一个不同的线程 2 也在执行相同的代码， N 是一个全局变量，所以这里我们说的这个 N 都是同一个 N。\n实际上机器运行的并不是这样的代码，而是由编译器吐出来的机器码（machine code）。\nLD  X , register1ADD 1 , register1STORE register1 , X\n\n你可以假设所有的线程都在执行这行代码，他们都会执行加载 x 到寄存器，x 从 0 开始有效，这意味着，所有线程都把 0 读入寄存器，然后他们都给寄存器加 1，这样所有线程各有自的寄存器的值是 1，最后再把寄存器的值 1 重新保存到内存里，现在，这两个线程对 N 做自增后，结果都是 1，但是碰巧这样写并不正确，碰巧程序想要的结果不是 1。\n❓ 指令的原子性\n这些独立的指令是不是原子的（atomic），答案是有些是，有些不是，对于 32 位的 store 指令它极有可能是原子的，从某种意义上来说，如果有两个处理器，最终要么是其中一个处理器上的 32 位值，要么是另一个处理器上的 32 位值，而不是一个混合的值。其它尺寸大小的未必就这么简单，比如一个字节的存储这依赖于你所使用的 CPU。这依赖于处理器和更复杂的指令。\n比如微处理器上的自增指令，它能直接给内存上某个地址的值加 1，未必就是原子的，尽管这些指令存在原子版本的。\n所以这是一个非常经典的错误，通常我们叫他“竞争”（race），后面我打算会多次提起。称为 race 是因为如果一个 CPU 已经开始执行这段代码，另一些线程正在结束这段代码，这就是 race，第一个处理器能够在第二个处理器开始执行 load 前执行 store，如果第一个处理器的 store(寄存器中的数据存入内存)确实是在第二个处理器 load （内存放入寄存器）之前，那么第二个处理器就能看到第一个处理器存储的值，第二个处理器将 load 值 1，然后再加 1，再把 2 存入。\n解决这个问题的方式很简单，加个锁就行了，只有在持有锁的时候，这个共享数据才能被使用，Go 调用 Lock 来锁住 mutex，你能看到 mu.Lock()加在这一段使用共享数据的代码前面，然后在结束的地方调用 mu.Unlock()。无论哪个线程执行到这里，只有足够幸运的那个线程才能第一个抢到锁，然后执行所有这些代码，在结束之前，另一个线程都不能继续，你可以考虑把这些在锁中间的代码封装起来。\n❓ Go是如何知道我们正在锁住哪些变量\n答案是 go 并不知道，在这个锁里的任何位置他们一点关联都没有。所以，这里新的东西是这个变量(mu)，它是个 mutex，在 lock 和任何变量之间他们并没有什么关联。\n2.2.5 Coordination——协作协作与指导线程运作有关，当我们正在执行涉及到多线程情况下的加锁时，可能并不知道其它线程也在加锁，他们只是想在没有人干涉的情况下拿到数据。但也有一些情况你确实就是故意的想让不同的线程之间互相受到制约，比如你生产某些数据，但是你又和我不是同一个线程，我想在你生产完数据前一直等待，直到你完成后，我再去读取。或者是你启动了一堆线程去抓取 web 页面，然后需要等待所有线程都执行结束。\n所以当我们想特意的互相等待的时候，这种情况通常就称为 coordination (协作)。Go 中有很多技术可以做到，比如 channel (通道)，channel 是一种用于发数据从这个线程到另一个线程的工具。\n也有一些其它工具用于特殊的目的，比如有个东西叫 condition variables (条件变量)，还有WaitGroup。\n2.2.6 Deadlock——死锁死锁Deadlock：计算机系统中多道程序并发执行时，两个或两个以上的进程由于竞争资源而造成的一种互相等待的现象（僵局），如无外力作用，这些进程将永远不能再向前推进。\n四个条件同时出现，死锁将会发生\n1️⃣ Mutual exclusion互斥：一次只有一个进程可以使用一个资源\n2️⃣ Hold and wait占有并等待：一个进程应该占有至少一个资源，并等待另一个资源，而该资源被另一个进程所占有\n3️⃣ No preemption不可抢占：一个资源只有当持有它的进程完成任务后自由的释放\n4️⃣ Circular wait循环等待：等待资源的进程之间存在环\n2.2.7 Web爬虫package mainimport (\t&quot;fmt&quot;\t&quot;sync&quot;)//// Several solutions to the crawler exercise from the Go tutorial// https://tour.golang.org/concurrency/10////// Serial crawler//func Serial(url string, fetcher Fetcher, fetched map[string]bool) &#123;\tif fetched[url] &#123;\t\treturn\t&#125;\tfetched[url] = true\turls, err := fetcher.Fetch(url)\tif err != nil &#123;\t\treturn\t&#125;\tfor _, u := range urls &#123;\t\tSerial(u, fetcher, fetched)\t&#125;\treturn&#125;//// Concurrent crawler with shared state and Mutex//type fetchState struct &#123;\tmu      sync.Mutex\tfetched map[string]bool&#125;func ConcurrentMutex(url string, fetcher Fetcher, f *fetchState) &#123;\tf.mu.Lock()\talready := f.fetched[url]\tf.fetched[url] = true\tf.mu.Unlock()\tif already &#123;\t\treturn\t&#125;\t\turls, err := fetcher.Fetch(url)\tif err != nil &#123;\t\treturn\t&#125;\tvar done sync.WaitGroup\tfor _, u := range urls &#123;\t\tdone.Add(1)\t    u2 := u\t\tgo func() &#123;\t\t\tdefer done.Done()\t\t\tConcurrentMutex(u2, fetcher, f)\t\t&#125;()\t\t//go func(u string) &#123;\t\t//\tdefer done.Done()\t\t//\tConcurrentMutex(u, fetcher, f)\t\t//&#125;(u)\t&#125;\tdone.Wait()\treturn&#125;func makeState() *fetchState &#123;\tf := &amp;fetchState&#123;&#125;\tf.fetched = make(map[string]bool)\treturn f&#125;//// Concurrent crawler with channels//func worker(url string, ch chan []string, fetcher Fetcher) &#123;\turls, err := fetcher.Fetch(url)\tif err != nil &#123;\t\tch &lt;- []string&#123;&#125;\t&#125; else &#123;\t\tch &lt;- urls\t&#125;&#125;func master(ch chan []string, fetcher Fetcher) &#123;\tn := 1\tfetched := make(map[string]bool)\tfor urls := range ch &#123;\t\tfor _, u := range urls &#123;\t\t\tif fetched[u] == false &#123;\t\t\t\tfetched[u] = true\t\t\t\tn += 1\t\t\t\tgo worker(u, ch, fetcher)\t\t\t&#125;\t\t&#125;\t\tn -= 1\t\tif n == 0 &#123;\t\t\tbreak\t\t&#125;\t&#125;&#125;func ConcurrentChannel(url string, fetcher Fetcher) &#123;\tch := make(chan []string)\tgo func() &#123;\t\tch &lt;- []string&#123;url&#125;\t&#125;()\tmaster(ch, fetcher)&#125;//// main//func main() &#123;\tfmt.Printf(&quot;=== Serial===\\n&quot;)\tSerial(&quot;http://golang.org/&quot;, fetcher, make(map[string]bool))\tfmt.Printf(&quot;=== ConcurrentMutex ===\\n&quot;)\tConcurrentMutex(&quot;http://golang.org/&quot;, fetcher, makeState())\t\tfmt.Printf(&quot;=== ConcurrentChannel ===\\n&quot;)\tConcurrentChannel(&quot;http://golang.org/&quot;, fetcher)&#125;//// Fetcher//type Fetcher interface &#123;\t// Fetch returns a slice of URLs found on the page.\tFetch(url string) (urls []string, err error)&#125;// fakeFetcher is Fetcher that returns canned results.type fakeFetcher map[string]*fakeResulttype fakeResult struct &#123;\tbody string\turls []string&#125;func (f fakeFetcher) Fetch(url string) ([]string, error) &#123;\tif res, ok := f[url]; ok &#123;\t\tfmt.Printf(&quot;found:   %s\\n&quot;, url)\t\treturn res.urls, nil\t&#125;\tfmt.Printf(&quot;missing: %s\\n&quot;, url)\treturn nil, fmt.Errorf(&quot;not found: %s&quot;, url)&#125;// fetcher is a populated fakeFetcher.var fetcher = fakeFetcher&#123;\t&quot;http://golang.org/&quot;: &amp;fakeResult&#123;\t\t&quot;The Go Programming Language&quot;,\t\t[]string&#123;\t\t\t&quot;http://golang.org/pkg/&quot;,\t\t\t&quot;http://golang.org/cmd/&quot;,\t\t&#125;,\t&#125;,\t&quot;http://golang.org/pkg/&quot;: &amp;fakeResult&#123;\t\t&quot;Packages&quot;,\t\t[]string&#123;\t\t\t&quot;http://golang.org/&quot;,\t\t\t&quot;http://golang.org/cmd/&quot;,\t\t\t&quot;http://golang.org/pkg/fmt/&quot;,\t\t\t&quot;http://golang.org/pkg/os/&quot;,\t\t&#125;,\t&#125;,\t&quot;http://golang.org/pkg/fmt/&quot;: &amp;fakeResult&#123;\t\t&quot;Package fmt&quot;,\t\t[]string&#123;\t\t\t&quot;http://golang.org/&quot;,\t\t\t&quot;http://golang.org/pkg/&quot;,\t\t&#125;,\t&#125;,\t&quot;http://golang.org/pkg/os/&quot;: &amp;fakeResult&#123;\t\t&quot;Package os&quot;,\t\t[]string&#123;\t\t\t&quot;http://golang.org/&quot;,\t\t\t&quot;http://golang.org/pkg/&quot;,\t\t&#125;,\t&#125;,&#125;\n\n\n\n这是一个使用多线程的例子，有三种不同风格的方案。\n爬虫就是你给它一个 URL 让它开始运行。在 web 页面里，包含有许多链接指向了其它的页面，所以 web 爬虫要做的就是把这些链接指向的页面提取出来，抓取这些页面后再检查所有这些页面里的 url，然后继续抓取这些 url 指向的页面，它应该要能够停止——比如直到 web 中所有的页面被抓取完。\n另外网页构成的 graph 和 URL 存在环，稍不注意可能就会陷入永无止境的爬取。所以爬虫的工作之一就是需要记住它抓取过的页面，或是已经开始抓取的页面，对于任何正在抓取中的页面都不应该有第二次抓取。\n它是一个树结构，这个树结构是一个包含了环的实际网页 graph 的子集，我们想避开环，不想抓取同一个页面 2 次，另外，实践证明抓取一个 web 页面需要花点时间，但是因为网络有较长的延迟服务器又很慢，所以你完全不会想一次只抓取一个页面。\n你需要使用并行化的方式持续的增加抓取页面的数量，直到达到呑吐极限，也就是每秒你抓取的页面数量不再增加为止，也就是并发数的增加耗尽了网络带宽。所以，我们希望利用并行化的方式抓取。\n最后一个挑战有时候也是最难解决的问题，当爬虫运行结束，一旦我们已经抓取了所有的页面，就需要停止爬虫。什么时候结束被证明是最难的一部分。\n串行化风格所以我的第一个爬虫是一个串行化的爬虫，上面这段代码是可以用的，这个串行爬虫在网页 graph 中进行深度优先搜索，它会使用一个 map 类型的变量 fetched ，它只是被当作一个 set 使用来记住它所抓取过的页面。在 18 行你给它一个 URL，如果这个 URL 已经被抓取过它就直接 return，如果没有被抓取过，首先它要把这个 URL 记下，然后开始抓取，fetcher 会真正开始抓取页面，然后提取页面中的 URL，接下来迭代所有的 URL，递归的调用它自己，对于所有的页面，它会把这些页面传递给自己。它只有一个表格，一个 fetched map，当我调用递归的抓取的时候，它又抓取了很多页面。，在抓取实例之外，需要意识到某些页面是已经抓取过的，所以我们十分依赖于在函数里传递的 fetched 对象。map 使用引用而不是拷贝，所以在底层go 把指向map对象的指针传递给每个crawl函数调用，因此这些调用共享同一个对象和内存的指针，而不是（对象）的拷贝。\nfunc Serial(url string, fetcher Fetcher, fetched map[string]bool) &#123;\tif fetched[url] &#123;\t\treturn\t&#125;\tfetched[url] = true\turls, err := fetcher.Fetch(url)\tif err != nil &#123;\t\treturn\t&#125;\tfor _, u := range urls &#123;\t\tSerial(u, fetcher, fetched)\t&#125;\treturn&#125;\n\n\n并发风格——共享数据与互斥\n//// Concurrent crawler with shared state and Mutex//type fetchState struct &#123;\tmu      sync.Mutex\tfetched map[string]bool&#125;func ConcurrentMutex(url string, fetcher Fetcher, f *fetchState) &#123;\tf.mu.Lock()\talready := f.fetched[url]\tf.fetched[url] = true\tf.mu.Unlock()\tif already &#123;\t\treturn\t&#125;\t\turls, err := fetcher.Fetch(url)\tif err != nil &#123;\t\treturn\t&#125;\tvar done sync.WaitGroup\tfor _, u := range urls &#123;\t\tdone.Add(1)\t\tgo func(u string) &#123;\t\t\tdefer done.Done()\t\t\tConcurrentMutex(u, fetcher, f)\t\t&#125;(u)\t&#125;\tdone.Wait()\treturn&#125;func makeState() *fetchState &#123;\tf := &amp;fetchState&#123;&#125;\tf.fetched = make(map[string]bool)\treturn f&#125;\n\n\n这段代码明显比Serial crawler要复杂的多，它为每个fetch创建一个thread，最大的不同之处在于它做了两件事：一是必要的统计以注意到所有爬取完成的时刻，它也会处理共享表格，这个表格记录了已爬取的URL，所以这段代码仍然有URL表格即 f.fetched，这个表格被所有的crawler线程共享，所有的crawler线程执行在函数 ConcurrentMutex 内 ，所以我们仍然有 ConcurrentMutex 的树结构来探索 web graph 的不同部分。但它们中的每一个是被放在各自的goroutine中启动，而不是作为函数调用，它们都共享一个状态表记录已爬取URL的表格，因为如果有个goroutine爬取了一个URL，我们不希望另一个goroutine意外地爬取同一个URL ，11行和14行之间加上了互斥锁，用于防止race。\n当我们检查表中的URL条目之后，在20行URL被以常见的方式爬取urls, err :&#x3D; fetcher.Fetch(url)。之后另一个有趣的事情是线程的启动。在第25行 ，遍历fetch函数返回的URLsfor _, u :&#x3D; range urls。第27行，对每个URL启动一个goroutinego func(u string) 。func语法是一个闭包（closure）或一个匿名函数，func关键字声明了一个函数然后我们调用了这个函数。理解（这段代码）的方式是你把一个函数声明成一段数据 先写下func关键字，然后给出函数参数，之后写出函数体 结束，现在这是一个对象 。为了让它成为一个goroutine，我们要在func前加上go关键字，然后我们必须要调用这个函数，因为在go语法中go关键字后面接函数名以及要传递的参数。第24行的WaitGroup 是go语言定义的一个数据结构，用于帮助coordination。WaitGroup内部有一个计数器，调用WaitGroup.Add()来增加计数器，调用WaitGroup.Done()来减小计数器。第32行，Wait方法被调用，等待计数器归零，因此WaitGroup是一种用于等待若干事件结束的方式，它在很多不同场景中都有应用，这里我们应用它来等待最后一个goroutine结束，因为我们对于每个goroutine都对WaitGroup加一。\n❓ 如果某个子程序(subroutine)失败导致done没被调用该怎么办\n有些方式可以使function失败，goroutine死掉而整个程序不死，这对我们是个麻烦。所以实际上 正确的方式是defer done.Done()，以确保不论goroutine是怎么结束的，done都会被调用。\n❓ 为什么两个不同threads对done的调用不构成race\n（WaitGroup）内部有互斥锁或类似的机制，每个done的方法会在执行任何指令前先取得锁，于是同时调用WaitGroup的方法并不构成race\n非常难搞清楚你是不有一个race，你可能会有一段代码看起来非常合理，但实际上有某些你未知的race 是使用共享变量导致的 ，在实践中唯一能发现race的方法是使用自动化的工具。幸运的是go给我们提供了一个很不错的race探测器，go run -race crawler.go。你应该使用它。如果你把 -race 作为命令行参数，race检测器会告诉我们race发生的准确位置。\n如果你不执行任何代码，那么race探测器不会知道任何事，它将不会分析。它并不是做静态分析，race探测器不会看你的源代码，不会基于源代码作出判断，它观察一次具体的程序运行。所以如果这次具体的程序运行没有执行，race探测器不可能知道某些恰好读写共享数据的代码，这是需要小心的地方。需要设置某种测试装置以确保所有的代码都被执行。\n并发风格——channel\n//// Concurrent crawler with channels//func worker(url string, ch chan []string, fetcher Fetcher) &#123;\turls, err := fetcher.Fetch(url)\tif err != nil &#123;\t\tch &lt;- []string&#123;&#125;\t&#125; else &#123;\t\tch &lt;- urls\t&#125;&#125;func master(ch chan []string, fetcher Fetcher) &#123;\tn := 1\tfetched := make(map[string]bool)\tfor urls := range ch &#123;\t\tfor _, u := range urls &#123;\t\t\tif fetched[u] == false &#123;\t\t\t\tfetched[u] = true\t\t\t\tn += 1\t\t\t\tgo worker(u, ch, fetcher)\t\t\t&#125;\t\t&#125;\t\tn -= 1\t\tif n == 0 &#123;\t\t\tbreak\t\t&#125;\t&#125;&#125;func ConcurrentChannel(url string, fetcher Fetcher) &#123;\tch := make(chan []string)\tgo func() &#123;\t\tch &lt;- []string&#123;url&#125;\t&#125;()\tmaster(ch, fetcher)&#125;\n\n\n在这种实现方式中，不需要使用锁。有一个master线程，它有一个表格，但是这个表格是master函数私有的，master函数并不像前一个版本那样创建。这个版本为每个URL创建一个goroutine，但是只由master来创建，只有唯一一个master创建这些线程 ，所以我们没有一个函数的树形结构，我们只有一个master，在16行创建了自己的私有mapfetched :&#x3D; make(map[string]bool)，记录哪些URL已经爬取，然后创建一个channel，只有一个channel 所有的worker线程都将通过这个channel沟通。\n这个思路是，启动一个worker线程，每个worker线程在结束时只会通过channel发送恰好一份数据给master，这份数据包含了这个worker从网页上爬取的网页中的URL的列表。master在第17行循环中 从channel中读取数据for urls :&#x3D; range ch。如果URL还未被爬取，它将在第22行启动一个新的worker去爬取那个URL go worker(u, ch, fetcher)。\nworker线程不共享任何对象，worker和master之间也不共享任何对象，所以我们不必担心锁和race。\n","categories":["分布式系统"],"tags":["Golang","分布式系统","6.824"]},{"title":"MIT 6.824 Lecture3-GFS","url":"/2024/07/03/MIT-6.824-Lecture3-GFS/","content":"Lecture 3-GFS[(289条消息) 谷歌文件系统GFS理解_小炮车的博客-CSDN博客_google文件系统gfs](https://blog.csdn.net/SwjtuPC/article/details/123652626?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=GFS PRIMARY&amp;utm_medium&#x3D;distribute.pc_search_result.none-task-blog-2allsobaiduweb~default-0-123652626.142^v47^pc_rank_34_ctr25,201^v3^add_ask&amp;spm&#x3D;1018.2226.3001.4187)\n这门课程的主要内容是“大型存储”，GFS是这门课里有关如何构建大型存储系统的众多案例学习的第一篇。存储是一种关键的抽象，很多系统要么是设计的简单易用的存储接口，要么是基于底层存储进而构建。在分布式系统中，可能有各种各样重要的抽象可以应用在分布式系统中，但是实际上，简单的存储接口往往非常有用且极其通用。构建分布式系统大多都是关于如何设计存储系统，或是设计其它基于大型分布式存储的系统。因此我们会更加关注如何为大型分布式存储系统设计一个优秀的接口，以及如何设计优秀的存储系统的内部结构。\n感觉就是分布式存储是很多分布式的底层，因此一个优秀、简单、抽象的接口和优秀的存储内部结构就很重要了。这里一方面是说明存储的重要性，另一方面值得关注的是接口和存储内部结构，这两点都很重要。\n3.1 Why HARD为什么分布式存储系统会如此之难，以至于你需要做大量的工作才能让它正确工作？\n\nPerformance –&gt; Sharding\nFault –&gt; Tolerance\nTolerance –&gt; Replication\nRepl –&gt; In Consistency\nConsistency –&gt; Low Performance\n\n人们设计大型分布式系统或大型存储系统出发点通常是想获取巨大的性能加成，通过利用数百台计算机的资源来同时完成大量工作。因此，性能performance问题就成为了最初的诉求。 之后，很自然的想法就是将数据分割放到大量的服务器上，这样就可以并行的从多台服务器读取数据。我们将这种方式称之为分片（Sharding）。如果你在成百上千台服务器进行分片，你将会看见常态的故障。数千台服务器里每天会有一台服务器宕机，甚至每个小时都可能会发生错误。因此需要自动化的方法而不是人工介入来修复错误。每天都有大量错误发生，需要自动化的容错即fault tolerance。实现容错最有用的一种方法是使用复制，只需要维护2-3个数据的副本，当其中一个故障了，你就可以使用另一个。如果想要容错能力就得有复制（replication）。如果有复制，那就有了两份以上的数据副本，而且很容易不一致。本来想有了多个副本，就能通过任一实现容错，现在发现副本间数据很难完全一致（严格来说，它们就不再互为副本了）。这时候向不同副本请求，获取的数据也就不一样了。因此复制又带来了不一致的问题inconsistency。通过合理的设计可以避免不一致的问题，并且让数据看起来也表现的符合预期。但这样需要额外的工作，需要服务器间额外的网络交互，这样又导致性能降低。因此为了获得一致性，又需要导致性能降低。实际设计系统时，这些问题都难以避免，因此就要在性能和一致性之间权衡，并为一致性的保障做出性能上的让步，否则系统就会出现异常问题。\n3.2 Strong Consistency对于具备强一致 strong consistency或者好的一致性 good consistency的系统，从应用程序或者客户端看起来就像是和一台服务器在通信。尽管我们会通过数百台计算机构建一个系统，但是对于一个理想的强一致模型，你看到的就像是只有一台服务器，一份数据，并且系统一次只做一件事情。可以认为完全就是单个服务器上的单线程，同一时间只处理来自客户端的一个请求。举例来说：（一个强一致性系统的示例）一个只支持put, get的 key-value 系统。为了让服务有可预期的行为，需要定义一条规则：一个时间只执行一条请求。这样每个请求都可以看到之前所有请求按照顺序执行生成的数据。如果我们有一些客户端，客户端C1发起写请求将X设置成1；在同一时刻，客户端C2发起写请求将X设置成2。在C1和C2的写请求都执行完毕之后，客户端C3会发送读取X的请求，并得到了一个结果。客户端C4也会发送读取X的请求，也得到了一个结果。现在的问题是，这两个客户端看到的结果是什么？\n学生提问：为什么一定要一次只处理一个请求？Robert教授：假设C1和C2在同一时间发起请求，之后在某个时刻，服务器会响应它们。但是无法判断两个请求处理的先后顺序，可能先处理C1后处理C2，这样最终结果是2；反之则是1。这个例子也说明，即使非常简单的系统，仍然会出现一些模糊的场景使得你不知道系统的执行过程以及输出结果。能做的只是从产生的结果来判断系统的输出是一致性还是非一致性。如果C3读X得到2，那么C4最好也是读X得到2，否则就不是强一致性了。但是这里的单系统又会带来容错能力的问题，又需要构建多副本的分布式系统，但这却又是所有问题的开始。\n3.3 Bad Replication Design假设有一个类似上面的支持put, get的 key-value 系统，但是这里启动了两个服务以便于容错。假设客户端C1和C2都想执行写请求，其中一个要写X为1，另一个写X为2；每一个请求同时发给两个服务。这时，两个服务处理C1和C2的先后顺序有可能不一致，就会导致X最终结果不一致。如果C3从S1读数据，C4从S2读数据，这两个客户端读取的数据不一样。如果挂了一个服务，那么后面读取的可能和之前读到的值不同。这个问题是可以解决的，但是需要服务器之间额外的通信，同时也会提高系统的复杂度。获取强一致性会带来复杂度的提升，当然也有很多方法能够在还不错的一致性和存在小瑕疵之间平衡。\n3.4 GFS的设计目标Google有大量的数据（网页、视频、索引中间文件），需要大量的磁盘来存储这些数据，同时也需要能借助MapReduce这样的工具来快速处理这些数据，因此Google需要能够快速的并行访问这些海量数据。谷歌构建了一个大型快速的文件系统，这个文件系统的数据是全局有效的，不同应用程序都可以从中读取数据。为了提高容量，文件会被GFS分割之后存放在多个服务器上，这样一方面从多个服务器上同时读同一个文件，获得了更高的吞吐；另一方面文件分割存储还可以保存比单个磁盘还要大的文件。因为在数百台服务器上构建了存储系统，系统需要具有一定的故障修复能力。GFS被设计成只在一个数据中心运行，单个GFS只存在于单个数据中心的单个机房里。理论上应该副本间跨数据中心比较好，但是这样实现起来比较困难。GFS也只是谷歌工程师内部使用。\n单数据中心可能是距离带来的性能影响，需要大量额外的设计逻辑。\nGFS在各个方面对大型的顺序文件读写做了定制，是为TB级别的文件而生，只支持顺序访问，不支持随机访问。某种程度上来说，它有点像批处理的风格。GFS并没有花费过多的精力来降低延迟，它的关注点在于巨大的吞吐量上，因此单次操作都涉及到MB级别的数据。存储系统有单独针对小份数据优化的系统，但GFS并不是。GFS论文发表在2003年的SOSP会议上，它描述了一个真正运行在成百上千台计算机上的系统，规模远大于学术界。反映了工业界对于保障系统正常工作和节省成本的经验。论文也提出了一个当时非常异类的观点：存储系统具有弱一致性也是可以的，GFS并不保证返回正确的数据，其目标是提供更好的性能。学术论文做多是多个Master节点共同分担工作，但GFS却使用单个Master节点（Active-Standby模式，只有一个Master节点在工作）。\n学生提问：如果GFS返回错误的数据，会不会影响应用程序？Robert教授：如果你通过搜索引擎做搜索，20000个搜索结果中丢失了一条或者搜索结果排序是错误的，没有人会注意到这些。尽管GFS可能会返回错误的数据，但是可以在应用程序中做一些补偿。例如论文中提到，应用程序应当对数据做校验，并明确标记数据的边界，这样应用程序在GFS返回不正确数据时可以恢复。\n关于这个问题，后面关于spanner等基于GFS的系统是一个很好的答案。\n3.5 Master Data了解系统如何容错以及一致性，就需要知道master存放的数据。\n\n一个master节点，Active-Standby模式，只有一个Master节点在工作，用来管理文件和Chunk的信息\n上百个客户端\n大量Chunk服务器，每个上面有1-2块磁盘，用来存储实际的数据。\n\nMaster节点知道每一个文件对应的所有的Chunk的ID，每个Chunk 64MB，多个Chunk共同构成了一个文件。比如一个1G的文件，先从master节点查询对应的Chunk所在服务器，之后直接从Chunk Server读取对应的数据。Master节点内保存的数据内容主要是两个表单：\n\n\n文件名到Chunk ID或者Chunk Handle数组的对应，即一个文件对应了哪些ChunkID。\nChunk ID到Chunk数据的对应关系。这里的数据又包括了：\n每个Chunk存储在哪些服务器上，即Chunk服务器的列表\n每个Chunk当前的版本号，通过这个递增字段，用来标识最新的版本信息，cs对应的chunk值小则认为数据是不准确的\n主Chunk对应的服务器，因为对Chunk的写操作都必须在Primary Chunk 上顺序处理\n主Chunk的租约过期时间，主Chunk只能在特定的租约时间内担任主Chunk\n\n\n\n以上数据都存放在内存中，同时会有log以及checkPoint存放在磁盘上，内存中用于快速访问，磁盘中用于持久化。有些数据需要存在磁盘上，而有些不用。它们分别是：\n\nChunk Handle的数组（第一个表单）要保存在磁盘上，标记成NV（non-volatile, 非易失）表示对应的数据会写入到磁盘上。\nChunk服务器列表不用保存到磁盘上。因为Master节点重启之后可以与所有的Chunk服务器通信，并查询每个Chunk服务器存储了哪些Chunk，这里标记成V（volatile），\n版本号要不要写入磁盘取决于GFS是如何工作的，我认为它需要写入磁盘\n主Chunk的ID，Master节点重启之后会忘记谁是主Chunk，它只需要等待60秒租约到期，那么它知道对于这个Chunk来说没有主Chunk，这个时候，Master节点可以安全指定一个新的主Chunk，这里标记成V。\n类似的，租约过期时间也不用写入磁盘，这里标记成V。\n\n如果文件写满了一个64MB Chunk，之后需要新增一个Chunk或者由于指定了新的主Chunk而导致版本号更新，Master节点需要向磁盘中的Log追加一条记录，刚刚向这个文件添加了一个新的Chunk或者刚刚修改了Chunk的版本号。这种更新都需要落盘，因为磁盘更新速度有限，进而影响master节点更新速度，所以要尽可能的少写入数据到磁盘中。在磁盘中维护log而不是数据库。log数据都是向同一个地址追加，可以将最近的多个log记录一次性的写入，这样只需要等待磁盘的磁碟旋转一次。数据库本质上来说是某种B树（b-tree）或者hash table。对于B树来说，每一份数据都需要在磁盘中随机找个位置写入。当Master节点故障重启，并重建它的状态，log的最开始可能是几年之前，通过在磁盘中创建一些checkpoint点，从log中的最近一个checkpoint开始恢复，再逐条执行从Checkpoint开始的log，最后恢复自己的状态。\n3.6 GFS读文件（Read File)客户端（或者应用程序）将file name，offset，size发送给MasterMaster根据file name以及偏移量&#x2F;64MB就可以找到Chunk Handle，之后将这个chunk对应的服务器列表发送给客户端，客户端会缓存chunk和服务器列表的对应关系客户端会选择一个网络上最近的服务器（Google的数据中心中，可以从IP地址的差异判断网络位置的远近），并将Chunk Handle和偏移量发送给那个Chunk server，之后返回给客户端数据\n\n[!CAUTION]\n1.后面基于GFS的应用可以知道，为了提高效率，而且GFS是大文件的，所以一个文件可能应用只需要读取其中的一部分数据，因为这个文件本身就被应用用来对应多条不同的数据了。2.可能有点绕结合3.5的图即可\n\nChunk服务器会在本地的硬盘上，将每个Chunk存储成独立的Linux文件，并通过普通的Linux文件系统管理，Chunk文件会按照Handle（也就是ID）命名。Chunk服务器需要做的就是根据文件名找到对应的Chunk文件，之后从文件中读取对应的数据段，并将数据返回给客户端。学生提问：如果客户端有偏移量信息，那可以直接算出来是第几个Chunk吧？Robert教授：客户端可以算出来是哪个Chunk，但是客户端不知道Chunk在哪个服务器上。为了获取服务器信息，客户端需要与Master交互。Master节点找到了Chunk对应的ID，并确定了Chunk存储在哪个服务器上。\n学生提问：如果读取的数据超过了一个Chunk怎么办？Robert教授：会将一个读请求拆分成多个读请求（文件对应的多个chunk）再发送到Master节点，之后再向两个不同的Chunk服务器读取数据。\n学生提问：能再介绍一下读数据跨越了Chunk边界的情况吗？Robert教授：GFS的库会将读请求拆分，之后再将它们合并起来。比如需要Chunk7的最后两个字节，Chunk8的头两个字节，获取到这些数据之后，会将它们放在一个buffer中，再返回给调用库的应用程序。Master节点会告诉库有关Chunk的信息，而GFS库可以根据这个信息找到应用程序想要的数据。应用程序只需要确定文件名和数据在整个文件中的偏移量，GFS库和Master节点共同协商将这些信息转换成Chunk。\n学生提问：从哪个Chunk服务器读取数据重要吗？Robert教授：实际上不同Chunk服务器上的数据并不一定完全相同，应用程序应该要能够容忍这种情况。如果从不同的Chunk服务器读取数据，可能会略微不同。GFS论文提到，客户端会尝试从同一个机架或者同一个交换机上的服务器读取数据。\n3.7 GFS写文件（Write File）从应用程序的角度来看，写文件和读文件的接口都是调用GFS的库。对于写文件，客户端会向Master节点发送请求说：我想向这个文件名对应的文件追加数据，请告诉我文件中最后一个Chunk的位置，这里即为记录追加（Record Append）。\n客户端根据文件名请求master，获取chunkID（这里肯定是最后一个，当然如果是新文件第一个chunkID也是最后一个），以及对应的服务器列表，进而能够往primary chunk写文件。\n不同客户端写同一份日志文件，没有一个客户端会知道文件究竟有多长，因此也就不知道该往什么样的偏移量，或者说向哪个Chunk去追加数据。这个时候，客户端可以向Master节点查询哪个Chunk服务器保存了文件的最后一个Chunk。\n这里有很多细节冲突问题，详见下文及3.8并发量很高的情况下，返回了最后一个chunk，但是此时又被写满了，这个已经不是最后一个了？这个应该是首先会等client发送的所有数据到达之后开始写，这时候chunk发现没有足够空间了，会返回客户端错误是不是新的chunk都是通过master指定的？应该是的，之后放在文件对应的chunk list里\n写Primary Chunk写文件必须写主副本，通过master获取chunk对应的服务器列表中的主副本信息。但有时Master不一定指定了Chunk的主副本，因此需要考虑Chunk的主副本不存在的情况。对于读文件来说，可以从任何最新的Chunk副本读取数据。Master节点需要告诉客户端向哪个Chunk服务器（也就是Primary Chunk所在的服务器）去做追加操作，Master节点的部分工作就是弄清楚在追加文件时，客户端应该与哪个Chunk服务器通信。\nNo Primary 选主的逻辑\n\n会找出所有存有Chunk最新副本的Chunk服务器，因为某个副本可能因为宕机尚未更新数据\n\n找出新的Chunk副本。最新的副本是指副本中保存的版本号与Master中记录的Chunk的版本号一致。Chunk副本中的版本号是由Master节点下发的，Master节点知道，对于一个特定的Chunk，哪个版本号是最新的。\n\nMaster找到最新的副本\n\n选一个作为Primary，其他的作为Secondary\n\nMaster会增加版本号\n\nMaster节点会向Primary和Secondary副本对应的服务器发送消息告知主备关系、最新版本号–&gt;Lease\nmaster持久化版本号\n\n2.b应该是master向chunk的主副本发放lease，增加版本号\n\n\n\n\n几点说明：\n\nmaster通过版本号区别正常副本和数据落后的副本，同时master重启之后，依然可以通过版本号区分副本的情况。\nmaster会给primary一个60s的租约（60s之后停止成为primary），持有租约才能够是primary，这种机制可以确保我们不会同时有两个Primary。\n\n\n[!CAUTION]\n这里的60s，后面可以通过和master通信获得延期，实际上3个副本中的primary是master说了算\n\n学生提问：为什么不将所有Chunk服务器上保存的最大版本号作为Chunk的最新版本号？Robert教授：master重启之后，对于每一个chunk，汇总其各副本的版本号，但是无法确认当前最大的就是最新的，可能最新的并未启动。当Master找不到持有最新Chunk的服务器时，有两种可能：要么Master会等待，并不响应客户端的请求；要么会返回给客户端现在还不知道Chunk在哪，过会再重试吧。比如机房断电导致服务器大规模重启，这时只能等待，因为不会想使用Chunk的旧数据。\n\n\n通过版本号匹配，确认最新的chunk版本，这里有两点思考，1）应该是并未保存当前的副本都有哪些节点，全靠上报，当然这里是可以简单优化的2）通过版本号确定最新的，第二个有点类似raft选主，最新的term可以成为leader\n因为肯定不想使用旧数据，所以只能等待最新版本的chunk上线\n一个思考：这种通过别人选主和raft副本之间自己选主的区别联系优劣？\n\n\n学生提问：如果Chunk服务器上报的版本号高于Master存储的版本号会怎么样？Robert教授：GFS论文说，chunk server上报了一个比Master记住的版本更高的chunk版本。Master会认为它在分配新的Primary服务器时出现了错误，并且会使用这个更高的版本号来作为Chunk的最新版本号。当Master向Primary和Secondary发送完消息之后就崩溃了，可能会出现上面这种情况。为了让Master能够处理这种情况，Master在发送完消息之后，需要将Chunk的最新版本写入到磁盘中。这里的写入或许需要等到Primary和Secondary返回确认消息之后。我（Robert教授）也不太确定Master究竟是先写本地磁盘中的版本号，然后再通知Primary和Secondary，还是反过来。但是不管怎么样，Master会更新自己的版本号，并通知Primary和Secondary说，你们现在是Primary和Secondary，并且版本号更新了。\n感觉是要等chunk的副本确认版本号之后，master才能持久化更新chunkID，保障master的版本号永远不会大于chunk的，不然永远找不到最新的了。同样，这种情况才会出现chunk最新版本号更高的问题。磁盘故障什么的除外。\nPrimary写\n\n客户端根据文件名从master获取到了最后一个chunkID以及对应的ChunkServer及其中的primary\n客户端发送要追加的数据\nchunkServer会将数据写入临时位置，并不会直接追加到文件中，\n当所有的服务器都返回确认消息说，已经有了要追加的数据，客户端会向Primary服务器发送一条消息说，你和所有的Secondary服务器都有了要追加的数据，现在我想将这个数据追加到这个文件中\nPrimary会查看当前文件结尾的Chunk，并确保Chunk中有足够的剩余空间，然后将客户端要追加的数据写入Chunk的末尾，同时也会将offset发送给Secondary执行追加\nSecondary返回成功给primary\nprimary收到所有成功回复，会向客户端返回写入成功，如果有一个服务器写失败或者超时，会向客户端返回写入失败\n\n几点说明：\n\nPrimary服务器或许会从大量客户端收到大量的并发请求，Primary服务器会以某种顺序，一次只执行一个请求。\n对于Secondary服务器来说，可能会执行失败，比如说网络丢包，磁盘空间不足，发生故障\n如果客户端从Primary得到写入失败，那么客户端应该重新发起整个追加过程，客户端首先会重新与Master交互，找到文件末尾的Chunk\n\n\n\nprimary控制写入的offset\n这里要求三副本都写成功才能返回给客户端成功，之后客户端可以直接就近读取\n只要写失败，客户端都要重新请求master，因为失败原因多多难以预料，保险起见直接重新走流程\n\n\n关于master指定primary 以及版本号的问答\n\n什么时候版本号会增加？\nRobert教授：版本号只在Master节点认为Chunk没有Primary时才会增加。在一个正常的流程中，如果对于一个Chunk来说，已经存在了Primary，那么Master节点会记住已经有一个Primary和一些Secondary，Master不会重新选择Primary，也不会增加版本号。它只会告诉客户端说这是Primary，并不会变更版本号。\n\n如果Master节点发现Primary挂了会怎么办？\nRobert教授：Master指定了一个Primary，如果之后ping不通，并不会立即选主，因为这里可能是多种原因导致一两次不通，更主要是这样会导致同时存 在两个primary（从客户端的视角，客户端1认为A是主，后面的客户端2认为B是主），会分别处理不同的写请求，最终会导致有两个不同的数据拷贝。这被称为脑裂（split-brain），通常是由网络分区引起的，比如说Master无法与Primary通信，但是Primary又可以与客户端通信，这就是一种网络分区问题，网络故障是这类分布式存储系统中最难处理的问题之一。要避免错误的为同一个Chunk指定两个Primary的可能性。Master采取的方式是，当指定一个Primary时，为它分配一个租约，Primary只在租约内有效。Master和Primary都会知道并记住租约有多长，当租约过期了，Primary会停止响应客户端请求，它会忽略或者拒绝客户端请求。如果Master不能与Primary通信，并且想要指定一个新的Primary时，Master会等到前一个Primary的租约到期。所以master必须等到租约到期之后，这样可以确保不会出现这种脑裂情况。\n\n\n这里的租约，肯定不能用系统时间，如果用倒计时的话，是否需要考虑网络上花费的时间？比如master指定primary之后就开始计时，或者收到primary的响应之后开始，总之master和指定的primary必有先后。好像lease的话，一般会在块到期的前几秒时间就立即发送消息，进行续租。但是过期的判断是否也加上这个？加上这个是否带来延迟。\n关于写入的问答如果是对一个新的文件进行追加，那这个新的文件没有副本，会怎样？Robert教授：Master节点或许会通过随机数生成器创造一个新的Chunk ID。之后Master节点会创建一条新的Chunk记录，再随机选择一个Primary和一组Secondary并告诉它们，你们将对这个空的Chunk负责，请开始工作。\n写文件失败之后Primary和Secondary服务器上的状态如何恢复？Robert教授：Primary会回复客户端说执行失败，部分副本还是成功将数据追加了。一个Chunk的部分副本成功完成了数据追加，而另一部分没有成功，这种状态是可接受的，没有什么需要恢复，这就是GFS的工作方式。\n写文件失败之后，读Chunk数据会有什么不同？Robert教授：如果写文件失败之后，一个客户端读取相同的Chunk，客户端可能可以读到追加的数据，也可能读不到，取决于客户端读的是Chunk的哪个副本。\n可不可以通过版本号来判断副本是否有之前追加的数据？Robert教授：所有的Secondary都有相同的版本号，版本号只会在Master指定一个新Primary时才会改变，通常只有在原Primary发生故障了，才会指定一个新的Primary。副本（参与写操作的Primary和Secondary）都有相同的版本号，你没法通过版本号来判断它们是否一样，或许它们就是不一样的（取决于数据追加成功与否）。\n客户端将数据拷贝给多个副本会不会造成瓶颈？Robert教授：考虑到底层网络，写入文件数据的具体传输路径可能会非常重要。当论文第一次说客户端会将数据发送给每个副本。之后论文又改变了说法，说客户端只会将数据发送给离它最近的副本，之后那个副本会将数据转发到另一个副本，以此类推形成一条链，直到所有的副本都有了数据。这样一条数据传输链可以在数据中心内减少跨交换机传输（否则，所有的数据吞吐都在客户端所在的交换机上）。\n为什么立即指定一个新的Primary是坏的设计？Robert教授：因为客户端会通过缓存提高效率，客户端会在短时间缓存Primary的身份信息（这样，客户端就不用每次都会向Master请求Primary信息）。即使没有缓存，也有可能刚向客户端返回之后，master就指定了新的primary。如果不采用其它机制，前一个客户端是没办法知道收到的Primary已经过时了，此时如果前一个客户端执行写文件，那么就会与后来的客户端产生两个冲突的副本。\n如果写入数据失败了，不是应该先找到问题在哪再重试吗？Robert教授：论文中在重试追加数据之前没有任何中间操作，因为可能是网络导致部分数据丢失。客户端重试，对于大多数错误来说可以直接解决。我们希望如果某个副本出错，master能够指定新的，剔除出错的副本，同时指定版本号和新的primary，旧的副本也永远因为版本号旧被抛弃。但是论文里只是说，客户端重试，并且期望之后能正常工作。Master节点会ping所有的Chunk服务器，如果Secondary服务器挂了，Master节点可以发现并更新Primary和Secondary的集合，之后再增加版本号。但是这些都是之后才会发生（而不是立即发生）。\n3.8 GFS的一致性对于一个新建的文件f1，会指定一个新的chunk以及对应的三个副本。客户端向文件追加数据A，此时三个副本（一个Primary和两个Secondary），都成功的将数据追加到了Chunk，Chunk中的第一个记录是A。第二个客户端向文件f1追加数据B，由于网络问题导致一个secondary副本写失败，现在我们有两个副本有数据B，另一个没有。第三个客户端向文件f1追加数据C，发送给主副本之后，Primary选择了偏移量，并将偏移量告诉Secondary，将数据C写在Chunk的这个位置。第二个客户端会收到写失败的回复，之后会再次请求追加数据B，此时一切正常，写入成功。又一个客户端向文件f1追加数据D，最终写成功两个副本，但是这个客户端挂了，因此并不会再次进行重试，最后数据D出现在某些副本中，而其他副本则完全没有。在GFS的这种工作方式下，Primary返回写入失败会导致不同的副本有完全不同的数据。\n\n如果一个客户端读文件f1，读到的内容取决于读取的是Chunk的哪个副本，不同的副本，读取数据的顺序是不一样的。如果读取的是第一个副本，那么客户端可以读到A、B、C，然后是一个重复的B。如果读取的是第三个副本，那么客户端可以读到A，一个空白数据，然后是C、B。\n客户端重新发起写入的请求时从哪一步开始重新执行的？Robert教授：根据我从论文中读到的内容，（当写入失败，客户端重新发起写入数据请求时）客户端会从整个流程的最开始重发。客户端会再次向Master询问文件最后一个Chunk是什么，因为文件可能因为其他客户端的数据追加而发生了改变。\n为什么GFS要设计成多个副本不一致？Robert教授：我不明白GFS设计者为什么要这么做。GFS可以设计成多个副本是完全精确同步的。但是为了保持同步，要使用各种各样的技术。其中一条规则就是不能允许这种只更新部分服务器的不完整操作。即使客户端挂了，系统只要收到了请求，就要保障完成，primary需要确保每一个副本都得到每一条消息。\n如果第一次写B失败了，C应该在B的位置吧？Robert教授：实际上并没有。Primary将C添加到了Chunk的末尾，在B第一次写入的位置之后。当写C的请求发送过来时，Primary实际上可能不知道B的命运是什么。因为我们面对的是多个客户端并发提交追加数据的请求，为了获得高性能，你会希望Primary先执行追加数据B的请求，一旦获取了下一个偏移量，再通知所有的副本执行追加数据C的请求，这样所有的事情就可以并行的发生。Primary也可以判断B已经写入失败了，然后再发一轮消息让所有副本撤销数据B的写操作，但是这样更复杂也更慢。\nprimary不去校验其它副本有没有写成功，会指定其他副本写入的offset，这样如果自己写成功了，其他副本有失败的，也不会有影响；如果自己写失败，其它副本成功了，也时按照自己的offset写入新的。这样做的目的大概是为了提高性能，但是客户端就要自己处理这种乱序的数据问题。\nGFS这样设计的理由是足够的简单，但是同时也给应用程序暴露了一些奇怪的数据。这里希望为应用程序提供一个相对简单的写入接口，但应用程序需要容忍读取数据的乱序。如果应用程序不能容忍乱序，应用程序要么可以通过在文件中写入序列号，这样读取的时候能自己识别顺序，要么如果应用程序对顺序真的非常敏感那么对于特定的文件不要并发写入。例如，对于电影文件，你不会想要将数据弄乱，当你将电影写入文件时，你可以只用一个客户端连续顺序而不是并发的将数据追加到文件中。\n将GFS升级成强一致系统（增加了系统的复杂度，增加了系统内部组件的交互）\n\n你可能需要让Primary来探测重复的请求，这样第二个写入数据B的请求到达时，Primary就知道，我们之前看到过这个请求，可能执行了也可能没执行成功。Primay要尝试确保B不会在文件中出现两次。首先需要的是探测重复的能力。\n\n这里大概是考虑到客户端或者网络什么的，会出现重复的请求，通过序列号应该就能支持。\n\n\n对于Secondary来说，如果Primay要求Secondary执行一个操作，Secondary必须要执行而不是只返回一个错误给Primary。对于一个严格一致的系统来说，是不允许Secondary忽略Primary的请求而没有任何补偿措施的。如果Secondary有一些永久性故障，例如磁盘被错误的拔出了，你需要有一种机制将Secondary从系统中移除，这样Primary可以与剩下的Secondary继续工作。但是GFS没有做到这一点，或者说至少没有做对。\n\n这里是否有点绝对，首先无法保障secondary一定能成功，这时primary认为大家都失败了即可。\n\n\n当Primary要求Secondary追加数据时，直到Primary确信所有的Secondary都能执行数据追加之前，Secondary必须小心不要将数据暴露给读请求。在第一个阶段，Primary向Secondary发请求，要求其执行某个操作，并等待Secondary回复说能否完成该操作，这时Secondary并不实际执行操作。在第二个阶段，如果所有Secondary都回复说可以执行该操作，这时Primary才会说，好的，所有Secondary执行刚刚你们回复可以执行的那个操作。这是现实世界中很多强一致系统的工作方式，这被称为两阶段提交（Two-phase commit）。\n\n这里是不能让客户端读到脏数据\n\n\n当Primary崩溃时，可能有一组操作由Primary发送给Secondary，Primary在确认所有的Secondary收到了请求之前就崩溃了。当一个Primary崩溃了，一个Secondary会接任成为新的Primary，但是这时，新Primary和剩下的Secondary会在最后几个操作有分歧，因为部分副本并没有收到前一个Primary崩溃前发出的请求。新的Primary上任时，需要显式的与Secondary进行同步，以确保操作历史的结尾是相同的。\n\n对于GFS，切换primary时，客户端会超时失败，之后请求master，最终得到了新的primary信息，这时不管或者primary写成功失败，它也无需考虑别人上次是成功失败，它只需要把自己最后的offset发过去，但是这样客户端读不同的副本得到的结果不一致，客户端需要自己处理这种不一致。\n为了保障强一致性，新primary就需要有一个同步操作，让大家都一致。\n\n\n最后，时不时的，Secondary之间可能会有差异，或者客户端从Master节点获取的是稍微过时的Secondary。系统要么需要将所有的读请求都发送给Primary，因为只有Primary知道哪些操作实际发生了，要么对于Secondary需要一个租约系统，就像Primary一样，这样就知道Secondary在哪些时间可以合法的响应客户端。\n\n这里应该是客户端读的时候，如果读secondary，可能这个secondary持有的数据并不是新的（新加入的，还在catch up阶段），这时它就不应该响应客户端。\n读取也是一个很有趣的事，这里可以在raft中获得更多体会。\n\n\n\nGFS单master的问题最后，让我花一分钟来介绍GFS在它生涯的前5-10年在Google的出色表现，总的来说，它取得了巨大的成功，许多许多Google的应用都使用了它，许多Google的基础架构，例如BigTable和MapReduce是构建在GFS之上，GFS在Google内部广泛被应用。它最严重的局限可能在于，它只有一个Master节点，会带来以下问题：\n\nMaster节点必须为每个文件，每个Chunk维护表单，随着GFS的应用越来越多，这意味着涉及的文件也越来越多，最终Master会耗尽内存来存储文件表单。你可以增加内存，但是单台计算机的内存也是有上限的。\n\n这个大概是单master内存有限，后面可以将元数据剥离出来。\n\n\n单个Master节点要承载数千个客户端的请求，而Master节点的CPU每秒只能处理数百个请求，尤其Master还需要将部分数据写入磁盘，很快客户端数量超过了单个Master的能力。\n\n单节点复杂所有的选主，而且客户端要从master获取primary的信息，这里能想到的一个就是根据业务搭建一个新的集群。\n思考：现实问题中在多集群和单一集群之间的利弊与权衡？即搭建多个集群固然简单，有什么弊端吗？\n\n\n应用程序发现很难处理GFS奇怪的语义（本节最开始介绍的GFS的副本数据的同步，或者可以说不同步）。\n\n从我们读到的GFS论文中，Master节点的故障切换不是自动的，需要人工干预来处理已经永久故障的Master节点，并更换新的服务器，这可能需要几十分钟甚至更长的而时间来处理，对于某些应用程序来说，这个时间太长了。\n\n这个感觉时Google自己留了一手。\n\n\n\n","categories":["分布式系统"],"tags":["分布式系统","6.824","GFS"]},{"title":"垂类心理健康咨询大模型MeChat的部署和性能对比","url":"/2024/08/01/MeChat/","content":"垂类心理健康咨询大模型MeChat的部署和性能对比部署和运行qiuhuachuan&#x2F;smile: SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support (github.com)\ngit clone https://github.com/qiuhuachuan/smile.git //如果网络不行就git clont到本地再scp到服务器 data目录可以忽略掉curl --proto &#x27;=https&#x27; --tlsv1.2 -sSf https://sh.rustup.rs | sh //rust complier 然后要重新打开终端 已有rust complier即忽略这条命令RUSTUP_TOOLCHAIN=1.72.0 pip install tokenizers==0.13.2 /*执行上面这条命令，如果不这样做会报错：报错：ERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects报错： error: casting `&amp;T` to `&amp;mut T` is undefined behavior, even if the reference is unused, consider instead using an `UnsafeCell`*/vi requirements.txt //修改requirements.txt中的torch版本为2.2.0，设置完后:wq!退出pip install -r requirements.txt .0export HF_HOME=&quot;~/verticalLLM/lzjr/smile/cache&quot; export HF_ENDPOINT=https://hf-mirror.com //临时换源export HF_HUB_OFFLINE=0 //设置线上的echo $HF_ENDPOINTecho $HF_HUB_OFFLINE/*注意这个目录是要有权限操作的，这一步的目的是如果不这样操作直接运行Mechat.py会报错：报错：PermissionError: [Errno 13] Permission denied: &#x27;/data/.cache/huggingface/modules/transformers_modules/THUDM&#x27;*/python MeChat.py\n\n开始下载了\n\n加载完之后，开始运行\n\n表现对比可以看到Mechat扩展真实的心理互助 QA为多轮的心理健康支持多轮对话，提高了通用语言大模型在心理健康支持领域能力的表现，更加符合在长程多轮对话的应用场景；而通用大模型并不能做到这一点。\n\n人到老年似乎越来越孤独，孤独终老会不会很可怜?\n\nMechat\n\n\n\nKimi\n\n\n\n\n强迫思维严重影响到我的学习与生活该怎么办？\n\nMechat\n\n\nKimi\n\n\n\n\n女儿10岁同学不和她玩，女儿就动手煽了同学的脸？已经是第二次动手打人家，上一次也是因为不和她玩孩子是不是有心理问题？\n\nMechat\n\n\nKimi\n\n\n\n\n不论睡多久，只要开会就犯困，为什么？工作以来，对于那种不是在解决问题，或者是流水账的会议，就一定会犯困，坚持不过30分钟。新单位想转正，试用期开会三次打盹三次，但实在是太无聊。每次开会就会特别困(இдஇ; )，无语눈_눈，困死了(๑ó﹏ò๑)\n\nMechat\n\n\nKimi\n\n\n\n\n还有50天考研非常没信心，觉得未来模糊对不起父母\n\nMechat\n\n\nKimi\n\n\n\n\n\n","categories":["大模型"],"tags":["LLM","MeChat"]},{"title":"TOR Leaf Spine交换机","url":"/2025/06/25/TOR%20Leaf%20Spine%E4%BA%A4%E6%8D%A2%E6%9C%BA/","content":"TOR Leaf Spine交换机Spine、Leaf、ToR 交换机：数据中心网络的三层核心架构这三种交换机是现代数据中心网络架构（通常称为 Spine-Leaf 架构）的核心组件，主要用于处理东西向流量（服务器之间的流量），替代了传统的三层网络架构（接入层-汇聚层-核心层）。\n1. ToR（Top-of-Rack）交换机 - 接入层\n位置：位于服务器机柜顶部\n\n功能：\n\n直接连接机柜内的服务器（每个ToR连接12-48台服务器）\n提供1G&#x2F;10G&#x2F;25G端口连接服务器\n提供40G&#x2F;100G&#x2F;400G上行端口连接Leaf层\n实现机柜内部服务器之间的数据交换\n\n\n特点：\n\n端口密度高\n\n\n部署成本低（单机柜部署）\n\n易于维护（故障仅影响单个机柜）\n\n\n应用场景：\n[机柜]|-- ToR 交换机    ├── 服务器1    ├── 服务器2    └── ...（其他服务器）\n\n2. Leaf 交换机 - 汇聚层\n位置：位于一组机柜的中心汇聚点\n\n功能：\n\n汇聚多个ToR交换机的流量\n提供跨机柜通信能力\n连接所有Spine交换机（全互连架构）\n实施网络策略（ACL、QoS等）\n\n\n特点：\n\n高上行带宽（通常100G&#x2F;400G端口）\n\n\n支持ECMP（等价多路径）\n\n可堆叠或集群部署\n\n\n连接关系：\nLeaf 交换机├── ToR 交换机1 (机柜1)├── ToR 交换机2 (机柜2)├── ...└── Spine 交换机（所有）\n\n3. Spine 交换机 - 核心层\n位置：数据中心网络核心\n\n功能：\n\n连接所有Leaf交换机\n提供Leaf之间的高速互连\n不连接任何服务器\n实现数据中心的横向扩展\n\n\n特点：\n\n超高背板带宽（通常&gt;10Tbps）\n\n\n低延迟（微秒级转发）\n\n高端口密度（通常48-128个100G+端口）\n\n\n关键作用：\nSpine 交换机（Spine 1）   Spine 交换机（Spine 2）     |       |                   |       |  Leaf1    Leaf2              Leaf1    Leaf2   / \\      / \\                / \\      / \\ ToR1 ToR2 ToR3 ToR4        ToR1 ToR2 ToR3 ToR4\n\n三层架构的工作原理服务器A → ToR交换机1 → Leaf交换机1                       ↘                      Spine交换机（所有）                      ↗服务器B → ToR交换机2 → Leaf交换机2\n\n\n同一机柜通信(服务器A → ToR → 服务器B) ：流量不离开机柜\n同Leaf不同机柜通信(服务器A → ToR1 → Leaf → ToR2 → 服务器C) ：流量在Leaf层完成\n跨Leaf通信(服务器A → ToR1 → Leaf1 → Spine → Leaf2 → ToR2 → 服务器D) ：必经Spine层\n\n与传统三层架构对比\n\n\n特性\n传统架构（核心-汇聚-接入）\nSpine-Leaf 架构\n\n\n\n扩展性\n垂直扩展（纵向）\n水平扩展（横向）\n\n\n最大跳数\n4跳以上\n固定2跳\n\n\n带宽收敛比\n4:1 或更高\n1:1（无阻塞）\n\n\n东西向流量优化\n差\n极佳\n\n\n故障域\n大范围\n隔离域小\n\n\n适用场景\n南北向流量为主\n云计算&#x2F;虚拟化环境\n\n\n技术演进趋势\n融合架构：现代超融合系统中，ToR和Leaf常合并为分布式架构\n智能网卡：在ToR层引入DPU&#x2F;IPU智能网卡卸载网络功能\n光电混合：Spine层开始采用光电混合交换技术提高能效比\n可编程芯片：P4可编程芯片在Leaf和Spine层逐渐普及\n\n现代云数据中心（如AWS&#x2F;Azure&#x2F;GCP）大多采用这种架构，Facebook甚至实现了单层Spine架构（称为F16），支持数十万台服务器的无阻塞通信。\n","categories":["计算机网络"],"tags":["分布式系统","集群","基础架构"]},{"title":"Mem0 Building Production-Ready AI Agents with Scalable Long-Term Memory","url":"/2025/08/12/Mem0%20Building%20Production-Ready%20AI%20Agents%20with%20Scalable%20Long-Term%20Memory/","content":"Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory为什么仅扩大上下文窗口还不够？近年来，各大模型厂商不断推出具有更长上下文窗口的模型，从128K到甚至千万级Token。然而，这只是“推迟”了问题的发生，并未从根本上解决问题。在实际应用中，扩大上下文窗口面临两大瓶颈：\n\n信息丢失与噪声干扰：在长达数周或数月的交互中，对话历史不可避免地会超出任何上下文窗口的限制。更重要的是，对话内容往往是发散的。用户可能在讨论完饮食偏好后，又进行了数小时关于编程问题的交流。当再次回到食物话题时，关键的“素食”信息可能被埋没在海量的无关代码讨论中，这便是所谓的“大海捞针”问题。\n性能与成本的挑战：处理超长上下文不仅会显著增加模型的推理延迟，还会带来高昂的Token成本。此外，研究表明，LLM的注意力机制在处理超长序列时会发生退化，模型难以有效利用距离遥远的信息。\n\n因此，我们需要一种更智能的记忆机制，它应能模仿人类的认知过程：选择性地存储重要信息，整合相关概念，并在需要时准确检索。\nMem0：事件记忆向量库\nMem0 采用增量处理范式，能够无缝地在持续对话中运行。其核心架构由提取（Extraction）和更新（Update）两个阶段组成。\n1. 提取阶段：动态捕捉关键信息当系统接收到一个新的消息对（如用户提问和AI回答）时，提取阶段便会启动。为了准确理解当前对话的上下文，系统会结合两种信息源：\n\n全局上下文：从数据库中检索的整个对话的摘要（Summary），提供对话的宏观主题。\n局部上下文：最近的几条消息，提供细粒度的即时背景。\n\n这两种上下文与新消息对共同构成一个完整的提示（Prompt），输入给一个LLM（论文中使用GPT-4o-mini）来执行提取功能。该LLM会从最新的交流中提炼出关键事实（如“用户是素食主义者”），形成一组候选记忆。\n2. 更新阶段：智能管理记忆库提取出的候选记忆并不会被直接存入数据库，而是会进入更新阶段，以确保记忆库的一致性和无冗余。该过程通过一个智能的“工具调用（Tool Call）”机制实现，具体流程如下：\n\n对于每一个候选记忆，系统会：\n\n在向量数据库中检索出语义最相似的已有记忆。\n将候选记忆与这些相似记忆一同提交给LLM。\nLLM会自主决策执行以下四种操作之一：\n\n\nADD：如果候选记忆是全新的信息，则添加。\nUPDATE：如果候选记忆是对现有信息的补充或更新，则进行修改。\nDELETE：如果候选记忆与现有信息相矛盾，则删除旧信息。\nNOOP：如果候选记忆是重复或无关的，则不执行任何操作。\n\n通过这种方式，Mem0 能够动态维护一个精炼、准确且与时俱进的记忆库。\nMem0-g：利用图结构深化记忆为了捕捉信息之间更复杂的关系，研究团队还提出了 Mem0 的增强版——Mem0-g（g代表graph）。它将记忆存储为知识图谱，其中节点代表实体（如人、地点），边代表它们之间的关系（如“居住在”、“喜欢”）。\n\n相比于向量数据库，知识图谱能够存储更加复杂的关系、高级的概念和知识，当它和专注于存储事实片段的向量数据库结合时，能够做到互补，使得整个记忆系统更加完备。\nMem0-g 的核心流程同样分为提取和更新：\n\n图提取：通过一个两阶段的LLM流程，首先从文本中识别出关键实体及其类型（如“Alice - Person”），然后生成连接这些实体的关系三元组（如 (Alice, lives_in, San_Francisco)）。\n图更新与冲突解决：在集成新信息时，Mem0-g 会检测新关系是否与图中已有关系冲突。如果存在冲突，一个基于LLM的“更新解析器”会决定是否将旧关系标记为“过时”，而不是直接删除。这种设计保留了信息的时序性，为更复杂的时间推理提供了可能。\n\n通过将结构化的图表示与语义灵活性相结合，Mem0-g 能够支持更高级的推理，尤其是在需要跨越多个互联事实进行推断的场景中。\n性能深度评测：Mem0与主流方案的对决研究团队在长对话记忆评测基准 LOCOMO 上，将 Mem0 和 Mem0-g 与六大类基线方法进行了全面对比，包括已有的记忆增强系统、多种配置的RAG、全上下文方法、开源记忆方案以及商业平台。\n核心发现1：Mem0在效率与效果间取得最佳平衡评测结果（如下表和图所示）清晰地表明，与简单粗暴的RAG和全上下文方法相比，Mem0的优势巨大。\n\n\n\n方法\n平均检索Token数\n总响应延迟 (p95, 秒)\n综合质量评分 (J)\n\n\n\nRAG (最佳配置)\n~8192\n9.942\n60.97%\n\n\n全上下文\n~26031\n17.117\n72.90%\n\n\nMem0\n1764\n1.440\n66.88%\n\n\nMem0-g\n3616\n2.590\n68.44%\n\n\n\nMem0 vs. RAG：Mem0 的质量评分（J score）比最佳RAG配置高出近10%。这证明了提取精炼事实远比检索包含大量噪声的原始文本块更有效。\nMem0 vs. 全上下文：虽然全上下文方法凭借完整信息获得了最高的质量评分，但其延迟是Mem0的近12倍，Token成本也极高，完全不适用于生产环境。Mem0 以极小的性能牺牲换来了91%的延迟降低和超过90%的Token成本节省，展现了卓越的实用性。\n\n\n上图展示了不同方案的端到端延迟（线图，越低越好）和响应质量（柱状图，越高越好）。Mem0和Mem0-g在保持高质量的同时，延迟远低于全上下文方法。\n核心发现2：Mem0与Mem0-g各擅胜场\nMem0：凭借其简洁高效的自然语言记忆，在处理单跳问题（需要单个事实）和多跳问题（需要整合多个分散事实）时表现最佳。它的搜索延迟极低，非常适合需要快速响应的交互式应用。\nMem0-g：其图结构在处理需要理解事件顺序和关系的时间推理问题和开放域问题时大放异彩。结构化的关系表示显著提升了模型在这些复杂任务上的判断力。\n\n\n上图对比了各方案的搜索&#x2F;检索延迟。Mem0的搜索延迟（0.148s）是所有方法中最低的，体现了其高效的检索机制。\n核心发现3：Mem0在系统开销上远优于同类产品与商业记忆平台 Zep 相比，Mem0 的系统开销优势明显。Zep 为了构建记忆图谱，平均每段对话消耗超过600k Token，而 Mem0 仅需约7k Token。此外，Zep 的记忆构建过程涉及大量异步处理，导致新添加的记忆需要数小时才能被有效检索，这对于实时应用是不可接受的。相比之下，Mem0 的记忆构建在几分钟内即可完成。\n总结：迈向拥有持久记忆的AI未来Mem0 和 Mem0-g 通过动态提取、智能更新和高效检索，为解决LLM的长期记忆问题提供了一个强大且实用的解决方案。它们成功地在推理精度、响应速度和部署成本之间取得了理想的平衡。\n\nMem0 以其极致的效率和简洁性，为需要快速、直接事实检索的应用场景提供了理想选择。\nMem0-g 则通过结构化的图记忆，为需要深度关系理解和复杂时序推理的任务解锁了新的可能性。\n\n这项工作为构建更可靠、更高效、更具“人性”的AI代理铺平了道路，使它们能够像人类一样，在长时间的互动中建立连贯、有深度的关系。未来的研究将继续优化图操作的效率，并探索更复杂的混合记忆架构，推动AI向着能够进行真正长期合作的智能伙伴不断迈进。\n","categories":["大模型"],"tags":["人工智能","Agent","上下文"]},{"title":"保研复习准备","url":"/2024/06/24/%E4%BF%9D%E7%A0%94/","content":"保研(453条消息) 2021年计算机保研面试题_一个主机将两个端口接到网络上是否会提升吞吐量_Challow的博客-CSDN博客\n(453条消息) 吐血整理，20个计算机保研常见问题及回答模板_计算机专业20个面试常见问题_Baoyan_cs的博客-CSDN博客\n[(453条消息) 2021计算机保研经历(清软, 北深, 浙大, 南大, 中科大, 北航, 哈深, 南开, 华科, 武大, 中大)_inicho的博客-CSDN博客](https://blog.csdn.net/qq_43280818/article/details/123450451?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=计算机网络 保研&amp;utm_medium&#x3D;distribute.pc_search_result.none-task-blog-2allsobaiduweb~default-9-123450451.142^v87^insert_down28,239^v2^insert_chatgpt&amp;spm&#x3D;1018.2226.3001.4187)\n计网[(453条消息) 计算机网络保研面试题整理（自用）_乌鸡摸鱼的博客-CSDN博客](https://blog.csdn.net/m0_52571748/article/details/119513761?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=计算机网络 保研&amp;utm_medium&#x3D;distribute.pc_search_result.none-task-blog-2allsobaiduweb~default-1-119513761.142^v87^insert_down28,239^v2^insert_chatgpt&amp;spm&#x3D;1018.2226.3001.4187)\n[(453条消息) 计算机专业保研面试复习笔记——计算机网络_计算机保研复习_欧二lord的博客-CSDN博客](https://blog.csdn.net/weixin_43117620/article/details/109198194?ops_request_misc=%7B%22request%5Fid%22%3A%22168433738716800227438825%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=168433738716800227438825&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-109198194-null-null.142^v87^insert_down28,239^v2^insert_chatgpt&amp;utm_term=计算机网络 保研&amp;spm&#x3D;1018.2226.3001.4187)\n(454条消息) IPV6基本报头_ipv6报头_yibasuo18176的博客-CSDN博客\n[(454条消息) BGP、IBGP、EBGP、IGP、EGP_bgp和egp的区别_zhaomax的博客-CSDN博客](https://blog.csdn.net/zhaomax/article/details/52399403?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=IGP BGP&amp;utm_medium&#x3D;distribute.pc_search_result.none-task-blog-2allsobaiduweb~default-4-52399403.142^v87^insert_down28,239^v2^insert_chatgpt&amp;spm&#x3D;1018.2226.3001.4187)\n操作系统(453条消息) 计算机操作系统保研面试题整理（自用）_乌鸡摸鱼csdn_乌鸡摸鱼的博客-CSDN博客\n(453条消息) 操作系统笔记（含王道计算机考研——操作系统课件）_操作系统考研笔记_一只不吃老鼠的猫的博客-CSDN博客\n(454条消息) OS之存储管理 — 磁盘调度算法_os 对磁盘操作 写优先_如是说如是的博客-CSDN博客\n计组(453条消息) 计算机组成原理保研面试题整理（自用）_计算机组成原理面试题_乌鸡摸鱼的博客-CSDN博客\n(453条消息) 王道计算机考研——计算机组成原理笔记_王道计算机组成原理_一只不吃老鼠的猫的博客-CSDN博客\n数据结构(453条消息) 保研面试复习之数据结构篇_数据结构保研复习_abtgu的博客-CSDN博客\n(453条消息) 数据结构基础概念知识点_保研&#x2F;考研&#x2F;面试复习_顺序哈希分块折半_Raising_的博客-CSDN博客\n(454条消息) 胜者树与败者树_胜者树和败者树_whz_zb的博客-CSDN博客\n[(454条消息) 详解全局变量，全局变量与静态变量的区别_静态变量和全局变量_舒泱的博客-CSDN博客](https://blog.csdn.net/weixin_43222324/article/details/106989714?ops_request_misc=%7B%22request%5Fid%22%3A%22168474123716800226594104%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=168474123716800226594104&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-106989714-null-null.142^v87^insert_down28,239^v2^insert_chatgpt&amp;utm_term=全局变量 静态变量&amp;spm&#x3D;1018.2226.3001.4187)\n概率论概率论.pdf - 成电飞书云文档 (feishu.cn)\n高等数学高等数学知识点最全汇总.pdf - 成电飞书云文档 (feishu.cn)\n(454条消息) 傅里叶级数和傅里叶变换简介和推导_傅里叶级数和傅里叶变换的区别和联系_HKDER的博客-CSDN博客\n离散数学离散数学.docx - 成电飞书云文档 (feishu.cn)\n线代线代.pdf - 成电飞书云文档 (feishu.cn)\n数据库数据库.pdf - 成电飞书云文档 (feishu.cn)\n软件工程JAVA&amp;C++[(454条消息) java—垃圾回收算法(GC)_会飞的猪zhu的博客-CSDN博客](https://blog.csdn.net/m0_58196614/article/details/126426266?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=Java 的垃圾回收算法&amp;utm_medium&#x3D;distribute.pc_search_result.none-task-blog-2allsobaiduweb~default-0-126426266.142^v87^insert_down28,239^v2^insert_chatgpt&amp;spm&#x3D;1018.2226.3001.4187)\n经验贴2021年计算机保研经验帖 - 知乎 (zhihu.com)\n2022南大cs夏令营笔试面试准备 - 知乎 (zhihu.com)\nhttps://www.rstk.cn/news/624725.html?action=onClick\n2021年半跨CS保研经历（已上岸pku） - 知乎 (zhihu.com)\n机试真题Muyiyunzi&#x2F;BUAA-CS-Codes: 北京航空航天大学计算机学院研究生考试复试上机部分往年试题及解答 (github.com)\n","categories":["博客"],"tags":["算法","数据结构","保研","计算机网络","高等数学","线性代数"]},{"title":"TCP连接中ACK,SEQ变化","url":"/2025/08/03/TCP%E8%BF%9E%E6%8E%A5%E4%B8%ADACK,SEQ%E5%8F%98%E5%8C%96/","content":"TCP连接中ACK,SEQ变化以下是 TCP 连接中 ACK 和 SEQ 交互变化的详细示例（包含完整的三次握手、数据传输和四次挥手过程）：\n📡 连接建立阶段（三次握手）\n客户端 → 服务器SYN=1, SEQ=X（随机初始序列号）客户端声明自己的初始序列号 X\n服务器 → 客户端SYN=1, ACK=1, SEQ=Y, ACK=X+1服务器确认收到 X（ACK&#x3D;X+1）并声明自己的初始序列号 Y\n客户端 → 服务器ACK=1, SEQ=X+1, ACK=Y+1客户端确认收到 Y（ACK&#x3D;Y+1），准备开始数据传输\n\n\n📦 数据传输阶段sequenceDiagram    participant Client    participant Server    Client-&gt;&gt;Server: SEQ=100, Data=&quot;ABC&quot;（3字节）    Server-&gt;&gt;Client: ACK=103（SEQ=500，ACK号=100+3）        Client-&gt;&gt;Server: SEQ=103, Data=&quot;DEF&quot;（3字节）    Server-&gt;&gt;Client: ACK=106（SEQ=500，ACK号=103+3）        Server-&gt;&gt;Client: SEQ=500, Data=&quot;Hello&quot;（5字节）    Client-&gt;&gt;Server: ACK=505（SEQ=106，ACK号=500+5）\n\n🔄 交互规则：\n每次发送数据：SEQ = 上次SEQ + 数据长度（如客户端第一次 SEQ&#x3D;100，发送3字节后，下次 SEQ&#x3D;103）\nACK号计算：ACK = 对方SEQ + 接收数据长度（如服务器收到 SEQ&#x3D;100的3字节数据，返回 ACK&#x3D;103）\nACK包不携带数据时：SEQ 不变，只携带ACK号（纯ACK包不消耗序列号）\n\n\n🚪 连接关闭阶段（四次挥手）\n客户端 → 服务器FIN=1, SEQ=110, ACK=500客户端请求关闭（FIN消耗1序列号）\n服务器 → 客户端ACK=1, SEQ=500, ACK=111确认收到 FIN（ACK&#x3D;110+1）\n服务器 → 客户端FIN=1, ACK=1, SEQ=505, ACK=111服务器发出 FIN（消耗1序列号）\n客户端 → 服务器ACK=1, SEQ=111, ACK=506确认 FIN（ACK&#x3D;505+1），等待2MSL后关闭\n\n\n🔍 关键规则总结：\n\n\n操作\nSEQ 变化\nACK 变化\n\n\n\n发送SYN&#x2F;FIN\n+1\n不变\n\n\n发送数据（N字节）\n+N\n不变\n\n\n发送纯ACK包\n不变\n更新为期待的下个SEQ\n\n\n接收数据后ACK\n不变\n&#x3D;收到数据最后字节+1\n\n\n\n📌 重要说明：ACK号总是​​期望收到的下一个字节序号​​（如收到SEQ&#x3D;100的10字节数据，返回ACK&#x3D;110）初始序列号 (ISN) 是随机值（防止序列号预测攻击），后续SEQ基于ISN累加\n\n","categories":["计算机网络"],"tags":["计算机网络"]},{"title":"Windows11下安装WSL","url":"/2024/07/19/Windows11%E4%B8%8B%E5%AE%89%E8%A3%85WSL/","content":"Windows11下安装WSL一、WSL是什么？开发人员可以在 Windows 计算机上同时访问 Windows 和 Linux 的强大功能。 通过适用于 Linux 的 Windows 子系统 (WSL)，开发人员可以安装 Linux 发行版（例如 Ubuntu、OpenSUSE、Kali、Debian、Arch Linux 等），并直接在 Windows 上使用 Linux 应用程序、实用程序和 Bash 命令行工具，不用进行任何修改，也无需承担传统虚拟机或双启动设置的费用。\n二、安装步骤\n确保电脑虚拟化开启\n\n控制面板-&gt;程序-&gt;启用或关闭 windows 功能，开启 Windows 虚拟化和 Linux 子系统（WSL2)以及Hyper-V。由于在Windows11中并没有Hyper-V，需要进行手动配置\n\n\n配置Hyper-V\n家庭版windows11没有Hyper-V，需要配置Hyper-V。打开vs code创建Hyper-7.cmd，复制以下内容并保存后执行。\npushd &quot;%~dp0&quot;dir /b %SystemRoot%\\servicing\\Packages\\*Hyper-V*.mum &gt;hyper-v.txtfor /f %%i in (&#x27;findstr /i . hyper-v.txt 2^&gt;nul&#x27;) do dism /online /norestart /add-package:&quot;%SystemRoot%\\servicing\\Packages\\%%i&quot;del hyper-v.txtDism /online /enable-feature /featurename:Microsoft-Hyper-V-All /LimitAccess /ALL\n\n\n系统安装win11 使用 WSL2 安装 linux 子系统 ubuntu 出现错误：无法解析服务器的名称或地址。原本显示报错：ConnectionError: Couldn’t reach https://raw.githubusercontent.com/huggingfac无法访问。\n解决方法：\n\n修改 本地 host 文件。记事本打开 C:\\Windows\\System32\\drivers\\etc\\hosts 文件，添加如下解析地址（4个中有一个好用就添加它）\n在https://www.ipaddress.com这个网站中的查询框中输入：raw.githubusercontent.com在里面找到相应的的ipv4地址，这四个地址随便选一个即可（好用的）：\n\n185.199.108.133 raw.githubusercontent.com185.199.109.133 raw.githubusercontent.com185.199.110.133 raw.githubusercontent.com185.199.111.133 raw.githubusercontent.com\n\n\n\n\n在CMD中刷新 DNS 解析缓存ipconfig &#x2F;flushdns\n\n再次运行查看或安装命令查看可安装的 WSL\nwsl -l -o\n\n\n\n列出已安装版本\nwsl -l -v\n\n\n\nwsl –install -d(安装):\nwsl --install -d Ubuntu-22.04\n\nwsl -d (运行)：\nwsl -d Ubuntu-22.04\n\n\n\n修改到D盘\n由于默认是到C盘，现修改到C盘。\n\n关闭子系统\n关闭界面&#x2F;输入如下命令关闭子系统。\nwsl --shutdown Ubuntu-22.04\n\n导出子系统\nwsl --export Ubuntu-22.04 D:/WSL/Ubuntu22.04.tar\n\n\n\n注销原子系统\nwsl --unregister Ubuntu-22.04\n\n\n\n\n从D盘导入\nwsl --import Ubuntu-22.04 D:/WSL/Ubuntu-22.04.tar\n\n\n\n\n再次运行导入好的系统\n\n\n\n\n\n","categories":["WSL"],"tags":["WSL"]},{"title":"保研经验贴","url":"/2024/06/24/%E4%BF%9D%E7%A0%94%E7%BB%8F%E9%AA%8C%E8%B4%B4/","content":"保研经验贴背景今天被两三个25届的同学问到保研的事 尘封许久的记忆再次打开 再次汇总了之前收到的所有信息和仅存的记忆 给一点模板上的参考注:是疫情解封后第一次线下 故之前很多经验贴没有参考性\nbg: 985本SE\nrank: 3&#x2F;181 3.99&#x2F;4.00\n论文: 无\n竞赛: 双国三 双省一 一省三 n校奖\n奖学金: 两年国奖\n方向: 分布式系统&#x2F;存储 偏架构和系统设计方向\n实习: 某自驾公司地图存储系统&#x2F;字节抖音电商开发岗\n由于夏令营已经上岸 故没有参加后续预推免\n入营:\n夏令营:\n①北大计算机 直博（放弃且意愿不强 真不想读博）\n②北大软微 硕士（计算机学院组➕老师 最终去向）\n③中国科学院计算所 硕士\n④上海交通大学电院 硕士\n⑤南京大学计算机学院 硕士\n⑥北京航空航天大学计算机学院 硕士（放弃）\n⑦中国人民大学信院 硕士\n⑧西安交通大学计算机学院 硕士\n被拒:\n①复旦大学计算机学院（只要第一我也没办法）\n参加:\n由于在实习真抽不开时间去其他地方参营\n①北大软微\n②北航计算机\n③南大计算机（参加了部分 获得软件所的通过了但后面不是很想去参加了…跟北大有冲突也是个重要原因）优营\n①北大软微\n②北航计算机\n准备阶段数学方面:\n①概率论②线性代数③微积分④离散数学\n这部分需要从头到尾过一遍 相关概念、联系一定要熟，各部分重点其实网上总结🉐十分详细了 一定好好准备！\n英语方面:\n①各种日常口语➕部分计算机相关专业的词汇 不需要特别详细 但我建议提早一个月进入状态\n专业知识:\n①数据结构②计算机网络③操作系统④计组⑤编译原理⑥机试！！！（别说其他语言了 现在学c++还来得及 STL弄熟➕王道机试指南➕力扣➕到处搜集真题 爆！！！）\n四五很少考 南大计算机的笔试特别喜欢考编译原理——题简直又多又长又难 数据结构重中之重 机试一定好好准备！！！\n执行阶段南大计算机（流程繁琐）\n①最开始我记得是软件所有个面试，线上的，会问一些离散数学（平面图 哈密顿图等等）和一些数据结构的题 差不多十五分钟（这一部分是提前了差不多两个月进行的）\n②后续在临近夏令营的时候还有一轮线上笔试 巨难（如果没学过编译原理就寄了）\n③后续就是去线下啦 但遗憾没去看看美丽的仙林校区😭\n北航计算机（特色大模拟➕不报销车费路费 甚至不包吃）\n①第一天就是两道机试 总共两小时 第一道大模拟真的搞的头大（好在还是写对了） 第二道真是完全一点不会（不是常规的算法题） 这一轮🉐至少做对一个才能进入下一轮\n②第二天面试 数学➕英语➕各种专业问题 甚至还问了我前端➕后端➕java和c++ python语言特性使用场景（好在哥们也是实习面试了几十轮还是信手拈来的）\n老师全程压力面，不能怂！\n然后优营发的很快，我记得是7月2号就发了，也是我第一个优营\n北大软微\n软微从22年开始比较特殊，首先据说要退学费，其次夏令营的师资和实验室可以是计算机学院&#x2F;智能学院的，加上还是硕士简直不要太香好吧\n①第一天闲聊吹水 我就记得紫燕百味鸡外卖还挺好吃\n②先来三道算法题！（30min 我们组跟系统方向强相关三道分别是mid mid hard难度的 可以写伪代码）其实我第三道有点问题但由于太自信甚至后续面试当场给出来数学证明让老师也疑惑住了\n③面试: 自我介绍➕各种问题的提问 甚至问到我一些关于实习用到的juiceFS和一些底层的概念&#x2F;分布式共识&#x2F;运维&#x2F;缓存等，还问到代码量（必然是多多），以及数学上面的证明➕算法题复盘➕一些其他的问题，其实都还好，虽然没全准备过但意外达的非常好（最终拟录取看复试分数排名竟然差不多前1％）\n优营隔了几天就发了 \n一些被问到的问题\n论文是必须的吗？\n有最好，如果搞ai必须有相关实习&#x2F;科研经历，如果走system路线有实习或者经历都行\n\n四六级真的重要吗？\n我觉得一般重要 不要太低就行\n\n给计算机专业课重要程度排个序\n数据结构＞计算机网络&#x3D;操作系统＞计组＞编译原理\n\n事先套磁了吗？\n五月份套了一个，但强com。我建议现在3月份就可以开始套了，越早越好！\n\n\n","categories":["经验贴"],"tags":["保研"]},{"title":"关于动态规划/性价比/背包问题的思考","url":"/2024/06/24/%E5%85%B3%E4%BA%8E%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%20%E6%80%A7%E4%BB%B7%E6%AF%94%E9%97%AE%E9%A2%98%20%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98%E7%9A%84%E6%80%9D%E8%80%83/","content":"关于动态规划&#x2F;性价比&#x2F;背包问题的思考01背包本质上就可以用空间换时间，动规本质上也是那空间换时间，本身也就是一个贪心算法，所以01背包&lt;–&gt;贪心&lt;–&gt;动态规划\n如果说是0-1背包问题，需要逆序更新，原因是东西只有一个，不能影响之前的部分\n如果是东西有无数个，则直接顺序更新\n如果东西是牛奶之类的，有性价比，并且可以买非整数数量的，可以退化为贪心来做，结构体：数量，价格，性价比，sort一下就完事儿了。\n讲究序列（排列问题），先遍历背包，不要求序列（组合问题），先遍历物品\n滚动数组\n另外，0-1背包要求倒序，若要求组合而非排列，即为先物品，再背包，且倒顺序，滚动数组添加\n而且，如果是算有多少种，直接加就行,dp[0]&#x3D;1，其他为0\ndp[j]+=dp[j-nums[i]]    //这里怎么去理解呢，会导致重复吗？    //不会重复\n\n如果是要算最多&#x2F;最少，还要min和max比较\ndp[j]=max(dp[j],dp[j-nums[i]]+value[i])\n\n[(425条消息) 背包问题（背包九讲）_你好世界wxx的博客-CSDN博客](https://blog.csdn.net/weixin_42638946/article/details/114028588?ops_request_misc=%7B%22request%5Fid%22%3A%22167933155516800186567314%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&amp;request_id=167933155516800186567314&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~pc_rank_34-6-114028588-null-null.142^v74^pc_new_rank,201^v4^add_ask,239^v2^insert_chatgpt&amp;utm_term=01背包问题 凑整&amp;spm&#x3D;1018.2226.3001.4187)\n01背包// Created by WXX on 2021/2/24 14:36#include &lt;iostream&gt;using namespace std;const int N = 1010;int n, m;int v[N], w[N];int f[N];int main() &#123;    cin &gt;&gt; n &gt;&gt; m;    for (int i = 1; i &lt;= n; i++) cin &gt;&gt; v[i] &gt;&gt; w[i];    for (int i = 1; i &lt;= n; i++)        for (int j = m; j &gt;= v[i]; j--) //倒叙            f[j] = max(f[j], f[j - v[i]] + w[i]);    cout &lt;&lt; f[m] &lt;&lt; endl;    return 0;&#125;\n\n完全背包// Created by WXX on 2021/2/24 15:21#include &lt;iostream&gt;using namespace std;const int N = 1010;int n, m;int v[N], w[N];int f[N];int main() &#123;    cin &gt;&gt; n &gt;&gt; m;    for (int i = 1; i &lt;= n; i++) cin &gt;&gt; v[i] &gt;&gt; w[i];    for (int i = 1; i &lt;= n; i++)        for (int j = v[i]; j &lt;= m; j++)//顺序            f[j] = max(f[j], f[j - v[i]] + w[i]);    cout &lt;&lt; f[m] &lt;&lt; endl;    return 0;&#125;\n\n多重背包// Created by WXX on 2021/2/24 16:07#include &lt;iostream&gt;using namespace std;const int N = 110;int n, m;int v[N], w[N], s[N];int f[N][N];int main() &#123;    cin &gt;&gt; n &gt;&gt; m;    for (int i = 1; i &lt;= n; i++) cin &gt;&gt; v[i] &gt;&gt; w[i] &gt;&gt; s[i];    for (int i = 1; i &lt;= n; i++)  // 先循环物品        for (int j = 0; j &lt;= m; j++)  // 再循环容量            for (int k = 0; k &lt;= s[i] &amp;&amp; k * v[i] &lt;= j; k++)  // 最后循环决策                f[i][j] = max(f[i][j], f[i - 1][j - k * v[i]] + k * w[i]);    cout &lt;&lt; f[n][m] &lt;&lt; endl;    return 0;&#125;\n\n","categories":["博客"],"tags":["Java","C++","算法","数据结构","动态规划","贪心","背包问题"]},{"title":"保研夏令营他人经验总结","url":"/2024/06/24/%E4%BF%9D%E7%A0%94%E8%B5%84%E6%BA%90/","content":"保研夏令营准备\nCSP，最好300+？（对于北航有效）\n报名一般5月开始，联系老师建议4月\n\n入营\n主要看成绩，高质量科研成果加分，实习经历、获奖无用，入营后成绩影响不大（rank1可加印象分）——郑博文\n清北上交学硕rank1都不一定进得去\n都留给本校学生了\n复旦卡rank1\n南大比较海rank5&#x2F;6好像就行\n中科大有点歧视非计科出身，软院入营看运气\n自动化所要rank1&#x2F;2\n计算所联系老师\n清深热门专业也比较难入\n其他方向还好\n北大整个都是联系老师流的\n浙大夏令营没有学硕，就不说了\n清华也没学硕，直博也不给offer\n人大高瓴要rank1&#x2F;2        ——郑博文\n\n机试\n非常不推荐力扣（不需要自己设计数据结构、不需要自己处理输入输出），不推荐其他语言\n语言：C++        平台：洛谷、AcWing        ——郑博文\n狠抓，因为很多学校都因为这个初筛，人工智能机试卷中卷，尽量现在就连起来  leetcode（主要看思想） pat要相对难一点，重点！！！要看输入输出；在保研成绩稳的情况下，准备机试（我摔了很多次的地方一定要在强调很多遍） 数据结构——刘欣宇\n计算所机试vipl实验室如果用c++的话  不能调用stl库  考的也就是用c实现了  其他的都是可以调用库的——刘欣宇\n有一本王道机试指南  你可以找找电子版  里面题很经典 前面的比较简单  尽量早点过  后面图论也比较容易考，算法里面很爱考贪心  动态规划，你也可以看看时间函数  我遇到过两次机试  是考时间的  题目大概是  上班打卡，下班也要打卡，打卡方式有很多种，但是都是同一个人的，这个人会进出公司，看谁累计上班时间长 ——刘欣宇\n\n笔试\n看是计算机学院还是ai学院，数据结构比较重视，其他三门专业课主要看知识点，数据结构刷了一本王道        ——郑博文\n大多数学校没有笔试，南大、计算所有，南大难，考底层，计算所  有单独的数学考试（他还考了少量的微积分  极少极少）——刘欣宇\n\n面试\n408和数学也要复习 面试会问你，408里面 数据结构》计网》操作系统  计组\n先看数据结构  数学（线代很爱问正定矩阵  概率论很爱问大数定律和中心极限定理） 然后在看计网 os ，计组基本上没问——刘欣宇\n\n科研\n最好找个外校的实验室，计院的也行，本校实验室不算实习，但可以让老师帮挂公司\n一定要高质量科研成果        ——郑博文\n\n心态\n突然想起来  心态也很重要  有可能夏令营啥也没拿到  或者只有一个  但是别慌 预推免还有  预推免先都报上  如只要能面试  就有很大概率候补到  不要全都选很好的专业  很容易落得一场空  坚信  只要我面试了 肯定会有候补到的时候；今年浙软  南大计算机  北航计算机 国防科大都快被鸽穿了 ——刘欣宇\n\n一些文章链接https://blog.csdn.net/mengwuyaaa/article/details/82918032?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-82918032-blog-125315403.pc_relevant_vip_default&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-82918032-blog-125315403.pc_relevant_vip_default&amp;utm_relevant_index=2\n经验贴的一些阅读人品导师人品最重要，千万不要去坑导直博，即使是清北的。\n可以先去导师评价网找找，目前可用的有 研控 、硕博导师评价网，另外我这里还有导师评价网后台数据库 excel（包含全国各大院校 1 万条导师评价信息），以及上交电院导师评价，不方便发，需要的话可以私戳。\n然后就是在百度、谷歌上搜，还可以去问组内 &#x2F; 隔壁组学长学姐。如何联系学长学姐？一种方法是找本校保研到该校或在绿群找到保研到该校的学长学姐，请他介绍介绍；另一种方法是通过导师的论文，推测出学长学姐的名字，然后在论文网站里找邮箱发邮件问。注意要兼听则明\n专业课怎么复习如果时间不是很充裕，不要全面撒网，每门课要复习的也就一二十个常见问题，找找保研 &#x2F; 考研面试重点问题来看看就行。\n要复习的课有：\n\n数学：线性代数、概率论、高数\n计算机：数据结构、计组、操作系统、计网、算法、数据库、软件工程、编译原理、编程语言\n人工智能：机器学习、深度学习\n\n注意这些课不必完全复习，挑几门和研究方向相关的看看重点就行，比如对于 AI 方向，最重要的是数学、数据结构、人工智能。\n没有科研经历咋办和老师方向一致的科研经历非常重要，即使没有产出论文，也是巨大的加分项，这就像去找工作，实习经历是巨大的加分项一样。\n如果你现在是大三下学期开学之前的话，可以去联系本校老师进实验室做科研。如果已经很晚了，如六月份了，可以去找一些论文，复现或者读懂代码，掌握好细节，包装成一个项目，耗时半个月左右，前提是不能被问穿，得答得上来。\n一段科研经历，老师更关注你做了什么，而不是这个科研做的结果。要讲好一个项目，需要讲好 motivation（为什么做）、method（做了什么）、result（做得咋样）、contribution（你做了啥），其中最重要的是 contribution 和 motivation。不要说得太直白，尽量学术化一点。（可以参考顶会论文的 Introduction，看看怎样讲好一个故事）。老师也非常喜欢问你的科研项目里面用到的东西的底层原理，而这些东西你可能就是在 PyTorch 里面调了个库，需要注意一下。\n如果有论文，论文的内容、细节一定要清楚，还有 EI 会议之类的水文不建议写在简历，如果被问穿了，可能是减分项\n要准备哪些文书文书材料的模板后续我会整理发出来。\n\n简历：推荐 超级简历WonderCV ，内容写保研要素中比较重要的就行，包括：联系方式、学校、专业、成绩、排名、获奖、项目、数学、编程、英语、读博意向等，自己的劣势部分不要往上面写。\n个人陈述：准备 1000 字、2000 字的，就是简历的扩充，重点是讲做过的项目，研究规划等。\n推荐信：准备 2 封教授推荐信即可，这东西没人看，注意复旦、北航等学校需正教授推荐信，清华、复旦等学校要求老师本人在线填写或用本人的邮箱发送推荐信。\n套磁信：既要简洁了当，直言主题，又不能不客套。edu邮箱比较正式，gmail有邮件追踪插件mailtrack。\nPPT：相当于把简历讲出来，大部分的篇幅应该讲项目，和学习无关的不要讲太多。\n各种证明材料：成绩单、排名证明、获奖证书、身份证、学生证、英语证明，都扫描成pdf。\n\n一些有用的网站\n邮件追踪：Gmail 有个插件 mailtrack，可以看到你发的邮件什么时候被老师打开了，打开了几次。\n查老师学术水平：Google Scholar、dblp、AMiner、CSRankings、Semantic Scholar\n查国家自然科学基金：测试狗基金查询、基金委查询系统\n导师评价网：研控 、硕博导师评价网\n机试刷题平台：AcWing\n夏令营 &#x2F; 预推免开营信息：保研信息网\n中科院计算所各实验室介绍：中科院计算所实验室情况简要介绍-王道论坛\n\n清北华五院系分析1 清华大学清华的 offer 基本在预推免发，夏令营发 offer 的只有叉院、深研院。除了软件、深研院外，外校基本只能拿直博。夏令营各院系自己组织，可以报多个，但有些院系没有夏令营。预推免是学校系统上报，最多报两个。\n\n计算机系（贵系）：国内计算机 top1，需要尽早联系导师。开夏令营，但不发 offer，通过机试的，预推免免试。机试很难，3 道编程题，难度和 CSP 第 3-4 题差不多。\n自动化系（雷系）：有做 AI 的老师，注意自动化系的硕士分三种，学硕、大数据工程（要去贵州）、校企联培（要去企业）。\n叉院：国内 bar 最高的学院，至少要 985 rk1 + 在投顶会 &#x2F; ACM，6 月初就开营。\n软件学院：没有夏令营，基本上是专硕，强com，主要看机试成绩，机试难度中等。\n网研院：相当于贵系网安专业，难度比贵系低。\n深研院：有计算机技术、人工智能、大数据、TBSI 四个方向，TBSI 是学硕，其他都是专硕，计算机技术机试很难，人工智能最卷，TBSI 要求六级 500+。\n高等研究院：有 msra 校企联培博士，导师郭百宁，但是好像没啥人知道，可以早点联系捡漏。\n\n2 北京大学北大的 offer 大多是夏令营发出去，预推免相当于补录了，可以报多个院系。\n\n计算机学院：超弱 com，完全取决于老师要不要你，夏令营无机试，面试走过场，需要尽早联系导师，去进组实习，bar 比贵系低，985 前 5% 就可以试试。夏令营之后，软件所一般鸽的比较多，还有外校基本只能拿直博。\n\n智能学院：原信科智能所，和计算机学院的情况差不多。\n\n软微：基本全是专硕，纯就业向，强com，入营主要看排名，不过据说从今年开始，也要做科研了。\n\n深研院：基本全是学硕，弱com，不过坑导较多。\n\n软微：\n\n不得不说北京真的是大城市，这是我第一次来北京，真的感受到了首都的魅力。\n   复试分为两个部分：手撕算法题 + 面试\n  手撕算法题部分，当天面试的所有人都在一起写题，一共有三道题，选其中一道题手撕代码就可以了，难度大概是 easy 到 medium 之间吧，手撕快排也有，大模拟也有。\n\n  面试部分，首先你要给每位老师发你的简历，老师看到我是湖大的，就要我英文描述一下湖大的风景，其实我早有准备，当时背的是介绍长沙，我就活用了。然后老师让我抽一道基础题，我抽到了数据库系统，其实很不巧我就数据库没怎么复习，但是还是凭自己的记忆说了一通，然后老师还问了数据库系统和数据库管理系统的区别，我记得他说的是 DBS 和 DBMS 的区别，当时我秒懂，DBMS 我会啊，所以我又说了一通。\n\n  接着老师会拿出刚刚手撕的算法题问你觉得怎么样，写得对不对，你要尽可能展现出你的算法功底就好了，比方说一个很简单的求平方和，没有给你数据范围时，其实是一个大数乘法 + 大数加法。然后老师开始问我项目了，大概问了我的代码量和实现难点。\n\n\n\n\n\n\n3 中科院中科院各所差别极大，所内各组也差别极大，所谓“强组清北，弱组211”。中科院的师生比很高，一般硕导一年 0-1 个硕士名额，博导一年1硕1博，中科院可以报任意多个所（多准备几个邮箱多注册几个号就行）。计算机相关的研究所有：\n表格 还在加载中，请等待加载完成后再尝试复制\n各所基本是夏令营就招完学生，预推免相当于补录，另外，国科大计算机学院、人工智能学院也招生（比两所容易一些），导师基本是两所的。最后再说一下，虽然两所的实力要略强于华五，如果你以后从事专业相关的事情（如：学术届、企业技术岗），可以来两所；但如果以后从事非专业相关的事情（如：考公），更建议去华五。\n\n计算所：体系结构方向亚洲第一，AI 方向实力也很强，超弱com，你甚至没入营都可以拿 offer，有霸面机制，即如果你没有入营，老师也可以邀请你来面试，和入营的没区别。计算所是分组来考核的，所里不管，牛组竞争非常激烈（如寒武纪、龙芯、vipl等）。体系结构和 AI 的大牛很多，就不细说了。还有要注意很多组要求博士延毕一年。\n自动化所：体量很大，光模式识别国重就 100 多位老师，AI 方向特别 CV 很强，模式识别国重有很多 AI 大牛。强 com，bar 985 前 5，以“未来的邀约”闻名于保研圈。\n软件所：有计算机科学国重（软件与理论方向），另外中文信息实验室的孙l、韩xp老师也比较强（NLP 方向）。\n信工所：有网安国重，有个 CV 组也很强（操xc组），不过，操老师去年跳槽到中山当院长了。\n神仙院：深圳先进技术研究院，下面的数字所有个 MM Lab 很强，和港中大那个 MM Lab 、商汤、上海浦江实验室关系密切，负责人是乔y老师（3万引），另外组里董c老师也是大牛。\n\n4 上海交通大学招生主要在夏令营，预推免招的少。注意上交电院博士毕业是出了名的难，据说基本 6 年起步。密西根是单独报名，其他院系在学校系统上报名，只能报一个。\n\n计算机系、网安：上交计算机系像贵系那样，各方向都有，都比较强。硕士非常难，2021 年非华五只录了 4 个，有机试。直博入营容易，没有机试，关键是要找到导师接收（直博没有导师接收，拿了优营也没用）。上交牛导很多，AI 方向有几个年轻老师特别火，如卢cw、张wn、张qs、严jc 等。\n软件学院：国内最强的软件学院，以 ipads实验室（分布式系统方向）闻名，机试听说是开发软件，比较硬核。\n网安学院：比计算机系要容易。\n密西根学院：想去上交，密西根最容易，不过学费贵，导师一般。\n\n5 浙江大学浙大的计算机图形学国内第一，计算机学院体量也非常大。浙大只能报一个学院。\n\n计算机学院：夏令营只有直博，要去做一个多月的项目，内容由报名老师指定，8月下旬，每个博导可以推荐 1 名学生（院士 2 名），进入学院答辩环节（走过场）。浙大大量名额（含所有硕士名额）在预推免，不过要跟浙大本校竞争。CAD&amp;CG 国重里面有很多 CG、CV 大牛。\n软件学院：在宁波，纯就业向，夏令营入营点击就送，千人海王营，考核要做项目，优营容易拿，但没什么用，还是要参加预推免，预推免有机试。\n工程师学院：夏令营、预推免都有，比计算机学院容易。\n国际联合学院：在嘉兴市海宁市（县级市），不太了解，招计算机专业的学生。\n\n6 复旦大学复旦的计算机是 B+，但是人工智能方向很强，学校 title 好，魔都位置好。复旦只能报一个学院。\n\n计算机学院：发放 offer 夏令营：预推免 &#x3D; 1 : 2，夏令营的 bar 巨高，985 一个专业只能入一个。有机试但不算分。NLP 组（黄邱张）很强，CV 方向姜yg组、薛xy组也比较强。\n大数据学院：发统计学或金融学位证，难度不比计算机学院低，对数学要求高。\n工研院：难度比计算机学院低。\n类脑智能研究院：有部分老师做 AI 和生物交叉。\n\n7 南京大学南大三个学院都可以报，但只能入一个，海王营，入营后有线上笔试，考408等专业课，没有机试，南大是超强 com。\n\n计算机系：软件所非常强，软件所在学院夏令营前有自己办的夏令营，另外 MCG 组的王lm老师是南大 CV 最强的老师，NLP 组黄sj老师也比较强。\n人工智能学院：lamda（周zh组）非常强，主要是做机器学习、数据挖掘的， lamda 在学院夏令营前也有自己办的夏令营，lamda 一共两轮面试，第一轮学长面，第二轮报考老师面。注意拿了 lamda offer 后，还需要人工智能学院优营才能录取，南大的 com 非常强。\n软件学院：比 CS、AI 容易一些，纯就业型。\n\n8 中国科学技术大学中科大没有直博，全是硕士，系统里可以报三个志愿，只能入一个，基本上只有一志愿有用，中科大是弱 com。还有入营中科大后会收到入营大礼包！！！\n\n计算机学院：入营歧视软件专业，我校计算机前5%可入，软件只能入1%，没有预推免。AI方向做数据挖掘的多，几乎没有做CV的（都在自动化系、电子系）。BDAA（陈eh组）很强，陈eh老师是杰青，组里还有刘q、连df两位优青，人好学术好。网络方向李xy（ACM &#x2F; IEEE fellow）组很牛，组里张yy老师也是IEEE fellow，做智能感知的。另外计算机学院还有网红教授张l（逃）\n自动化系（10系）：自动化系和电子系虽然同属信息学院，但招生是分开的，必须导师推荐才能入营，预推免有少量名额。CV 方向的张tz，查zj老师很强，都是优青+万引。\n电子系（6系）：虽然叫电子系，其实很多老师是做人工智能的，大牛很多。何xn组（巨牛，30岁，2.2万引）非常强，何老师组里两位小老板也很强，王x（7k引）、冯fl（4k引），都是30岁出头。电子系AI方向还有吴f（院士候选人）、李hq、张yd等杰青，周wg、刘d、谢ht、王j等优青，实力非常强。\n大数据学院：就是计算机、自动化、电子的老师，一般科大本校喜欢拿大数据学院名额，所以外校入营难，没有预推免。\n网安学院：何xn的两个小老板都挂在网安学院，这里甚至还能找到潘建伟。\n软件学院：一共就几个保研招生名额，主要招考研。\n苏州研究院：比本部简单一些，值得一提的是，中科院计算所奇迹组的周sh老师（IEEE fellow，万引，医学影像大牛）全职来中科大，在这里招生物医学工程专业的学生（医学 CV 方向）。\n先研院：比本部简单一些。\n科学岛：中科院合肥物质研究院，发中科大毕业证，入营点击就送，最容易上岸华五的地方。\n\n9 中国人民大学人大在中关村，位置好，学术强的老师大多在高瓴，强 com。人大信息和高瓴可以都报，也可以都入营，\n\n信息学院（王老吉）：夏令营 4 月 20 号左右就开放报名了，然后愣是 6 月 29 才发入营名单，官网通告栏一直是王老吉奖学金获奖公示，绿群群友们天天去刷学院官网都等不到入营名单，故称为王老吉学院。王老吉招生人数少，之前入营也少，bar 很高（学硕卡 985 rk2 左右），但今年是海王营了。王老吉数据库方向比较强，无预推免。\n高瓴人工智能学院（加多宝）：王老吉的 hxd 当然是加多宝了。高瓴的老师基本都是做 AI 的（偏信息检索、数据挖掘），没有什么比较差的，下限很高，都做学术。高瓴只有学硕和直博，都在夏令营招生，没有预推免，鸽子比较多，一般入营即 offer，学硕 bar 挺高，可能 985 2% 左右，直博低一些。文jr、徐j等老师都是 msra 过来的，IR 大牛，严r老师是北大王选所过来的，NLP 大牛，还有几个姚班毕业的 AP 也很强。高瓴最大的劣势就是人大这个 title 不够好了吧。\n\n10 其他学校的部分AI牛组我保研过程中了解到的其他学校的一些 AI 牛组（还有很多没列上来）：\n南开大学程mm组（CV）、哈工大SCIR实验室（刘t组，NLP）、北航VR国重（CV）、厦门大学mac实验室（纪rr组，CV）、东南大学palm实验室（耿x组）、中山大学郑ws组（CV）、华科白x组（OCR）、上科大虞jy组（CV）、西湖大学李zq组（原自动化所大牛）、西湖大学张y组（NLP）。\n","categories":["经验贴"],"tags":["保研","夏令营"]},{"title":"C++刷题","url":"/2024/06/24/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/","content":"C++数据结构与算法[(459条消息) 【C语言】程序运行过程：预处理&#x2F;编译&#x2F;汇编&#x2F;链接_预处理编译汇编链接_慕雪华年的博客-CSDN博客](https://blog.csdn.net/muxuen/article/details/123227200?ops_request_misc=%7B%22request%5Fid%22%3A%22168596052316800182799736%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=168596052316800182799736&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-123227200-null-null.142^v88^control_2,239^v2^insert_chatgpt&amp;utm_term=预处理 编译 汇编 链接&amp;spm&#x3D;1018.2226.3001.4187)\n(443条消息) 保研机试——1基础算法（排序、哈希、模拟（日期、图形、查找、进制、字符串）、递归与分治、贪心）_Yuezero_的博客-CSDN博客\n[(425条消息) 数据结构保研面试题整理（自用）_保研数据结构常温问题_乌鸡摸鱼的博客-CSDN博客](https://blog.csdn.net/m0_52571748/article/details/120505195?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=数据结构 保研&amp;utm_medium&#x3D;distribute.pc_search_result.none-task-blog-2allsobaiduweb~default-0-120505195.142^v73^pc_search_v2,201^v4^add_ask,239^v2^insert_chatgpt&amp;spm&#x3D;1018.2226.3001.4187)\n(463条消息) 插入排序–折半插入排序（来一来，看一看，走过路过，不要错过）_老 胡的博客-CSDN博客\nP问题、NP问题、NPC问题、NP-hard问题详解 - 知乎 (zhihu.com)\n[保研机试整理 - 知乎 (zhihu.com)\n什么时候才考虑用二分答案的技巧？正向求出答案不好入手，求解答案远远没有验证答案简单。\n已知前序后序算中序有多少种：\n[(441条消息) 二叉树遍历（已知前序和后序遍历，求中序遍历的可能的序列数）_已知二叉树的前序遍历和后序遍历_我要出家当道士的博客-CSDN博客\n\n(462条消息) 堆排序的时间复杂度分析_一只牛_007的博客-CSDN博客\n建立索引树：[(462条消息) 2020北航计算机夏令营机试题目个人理解_北航夏令营 机试_四处碰壁嘤嘤怪的博客-CSDN博客](https://blog.csdn.net/Bernie_double/article/details/118190022?ops_request_misc=%7B%22request%5Fid%22%3A%22168715279416800185829257%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=168715279416800185829257&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~baidu_landing_v2~default-5-118190022-null-null.142^v88^control_2,239^v2^insert_chatgpt&amp;utm_term=北航夏令营 机试&amp;spm&#x3D;1018.2226.3001.4187)\n注意scanf后，用getchar()吃掉回车\n表示最大 INT_MAX(climits)\n//mallocint *nums;nums=(*int)malloc(10*sizeof(int));//long long int 别用cin coutlong long a;scanf(&quot;%lld&quot;,&amp;a);printf(&quot;%lld&quot;,a);\n\nscanf还会返回成功输入的变量的个数,因此可判定EOF\nFloyd判圈法很吊\n1.lower_bound(v.begin(), v.end(), key)-v.begin()返回有序序列中大于等于key的第一个值的位置2.upper_bound(v.begin(), v.end(), key)-v.begin()返回有序序列中大于key的第一个值的位置3.lower_bound(v.begin(), v.end(), key, greater())-v.begin()返回有序序列中小于等于key的第一个值的位置4.upper_bound(v.begin(), v.end(), key, greater())-v.begin()返回有序序列中小于key的第一个值的位置5.上述四个函数，若无满足条件的值，则返回v.size() \n文件操作freopen(&quot;1.in&quot;,&quot;r&quot;,stdin);freopen(&quot;1.out&quot;,&quot;w&quot;,stdout);\n\n\n\n一些常用的库\nalgorithm\nvector\nmap\nqueue\niostream\nstring\nbits&#x2F;stdc++.h（带上就对了）\ncmath(sqrt之类的)\nclimits（INT_MAX INT_MIN）\n\nSTL内置find()复杂度：algorithm的find 复杂度是O(n)，对vector，string等 顺序查询。map::find 和 set::find 复杂度是O(logn)，因为map和set底层都是红黑树。\n\nvector:下面是一些常用的vector方法：\n\npush_back：在vector的末尾添加一个元素。\n\npop_back：删除vector末尾的一个元素。\n\nsize：返回vector中元素的个数。\n\nclear：删除vector中所有的元素。\n\nempty：判断vector是否为空。\n\nat：返回vector中指定位置的元素。\n\nfront：返回第一个元素。\n\nback：返回最后一个元素。\n\nerase：删除vector中指定位置的元素。\n\ninsert：在vector中指定位置插入一个元素或多个元素。\n\nresize：改变vector的大小。\n\nreserve：为vector预留一定的空间。\nreverse(a.begin(),a.end());\n\n\n\nswap：交换两个vector中的元素。\n\nbegin：返回指向vector第一个元素的迭代器。\n\nend：返回指向vector最后一个元素之后的迭代器。 这些方法能够满足大部分情况下的需求，可以根据具体的使用场景选择合适的方法进行操作。\n\n\n要取迭代器的值，直接*指针取值\n对于向量(vector)，它是一种支持随机访问的容器，因此可以直接通过下标访问向量中的元素。\nvector&lt;int&gt; v = &#123;1, 2, 3, 4, 5&#125;;// 使用auto关键字定义迭代器for (auto it = v.begin(); it != v.end(); it++) &#123;    cout &lt;&lt; *it &lt;&lt; &quot; &quot;;&#125;\n\nvector不能直接使用sort函数进行排序，需要传入一个迭代器指定排序的范围。修改代码如下：\nsort(v.begin(),v.end(),com);\n\nmap以下是C++中map类的常用方法：\n\ninsert(make_pair&lt;key, value&gt;)：向map中插入一个键值对。\n\n**erase(key)**：删除map中指定键的元素。\n\n**clear()**：清空map中所有元素。\n\nsize()：返回map中元素的个数。\n\nempty()–&gt; bool：返回map是否为空 。\n\nfind(key)：查找map中是否存在指定键的元素，如果存在则返回指向该元素的迭代器，否则返回end()迭代器。\n常常和end联合起来用判断找到没。(这个适合动态查找，底层红黑树实现)\n\ncount(key)：返回指定键在map中出现的次数，如果不存在则返回0或1。\n\nbegin()：返回指向map第一个元素的迭代器。\n\nend()：返回指向map最后一个元素后面的位置的迭代器。\n\noperator[]：通过键访问map中的元素，如果键不存在，则自动插入一个新的键值对并返回对应的值。\n\nlower_bound(key)：返回第一个大于或等于指定键的元素的迭代器。\n\nupper_bound(key)：返回第一个大于指定键的元素的迭代器。\n\nequal_range(key)：返回一个pair对象，其中包含lower_bound和upper_bound返回的迭代器。\n\nswap(map2)：交换当前map和map2的元素。 C++中的map类是一种关联式容器，用于存储键值对，其中每个键都唯一，并且按照一定的顺序排列。map的底层实现通常是红黑树，因此查找、插入和删除操作的时间复杂度为O(log n)，其中n是map中元素的个数。map类提供了丰富的方法，可以方便地进行键值对的操作，例如插入、删除、查找、排序等。同时，由于map使用键值对来存储数据，因此可以将map看作是一种特殊的数组，其下标为键，对应的值为数组元素。因此，可以通过下标来访问和修改map中的元素。\n\n\nmap&lt;string, int&gt; m = &#123;&#123;&quot;apple&quot;, 1&#125;, &#123;&quot;banana&quot;, 2&#125;, &#123;&quot;orange&quot;, 3&#125;&#125;;// 使用auto关键字定义迭代器for (auto it = m.begin(); it != m.end(); it++) &#123;    cout &lt;&lt; it-&gt;first &lt;&lt; &quot;: &quot; &lt;&lt; it-&gt;second &lt;&lt; endl;&#125;\n\n\n\n在 C++ 中，unordered_map 和 map 都是关联容器，但它们在底层实现、性能特性和使用场景上有显著区别。以下是两者的详细对比：\n\n🧠 核心区别总结\n\n\n\n特性\nmap (std::map)\nunordered_map (std::unordered_map)\n\n\n\n底层数据结构\n红黑树 (自平衡二叉搜索树)\n哈希表 (桶数组 + 链表&#x2F;红黑树)\n\n\n元素顺序\n按键升序排列 (默认)\n无序存储 (取决于哈希函数)\n\n\n查找时间复杂度\nO(log n)\n**平均 O(1)**，最差 O(n)\n\n\n插入&#x2F;删除时间\nO(log n)\n平均 O(1)，最差 O(n)\n\n\n内存占用\n较低 (树结构)\n较高 (预分配桶空间)\n\n\n自定义排序\n支持比较函数\n不支持排序\n\n\n键类型要求\n需定义 &lt; 运算符\n需定义哈希函数和 == 运算符\n\n\n结论：在不需要顺序且哈希函数良好的场景，优先选择 unordered_map 以获得更高性能。\n\nstackC++ 中的 stack 库提供了以下常用的方法：\n\npush(elem)：将元素 elem 压入栈顶。\npop()：弹出栈顶元素。\ntop()：返回栈顶元素，但不弹出。\nempty()：判断栈是否为空。\nsize()：返回栈中元素的个数。 除此之外，stack 还支持以下操作：\nemplace(args…)：构造一个新元素并将其压入栈顶。\nswap(stack)：交换两个 stack 的元素。\noperator&#x3D;&#x3D;、operator!&#x3D;、operator&lt;、operator&lt;&#x3D;、operator&gt;、operator&gt;&#x3D;：比较两个 stack 是否相等、不相等、小于、小于等于、大于、大于等于。 具体用法可以参考下面的示例代码\n\nstack元素可以是任何类型。\n\nqueueC++中的queue是一种容器适配器，用于实现“先进先出”（FIFO）的数据结构。queue基于deque或list进行实现，提供了一些方法来操作队列，包括入队、出队、获取队首元素、获取队列大小等。以下是queue的常用方法：\n\npush(element)：将一个元素加入队列的尾部。\npop()：将队列头部的元素弹出，但没有返回值。\nfront()：返回队列头部的元素。\ntop():返回队列头部元素（和front一样）\nback()：返回队列尾部的元素。\nempty()：判断队列是否为空。\nsize()：返回队列中元素的个数。 使用queue需要包含头文件，可以通过以下方式创建一个queue对象：\n\n对于队列(queue)，由于它是一种先进先出(FIFO)的数据结构，因此只能通过front()和back()函数来访问队列的头部和尾部元素，而不能直接通过下标访问。如果要使用下标访问队列元素，需要先将队列转换为数组或向量。 \n\npriority_queue#include &lt;queue&gt;//对于基础类型 默认是大顶堆    priority_queue&lt;int&gt; a;     //等同于 priority_queue&lt;int, vector&lt;int&gt;, less&lt;int&gt; &gt; a;        priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt; &gt; c;  //这样就是小顶堆    priority_queue&lt;string&gt; b;\n\n\n\n对于优先队列，复杂结构类型要重载运算符(436条消息) C++ 运算符重载_c 重载运算符_高祥xiang的博客-CSDN博客\nstruct complex&#123;int real;int imag;......bool operator&lt;(Complex c)const&#123;return real*real+imag*imag&lt;c.real*c.real+c.imag*c.imag;&#125;&#125;\n\n注意上面这个const是必须要有的\n在 C++ 中，自定义排序函数后面添加 const 关键字是必要的，这涉及到函数对象的常量性和 STL 的内部工作机制。以下是详细解释：\n原因分析\nSTL 要求比较函数是常量成员函数STL 容器（如 set&#x2F;map）内部实现会在常量上下文中调用比较函数。如果比较函数不是 const，编译器会报错，因为它可能修改函数对象的状态。\n保证比较操作的纯函数特性比较操作应该是无状态的（不改变对象状态）且幂等的（相同输入永远得到相同输出）。const 确保比较函数不会意外修改函数对象的内部状态。\n允许编译器优化标记为 const 的函数对象可以被编译器视为只读对象，从而进行更积极的优化。\n\n\nstringC++中的string类是一个封装了字符串操作的类，提供了一系列方法来处理和操作字符串。以下是常用的string类方法：\n\nlength()：返回字符串的长度。\n\nsize()：返回字符串的长度。\n\nclear()：清空字符串。\n\nempty()：判断字符串是否为空。\n\nassign(str)：将字符串的值设置为str。\n\nassign(str, pos, len)：将字符串的值设置为str中从pos位置开始的长度为len的子串。\n\nappend(str)：在字符串的末尾添加str。\n\nappend(str, pos, len)：在字符串的末尾添加str中从pos位置开始的长度为len的子串。\n\npush_back(ch)：在字符串的末尾添加一个字符。\n\ninsert(pos, str)：在字符串的pos位置插入str。\n\nerase(pos, len)：删除从pos位置开始长度为len的子串。\nerase(n):删除indexn后面的字符\n\nreplace(pos, len, str)：替换从pos位置开始长度为len的子串为str。\n\nsubstr(pos, len)：返回从pos位置开始长度为len的子串。\n\nfind(str)：查找str在字符串中第一次出现的位置，返回该位置的索引值。(找不到就是-1)\n\nrfind(str)：查找str在字符串中最后一次出现的位置，返回该位置的索引值。\n\ncompare(str)：比较字符串和str的大小，返回0（相等）、1（大于）或-1（小于）。 除了以上列举的方法，string类还支持重载运算符，例如+（字符串拼接）、+&#x3D;（字符串拼接赋值）、&#x3D;&#x3D;（字符串相等判断）、[]（访问字符串中指定位置的字符）等。string类的使用非常方便，可以像使用普通变量一样对字符串进行赋值、拼接、查找、替换等操作。例如：\n\n\n注意string s，其s[i]类型为char，char强制类型转换可以这样转换\nstring(1,s[i])，1表示char长度\ns[i]可以直接比较\n输入str1,如果str1为空则退出\n\nscanf不会读回车，如果下一行是gets会直接读取缓冲区中的回车，所有会用一个getchar()在中间把缓冲区中的回车抵消掉\nstoi(str) 将其转换为整数，注意，如果是”04”,直接变成4\nstring::npos用于判断结尾（其实找不到直接-1也行）：\n//find函数返回 jk 在 s 中的下标位置\tposition = s.find(&quot;jk&quot;);\t// 如果没找到，返回一个特别的标志\t// c++中用npos表示，我这里npos取值是4294967295\tif(position != s.npos)\t&#123;\t\tcout &lt;&lt; &quot;position: &quot; &lt;&lt; position &lt;&lt; endl;\t&#125;\telse\t&#123;\t\tcout &lt;&lt; &quot;Not found the flag&quot; &lt;&lt; endl;\t&#125;\n\n如果输入的字符串有空格，那么用如下代码\ngetline(cin,str)\n\n可以直接通过下标修改字符\n删除字符串内重复字符:\nstring str=&quot;aadfgggh&quot;;//去重复sort(str.begin(),str.end());str.erase(unique(str.begin(),str.end()),str.end());  \n\n删除字符串内某个指定字符:\nstring str=&quot;aadfgggh&quot;;str.erase(remove(str.begin(),str.end(),&#x27;a&#x27;),str.end()); //在容器中, 删除[begin,end)之间的所有值等于&#x27;a&#x27;的值.\n\n\n\n#include&lt;string&gt;string::erase(begin,end)：删除[begin,end)之间的所有值c\n\n\n\n在Find the Smallest Number中，我发现string的超出index一位的位置依然可以访问，但是没有数\n\nalgorithmC++标准库中的algorithm库提供了许多常用的算法，这些算法可以用于处理容器中的数据，例如排序、查找、遍历等。以下是algorithm库中常用的方法：\n\nsort(first, last, func)：对[first, last)区间内的元素进行升&#x2F;降序排序（取决于func返回）。\nreverse(first, last)：对[first, last)区间内的元素进行翻转。\nfind(first, last, val)：在[first, last)区间内查找值为val的元素，返回该元素的迭代器。如果没有找到，返回last。\nfind_if(first, last, pred)：在[first, last)区间内查找满足条件pred的第一个元素，返回该元素的迭代器。如果没有找到，返回last。\ncount(first, last, val)：统计[first, last)区间内值为val的元素个数。\ncount_if(first, last, pred)：统计[first, last)区间内满足条件pred的元素个数。\naccumulate(first, last, init)：对[first, last)区间内的元素进行累加，初始值为init。\nmax_element(first, last)：返回[first, last)区间内的最大元素的迭代器。\nmin_element(first, last)：返回[first, last)区间内的最小元素的迭代器。\nunique(first, last)：对[first, last)区间内的元素去重，返回去重后的末尾迭代器。\nremove(first, last, val)：删除[first, last)区间内值为val的元素，返回删除后的末尾迭代器。\nremove_if(first, last, pred)：删除[first, last)区间内满足条件pred的元素，返回删除后的末尾迭代器。\nfor_each(first, last, func)：对[first, last)区间内的元素执行操作func。\ntransform(first1, last1, first2, result, op)：将[first1, last1)区间内的元素和[first2, …)区间内的元素进行op操作，并将结果存储到[result, …)区间内。\n\nclimits中定义的常量主要有以下几种：\n\n整数类型的最大值和最小值：INT_MAX、INT_MIN、LONG_MAX、LONG_MIN、SHRT_MAX、SHRT_MIN等等。\n字符类型的最大值和最小值：CHAR_MAX、CHAR_MIN、SCHAR_MAX、SCHAR_MIN、UCHAR_MAX等等。\n位数相关的常量：CHAR_BIT、INT_BIT、LONG_BIT等等。\n其他常量：MB_LEN_MAX表示一个多字节字符的最大长度，FLT_MAX、FLT_MIN、DBL_MAX、DBL_MIN等等表示浮点类型的最大值和最小值。\n\nsetC++ 中的 set 数据结构详解\nset 是 C++ 标准模板库（STL）中的一种关联容器，用于存储唯一元素（不允许重复值），并按照特定顺序自动排序。以下是核心特性详解：\n\n一、核心特性\n\n唯一性  \n\n自动去重，插入重复元素会被忽略\n示例：插入 &#123;1, 2, 2, 3&#125; 实际存储 &#123;1, 2,  3&#125;\n\n\n自动排序  \n\n默认升序排列（可通过比较函数自定义）\n基于红黑树（自平衡二叉搜索树）实现\n\n\n不可直接修改元素  \n\n元素为常量（const），需先删除旧值再插入新值\n原因：修改值可能破坏内部排序结构\n\n\n高效操作  \n\n查找&#x2F;插入&#x2F;删除：平均时间复杂度 O(log n)\n迭代器支持双向遍历（++&#x2F;--操作）\n\n\n\n\n二、基本操作示例\n1. 构造与初始化set&lt;T&gt; s; → 创建空 setset&lt;T&gt; s = &#123;e1, e2, ...&#125;; → 初始化列表set&lt;T&gt; s(begin, end); → 用迭代器范围构造set&lt;T&gt; s(other_set); → 拷贝构造2. 插入元素s.insert(value); → 插入单个值（返回 pair&lt;iterator, bool&gt;）s.insert(&#123;v1, v2, ...&#125;); → 插入多个值（C++11）s.emplace(args...); → 直接构造元素（避免拷贝）3. 删除元素s.erase(value); → 删除指定值（返回删除数量 0 或 1）s.erase(iterator); → 删除迭代器指向的元素s.erase(begin, end); → 删除范围（左闭右开）s.clear(); → 清空所有元素4. 查找操作s.find(value); → 返回指向 value 的迭代器（未找到返回 end()）s.count(value); → 返回 1（存在）或 0（不存在）s.lower_bound(value); → 返回首个 ≥ value 的迭代器s.upper_bound(value); → 返回首个 &gt; value 的迭代器s.equal_range(value); → 返回 pair&lt;lower_bound, upper_bound&gt;5. 容量查询s.size(); → 返回元素数量s.empty(); → 判断是否为空（true/false）s.max_size(); → 返回理论最大容量6. 遍历与迭代s.begin(); → 返回指向首元素的迭代器s.end(); → 返回尾后迭代器s.rbegin(); → 返回反向迭代器（逆序遍历）s.rend(); → 反向尾后迭代器7. 比较与合并（C++17+）s1.merge(s2); → 合并 s2 到 s1（重复元素保留在 s2）s1 == s2; → 判断两 set 内容是否相同8. 节点操作（C++17+）auto node = s.extract(value); → 移除元素但不销毁（返回节点句柄）s.insert(node); → 重新插入提取的节点9. 自定义排序set&lt;T, Compare&gt; s; → 定义比较函数（需 operator()(a,b) const）10. 其他swap(s1, s2); → 交换两个 set 内容std::distance(s.begin(), s.end()); → 计算元素数量（等效 size()）\n\n\n三、底层实现：红黑树（Red-Black Tree）\n\n\n\n特性\n说明\n\n\n\n自平衡二叉搜索树\n通过颜色标记和旋转保持近似平衡\n\n\n高度约束\n从根到叶子的最长路径 ≤ 2×最短路径\n\n\n操作复杂度\n查找&#x2F;插入&#x2F;删除均为 **O(log n)**，最坏情况仍平衡\n\n\n迭代器稳定性\n插入&#x2F;删除不使其他迭代器失效（被删除元素的迭代器除外）\n\n\n\n四、关键成员函数\n\n\n\n函数\n功能描述\n时间复杂度\n\n\n\ninsert(value)\n插入元素（自动去重）\nO(log n)\n\n\nerase(value/it)\n删除元素或迭代器指向的元素\nO(log n)\n\n\nfind(value)\n返回指向元素的迭代器（未找到则end）\nO(log n)\n\n\ncount(value)\n返回元素是否存在（0或1）\nO(log n)\n\n\nlower_bound(value)\n返回首个 ≥ value 的迭代器\nO(log n)\n\n\nupper_bound(value)\n返回首个 &gt; value 的迭代器\nO(log n)\n\n\nsize()\n返回元素数量\nO(1)\n\n\nempty()\n判断是否为空\nO(1)\n\n\n\n五、自定义排序规则\n// 降序排列示例struct Compare &#123;    bool operator()(int a, int b) const &#123;        return a &gt; b;  // 自定义比较函数    &#125;&#125;;std::set&lt;int, Compare&gt; descSet = &#123;3,1,5&#125;;// 存储顺序: 5, 3, 1\n\n\n六、应用场景\n\n需要去重+排序的数据集合\n如统计唯一单词、排序ID列表\n\n\n高频查找操作\n比vector查找更高效（O(log n) vs O(n))\n\n\n范围查询\n利用lower_bound()/upper_bound()快速定位区间\n\n\n作为字典键集合\n与map结合使用（std::set&lt;T&gt; ≈ std::map&lt;T, bool&gt;）\n\n\n\n\n七、与 unordered_set 对比\n\n\n\n特性\nset\nunordered_set\n\n\n\n底层结构\n红黑树\n哈希表\n\n\n排序\n自动排序\n无序存储\n\n\n查找速度\nO(log n)\n平均O(1)，最差O(n)\n\n\n内存占用\n较低（树结构）\n较高（哈希桶预分配）\n\n\n迭代顺序\n稳定（升序）\n不可预测\n\n\n自定义排序\n支持比较函数\n需自定义哈希函数\n\n\n\n💡 选择原则：  \n\n需要顺序访问 → 选 set  \n只需检查存在性 → 选 unordered_set（更高效）\n\n\n设置输出精度设置输出精度为1位小数\ncout &lt;&lt; fixed &lt;&lt; setprecision(1) &lt;&lt; ans &lt;&lt; endl\n设置输出位数printf(“%02d”,&amp;)\n前面补零，两位，不够两位就补零\nKMPKMP 算法详解 - 知乎 (zhihu.com)\n(427条消息) 从头到尾彻底理解KMP（2014年8月22日版）_kmp算法难吗是什么级别_v_JULY_v的博客-CSDN博客\n//nextvoid GetNext(char* p,int next[])&#123;\tint pLen = strlen(p);\tnext[0] = -1;\tint k = -1;\tint j = 0;\twhile (j &lt; pLen - 1)\t&#123;\t\t//p[k]表示前缀，p[j]表示后缀\t\tif (k == -1 || p[j] == p[k]) \t\t&#123;\t\t\t++k;\t\t\t++j;\t\t\tnext[j] = k;\t\t&#125;\t\telse \t\t&#123;\t\t\tk = next[k];\t\t&#125;\t&#125;&#125;\n\n//kmpint KmpSearch(char* s, char* p)&#123;\tint i = 0;\tint j = 0;\tint sLen = strlen(s);\tint pLen = strlen(p);\twhile (i &lt; sLen &amp;&amp; j &lt; pLen)\t&#123;\t\t//①如果j = -1，或者当前字符匹配成功（即S[i] == P[j]），都令i++，j++    \t\tif (j == -1 || s[i] == p[j])\t\t&#123;\t\t\ti++;\t\t\tj++;\t\t&#125;\t\telse\t\t&#123;\t\t\t//②如果j != -1，且当前字符匹配失败（即S[i] != P[j]），则令 i 不变，j = next[j]    \t\t\t//next[j]即为j所对应的next值      \t\t\tj = next[j];\t\t&#125;\t&#125;\tif (j == pLen)\t\treturn i - j;\telse\t\treturn -1;&#125;\n\n\n\n动态规划最大连续子序列#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;climits&gt;using namespace std;int dp[1000001];int nums[1000001];int main()&#123;\tint N;\twhile(cin&gt;&gt;N)&#123;\t\tif (N==EOF)break;\t\tint maxnum=INT_MIN;\t\tfor (int i=1;i&lt;=N;i++)&#123;\t\t\tcin&gt;&gt;nums[i];\t\t&#125;\t\tdp[1]=nums[1];\t\tif (N==1)&#123;\t\t\tcout&lt;&lt;dp[1]&lt;&lt;endl;\t\t\tbreak;\t\t&#125;\t\tfor (int i=2;i&lt;=N;i++)&#123;\t\t\tdp[i]=max(nums[i],dp[i-1]+nums[i]);\t\t\tmaxnum=max(dp[i],maxnum);\t\t&#125;\t\tcout&lt;&lt;maxnum&lt;&lt;endl;\t\t\t&#125;\treturn 0;&#125; \n\n最大子矩阵#include &lt;iostream&gt;#include &lt;algorithm&gt;using namespace std;int dp[101];int matrix[101][101];int support[101][101];int arr[101];int hangmax(int n)&#123;\tint maxnum;\tfor (int i=1;i&lt;=n;i++)&#123;\t\tdp[i]=max(arr[i],dp[i-1]+arr[i]);\t\tmaxnum=max(maxnum,dp[i]);\t&#125;\treturn maxnum;&#125;int allmax(int n)&#123;\tint maxnum;\tfor (int i=1;i&lt;=n;i++)&#123;\t\tfor (int j=i;j&lt;=n;j++)&#123;\t\t\tfor (int k=1;k&lt;=n;k++)&#123;\t\t\t\tif (i==1)&#123;\t\t\t\t\tarr[k]=support[j][k];\t\t\t\t&#125;else&#123;\t\t\t\t\tarr[k]=support[j][k]-support[i-1][k];\t\t\t\t&#125;\t\t\t&#125;\t\t\tmaxnum=max(hangmax(n),maxnum);\t\t\t\t\t&#125;\t&#125;\treturn maxnum;&#125;int main()&#123;\tint n;\tcin&gt;&gt;n;\tfor (int i=1;i&lt;=n;i++)&#123;\t\tfor (int j=1;j&lt;=n;j++)&#123;\t\t\tcin&gt;&gt;matrix[i][j];\t\t\t\t\t&#125;\t&#125;\tfor (int i=1;i&lt;=n;i++)&#123;\t\tfor (int j=1;j&lt;=n;j++)&#123;\t\t\tif (i==1)support[i][j]=matrix[i][j];\t\t\telse&#123;\t\t\t\tsupport[i][j]=matrix[i][j]+support[i-1][j];\t\t\t&#125;\t\t&#125;\t&#125;\tint maxnum;\tmaxnum=allmax(n);\tcout&lt;&lt;maxnum&lt;&lt;endl;\treturn 0;\t\t&#125;\n\n最长递增&#x2F;减序列#include &lt;iostream&gt;#include &lt;algorithm&gt;using namespace std;int dp[26];int daodan[26];int countmax(int n)&#123;\tint maxnum=0;\tfor (int i=1;i&lt;=n;i++)&#123;\t\tdp[i]=1;\t&#125;\tfor (int i=2;i&lt;=n;i++)&#123;\t\tfor (int j=1;j&lt;i;j++)&#123;\t\t\tif (daodan[i]&lt;=daodan[j])\t\t\tdp[i]=max(1,dp[j]+1);\t\t\tmaxnum=max(maxnum,dp[i]);\t\t&#125;\t&#125;\treturn maxnum;&#125;int main()&#123;\tint n;\tcin&gt;&gt;n;\tfor (int i=1;i&lt;=n;i++)&#123;\t\tcin&gt;&gt;daodan[i];\t&#125;\tint maxnum;\tmaxnum=countmax(n);\tcout&lt;&lt;maxnum&lt;&lt;endl;\treturn 0;&#125;\n\n最大上升子序列和（O(N^2)）#include &lt;iostream&gt;#include &lt;algorithm&gt;using namespace std;int dp[1001];int nums[1001];int countmax(int n)&#123;\tint maxsum;\tfor (int i=1;i&lt;=n;i++)&#123;\t\tdp[i]=nums[i];\t&#125;\tfor (int i=2;i&lt;=n;i++)&#123;\t\tfor (int j=1;j&lt;i;j++)&#123;\t\t\tif (nums[i]&gt;nums[j])\t\t\tdp[i]=max(nums[i],dp[j]+nums[i]);\t\t\tmaxsum=max(maxsum,dp[i]);\t\t&#125;\t&#125;\treturn maxsum;&#125;int main()&#123;\tint n;\tcin&gt;&gt;n;\tfor (int i=1;i&lt;=n;i++)&#123;\t\tcin&gt;&gt;nums[i];\t&#125;\tint maxsum;\tif (n==1)&#123;\t\tcout&lt;&lt;nums[1];\t\treturn 0;\t&#125;\tmaxsum=countmax(n);\tcout&lt;&lt;maxsum&lt;&lt;endl;\treturn 0;&#125;\n\n最长公共子序列（LCS）17359483\n(461条消息) 最长公共子序列 (LCS) 详解+例题模板（全）_lxt_Lucia的博客-CSDN博客\n#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;string&gt;using namespace std;string s1;string s2;int countmax(string s1,string s2)&#123;\tint length1=s1.size();\tint length2=s2.size();\tint dp[length1][length2];\tfor (int i=0;i&lt;length1;i++)&#123;\t\tfor (int j=0;j&lt;length2;j++)&#123;\t\t\tdp[i][j]=0;\t\t&#125;\t&#125;\tint maxnum=0;\tfor (int i=0;i&lt;length1;i++)&#123;\t\tfor (int j=0;j&lt;length2;j++)&#123;\t\t\tif (s1[i]==s2[j])&#123;\t\t\t\tif (i==0||j==0)&#123;\t\t\t\t\tdp[i][j]=1;\t\t\t\t&#125;else&#123;\t\t\t\t\tdp[i][j]=dp[i-1][j-1]+1;\t\t\t\t&#125;\t\t\t&#125;else&#123;\t\t\t\tif (i==0||j==0)&#123;\t\t\t\t\tdp[i][j]=0;\t\t\t\t&#125;else&#123;\t\t\t\t\tdp[i][j]=max(dp[i-1][j],dp[i][j-1]);\t\t\t\t&#125;\t\t\t\t\t\t\t&#125;\t\t\tmaxnum=max(maxnum,dp[i][j]);\t\t&#125;\t&#125;\treturn maxnum;&#125;int main()&#123;\twhile(cin&gt;&gt;s1&gt;&gt;s2)&#123;\t\tint maxnum=countmax(s1,s2);\t\tcout&lt;&lt;maxnum&lt;&lt;endl;\t\t\t&#125;\treturn 0;&#125;\n\nLIS（Nlogn）(465条消息) 最长上升子序列 (LIS) 详解+例题模板 (全)_lxt_Lucia的博客-CSDN博客\n01背包#include &lt;iostream&gt;using namespace std;struct d&#123;\tint price;\tint score;&#125;;int main()&#123;\tint C,N;\twhile (cin&gt;&gt;C&gt;&gt;N)&#123;\t\tif (C==0&amp;&amp;N==0)break;\t\tint dp[C+1];\t\td deal[N];\t\tfor (int i=0;i&lt;=C;i++)&#123;\t\t\tdp[i]=0;\t\t&#125;\t\tfor (int i=0;i&lt;N;i++)&#123;\t\t\tint price;\t\t\tint score;\t\t\tcin&gt;&gt;price&gt;&gt;score;\t\t\tdeal[i].price=price;\t\t\tdeal[i].score=score;\t\t&#125;\t\tfor (int i=0;i&lt;N;i++)&#123;\t\t\tfor (int j=C;j&gt;=1;j--)&#123;\t\t\t\tif (j&gt;=deal[i].price)&#123;\t\t\t\t\tdp[j]=max(dp[j-deal[i].price]+deal[i].score,dp[j]);\t\t\t\t&#125;\t\t\t\t\t&#125;\t&#125;\t\tcout&lt;&lt;dp[C]&lt;&lt;endl;\t\t\t&#125;\treturn 0;&#125;\n\n有个背包的变种\n(465条消息) 复旦大学2021年计算机学院机试题解_复旦oj_PyKt的博客-CSDN博客\n这里是直接顺序的\nDFS BFS排序归并#include &lt;stdio.h&gt;#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstdlib&gt;#include &lt;cmath&gt;using namespace std;void merge(int* a, int low, int mid, int hight)  //合并函数&#123;\tint* b = new int[hight - low + 1];  //用 new 申请一个辅助函数\tint i = low, j = mid + 1, k = 0;    // k为 b 数组的小标\twhile (i &lt;= mid &amp;&amp; j &lt;= hight)  \t&#123;\t\tif (a[i] &lt;= a[j])\t\t&#123;\t\t\tb[k++] = a[i++];  //按从小到大存放在 b 数组里面\t\t&#125;\t\telse\t\t&#123;\t\t\tb[k++] = a[j++];\t\t&#125;\t&#125;\twhile (i &lt;= mid)  // j 序列结束，将剩余的 i 序列补充在 b 数组中 \t&#123;\t\tb[k++] = a[i++];\t&#125;\twhile (j &lt;= hight)// i 序列结束，将剩余的 j 序列补充在 b 数组中 \t&#123;\t\tb[k++] = a[j++];\t&#125;\tk = 0;  //从小标为 0 开始传送\tfor (int i = low; i &lt;= hight; i++)  //将 b 数组的值传递给数组 a\t&#123;\t\ta[i] = b[k++];\t&#125;\tdelete[]b;     // 辅助数组用完后，将其的空间进行释放（销毁）&#125;void mergesort(int* a, int low, int hight) //归并排序&#123;\tif (low &lt; hight)\t&#123;\t\tint mid = (low + hight) / 2;\t\tmergesort(a, low, mid);          //对 a[low,mid]进行排序\t\tmergesort(a, mid + 1, hight);    //对 a[mid+1,hight]进行排序\t\tmerge(a, low, mid, hight);       //进行合并操作\t&#125;&#125;int main()&#123;\tint n, a[100];\tcout &lt;&lt; &quot;请输入数列中的元素个数 n 为：&quot; &lt;&lt; endl;\tcin &gt;&gt; n;\tcout &lt;&lt; &quot;请依次输入数列中的元素：&quot; &lt;&lt; endl;\tfor (int i = 0; i &lt; n; i++)\t&#123;\t\tcin &gt;&gt; a[i];\t&#125;\tmergesort(a, 0, n-1);\tcout &lt;&lt; &quot;归并排序结果&quot; &lt;&lt; endl;\tfor (int i = 0; i &lt; n; i++)\t&#123;\t\tcout &lt;&lt; a[i] &lt;&lt; &quot; &quot;;\t&#125;\tcout &lt;&lt; endl;\treturn 0;&#125;\n\n\n\n快速幂const long long m=1e9+7;long long quickpow(long long a,long long b)&#123;\tlong long sum=1;\twhile(b)&#123;\t\tif(b&amp;1)//与运算，可判断奇偶，详细见注释\t\tsum=sum*a%m;//取模运算\t\ta=a*a%m;\t\tb&gt;&gt;=1;//位运算，右移，相当于除以2\t&#125;\treturn sum;&#125; \n\n模拟问题就是找规律，还行\n日期问题要预处理\n最大公因数&#x2F;最小公倍数最小公倍数&#x3D;a*b&#x2F;c\nc为最大公因数\n//最大公因数int biggest(int a,int b)&#123;\treturn b!=0?biggest(b,a%b):a;&#125;//最小公倍数int smallest(int a, int b)&#123;   \tint big=biggest(a,b);    return a*b/big;&#125;\n\n素数筛法#include&lt;iostream&gt;using namespace std;int n;int main()&#123;\twhile (cin&gt;&gt;n)&#123;\t\tif (n==0)break;\t\tif (n==2)&#123;\t\t\tcout&lt;&lt;-1&lt;&lt;endl;\t\t\tcontinue;\t\t&#125;\t\tbool sushu[n+1];\t\tfor (int i=2;i&lt;=n;i++)&#123;\t\t\tsushu[i]=true;\t\t&#125;\t\tfor (int i=2;i&lt;=n;i++)&#123;\t\t\tif (sushu[i]==false)continue;\t\t\tfor (int j=i;j*i&lt;=n;j++)&#123; //j直接从i开始，提高效率\t\t\t\tif (j*i&lt;n)&#123;\t\t\t\t\tsushu[j*i]=false;\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;\t\tfor (int i=2;i&lt;n;i++)&#123;\t\t\tif (sushu[i])&#123;\t\t\t\tif (i%10==1)&#123;\t\t\t\t\tcout&lt;&lt;i&lt;&lt;&quot; &quot;;\t\t\t\t&#125;\t\t\t&#125;\t\t\t\t&#125;\t\tcout&lt;&lt;endl;\t\t\t&#125;\treturn 0;&#125;\n\n对于一个数n，其质因数最多只有一个大于其平方根！\n矩阵乘法（构造函数）#include &lt;iostream&gt;using namespace std;struct Matrix&#123;\tint matrix[10][10];\tint row;\tint col;\tMatrix(int a,int b):row(a),col(b)&#123;&#125;//注意构造函数的写法&#125;;Matrix Multiply(Matrix a,Matrix b)&#123;\tMatrix ans=Matrix(a.row,b.col);\tfor (int i=0;i&lt;a.row;i++)&#123;\t\tfor (int j=0;j&lt;b.col;j++)&#123;\t\t\tint temp=0;\t\t\tfor (int k=0;k&lt;a.col;k++)&#123;\t\t\t\ttemp+=a.matrix[i][k]*b.matrix[k][j];\t\t\t&#125;\t\t\tans.matrix[i][j]=temp;\t\t&#125;\t&#125;\treturn ans;&#125;void printMatrix(Matrix m)&#123;\tint row=m.row;\tint col=m.col;\tfor (int i=0;i&lt;row;i++)&#123;\t\tfor (int j=0;j&lt;col;j++)&#123;\t\t\tif (j!=0)&#123;\t\t\t\tcout&lt;&lt;&quot; &quot;;\t\t\t&#125;\t\t\tcout&lt;&lt;m.matrix[i][j];\t\t&#125;\t\tcout&lt;&lt;endl;\t&#125;&#125;int main()&#123;\tMatrix a=Matrix(2,3);\tMatrix b=Matrix(3,2);\tfor (int i=0;i&lt;2;i++)&#123;\t\tfor (int j=0;j&lt;3;j++)&#123;\t\t\tcin&gt;&gt;a.matrix[i][j];\t\t&#125;\t&#125;\tfor (int i=0;i&lt;3;i++)&#123;\t\tfor (int j=0;j&lt;2;j++)&#123;\t\t\tcin&gt;&gt;b.matrix[i][j];\t\t&#125;\t&#125;\tMatrix c=Multiply(a,b);\tprintMatrix(c);\treturn 0;\t&#125;\n\n高精度最小生成树prim算法求最小生成树- CSDN搜索\nkruscal\n#include &lt;iostream&gt;#include &lt;queue&gt;using namespace std;struct edge&#123;\tint a;\tint b;\tint weight;\tbool operator&gt;(edge c)const&#123;\t\treturn weight&gt;c.weight;\t&#125;\tedge(int q,int w,int e):a(q),b(w),weight(e)&#123;&#125;&#125;;priority_queue&lt;edge,vector&lt;edge&gt;,greater&lt;edge&gt;&gt;edges;int graph[100];int find(int x)&#123;\tif (graph[x]==-1)return x;\telse&#123;\t\tint temp;\ttemp=find(graph[x]);\tgraph[x]=temp;\treturn temp;\t&#125;\t&#125;int main()&#123;\tint n;\twhile (cin&gt;&gt;n)&#123;\t\tif (n==0)break;\t\tint a,b,weight;\t\tint num=n*(n-1)/2;\t\tmemset(graph,-1,sizeof(graph));\t\tfor (int i=1;i&lt;=n;i++)&#123;\t\t\tgraph[i]=-1;\t\t&#125;\t\twhile (num--)&#123;\t\t\tcin&gt;&gt;a&gt;&gt;b&gt;&gt;weight;\t\t\tedge edge1=edge(a,b,weight);\t\t\tedges.push(edge1);\t\t&#125;\t\tint sum=0;\t\tint count=0;\t\twhile (!edges.empty()&amp;&amp;count&lt;n-1)&#123;\t\t\tedge temp=edges.top();\t\t\tedges.pop();\t\t\tint a=find(temp.a);\t\t\tint b=find(temp.b);\t\t\tint weight=temp.weight;\t\t\tif (a!=b)&#123;\t\t\t\tgraph[a]=b;\t\t\t\tcount++;\t\t\t\tsum+=weight;\t\t\t&#125;\t\t&#125;\t\tcout&lt;&lt;sum&lt;&lt;endl;\t&#125;\treturn 0;&#125;\n\n\n\n弗洛伊德for (int k = 1;k &lt;= n;k ++) &#123;  for (int i = 1;i &lt;= n;i ++) &#123;  for (int j = 1;j &lt;= n;j ++) &#123;  if (ans[i][k] == 无穷 || ans[k][j] == 无穷) continue;  if (ans[i][j] == 无穷 || ans[i][k] + ans[k][j] &lt; ans[i][j])  ans[i][j] = ans[i][k] + ans[k][j];  &#125;  &#125;  &#125; \n\n迪杰斯特拉for (int i = 1;i &lt;= n;i ++) &#123; //初始化 Dis[i] = -1; //所有距离为-1，即不可达 mark[i] = false; //所有结点不属于集合K &#125;  Dis[1] = 0; //得到最近的点为结点1,长度为0 mark[1] = true; //将结点1加入集合K int newP = 1; //集合K中新加入的点为结点1  for (int i = 1;i &lt; n;i ++) &#123; //循环n-1次,按照最短路径递增的顺序确定其他n-1个点的最短路径长度 for (int j = 0;j &lt; edge[newP].size();j ++) &#123; //遍历与该新加入集合K中的结点直接相邻的边 int t = edge[newP][j].next; //该边的另一个结点 int c = edge[newP][j].c; //该边的长度 if (mark[t] == true) continue; //若另一个结点也属于集合K,则跳过 if (Dis[t] == - 1 || Dis[t] &gt; Dis[newP] + c) //若该结点尚不可达,或者该结点从新加入的结点经过一条边到达时比以往距离更短 Dis[t] = Dis[newP] + c; //更新其距离信息 &#125;  int min = 123123123; //最小值初始化为一个大整数,为找最小值做准备 for (int j = 1;j &lt;= n;j ++) &#123; //遍历所有结点 if (mark[j] == true) continue; //若其属于集合K则跳过 if (Dis[j] == -1) continue; //若该结点仍不可达则跳过 if (Dis[j] &lt; min) &#123; //若该结点经由结点1至集合K中的某点在经过一条边到达时距离小于当前最小值 min = Dis[j]; //更新其为最小值 newP = j; //新加入的点暂定为该点 &#125;\n\n欧拉回路（hierholzer）(462条消息) 欧拉回路（hierholzer算法）_逐步插入回路法_run around的博客-CSDN博客\n关键路径（AOE网）最早开始时间&#x3D;最晚开始时间\n用拓扑图\n最早开始时间（所有先序活动的最晚完成时间）\n最晚开始时间（所有后续活动的最早开始时间减去该活动花费的时间）\n注意源点的最早开始时间不一定为0，要初始化\n汇点的最晚开始时间初始化为totalTime-该汇点任务的时间\n非汇点的最晚开始时间为无穷\n如果只是要求关键路径的长度，其实在earliest[i]初始化的时候就设置为任务的时间就行，但如果要算其他的，就还是设置为0\n7 511 20 17 10 11 17 175 46 17 32 42 1\n#include &lt;iostream&gt;#include &lt;queue&gt;#include &lt;vector&gt;#include &lt;climits&gt;#define yushu 1e9+7using namespace std;queue&lt;int&gt;zero;vector&lt;int&gt;re;struct edge&#123;\tint to;\tint weight;&#125;;int in[100001];vector&lt;edge&gt;edges[100001];int task[100001];int earliest[100001];int latest[100001];int max(int a,int b)&#123;\treturn a&gt;b?a:b;&#125;int min(int a,int b)&#123;\treturn a&lt;b?a:b;&#125;int main()&#123;\tint n,m;\tcin&gt;&gt;n&gt;&gt;m;\tfor (int i=1;i&lt;=n;i++)&#123;\t\tin[i]=0;\t\tcin&gt;&gt;task[i];\t&#125;\tint num=m;\tint allTime=0;\tcout&lt;&lt;&quot;input edge&quot;&lt;&lt;endl;\twhile (num--)&#123;\t\tint a,b;\t\tcin&gt;&gt;a&gt;&gt;b;\t\tin[b]++;\t\tedge temp;\t\ttemp.to=b;\t\ttemp.weight=task[b];\t\tedges[a].push_back(temp);\t&#125;\tcout&lt;&lt;&quot;input finished.&quot;&lt;&lt;endl;\tfor (int i=1;i&lt;=n;i++)&#123;\t\tcout&lt;&lt;&quot;earliest[&quot;&lt;&lt;i&lt;&lt;&quot;]:&quot;&lt;&lt;earliest[i]&lt;&lt;endl;\t\tif (in[i]==0)&#123;\t\t\tzero.push(i);\t\t&#125;\t&#125;\twhile (!zero.empty())&#123;\t\tint node=zero.front();\t\tcout&lt;&lt;&quot;zero:&quot;&lt;&lt;node&lt;&lt;endl;\t\tzero.pop();\t\tre.push_back(node);\t\tfor (int i=0;i&lt;edges[node].size();i++)&#123;\t\t\tint to=edges[node][i].to;\t\t\tint weight=edges[node][i].weight;\t\t\tcout&lt;&lt;&quot;edge:&quot;&lt;&lt;node&lt;&lt;&quot;-&quot;&lt;&lt;to&lt;&lt;&quot;:&quot;&lt;&lt;weight&lt;&lt;endl;\t\t\tearliest[to]=max(earliest[to],earliest[node]+task[node]);\t\t\tcout&lt;&lt;&quot;earliest[&quot;&lt;&lt;to&lt;&lt;&quot;]:&quot;&lt;&lt;earliest[to]&lt;&lt;endl;\t\t\tin[to]--;\t\t\tif (in[to]==0)&#123;\t\t\t\tzero.push(to);\t\t\t&#125;\t\t&#125;\t&#125;\tfor (int i=1;i&lt;=n;i++)&#123;\t\tallTime=max(allTime,earliest[i]+task[i]);\t&#125;\tcout&lt;&lt;&quot;reverse:&quot;&lt;&lt;endl;\tfor (int i=re.size()-1;i&gt;=0;i--)&#123;\t\tint u=re[i];\t\tif (edges[u].size()==0)&#123;\t\t\tlatest[u]=allTime-task[u];\t\t\tcout&lt;&lt;&quot;latest:[&quot;&lt;&lt;u&lt;&lt;&quot;]:&quot;&lt;&lt;latest[u]&lt;&lt;endl;\t\t&#125;else&#123;\t\t\tlatest[u]=99999999;\t\t\t\t&#125;\t\tfor (int j=0;j&lt;edges[u].size();j++)&#123;\t\t\tint to=edges[u][j].to;\t\t\tint weight=edges[u][j].weight;\t\t\tlatest[u]=min(latest[u],latest[to]-task[u]);\t\t\tcout&lt;&lt;&quot;latest:[&quot;&lt;&lt;u&lt;&lt;&quot;]:&quot;&lt;&lt;latest[u]&lt;&lt;endl;\t\t&#125;\t\t&#125;\t\tcout&lt;&lt;endl;\tfor (int i=1;i&lt;=n;i++)&#123;\t\t\tcout&lt;&lt;&quot;earliest[&quot;&lt;&lt;i&lt;&lt;&quot;]:&quot;&lt;&lt;earliest[i]&lt;&lt;endl;\t\t\tcout&lt;&lt;&quot;latest[&quot;&lt;&lt;i&lt;&lt;&quot;]:&quot;&lt;&lt;latest[i]&lt;&lt;endl;\t&#125;\t\tint sum=1;\tfor (int i=1;i&lt;=n;i++)&#123;\t\tsum*=(latest[i]-earliest[i]+1);\t&#125;\tcout&lt;&lt;allTime&lt;&lt;endl;\tcout&lt;&lt;sum&lt;&lt;endl;\treturn 0;\t\t&#125;\n\n(466条消息) AOE问题总结_DrCrypto的博客-CSDN博客\n(466条消息) AOE网关键路径求解例题_关键路径例题图解_HardyDragon_CC的博客-CSDN博客\n数位dp(443条消息) 2019年南京大学计算机考研复试机试真题_南大计算机专业考研机试_yc_cy1999的博客-CSDN博客\n一个整数可以变为多少个整数相加\n#include &lt;iostream&gt;#include &lt;algorithm&gt;using namespace std;const int N = 1010, mod = 1e9 + 7;int n;int f[N];//存所有状态int main()&#123;    cin &gt;&gt; n;    f[0] = 1;    for (int i = 1; i &lt;= n; i ++)        for(int j = i; j &lt;= n; j ++)//j是容量            f[j] = (f[j] + f[j - i]) % mod;    cout &lt;&lt; f[n] &lt;&lt; endl;    return 0;&#125;\n\n状压DP(462条消息) 291. 蒙德里安的梦想（状压dp）_seez的博客-CSDN博客\n[(462条消息) 状压dp] 蒙德里安的梦想(模板题+状压dp)_状压dp模板题_Ypuyu的博客-CSDN博客\n(462条消息) C++笔试题模版汇总(五)动态规划&#x2F;贪心_c++笔试题 考动态规划么_ai_XZP_master的博客-CSDN博客\n状态压缩DP学习总结+经典例题精解_状压dp-CSDN博客\n汉诺塔问题结论：把i个盘子移到另一个柱面上，需要2^i-1步\n关于汉诺塔问题 - 知乎 (zhihu.com)\n放置街灯（Placing Lampposts, UVa 10859）:star:\n经典贪心(450条消息) UVA-10382经典贪心问题，区间覆盖_uva 10382_KXL5180的博客-CSDN博客\n//酸奶工程#include&lt;bits/stdc++.h&gt;using namespace std;typedef long long ll;//定义long long，防止爆intll n,s;ll c[10010],y[10010];//存储费用和交互数量ll f[10010];ll sum=0;int main()&#123;    scanf(&quot;%lld%lld&quot;,&amp;n,&amp;s);    for(int i=1;i&lt;=n;i++)&#123;        scanf(&quot;%lld%lld&quot;,&amp;c[i],&amp;y[i]);    &#125;    for(int i=1;i&lt;=n;i++)&#123;        if(i==1)&#123;            f[i]=c[i];        &#125;        else&#123;            f[i]=min(c[i],f[i-1]+s);        &#125;        sum=sum+f[i]*y[i];    &#125;    printf(&quot;%lld&quot;,sum);&#125;\n\n\n\n跳跃问题(462条消息) Leetcode——跳跃问题II_跳跃问题2_Purple.’’的博客-CSDN博客\n分发糖果(462条消息) 「leetcode」135.分发糖果【贪心算法】详细图解_代码随想录的博客-CSDN博客\n线段树(462条消息) 线段树 从入门到进阶（超清晰，简单易懂）_线段树进阶_繁凡さん的博客-CSDN博客\n匈牙利算法(462条消息) 匈牙利算法详解_Amelie_xiao的博客-CSDN博客\n一个二分图中的最大匹配数等于这个图中的最小点覆盖数\nint M, N;            //M, N分别表示左、右侧集合的元素数量int Map[MAXM][MAXN]; //邻接矩阵存图int p[MAXN];         //记录当前右侧元素所对应的左侧元素bool vis[MAXN];      //记录右侧元素是否已被访问过bool match(int i)&#123;    for (int j = 1; j &lt;= N; ++j)        if (Map[i][j] &amp;&amp; !vis[j]) //有边且未访问        &#123;            vis[j] = true;                 //记录状态为访问过            if (p[j] == 0 || match(p[j])) //如果暂无匹配，或者原来匹配的左侧元素可以找到新的匹配            &#123;                p[j] = i;    //当前左侧元素成为当前右侧元素的新匹配                return true; //返回匹配成功            &#125;        &#125;    return false; //循环结束，仍未找到匹配，返回匹配失败&#125;int Hungarian()&#123;    int cnt = 0;    for (int i = 1; i &lt;= M; ++i)    &#123;        memset(vis, 0, sizeof(vis)); //重置vis数组        if (match(i))            cnt++;    &#125;    return cnt;&#125;\n\n回溯[(462条消息) 2018南京大学计算机夏令营机试第二题（回溯）_只会写臭虫的博客-CSDN博客](https://blog.csdn.net/weixin_43175029/article/details/94670710?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=Missing number  Given a positi&amp;utm_medium&#x3D;distribute.pc_search_result.none-task-blog-2allsobaiduweb~default-0-94670710.142^v88^control_2,239^v2^insert_chatgpt&amp;spm&#x3D;1018.2226.3001.4187)\n回溯就是dfs，并且在每次dfs时记得恢复原状态；如果只需要输出一种状态，设置flag标志位\nN皇后\n#include &lt;iostream&gt;using namespace std;const int N = 20;  // bool数组用来判断搜索的下一个位置是否可行// col列，dg对角线，udg反对角线// g[N][N]用来存路径 int n;char g[N][N];bool col[N], dg[N], udg[N]; void dfs(int u) &#123;    // u == n 表示已经搜了n行，故输出这条路径    if (u == n) &#123;        for (int i = 0; i &lt; n; i ++ ) puts(g[i]);   // 等价于cout &lt;&lt; g[i] &lt;&lt; endl;        puts(&quot;&quot;);  // 换行        return;    &#125;     // 枚举u这一行，搜索合法的列    int x = u;    for (int y = 0; y &lt; n; y ++ )        // 剪枝(对于不满足要求的点，不再继续往下搜索)          // 这里y-x+n是左上角到右下角,y+x是左下角到右上角        if (col[y] == false &amp;&amp; dg[y - x + n] == false &amp;&amp; udg[y + x] == false) &#123;            col[y] = dg[y - x + n] = udg[y + x] = true;            g[x][y] = &#x27;Q&#x27;;            dfs(x + 1);            g[x][y] = &#x27;.&#x27;;  // 恢复现场            col[y] = dg[y - x + n] = udg[y + x] = false;        &#125;&#125; int main() &#123;    cin &gt;&gt; n;    for (int i = 0; i &lt; n; i ++ )        for (int j = 0; j &lt; n; j ++ )            g[i][j] = &#x27;.&#x27;;     dfs(0);     return 0;&#125;    \n\n\n\n建立索引树[(462条消息) 2020北航计算机夏令营机试题目个人理解_北航夏令营 机试_四处碰壁嘤嘤怪的博客-CSDN博客](https://blog.csdn.net/Bernie_double/article/details/118190022?ops_request_misc=%7B%22request%5Fid%22%3A%22168715279416800185829257%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=168715279416800185829257&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~baidu_landing_v2~default-5-118190022-null-null.142^v88^control_2,239^v2^insert_chatgpt&amp;utm_term=北航夏令营 机试&amp;spm&#x3D;1018.2226.3001.4187)\n注意 建树不一定要指针，数组也可\n4 51 0 1 0 01 0 1 1 11 1 1 1 11 0 0 1 0\n","categories":["博客"],"tags":["C++","算法","数据结构"]},{"title":"日本数据基础设施-调研","url":"/2024/06/28/%E6%97%A5%E6%9C%AC%E6%95%B0%E6%8D%AE-%E8%B0%83%E7%A0%94/","content":"日本数据基础设施-调研1）法律法规促进数据流通与利用基本法日本的促进数据流通与利用基本法并不是一个单独的具体法律名称，而是对日本在数据流通与利用方面进行的一系列法律和政策探索的统称。以下是一些关键点，概述了日本在这一领域的实践和政策框架：\n\n多方协作机制 : 日本通过政府、产业界和行业协会的协作，推动数据流通与利用。政府层面成立新机构专项推进，如“数字厅”取代IT综合战略本部，统筹推进全国数字社会建设、数字化转型。\n\n《综合数据战略》 : 数字厅作为责任部门推动实施《综合数据战略》，旨在建立一个放心高效的数据使用机制，推动数据在国内以及跨国安全、高效流通。\n\n数据基础设施建设 : 产业层面积极建设数据基础设施、研发数据安全技术、建设数据交易市场。例如，NTT集团构建数据协作平台——全球可信数据空间，推动跨企业、跨行业、跨国界的数据利用与协作。\n\n数据社会联盟 : 成立数据社会联盟，对产业数据空间等领域的技术标准进行规范，推进数字技术研发和数据流通领域标准及规范的建立。目前正在开发跨学科的数据协作平台DATA-EX。\n\n数据流通利用基础 : 日本政府以及各行业组织在数据交易基础制度、数据流通基础设施等方面开展了一系列探索，包括数据权属、定价等相关制度规定。\n\n跨境数据流动 : 日本倡导数据自由流动，寻求在跨境数据流动方面发挥领导作用。例如，在G20大阪峰会上提出建立“数据流通圈”概念，推动建立新的国际数据监督体系。\n\n数据空间建设 : 推动数据空间建设，如政务数据GBiz平台、农业数据WAGRI平台、防灾信息SIP4D平台等，以实现企业间数据安全、可信、高效流通共享。\n\n多层次数据交易市场 : 鼓励多层次数据交易市场发展，推动数据资产化、资本化，例如“个人数据商店”和“数据银行”模式，探索个人数据收益分享制度。\n\n《数字社会形成基本法》 : 该法律是日本数字化转型的核心，它规定了数字社会形成措施的基本原则和政策，包括设立数字机构和制定优先计划，强调数据的流通和利用是数字社会的重要基石。\n\n个人号码制度 : 作为数字化政务的大前提，个人号码制度是日本政府推行的一项个人识别制度，通过个人号码卡实现行政手续的“一站式”服务。\n\n\n这些措施和政策体现了日本在促进数据流通与利用方面的全面战略和实践，旨在建立一个安全、高效、开放的数据生态系统。\n2003：日本个人信息保护法日本的个人信息保护法（Act on the Protection of Personal Information, APPI）在2003年首次制定，是一部旨在保护个人信息的法律，它规定了个人数据的处理方式，以确保个人权利和利益得到尊重，并在随后的几年中经过了多次修订，以应对新的挑战和需求，如技术进步和国际合作的需要。该法律的最近一次重大修订是在2020年，预计将在2022年6月11日前由政令规定的日期起施行。此外，2021年9月，日本个人信息保护委员会更新了关于该法律的指南问答，新增了人脸识别信息使用等具体规定。\n以下是关于该法律的一些关键点：\n\n立法目的: 该法律的目的是保护个人信息的合理和有效应用，同时促进新产业的创造和经济社会的活力，提高日本人民的生活质量。\n适用范围: 它适用于所有处理个人信息的实体，包括公司、政府机构和独立行政法人等。\n定义: 法律中定义了“个人信息”（personal information）是指可以识别特定个人的信息，以及“匿名处理信息”（anonymously processed information），即通过系统化的方式处理，使其无法识别特定个人的信息。\n基本原则: 法律提出了适当处理个人信息的总体愿景，并要求政府制定基本政策来促进个人信息保护措施的全面和整体推进。\n数据主体的权利: 法律赋予数据主体一系列权利，包括访问权、更正权和删除权等，以确保个人信息的准确性和安全。\n数据处理者的义务: 数据处理者必须采取必要的措施来保护个人信息，防止未经授权的访问、泄露、丢失或破坏，并在处理个人信息时遵守法律规定的原则和标准。\n数据泄露报告: 如果发生个人信息泄露，数据处理者必须按照规定向个人信息保护委员会（Personal Information Protection Commission, PPC）报告，并在必要时通知受影响的个人。\n跨境数据传输: 法律对个人信息的跨境传输提出了要求，确保在将个人信息传输到国外时，接收方有足够的保护措施来维护个人信息的安全。\n监管机构: 日本个人信息保护委员会是负责监督和执行个人信息保护法的独立行政机构。\n违规处罚: 违反个人信息保护法的行为可能会受到行政处罚，包括责令改正、业务暂停或终止，以及在某些情况下的刑事处罚。\n\n2021年6月：综合数据战略\n法律&#x2F;政策名称: 综合数据战略\n\n概要介绍:  2021年6月，日本发布“综合数据战略”，旨在“通过确保信赖和公益性，构筑安心且高效地使用数据的结构，同时，从世界范围内确保对日本数据本身及其生成、流通方式的信赖，在世界范围内放心地利用日本数据，也让世界数据能在日本放心存放的社会”。日本政府计划使行政机构本身成为全国最大的平台，让公共数据充分流动。其由日本数字政府内阁阁员会议下设置“数据战略特别工作组”具体制定。内阁会议决定将该工作组成果与《面向实现数字社会的重点计划》合并为《综合数据战略》。《综合数据战略》旨在建设日本打造世界顶级数字国家所需的数字基础；明确了数据战略的基本思路，制定了社会愿景以及实现该愿景的基本行动指南。\n2021年9月，日本成立了数字厅以实施该“综合数据战略”。在“综合数据战略”中，日本设想了一个“七层两要素”的数据治理架构：\n表1：日本“综合数据战略”提出的数据治理架构\n\n\n\n层级\n内容\n要素\n\n\n\n第七层\n战略、政策\n要素一：社会实施和业务改革\n\n\n第六层\n组织：行政及民间业务改革\n\n\n\n第五层\n规则：除了完善数据标准和质量等数据联合所需的规则外，还完善了用于放心利用数据的信任基础等规则。\n要素二：数据环境建设\n\n\n第四层\n利用环境：为各种各样的主体熟练使用个人数据存储、信息银行和数据交易市场等联合的数据提供有利环境。\n\n\n\n第三层\n合作平台（工具）：为了系统地联合上述数据，配备了目录等数据联合工具。\n\n\n\n第二层\n数据：从社会活动基础数据着手，从结构上构筑必要的数据。\n\n\n\n第一层\n基础设施：支撑数字社会的5G、数据中心、计算基础设施等基础设施\n\n\n\n之所以实施数据全产业链战略，是因为日本意识到其存在数字化设施不健全、缺乏基础数据、官民商数据共享不充分、社会整体的数据素养低、对隐私强烈担忧等问题。如不实施全面的措施，数据共享难以开展。此外，日本政府还计划使作为最大数据持有者的行政机构本身成为全国最大的平台，让公共数据充分流动。\n\n\n数字改革关联六法（相当一部分查不到细则，重点是《数字社会形成基本法》）\n日本国会在2021年5月通过了六部与数字化改革相关的法案，这些法案被统称为“数字改革关联六法”。这些法案的核心目标是推动日本的数字化转型，包括设立数字厅来统筹全国信息系统的管理，确立数字化社会的基本发展理念等。其中，《数字社会形成基本法》是这一系列法案中的重要组成部分，它规定了数字社会形成措施的基本原则和基本政策，以及中央政府、地方政府和企业经营者的责任。日本政府决定于2021年9月1日正式设立数字厅，作为数字化改革的统一领导部门。这些法案的通过被视为日本数字化改革向前迈出的一大步，标志着日本数字化战略重心从“网络建设”转向“数据活用”的新阶段。\n\n《数字社会形成基本法》:\n\n该法律是数字改革的核心，规定了数字社会形成措施的基本原则和基本政策，明确了中央政府、地方政府和企业经营者的责任，以及设立数字机构和制定优先计划的要求。\n\n\n《数字厅设置法》:\n\n该法律明确了数字厅作为数字化改革的统一领导部门的组织和职责，确立了数字厅在数字化改革中的中心地位。\n\n\n《数字改革关联法》:\n\n该法律是日本官方和民间的数字化改革指挥塔，涉及国家信息系统的统筹管理规则。\n\n\n《个人信息保护法》修正案:\n\n通过修改，将统一日本各地方自治体、民间机构等各不相同的个人信息保护法则，并导入全国统一的个人信息保护制度，推进日本行政手续线上化改革等数字化改革。\n\n\n《地方公共团体信息系统标准化法》:\n\n该法律旨在统一地方政府的信息系统，规定地方政府的信息系统应统一为国家指定的格式，以促进数据互通和标准化。\n\n\n其他相关法律:\n\n除了上述法律外，还包括其他与数字化改革相关的法律，如促进数据的开放和利用、加强网络安全等。\n\n\n\n这六部法律共同推动了日本数字化改革，旨在解决数字化进程中的各种问题，如行政电子化程度低下、数据孤岛、个人信息保护等，同时促进数据的开放、流通和利用，提高行政效率和透明度，推动经济社会的数字化转型。通过这些法律的实施，日本政府希望建立一个安全、便捷、高效的数字社会。\n2021年5月：数字社会形成基本法（重点）\n法律&#x2F;政策名称: 数字社会形成基本法\n概要介绍:  该法规定了数字社会形成措施制定的基本原则和基本政策，中央政府、地方政府和企业经营者的责任，设立数字机构，制定优先计划，标志着日本数字化的战略重心已从“网络建设”转向“数据活用”。\n相关涉及名词：\n个人数据商店（Personal Data Store，PDS）:\n定义: 个人数据商店代表用户管理其个人数据，并根据用户个人意愿将其提供给第三方。它允许用户控制自己的数据，并在第三方需要时提供数据，从而实现数据的有序流通及价值增值。\n\n\n数据银行:\n定义: 数据银行模式下，银行根据与用户个人签订的合同管理个人数据，并根据个人的指示或预先指定的条件向第三方提供数据。\n\n\nData Plaza:\n定义: 由富士通公司在2013年4月建立，旨在为客户提供一个互通有无、促进合作创新的平台，打破数据孤岛，使不同领域的客户能够安全、高效地共享信息。\n分类: Data Plaza可以归类为“数据的流通、开发利用”基础设施，因为它不仅促进了数据的流通，还提供了数据增值解决方案。\n\n\n数据使用权交易市场:\n定义: 这是一个以“数据使用权证书”作为数据交易标的的市场，将合法使用数据的权利证券化。\n\n\n个人号码制度:\n定义: 每位拥有日本在留卡的居民都将拥有一个12位数字的号码，用于多种行政和服务场合。\n\n\n数字厅:\n定义: 数字厅是日本政府为了推进数字化改革而设立的统一领导部门。\n\n\n地方公共团体信息系统标准化法:\n定义: 该法律旨在统一地方政府的信息系统，规定地方政府的信息系统应统一为国家指定的格式。\n\n\n\n\n\n2021年5月：数字厅设置法《数字厅设置法》 是日本为了推进行政数字化和改革而制定的一项重要法律。该法律确立了数字厅的组织结构、职责和运作方式。以下是《数字厅设置法》的一些关键点：\n\n成立时间: 2021年5月，日本国会通过了包括《数字厅设置法》在内的六部“数字改革关联法案”，并于2021年9月1日正式设立数字厅。\n\n目的: 数字厅的成立旨在加速日本的数字化改革，提高行政手续线上操作的便捷性，削减行政运营成本，并解决政府在数字化方面的滞后问题。\n\n组织结构: 数字厅由日本首相担任厅长，下设数字大臣负责具体事务。除数字大臣外，还有副大臣、大臣政务官以及数字总监等职位。\n\n人员构成: 数字厅的人员规模约为600人，其中包括约200名来自私营部门的数字化领域人才，体现了政府对民间专业人才的重视。\n\n职责: 数字厅负责统筹全国信息系统的管理，推进政府内部的数字化改革，实现从“数字化”到“数字治理”的质的提升。此外，数字厅还负责制定数字社会形成的基本政策和优先计划。\n\n权限: 数字厅拥有向其他中央政府部门发出业务修改等建议的权限，以促进不同政府部门间的标准化和互通化。\n\n目标: 数字厅的远期目标是“用智能手机在60秒内完成所有行政程序”，体现了日本政府对于提高行政效率的坚定决心。\n\n其他职责: 数字厅还负责推广“我的号码”系统，为所有居民提供身份证号码，这被视为改善公共数字服务的关键。\n\n\n《数字厅设置法》的制定和数字厅的成立标志着日本政府在数字化转型方面迈出了重要一步，展现了其推动国家治理现代化和提升公共服务效率的决心。\n2021年9月：数字厅的设立\n法律&#x2F;政策名称: 数字厅的设立\n概要介绍:  数字厅的成立旨在迅速且重点推进数字社会进程，统筹推进全国数字社会建设、数字化转型。\nIT方面技术战略的政府组织体制包括：\n由内阁的综合创新战略推进会议，负责政府内部调整及推进《综合创新战略》；\n内阁府的综合科学技术创新会议，汇总各部门的科学技术创新方面相关政策，实施综合调整；\n各省厅机构在各自管辖的产业和领域中，负责具体措施的制定和执行。\n\n\n\n2021年5月：地方公共团体信息系统标准法地方公共团体信息系统标准化法是日本为推进地方行政数字化和信息系统标准化而制定的法律。这项法律的目的是统一地方政府的信息系统，以促进数据互通和标准化。以下是关于该法律的一些关键点：\n\n统一信息系统: 该法律要求地方政府的信息系统应统一为国家指定的格式，以实现不同地方政府间的信息共享和系统互通。\n\n标准化对象: 标准化的对象包括儿童津贴、居民基本台帐、选举人名簿管理、固定资产税、个人居民税、法人居民税、轻型汽车税、就学、国民健康保险、国民年金、残疾人福利、后期高龄者医疗护理保险等。\n\n制定主体: 由中央政府负责制定地方公共团体信息系统标准化的基本方针；具体主管上述领域的负责人负责制定信息系统标准；首相和总务大臣负责制定数据协作、网络安全、云利用等各信息系统共通事项的标准。\n\n地方政府的义务: 地方政府必须在省厅规定的期限内使其信息系统达标，并努力在国家准备的“云活用”环境中活用信息系统。\n\n提高行政效率: 通过标准化，旨在提高行政手续线上操作的便捷性，削减行政运营成本，实现更高效的政府服务。\n\n促进数据共享: 该法律有助于打破数据孤岛，促进不同地方政府和中央政府之间数据的共享和利用。\n\n支持数字化改革: 作为数字改革关联六法的一部分，该法律支持日本政府推动的全面数字化改革，包括数字厅的设立和运作。\n\n\n地方公共团体信息系统标准化法是日本数字化转型战略的关键组成部分，它通过标准化措施，加强了地方政府信息系统的整合和互操作性，为建立一个更加高效和透明的行政体系奠定了基础。\n2）相关名词概念\n\n\n年份\n法规&#x2F;法律&#x2F;政策&#x2F;定义\n名词\n解释\n属于哪类的范围\n\n\n\n2021年\n数字社会形成基本法\n个人数据商店（Personal Data Store，PDS）\n个人数据商店代表用户管理其个人数据，并根据用户个人意愿将其提供给第三方。它允许用户控制自己的数据，并在第三方需要时提供数据，从而实现数据的有序流通及价值增值。\n个人\n\n\n2021年\n数字社会形成基本法\n数据银行\n数据银行模式下，银行根据与用户个人签订的合同管理个人数据，并根据个人的指示或预先指定的条件向第三方提供数据。\n政府\n\n\n2021年\n数字社会形成基本法\n政务数据GBiz平台、农业数据WAGRI平台、防灾信息SIP4D平台\n这些平台作为数据空间，促进不同领域数据的安全、可信、高效流通共享，属于数据流通的基础设施。\n政府\n\n\n2021年\n数字社会形成基本法\nData Plaza\n富士通公司2013年4月建立的数据交易机构，为客户提供互通有无、促进合作创新的平台，打破数据孤岛。\n企业\n\n\n2021年\n数字社会形成基本法\n数据使用权交易市场\n这个市场属于“数据的流通、开发利用”类别，因为它提供了一个平台，使得数据使用权可以像证券一样被交易和流通，从而促进了数据的开发利用。\n企业&#x2F;政府\n\n\n2021年\n数字社会形成基本法\n个人号码制度\n每位拥有日本在留卡的居民都将拥有一个12位数字的号码，用于多种行政和服务场合的制度。\n政府\n\n\n2021年\n数字厅设置法\n数字厅\n日本政府设立的统一领导部门，推进数字化改革，负责制定和推进相关政策。\n政府\n\n\n-\n《综合数据战略》的背景下\nDATA-EX\n建立一个数据协作平台，促进不同领域和不同行业的数据交换与利用，目标是连接各行业的特定数据平台，通过提供一个统一的数据交换环境，促进不同领域的数据交换和协作。\n日本数据社会联盟\n\n\n3）数据基础设施相关概念介绍\n\n\n年份\n法规&#x2F;法律&#x2F;政策&#x2F;定义\n名词\n解释\n属于哪类的范围\n属于哪种基础设施\n\n\n\n2021年\n数字社会形成基本法\n个人数据商店（Personal Data Store，PDS）\n个人数据商店代表用户管理其个人数据，并根据用户个人意愿将其提供给第三方。它允许用户控制自己的数据，并在第三方需要时提供数据，从而实现数据的有序流通及价值增值。\n个人\n数据的流通\n\n\n2021年\n数字社会形成基本法\n数据银行\n数据银行模式下，银行根据与用户个人签订的合同管理个人数据，并根据个人的指示或预先指定的条件向第三方提供数据。\n个人\n数据的供给\n\n\n2021年\n数字社会形成基本法\n政务数据GBiz平台、农业数据WAGRI平台、防灾信息SIP4D平台\n这些平台作为数据空间，促进不同领域数据的安全、可信、高效流通共享，属于数据流通的基础设施。\n政府\n数据的流通、供给\n\n\n2021年\n数字社会形成基本法\nData Plaza\n富士通公司2013年4月建立的数据交易机构，为客户提供互通有无、促进合作创新的平台，打破数据孤岛。\n企业\n数据的供给、流通\n\n\n2021年\n数字社会形成基本法\n数据使用权交易市场\n以“数据使用权证书”作为交易标的，将合法使用数据的权利证券化，激活数据交易流通的市场。\n企业&#x2F;政府\n数据的流通\n\n\n-\n《综合数据战略》的背景下\nDATA-EX\n建立一个数据协作平台，促进不同领域和不同行业的数据交换与利用，目标是连接各行业的特定数据平台，通过提供一个统一的数据交换环境，促进不同领域的数据交换和协作。\n日本数据社会联盟（政府）\n数据的流通\n\n\n","categories":["调研"],"tags":["基础设施","数据空间","数字化"]},{"title":"深入理解分布式系统（一）认识分布式系统","url":"/2024/06/24/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%EF%BC%88%E4%B8%80%EF%BC%89%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/","content":"认识分布式系统1.1 什么是分布式系统定义：\n分布式系统指的是由多台计算机组成的系统，这些计算机通过网络连接起来，协同工作以实现共同的目标。在分布式系统中，各个计算机之间相互独立，同时也需要协同工作来处理大量的数据和任务。分布式系统可以包括不同类型的计算机，包括服务器、台式机、移动设备等等。\n分布式系统的一个主要特点是其高度的可扩展性，可以随着需求增长而增加计算机的数量。分布式系统还具有高可靠性，因为即使其中一个计算机发生故障，系统也可以继续运行，不会因为单一点的故障而完全崩溃。分布式系统还可以提供更好的性能和更快的响应时间，因为可以将任务分配给多个计算机并行处理，而不是依靠单个计算机来处理所有任务。\n分布式系统的应用非常广泛，包括云计算、大数据处理、分布式数据库、分布式存储系统、分布式搜索引擎等等。\n1.2 为什么需要分布式系统分布式系统是由多个独立计算机组成的网络，这些计算机通过网络互相通信和协调，共同完成某些任务或提供某些服务。分布式系统之所以重要，是因为它可以带来以下几个好处：\n\n可靠性：分布式系统可以提高系统的可靠性，因为它可以在某个节点或多个节点发生故障的情况下继续工作。\n可扩展性：分布式系统可以通过增加计算机节点来扩展系统的处理能力，从而应对更大的工作负载。\n高性能：分布式系统可以将任务分割成多个子任务，并在多个节点上并行处理，从而提高系统的处理速度。\n负载均衡：分布式系统可以将负载分配到多个节点上，避免某个节点过度负载的情况发生，从而提高系统的稳定性和可用性。\n数据共享：分布式系统可以让不同节点之间共享数据，从而使得数据更容易被访问和处理。\n\n总之，分布式系统可以提高系统的可靠性、可扩展性、高性能和负载均衡能力，使得系统更加稳定和高效。因此，在大规模应用中，分布式系统已成为一种必要的技术手段。\n1.3 分布式系统的示例1.3.1 搜索引擎DNS是一个将IP地址和域名相互映射的分布式数据库，主要特点包括去中心化、可扩展性和健壮性。\n搜索引擎背后的分布式基础设施：\n\n一个全球化、巨大的多数据中心（一个中心上万台物理机）\n一个分布式文件系统（GFS）\n大规模结构化数据的存储系统（Bigtable）\n分布式锁服务(chubby)\n并行和分布式计算的编程模式（MapReduce）\n分布式数据库（Spanner）\n\n1.3.2 加密货币加密货币和分布式系统密不可分。事实上，加密货币的核心技术就是基于分布式系统。\n加密货币使用的是一种称为区块链的分布式账本技术。这种技术将账本数据分散存储在网络上的多个节点中，每个节点都有完整的账本副本，并通过加密算法进行验证和保护。这种分布式存储和验证方式使得区块链上的交易记录无法被篡改或删除，从而确保了加密货币的安全性和去中心化特点。\n此外，分布式系统还能够实现去中心化的交易和转账，以及实现智能合约等功能。智能合约是一种自动执行的计算机程序，可以自动化完成各种事务，例如支付、转账、投票等。\n(458条消息) 区块链技术必杀技之——智能合约_区块链智能合约_jeff-y的博客-CSDN博客\n总的来说，加密货币和分布式系统密切相关，加密货币的实现离不开分布式系统的技术支持，同时分布式系统也因为加密货币的需求而得到了广泛的应用和发展。\n加密货币中的区块链技术使用了Merkle Tree来实现快速验证交易的有效性。\nMerkle Tree是一种树状结构，它将数据分成小块并对这些块进行哈希运算。每个哈希值代表了它所对应数据块的内容。然后再将这些哈希值进行哈希，得到新的哈希值，称为父节点。父节点也可以再和其他父节点一起哈希，形成新的父节点，最终形成根节点。这个过程就像一棵树一样，因此被称为Merkle Tree。\n在加密货币的交易验证中，Merkle Tree被用来快速验证某个交易是否属于某个区块。每个区块中的所有交易数据被组织成Merkle Tree结构，根节点的哈希值被包含在区块头中。当其他节点需要验证某个交易是否属于该区块时，只需要验证该交易的哈希值与Merkle Tree中的对应哈希值是否匹配，如果匹配，则该交易有效，否则无效。\n通过Merkle Tree的结构，交易数据可以被高效地组织和验证，从而提高了加密货币系统的安全性和效率。\n1.4 分布式系统的挑战网络延迟问题，部分失效问题，时钟问题\n1.4.1 网络延迟问题分布式系统中的网络延迟是一个常见的问题，特别是在跨越不同的地理位置和数据中心时。网络延迟指的是从一个节点发送消息到另一个节点所需的时间。这个时间可以受到多种因素的影响，包括网络拓扑、带宽、传输协议和网络拥塞等。\n为了降低网络延迟，可以采取以下措施：\n\n网络拓扑优化：设计一个合理的网络拓扑，使得节点之间的距离尽可能短，减少网络传输所需的时间。\n协议选择优化：选择合适的协议，例如使用TCP&#x2F;IP协议时可以采用TCP快速打开（TCP Fast Open）协议来减少握手时间，或使用UDP协议来减少传输延迟。\n数据压缩优化：对需要传输的数据进行压缩，可以减少数据传输量，从而减少网络传输所需的时间。\n缓存优化：使用缓存技术可以减少对数据的重复访问，从而减少网络传输所需的时间。\n负载均衡优化：使用负载均衡技术可以将请求分散到多个节点上，减少单个节点的负载，从而减少网络传输所需的时间。\n\n综上所述，网络延迟是分布式系统中的一个重要问题，需要采取多种优化措施来降低延迟，提高系统的性能和可靠性。\n1.4.2 部分失效问题分布式系统中的部分失效问题是指在分布式系统中的某些节点或者服务发生故障或失效，而系统的其他部分仍然正常运行。这种情况下，分布式系统需要采取措施来保证系统的可用性和稳定性。\n以下是分布式系统中解决部分失效问题的一些常见方法：\n\n冗余备份：通过在分布式系统中增加冗余节点或服务来保证系统的可用性。当某些节点或服务失效时，冗余节点或服务可以接管其工作，从而保证系统的正常运行。\n负载均衡：将请求分散到多个节点上，可以减轻单个节点的负担，从而减少故障的发生概率。负载均衡也可以将请求转发到最近的可用节点上，提高系统的性能和可用性。\n异常检测和恢复：当某些节点或服务发生故障时，需要及时检测并采取恰当的措施进行恢复。这可以通过使用异常检测和恢复机制来实现，例如使用心跳检测机制来检测节点或服务是否存活。\n限流和熔断：当某些节点或服务的负载过高时，可以采用限流和熔断机制来保护系统免受过度负载的影响。限流机制可以控制流量的速率，熔断机制可以暂时关闭某些节点或服务，以防止它们的故障影响整个系统的正常运行。\n事务处理和回滚：当某些节点或服务发生故障时，可能会导致分布式事务失败。在这种情况下，需要采取事务处理和回滚机制来恢复故障，保证数据的一致性和可靠性。\n\n综上所述，分布式系统中的部分失效问题是一个常见的挑战，需要采取多种技术和机制来保证系统的可用性和稳定性。\n1.4.3 时钟问题分布式系统中的时钟问题是指由于系统中的节点位于不同的地理位置，所以节点的时钟存在偏差和不同步的问题。时钟偏差和不同步会导致分布式系统中的数据同步、事务处理和协议执行等方面出现问题，从而影响系统的正确性和可靠性。\n以下是分布式系统中解决时钟问题的一些常见方法：\n\n物理时钟同步：物理时钟同步是通过使用网络时间协议（NTP）或其他时钟同步协议来保证系统中的节点时钟保持同步。这可以减少节点之间的时钟偏差，从而提高系统的可靠性和正确性。\n逻辑时钟：逻辑时钟是一种基于事件顺序的时钟，可以用于跨越不同节点的事件顺序标记。例如，Lamport时钟和向量时钟可以记录事件的发生顺序，并通过比较时间戳来确定事件的先后关系。\n时钟漂移和修正：由于硬件时钟存在漂移，因此需要定期对时钟进行修正。例如，可以使用时间同步协议来校正时钟漂移，或者在节点之间进行时钟校准，从而减少时钟漂移的影响。\n时钟容忍度：时钟容忍度是指在分布式系统中接受的时钟误差范围。节点之间的时钟误差超出容忍度范围时，系统会采取相应的措施来避免时钟问题对系统产生不良影响。\n\n综上所述，时钟问题是分布式系统中的一个重要挑战，需要采取多种技术和机制来解决。物理时钟同步、逻辑时钟、时钟漂移和修正以及时钟容忍度等技术和机制可以用来解决时钟问题，提高系统的可靠性和正确性。\n","categories":["分布式系统"],"tags":["分布式系统","深入理解分布式系统"]},{"title":"深入理解分布式系统（七）案例研究","url":"/2024/06/26/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%EF%BC%88%E4%B8%83%EF%BC%89%E6%A1%88%E4%BE%8B%E7%A0%94%E7%A9%B6/","content":"案例研究7.1 分布式文件系统GFS\n(459条消息) 什么是簇：什么是卷_tianwailaibin的博客-CSDN博客\n【MIT 6.824】学习笔记 3: GFS - 知乎 (zhihu.com)\n\n7.2 分布式协调服务Zookeeper\n什么是ZooKeeper？ - 知乎 (zhihu.com)\nzookeeper原理详解 - 知乎 (zhihu.com)\n[Zookeeper纸上谈兵——Zookeeper与CAP原则-CSDN博客](https://blog.csdn.net/qq_38194699/article/details/109016025?ops_request_misc=%7B%22request%5Fid%22%3A%22171939403416800178545807%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&amp;request_id=171939403416800178545807&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-1-109016025-null-null.142^v100^pc_search_result_base8&amp;utm_term=Zookeeper纸上谈兵——Zookeeper与CAP原则_cap zookeeper_Amazing Coder的博客-CSDN博客]&amp;spm&#x3D;1018.2226.3001.4187)\n","categories":["分布式系统"],"tags":["分布式系统","深入理解分布式系统"]},{"title":"深入理解分布式系统（三）分布式系统基础","url":"/2024/06/26/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%EF%BC%88%E4%B8%89%EF%BC%89%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/","content":"分布式系统基础3.1 分区在分布式系统中，分区是指将数据分成若干个部分，分别存储在不同的节点上，以达到提高系统性能和可扩展性的目的。分区是分布式系统中数据管理的基础。\n在分区中，通常采用哈希算法对数据进行划分。具体来说，首先根据数据的某个属性进行哈希计算，得到一个哈希值，然后将这个哈希值映射到某个节点上，将对应的数据存储到这个节点上。通过这种方式，相同属性的数据会被分配到同一个节点上，从而提高数据访问的效率。\n分区可以带来以下好处：\n\n提高系统的可扩展性：由于数据被分割成多个部分，每个部分可以分别存储在不同的节点上，因此可以更容易地进行横向扩展，增加节点数量来提高系统的处理能力。\n提高系统的性能：由于相同属性的数据被分配到同一个节点上，因此可以更快地访问这些数据，从而提高系统的处理效率。\n提高系统的容错性：当某个节点发生故障时，只有该节点上的数据会受到影响，而其他节点上的数据仍然可以正常访问，从而提高了系统的容错性。\n\n但是，分区也会带来一些挑战和问题，如数据的一致性和分区策略的选择等。因此，在设计分布式系统时，需要仔细考虑分区策略和数据一致性等问题，以确保系统的正确性和稳定性。\n水平分区、垂直分区、列式数据库和行式数据库是关系型数据库的四种常见的数据分区和存储方式。\n\n水平分区\n\n水平分区是指将数据按照行进行切分，将每个分区的数据存储在不同的节点上。每个节点独立维护一个数据子集，这些数据子集之间相互独立。通常，水平分区的数据切分依据是数据的关键字或者某个属性，以便于查询时能够快速地定位数据。\n使用场景：水平分区通常适用于数据访问压力比较大的场景，如互联网应用、金融等领域，这些场景中需要高效的读写操作和数据访问。\n特点：水平分区的优点是能够将数据分散在多个节点上，减少单节点的压力，提高系统性能和可扩展性。缺点是需要考虑数据一致性的问题，当某个节点发生故障时，需要采取相应的措施保证数据的一致性。\n\n垂直分区\n\n垂直分区是指将数据按照列进行切分，将不同的列存储在不同的节点上。不同的节点维护不同的数据子集，但是数据之间存在关联关系。垂直分区的目的是将数据分开存储，减少节点之间的冗余数据。\n使用场景：垂直分区适用于需要对数据进行复杂查询和分析的场景，如数据仓库等。\n特点：垂直分区的优点是可以减少冗余数据，提高系统性能和存储效率，同时也能提高数据的安全性。缺点是可能会增加系统的复杂度，同时需要进行多表连接查询，对系统性能有一定影响。\n\n列式数据库\n\n列式数据库是指将数据按照列进行存储和访问的数据库系统。相比于传统的行式数据库，列式数据库更加适用于大规模数据的分析和查询，能够提供更高的查询效率和存储效率。列式数据库将每列数据存储在一个独立的文件或数据块中，这样可以避免读取不必要的数据，从而提高查询效率。\n使用场景：列式数据库适用于大规模数据的分析和查询，如数据仓库、在线分析处理等领域。\n特点：列式数据库的优点是查询效率高，存储效率高，能够快速响应复杂查询请求。缺点是更新效率相对较低，不适用于需要频繁进行更新操作的场景。\n\n行式数据库\n\n行式数据库是指将数据按照行进行存储和访问的数据库系统。行式数据库将同一行的数据存储在一起，这样能够提高数据的插入和更新效率。相比于列式数据库，行式数据库更适用于需要频繁进行更新操作的场景。\n使用场景：行式数据库适用于需要频繁进行更新操作的场景，如在线交易系统、客户关系管理等领域。\n特点：行式数据库的优点是支持高并发的写入操作，适用于需要频繁进行更新操作的场景。缺点是查询效率相对较低，尤其是对于大规模数据的查询，查询效率明显低于列式数据库。\n3.1.1 水平分区算法水平分区算法是指将数据按照某个属性值进行分区的一种算法。以下是几种常见的水平分区算法：\n\n范围分区\n\n范围分区是将数据按照某个属性值的范围进行分区的算法。例如，对于一个学生表，可以将学生按照年龄范围进行分区，比如0-10岁、11-20岁、21-30岁等等。\n\n哈希分区\n\n哈希分区是将数据按照某个属性值的哈希值进行分区的算法。例如，对于一个学生表，可以将学生按照学生编号进行哈希分区，将相同哈希值的学生存储在同一个分区中。\n\n轮询分区\n\n轮询分区是将数据按照一定的轮询方式进行分区的算法。例如，对于一个负载均衡系统，可以将请求按照轮询的方式分配给不同的服务器处理，以达到负载均衡的效果。\n以上算法只是水平分区的几种常见方法，实际应用中还可以根据具体的需求和数据特点进行适当的调整和优化。\n一致性哈希：\n一致性哈希（Consistent Hashing）是一种分布式哈希算法，它可以将数据和节点映射到同一个哈希环上，从而方便进行数据的分布式存储和访问。一致性哈希算法的核心思想是通过哈希函数将数据和节点映射到同一个环上，然后根据数据的哈希值在环上查找节点，从而实现分布式存储和访问。\n一致性哈希算法的优点是可以有效地解决节点的动态增加和删除问题。当新的节点加入系统时，只需要将它的哈希值插入到哈希环上，然后将相邻的数据重新映射到新节点上即可。当节点离开系统时，只需要将它的哈希值从哈希环上移除，然后将相邻的数据重新映射到其他节点上即可。\n另外，一致性哈希算法也可以有效地解决数据倾斜问题。由于哈希函数的随机性，一些节点可能会负责更多的数据，从而导致负载不均衡的问题。为了解决这个问题，一致性哈希算法引入了虚拟节点的概念，将每个物理节点映射到多个虚拟节点上，从而平衡节点的负载。\n总之，一致性哈希算法是一种简单有效的分布式哈希算法，可以在分布式系统中实现数据的高效分布式存储和访问。\n3.1.2 分区的挑战查询困难和事务\n3.2 复制  在分布式系统中，复制（Replication）是一种常见的技术，它将数据和计算资源复制到多个节点上。复制的好处包括：\n\n高可用性：如果一个节点失效，复制的数据和计算资源可以在其他节点上继续运行，保证系统的可用性。\n改善性能：通过将数据和计算资源复制到多个节点上，可以减少网络延迟和瓶颈，提高系统的响应速度和吞吐量。\n容错性：复制可以提高系统的容错性，即使某个节点发生故障，也可以在其他节点上继续运行，从而保障数据的完整性和可用性。\n提高可扩展性：复制可以提高系统的可扩展性，因为复制的数据和计算资源可以在不同的节点上进行并行处理，从而提高系统的处理能力。\n\n需要注意的是，复制也会带来一些负面影响，例如增加系统的复杂度和维护成本，以及可能导致数据一致性的问题。因此，在使用复制技术时，需要仔细考虑各种因素，并根据具体情况进行权衡。\n3.2.1 单主复制单主复制是指在分布式系统中，只有一个节点拥有写入权限，其他节点只能进行读取操作，并且该节点负责将写入的数据复制到其他节点上。单主复制的好处包括：\n\n简单易用：单主复制相对于其他复制方案来说比较简单，易于实现和维护。\n数据一致性：由于只有一个节点拥有写入权限，所以数据的一致性相对较容易维护，可以避免多个节点同时对同一数据进行写入操作导致的数据不一致问题。\n安全性：单主复制可以避免多个节点同时写入数据可能导致的数据冲突问题，从而保证数据的安全性。\n\n需要注意的是，单主复制也有一些缺点，例如：\n\n单点故障：由于只有一个节点拥有写入权限，如果该节点发生故障，整个系统将不可用。\n性能瓶颈：由于所有的写入操作都要经过单个节点，可能会成为性能瓶颈，限制了系统的扩展性和吞吐量。\n可用性问题：如果节点之间的网络连接出现问题，可能会导致数据无法及时复制到其他节点，从而影响系统的可用性。\n\n因此，在使用单主复制技术时，需要仔细考虑各种因素，并根据具体情况进行权衡。\n在单主复制中，可以进一步分为以下两种类型：\n\n主从复制（Master-Slave Replication）：在主从复制中，只有一个节点（主节点）拥有写入权限，其他节点（从节点）只能进行读取操作，并且主节点负责将写入的数据复制到从节点上。主节点的写入操作会被异步地复制到从节点上，从节点的数据与主节点可能存在一定的延迟，但从节点的数据最终会与主节点保持一致。主从复制可以提供高可用性和数据一致性，并且相对简单易用。\n主备复制（Master-Standby Replication）：在主备复制中，也只有一个节点（主节点）拥有写入权限，其他节点（备节点）只能进行读取操作，并且备节点与主节点之间的数据同步是实时的。当主节点发生故障时，备节点会接管主节点的功能，成为新的主节点，从而保证系统的高可用性。主备复制相对于主从复制来说，可用性更高，但是实现和维护的复杂度更高。\n\n脑裂：\n脑裂（Split-Brain）是指在分布式系统中，由于网络分区或者其他原因，导致系统中的节点失去联系，无法进行通信，进而导致系统出现数据不一致或者操作冲突的问题。\n当出现网络分区时，系统中的节点可能会被分为两个或者多个独立的部分，每个部分都认为自己是整个系统的唯一部分，而且可能会独立地进行写入操作，导致数据不一致的问题。这种情况被称为脑裂。\n脑裂可能会导致系统数据的不一致性，从而影响系统的正确性和可用性。为了避免脑裂的发生，可以采取以下措施：\n\n使用复制技术：通过将数据和计算资源复制到多个节点上，可以提高系统的可用性和容错性，减少脑裂的可能性。\n使用投票机制：在系统中使用投票机制，可以避免脑裂的发生。例如，在主从复制中，主节点可以将写入操作同步到多个从节点上，然后通过投票机制来确定哪个从节点应该成为新的主节点，从而避免脑裂的发生。\n限制节点的数量：在分布式系统中，可以限制节点的数量，从而减少系统的复杂度和容错难度，降低脑裂的风险。\n监控系统状态：对系统状态进行监控，及时发现和解决潜在的问题，可以有效地避免脑裂的发生。\n\n需要注意的是，虽然可以通过上述措施来减少脑裂的风险，但是完全避免脑裂是非常困难的，因此需要在设计和实现分布式系统时充分考虑脑裂的风险，并制定相应的应对策略。\n3.2.2 多主复制在分布式系统中，多主复制（Multi-Master Replication）是指多个节点拥有写入权限，并且可以同时进行写入操作的一种复制方式。每个节点都可以独立地进行写入操作，写入的数据会被异步地复制到其他节点上，从而实现数据的复制和同步。\n多主复制相对于单主复制来说，具有以下几个优点：\n\n高并发性：多主复制允许多个节点同时进行写入操作，可以提高系统的并发性和吞吐量，从而满足高并发场景下的需求。\n高可用性：多主复制允许多个节点同时拥有写入权限，当某个节点出现故障时，其他节点可以继续进行写入操作，从而保证系统的高可用性和容错性。\n灵活性：多主复制可以根据实际需求进行灵活配置，可以在多个节点之间平衡负载，提高系统的稳定性和可靠性。\n\n但是，多主复制也存在一些挑战和限制：\n\n冲突问题：当多个节点同时进行写入操作时，可能会发生数据冲突的问题，需要采取相应的冲突解决策略来避免数据不一致的问题。\n一致性问题：多主复制需要保证节点之间数据的一致性，需要使用相应的协调机制来保证数据的正确性和一致性。\n实现和维护的复杂度：多主复制的实现和维护相对复杂，需要考虑节点之间的同步和冲突解决等问题，增加了系统的复杂度和维护难度。\n\n需要注意的是，在设计和实现多主复制时，需要综合考虑系统的性能、可用性和一致性等方面的需求，以及各种冲突解决和协调机制的复杂度和实现难度，从而选择最合适的复制方式。\n解决冲突：\n在多主复制中，当多个节点同时对同一个数据进行写入操作时，可能会发生冲突，从而导致数据的不一致性。为了避免冲突问题，可以采用以下几种解决办法：\n\n乐观锁机制：每个节点在进行写入操作前，先获取当前数据的版本号，并在写入时附带版本号信息。当其他节点进行写入时，会发现版本号不一致，从而引发冲突。此时，节点可以根据具体的策略进行相应的处理，例如选择最新的版本进行更新，或者放弃当前的写入操作等。\n\n悲观锁机制：每个节点在进行写入操作时，先尝试获取对应的锁，如果获取不到，则说明有其他节点正在进行写入操作，此时可以等待一段时间后再次尝试获取锁，或者放弃当前的写入操作。\n\n时序复制机制：在多主复制中，通过使用全局唯一的时间戳或序列号来协调多个节点之间的写入操作，从而避免冲突。每个节点在进行写入操作时，需要带上对应的时间戳或序列号，当其他节点接收到写入请求时，会根据时间戳或序列号来确定写入的先后顺序，从而保证数据的一致性。\n\n基于版本向量的机制：每个节点在进行写入操作时，不仅记录当前数据的版本号，还记录其他节点最近的版本号信息。当其他节点进行写入时，会将自己的版本号信息传递给其他节点，从而形成一个版本向量，用于判断不同节点之间的数据冲突和一致性。\n\n由客户端解决冲突\n\n“最后写入胜利”（Last Writer Wins，LWW）是一种常见的多主复制冲突解决策略。该策略的基本思想是，当多个节点对同一个数据进行写入时，以最后写入的节点为准，即后来的写入操作会覆盖之前的写入操作。\n具体实现时，每个节点在进行写入操作时，都会记录对应的时间戳或版本号，当其他节点收到写入请求时，会比较当前节点的时间戳或版本号和自身记录的时间戳或版本号，以此来判断哪个写入操作更晚，从而决定是否接受该写入请求。当发生冲突时，以最后写入的节点为准，更新数据。\n需要注意的是，LWW策略虽然简单易实现，但也存在一些潜在的问题，例如可能导致数据的丢失、数据的不一致性等。因此，在选择冲突解决策略时，需要根据具体的应用场景和需求进行综合考虑，权衡不同策略的优缺点。\n\n因果关系跟踪\n因果关系跟踪（Causal tracing）是一种在分布式系统中用于跟踪不同节点之间交互的技术。在分布式系统中，不同节点之间的交互往往是异步的，并且可能经过多个中间节点，因此需要一种机制来跟踪交互的因果关系，以便分析和调试系统的行为。\n因果关系跟踪通常基于事件模型，即将系统的行为抽象为一系列事件，并记录事件之间的因果关系。具体来说，当一个节点发送请求给另一个节点时，需要将请求的相关信息（例如请求ID、时间戳等）附加到请求中，并在接收到响应时将响应的相关信息（例如响应ID、时间戳等）附加到响应中。这样，每个事件就可以通过相关的信息与之前和之后的事件建立因果关系。\n通过因果关系跟踪，可以实现分布式系统中的故障定位、性能调优、容错处理等功能。例如，在进行故障定位时，可以根据事件之间的因果关系，追溯出故障的来源；在进行性能调优时，可以通过分析事件之间的时间关系，找出系统中的瓶颈和优化空间；在进行容错处理时，可以根据因果关系判断不同节点之间的依赖关系，从而决定如何进行容错处理。\n目前，因果关系跟踪已经成为分布式系统中的一个重要组成部分，并且在开源工具和云服务平台中得到了广泛应用，例如OpenTelemetry、Zipkin、Jaeger等。\n\n\n需要注意的是，不同的解决办法适用于不同的场景和需求，选择合适的冲突解决策略需要综合考虑多方面的因素，包括系统的性能、可靠性、一致性和复杂度等。\n3.2.3 无主复制无主复制（Masterless replication）是一种分布式系统中常见的数据复制策略，与单主复制和多主复制不同，无主复制不需要指定特定的节点作为主节点，而是让所有节点都能够读取和写入数据。具体来说，无主复制通常采用以下两种方式实现：\n\n基于副本集：无主复制可以基于副本集实现，即将数据复制到多个节点上，并保证每个节点上的数据副本是一致的。当进行写入操作时，所有节点都可以接受写入请求，并将写入操作广播给其他节点进行更新。当进行读取操作时，每个节点都可以从自己本地的数据副本中读取数据。\n基于分片：无主复制也可以基于分片实现，即将数据划分为多个分片，并将每个分片复制到多个节点上。当进行写入操作时，只需要将写入操作发送给对应的分片所在的节点，并更新该节点上的数据副本。当进行读取操作时，只需要根据读取请求所涉及的分片，从对应的节点中读取数据。\n\n无主复制相比于单主复制和多主复制，具有更好的可伸缩性和容错性，因为每个节点都可以独立地接受读写请求，并且可以通过增加节点数目来提高系统的容错能力和吞吐量。但同时，无主复制也需要考虑数据一致性和冲突解决等问题，例如如何解决并发写入操作导致的冲突，如何保证数据的一致性等。\nDynamo架构中的两种数据修复方法：\n\n读修复（Read repair）：读修复是一种在读取数据时自动修复损坏或不一致数据的技术。在分布式系统中，由于数据副本之间可能存在网络分区或写冲突等问题，导致某些节点上的数据副本可能已经过期或损坏。当客户端从一个节点读取数据时，如果发现该节点上的数据副本已经过期或与其他节点上的副本不一致，该节点会尝试从其他节点中读取最新的数据，并将其与自己的数据副本进行比较和合并，从而实现数据的修复。\n\n反熵过程（Anti-entropy）：反熵过程是一种定期检查和修复数据不一致问题的技术。在分布式系统中，由于网络故障或其他原因，不同节点上的数据副本可能会出现不一致的情况，为了解决这个问题，系统可以定期启动反熵过程来检查和修复数据不一致。具体来说，反熵过程会周期性地比较不同节点之间的数据副本，将不同的数据副本进行合并，从而实现数据的一致性。\n反熵过程通常会使用Merkle树来检测和修复数据不一致问题。\nMerkle树是一种树形结构，它可以用来验证分布式系统中的数据一致性。在Merkle树中，每个叶子节点都是数据块的哈希值，每个非叶子节点都是其子节点哈希值的哈希值。通过比较不同节点之间的Merkle树，可以快速检测数据不一致的位置，并将不同的数据块进行合并。\n在反熵过程中，系统会对不同节点之间的Merkle树进行比较，检测不一致的位置，并将不同的数据块进行合并。具体来说，反熵过程会周期性地对所有节点的Merkle树进行比较，如果发现两个节点的Merkle树有不一致的位置，系统会将不同的数据块进行合并，并更新相应的节点。\n使用Merkle树来进行反熵过程有以下优点：\n\n高效性：Merkle树具有高效的验证和合并性能，可以快速检测和修复数据不一致问题。\n安全性：Merkle树可以有效地保护数据的安全性，因为如果任何一个节点的数据发生了改变，其对应的哈希值也会发生改变，从而导致整个Merkle树的哈希值发生改变。\n\n因此，Merkle树是反熵过程中常用的技术之一，可以有效地检测和修复分布式系统中的数据不一致问题。\n\n\nQuorum的数据冗余机制：\nQuorum是一种基于Raft协议的分布式一致性算法，它允许在一个集群中同时运行多个副本来提高系统的可靠性和容错性。在Quorum中，数据冗余机制通常通过副本集群来实现。\n具体来说，Quorum通过将数据复制到多个节点来实现数据冗余。在一个Quorum集群中，通常会有多个节点运行相同的应用程序，每个节点上都有一个或多个副本存储相同的数据。这些副本可以保证在节点故障或网络故障时，数据仍然可用。\nQuorum的数据冗余机制具有以下特点：\n\n多副本：每个节点上通常会运行多个副本，确保数据的可靠性和容错性。\n复制同步：Quorum使用Raft协议来保证多个副本之间的数据同步，确保每个副本都存储相同的数据。\n副本数量：Quorum要求在集群中至少有一半以上的节点存储相同的数据，这样可以确保在一定程度上抵御节点故障和网络故障。\n容错性：Quorum可以在节点故障或网络故障的情况下继续工作，确保数据的可用性。\n\n除了数据冗余机制，Quorum还支持其他一些功能，如数据复制和数据恢复。数据复制是指在集群中将数据从一个节点复制到另一个节点，以确保数据的可靠性和容错性。数据恢复是指在节点故障或网络故障的情况下，将数据从备份节点恢复到故障节点，以确保数据的可用性。这些功能都可以提高Quorum集群的可靠性和容错性。\nW&gt;N&#x2F;2\nW和R通常比N小（因为为了降低延迟）\n3.3 CAP定理CAP定理是指在一个分布式系统中，一致性（Consistency）、可用性（Availability）和分区容错性（Partition Tolerance）这三个特性无法同时满足，只能满足其中的两个。\n具体来说：\n\n一致性：所有节点在同一时刻看到的数据是相同的。\n可用性：客户端能够获得系统的响应，即使某些节点出现故障。\n分区容错性：即使网络中断或节点故障，系统仍能继续运行。\n\nCAP定理的核心观点是，在分布式系统中，当网络分区发生时，系统必须要做出选择：是保证一致性还是可用性。由于分布式系统不可避免地会发生网络分区，因此系统必须要容忍分区，否则会导致系统的不可用性。因此，CAP定理的实质是，在网络分区发生时，系统必须要在一致性和可用性之间做出取舍。\n需要注意的是，CAP定理中提到的一致性和可用性是指强一致性和高可用性，而不是最终一致性和可接受的可用性。最终一致性是指在一定时间内，系统最终会达到一致的状态；而可接受的可用性是指系统可以在一定时间内保证响应客户端的请求，但可能不是实时的。\nCAP定理是分布式系统设计和实现的基础原则之一，它提醒我们在设计分布式系统时要充分考虑系统的一致性、可用性和分区容错性之间的关系，并根据具体需求进行取舍。\n在网络分区发生时，分布式系统可能无法同时满足高可用性和强一致性，但是可以通过实现最终一致性来保证系统的可用性，并在一定时间内达到一致的状态。同时，如果系统对一致性要求不是非常高，也可以采用可接受的可用性来满足系统的需求。\n需要注意的是，最终一致性并不是一个具体的算法或协议，而是一种设计思想或范式。不同的分布式系统可以采用不同的最终一致性策略，例如基于版本的控制、基于时间戳的控制、基于向量时钟的控制等，来保证数据在不同节点之间的最终一致性。\n意义：\n\n系统开发需要取舍！不存在完美的系统！\nCP\nAP\n\n3.3.1 PACELC定理分布式理论 PACELC 了解么？ - 知乎 (zhihu.com)\nPACELC定理是指，在分布式系统中，一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance）三者不可同时兼备，只能选择其中的两项。\nPACELC定理是基于CAP定理发展而来的。CAP定理指出，在一个分布式系统中，Consistency（一致性）、Availability（可用性）、Partition tolerance（分区容错性）这三个因素不可同时保证。在分布式系统出现网络分区时，必须选择放弃一致性还是可用性中的一项，以保证系统的可靠性。\nPACELC定理是对CAP定理的进一步扩展和细化，将一致性进一步划分为了强一致性（Strong Consistency）和弱一致性（Weak Consistency），并在此基础上提出了三种情况：当出现网络分区时，系统只能保证两项中的其中之一，而具体保证哪两项则取决于分布式系统的设计和应用场景。\n具体来说，PACELC定理认为，在分布式系统中，当发生网络分区时，可以选择以下三种策略：\n\n保证分区容错性和强一致性，放弃可用性（PA&#x2F;EC）：这种情况下，系统会在网络分区发生时，停止接受请求，以保证数据的一致性。\n保证分区容错性和可用性，放弃强一致性（PA&#x2F;EL）：这种情况下，系统会允许不同节点的数据出现短时间的不一致，以保证系统的可用性。\n保证可用性和强一致性，放弃分区容错性（CA&#x2F;EL）：这种情况下，系统会在网络分区发生时，仍然继续接受请求，但可能会导致节点之间的数据不一致，以保证系统的可用性和数据的一致性。\n\n在实际应用中，选择哪种策略取决于具体的应用场景和需求，需要根据系统的性能要求、可用性要求、数据一致性要求以及成本等因素进行权衡和选择。\n3.3.2 BASE在分布式系统的上下文中，BASE 是 “Basically Available, Soft state, Eventually consistent” 的缩写。这是一组原则，可用于设计和实现分布式系统，优先考虑可用性和分区容忍性，而不是强一致性。\nBasically Available 指的是分布式系统应始终能够响应客户端请求，即使系统遇到故障或网络分区。Soft state 指的是系统状态随时间变化的想法，只要变化不是关键的，系统最终能够收敛到一致的状态，就是可接受的。Eventually consistent 指的是在足够的时间和适当的同步下，系统最终会在所有节点上变得一致。\n与优先考虑强一致性的 ACID（原子性，一致性，隔离性，持久性）原则不同，BASE 是一种更为松散的方法，可以在分布式系统中实现更高的可用性和可伸缩性，但代价是一些一致性上的权衡。\n3.4 一致性模型一致性模型是指在分布式计算中，确保多个节点之间数据的一致性和可靠性的模型。在分布式系统中，节点可能会同时读取和写入共享数据，因此必须确保在所有节点上数据的状态是一致的。\n常见的一致性模型包括：\n\n强一致性模型（线性一致性）：在任何时候，所有节点都能够读取到相同的数据。强一致性模型可以保证数据的完全一致性，但可能会影响系统的性能。\n弱一致性模型：在任何时候，不同节点读取到的数据可能会不一样。弱一致性模型通常可以提高系统的性能，但需要更复杂的算法来确保数据的一致性。\n最终一致性模型：在一定时间内，所有节点最终都能够读取到相同的数据。最终一致性模型通常是弱一致性模型和强一致性模型之间的一种妥协方案。\n\n一致性模型的选择取决于系统的需求和设计目标，需要综合考虑系统的性能、可靠性、一致性和可扩展性等方面。\n3.4.1 线性一致性模型线性一致性模型是一种强一致性模型，它保证在分布式系统中所有节点读取到的数据是一致的，即如果一个节点在时间轴上比另一个节点先写入数据，则先写入的数据一定先于后写入的数据被读取到。线性一致性模型是对强一致性模型的一种加强形式，它要求所有节点读取到的数据的顺序与它们写入的顺序一致，即数据的全局顺序与它们的时间戳有关。\n线性一致性模型的实现通常需要使用一些特殊的算法和技术，例如基于向量时钟（vector clock）的数据版本控制机制、分布式锁机制等。这些技术可以确保所有节点读取到的数据的顺序是一致的，同时还可以保证系统的性能和可扩展性。\n线性一致性模型通常用于需要强一致性保证的分布式应用，例如金融交易系统、在线游戏等。\n向量时钟：\n向量时钟是一种用于分布式系统中维护事件顺序的数据结构。它可以帮助分布式系统中的不同节点确定事件的先后顺序，并保证在不同节点中的时间戳的一致性。\n向量时钟的基本思想是：每个节点都维护一个向量，向量的长度等于节点的数量，每个节点的向量元素表示该节点上的事件数目。当节点上发生一个事件时，它会将该节点的向量元素加1，并将整个向量发送给其它节点。接收到向量后，节点会将它的本地向量与接收到的向量进行合并，并更新本地向量的元素值，以反映出其它节点上发生的事件情况。这样，每个节点都可以通过比较向量来判断事件的先后顺序。\n具体来说，如果向量V和W都是节点数为N的向量时钟，则V &lt;&#x3D; W的含义是V中的每个元素都小于等于W中对应元素。如果V &lt;&#x3D; W并且W &lt;&#x3D; V，则V和W是相等的。当向量V和W不相等时，就可以根据它们的比较结果来判断事件的先后顺序。\n向量时钟通常用于实现一些需要维护事件顺序的分布式应用，例如分布式数据库系统、分布式文件系统、分布式共识算法等。\n分布式锁：\n分布式锁是一种在分布式系统中实现互斥访问的机制，它可以帮助不同节点之间协调并发操作，避免出现冲突和竞争条件。\n在分布式系统中，多个节点可能同时访问共享资源，例如数据库、文件系统等。为了避免多个节点同时修改同一份数据，需要使用分布式锁来保证资源的互斥访问。当一个节点想要访问共享资源时，它需要先获取一个分布式锁，确保其他节点不能同时访问该资源。当节点完成操作后，需要释放锁，以允许其他节点继续访问资源。\n实现分布式锁的方法有很多种，其中比较常见的包括：\n\n基于数据库实现的分布式锁：将锁状态保存在数据库中，节点需要先获取数据库的一个排他锁，才能对锁进行操作。\n基于ZooKeeper实现的分布式锁：利用ZooKeeper提供的原子操作和临时节点机制，实现分布式锁。\n基于Redis实现的分布式锁：利用Redis提供的SETNX命令和expire命令，实现分布式锁。\n\n需要注意的是，在使用分布式锁时，需要考虑锁的粒度和性能等问题。如果锁的粒度过大，可能会导致锁竞争和性能瓶颈；如果锁的粒度过小，可能会导致锁冲突和死锁等问题。因此，在实际应用中，需要根据具体情况选择合适的锁粒度，并进行性能测试和优化。\n(459条消息) 什么是分布式锁？几种分布式锁分别是怎么实现的？_Java后端架构猛猛的博客-CSDN博客\n3.4.2 线性一致性的代价线性一致性通常需要付出较高的代价，因为要保证数据的全局顺序一致性，需要牺牲一定的可用性和延迟。\n在实现线性一致性时，需要考虑以下几个方面的代价：\n\n通信代价：为了保证数据的一致性，需要不断进行节点间的通信和同步操作，这会增加网络带宽的使用和延迟。\n吞吐量代价：由于要对所有的操作进行全局排序，需要在整个系统范围内协调所有节点的操作，这会对系统的吞吐量产生影响。\n可用性代价：在实现线性一致性时，如果某个节点发生故障，会影响整个系统的可用性。因此，在实现线性一致性时，需要采取一些机制来保证故障时的容错和恢复能力。\n性能代价：由于要保证全局顺序一致性，系统可能需要进行多轮操作和协调，这会增加系统的延迟和响应时间。\n\n因此，在实际应用中，需要根据具体需求和场景，综合考虑各种代价，选择合适的一致性模型和实现方式，以达到最优的性能和可用性。\n3.4.3 顺序一致性顺序一致性是一种弱一致性模型，它要求系统的操作按照提交的顺序执行，但不要求所有节点都看到相同的执行顺序。\n具体来说，对于任意两个操作，如果它们在一个节点上执行并且提交的顺序是相同的，则在所有节点上的执行顺序必须保持一致。但是，如果两个操作在不同节点上执行，则可能存在不同的执行顺序，即存在并发执行的可能性。因此，顺序一致性保证了操作的有序性，但是不保证全局的一致性。\n在实现顺序一致性时，系统可以采用一些机制来保证操作的有序性，例如对操作进行时间戳或序列号标记，或者采用基于向量时钟的算法来实现。\n相对于线性一致性来说，顺序一致性的代价较低，因为它不需要保证所有节点都看到相同的执行顺序。因此，顺序一致性通常用于一些对一致性要求不是特别高的场景，例如社交网络应用、在线游戏等。\n3.4.4 因果一致性（微信朋友圈）因果一致性是一种弱一致性模型，它要求系统的操作按照因果关系执行，即如果一个操作A在另一个操作B之前发生，那么操作B在所有节点上的执行必须在操作A之后。这意味着，因果一致性可以保证操作的有序性和因果关系，但不要求所有节点都看到相同的执行顺序。\n具体来说，因果一致性要求系统中的所有节点都按照相同的因果顺序执行操作。在实现因果一致性时，通常采用向量时钟或其他类似的机制来维护操作的因果关系。\n因果一致性相对于线性一致性和顺序一致性来说，代价更低，因为它不需要对所有操作进行全局排序，只需要保证操作的因果关系即可。因此，因果一致性通常用于一些对一致性要求不是特别高的场景，例如分布式日志系统、分布式数据库等。\n值得注意的是，因果一致性仅仅保证了操作的因果关系和有序性，而不保证操作的结果和值。因此，在使用因果一致性时，需要考虑数据一致性和可用性等方面的问题。\n3.4.5 最终一致性（搜索引擎、社交网络）最终一致性是一种弱一致性模型，它允许系统中的不同节点在一段时间内保持数据的不一致性，但最终会达到一致的状态。这意味着，当系统中存在多个副本时，这些副本在某个时间点上的状态可能不同，但经过一段时间的同步和协调后，最终会达到一致的状态。\n在实现最终一致性时，通常采用异步复制或延迟复制的方式，即不要求所有节点在短时间内达到一致的状态，而是允许节点在本地更新数据，并在后续的时间点上将更新的数据同步到其他节点。这样做可以提高系统的可用性和性能，并减少系统之间的通信负担。\n最终一致性适用于一些对数据一致性要求不是特别高的场景，例如搜索引擎、社交网络等。但是，最终一致性也存在一些问题，例如数据冲突和合并、数据同步的延迟等，需要在实际应用中进行适当的处理和解决。\n3.4.6 以客户端为中心的一致性模型 以客户端为中心的一致性模型是一种应用程序在客户端上维护数据一致性的模型。在这个模型中，客户端负责维护数据的一致性，而不是依赖于分布式系统来维护数据的一致性。\n具体来说，以客户端为中心的一致性模型通常采用乐观并发控制的策略。在这个策略中，客户端通过在本地缓存中保存数据副本来维护数据的一致性，并在修改数据时对缓存中的数据进行验证。如果数据未被其他客户端修改，则客户端可以直接提交修改。否则，客户端需要处理数据冲突，并根据一些策略来解决冲突。\n以客户端为中心的一致性模型适用于一些对一致性要求不是特别高的场景，例如移动应用、离线应用等。这种模型具有良好的可用性和性能，因为客户端可以通过本地缓存快速读写数据，而不必依赖于分布式系统进行通信。但是，它也存在一些问题，例如数据冲突和合并、数据同步的延迟等，需要在实际应用中进行适当的处理和解决。\n单调读（Monotonic Reads）和单调写（Monotonic Writes）是指一个线程对于一个特定变量的读操作或写操作，必须按照执行顺序，按照先后顺序看到最近的操作结果。\n例如，如果线程A先写入变量x，然后线程B读取变量x，那么线程B必须看到线程A的写入结果，而不是之前的旧值。\n读你所写（Read Your Writes，RYW）是指一个线程对于一个特定变量的读操作，必须在它自己的最近的写操作之后进行。这个特性在分布式系统中非常重要，因为它可以保证一个线程在写入某个变量之后，能够看到它自己的写入结果，而不是其他线程的旧值。\nPRAM（Parallel Random Access Machine）是一种并行计算模型，它描述了一种在共享内存并行计算机上进行并行计算的方式。PRAM模型中，所有处理器共享一个全局内存，并且可以在O(1)时间内进行读写操作。\n在PRAM模型中，单调读、单调写和读你所写是非常重要的一些性质，因为它们可以保证在并行计算中不会发生数据冲突和数据不一致的问题，从而保证并行计算的正确性和性能。\n3.5 隔离级别隔离级别是指在数据库事务中不同事务之间对数据的读写所采用的不同的隔离策略。常见的隔离级别有四种：读未提交、读已提交、可重复读和串行化。\n\n读未提交（Read Uncommitted）：最低的隔离级别，允许一个事务读取另一个事务未提交的数据，可能导致脏读、不可重复读、幻读等问题。\n读已提交（Read Committed）：在一个事务中，读取数据时只能读取已经提交的数据，可以避免脏读问题，但是可能会出现不可重复读和幻读问题。\n可重复读（Repeatable Read）：保证一个事务在多次读取同一数据时，能够看到同样的数据，即同一事务内多次查询结果集相同。但是，其他事务可以向该数据表中插入新的数据，导致幻读问题。\n串行化（Serializable）：最高的隔离级别，完全隔离每个事务，事务只能一个接一个地执行，避免了所有并发问题，但是效率较低。\n\n不同的隔离级别在事务处理中的性能和正确性上有不同的影响，需要根据具体的业务需求进行选择。一般来说，读已提交和可重复读是应用比较广泛的隔离级别。\n3.6 一致性和隔离级别的对比线性一致性和串行化都是数据库中保证事务正确性的机制，但是它们有不同的实现方式和应用场景。\n线性一致性（Linearizability）是指，在分布式系统中，每个操作都有一个全局的先后顺序，该顺序满足原子性、顺序性、一致性和实时性的要求。也就是说，线性一致性保证了分布式系统中的操作顺序与单个系统中的操作顺序相同，而且保证了操作的原子性、一致性和实时性。线性一致性保证了分布式系统中的操作表现出和单个系统一样的行为，对于应用程序来说，感知不到分布式环境的存在。\n串行化（Serialization）是指，在多个事务并发访问同一份数据时，数据库系统会把这些事务串行执行，以保证数据的正确性。串行化可以消除脏读、不可重复读和幻读等问题，但是会降低并发性能。\n虽然线性一致性和串行化都能保证数据的正确性，但是它们的应用场景不同。线性一致性更适用于分布式环境下的系统，例如分布式缓存、分布式队列等。而串行化更适用于事务并发访问同一份数据时，需要严格控制并发执行顺序的场景，例如银行转账、订单处理等。\n需要注意的是，线性一致性和串行化都会影响数据库的并发性能，因此需要根据具体的业务需求和系统架构来选择适合的一致性控制机制，以保证系统的正确性和并发性能。\n","categories":["分布式系统"],"tags":["分布式系统","深入理解分布式系统"]},{"title":"深入理解分布式系统（二）分布式系统模型","url":"/2024/06/24/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%EF%BC%88%E4%BA%8C%EF%BC%89%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E6%A8%A1%E5%9E%8B/","content":"分布式系统模型2.1 两将军问题“两将军问题”是一个经典的分布式系统问题，旨在研究在存在故障节点的情况下如何协调两个进程之间的通信。\n问题场景是两个将军分别率领一支军队进攻敌方城市。两个将军之间必须达成一致，以确定进攻时间和策略。但是，将军们分别位于两个不同的营地，只能通过信使进行通信。此外，有可能存在恶劣的天气或其它因素干扰通信，或者其中一个将军的信使被敌人抓住并修改了消息。\n该问题的关键是如何确保将军之间的通信可靠，并避免消息的丢失和篡改。经典的解决方案是使用拜占庭将军问题中的拜占庭容错算法，该算法可以容忍部分节点的故障和恶意攻击。\n具体实现上，将军们需要达成共识，以决定进攻时间和策略。首先，每个将军向所有其他将军发送一个决策信息，并等待回复。如果将军收到的回复都是一致的，他就可以确定其他将军的决策，并做出相应的行动。如果将军收到的回复不一致，他会将这些信息再次发送给所有其他将军，直到收到一致的回复。\n在该问题中，每个将军需要知道有多少其他将军参与协调，并且需要容忍其他将军的可能失败和恶意行为。这需要设计合适的算法和协议来保证将军之间的协作和共识。\n总之，“两将军问题”是一个经典的分布式系统问题，它探讨了如何在分布式系统中实现可靠通信和共识协作的问题。拜占庭容错算法提供了一种解决方案，可以容忍部分节点的故障和恶意攻击，从而确保将军之间的通信可靠性和一致性。\nTCP三次握手与其的关系\nTCP三次握手是一种建立TCP连接的过程，包括客户端发送SYN报文，服务器回复SYN+ACK报文，最后客户端回复ACK报文，建立连接。\n在分布式系统中，TCP三次握手是实现可靠通信的重要手段。它确保了客户端和服务器之间的连接在建立时具有可靠性和稳定性。通过三次握手，客户端和服务器可以确保对方已经准备好进行通信，同时也可以在连接建立之前进行一些必要的信息交换和验证，如协商连接参数和检查连接的有效性等。\n在分布式系统中，TCP三次握手也可以用于解决“两将军问题”，确保两个进程之间的通信可靠和一致。类似于TCP三次握手，两个进程可以通过发送和确认消息来建立连接，并在建立连接之前进行必要的验证和信息交换，以确保连接的可靠性和有效性。\n总之，TCP三次握手是分布式系统中实现可靠通信的重要手段，它可以确保连接的可靠性和有效性，同时也可以应用于解决其他类似的分布式系统问题，如“两将军问题”。\n2.2 拜占庭将军问题拜占庭将军问题（Byzantine Generals Problem）是分布式系统中的一个经典问题，涉及到在存在故障或恶意行为的情况下，如何进行分布式决策。\n问题场景是，在拜占庭帝国，几个将军率领各自的部队围攻敌人。他们必须就进攻或撤退达成一致的决策，但是将军之间只能通过消息传递进行通信。然而，有可能存在一些叛变的将军，他们会传递虚假信息，导致其他将军做出错误的决策。\n在这种情况下，如何确保将军们可以就正确的进攻或撤退做出决策，即使有些将军叛变或发生故障。\n拜占庭将军问题的解决方案是拜占庭容错算法（Byzantine Fault Tolerance Algorithm）。该算法可以容忍部分节点的故障和恶意攻击，从而确保分布式系统在存在故障或恶意行为的情况下仍然能够正确地工作。\n具体实现上，拜占庭容错算法需要将每个将军看作一个节点，将节点之间的通信看作消息传递。每个将军必须向其他将军发送自己的决策信息，并根据接收到的消息来做出最终的决策。\n在算法中，每个将军必须决定一个信任阈值（trust threshold），即可以容忍多少个叛变节点。如果叛变节点的数量超过信任阈值，则将军不再相信这些节点传递的信息。每个将军都需要向其他将军发送自己的决策信息，并在接收到足够数量的信息后，根据这些信息来做出最终的决策。\n拜占庭容错算法提供了一种解决分布式系统中存在故障或恶意行为的问题的方法，可以保证在一定程度上容忍节点的故障和恶意攻击，从而确保系统的可靠性和正确性。\n2.3 系统模型2.3.1 网络链路模型可靠链路、公平损失链路和任意链路是三种不同类型的链路模型，它们分别描述了网络链路的不同特性。\n\n可靠链路：指传输层提供的数据传输服务是可靠的，即数据包不会丢失、重复、乱序等，而且保证数据传输的正确性。这种链路通常用于需要可靠传输的应用，例如文件传输、电子邮件等。\n公平损失链路：指传输层提供的数据传输服务是不可靠的，即数据包可能会丢失、重复、乱序等，但是丢失的概率是公平的，即每个数据包有相同的丢失概率。这种链路通常用于需要低延迟和高吞吐量的应用，例如视频流和音频流。\n任意链路：指传输层提供的数据传输服务是不可靠的，数据包可能会丢失、重复、乱序等，并且丢失的概率也是不确定的。这种链路通常用于互联网等大规模、不可控的网络环境中。\n\n在实际应用中，不同的链路模型适用于不同的应用场景。例如，可靠链路适用于需要可靠传输的应用，公平损失链路适用于需要低延迟和高吞吐量的应用，任意链路则适用于大规模、不可控的网络环境。\n2.3.2 节点故障类型在分布式系统中，节点故障类型主要有以下几种：\n\n宕机故障：指节点因为硬件故障、软件故障等原因而停止工作，无法处理请求和发送响应。\n网络故障：指节点与网络中的其他节点失去了连接，无法正常通信。\n时钟偏差故障：指节点的本地时钟与其他节点的时钟存在偏差，导致节点无法准确判断事件的先后顺序。\n节点软件故障：指节点运行的软件出现了错误，导致节点无法正常处理请求和发送响应。\n节点配置故障：指节点的配置文件或者参数设置出现错误，导致节点无法正常工作。\n\n以上节点故障类型都可能对分布式系统的正常运行造成影响，因此在设计和实现分布式系统时需要考虑如何处理这些故障，提高系统的容错性和可靠性。常用的方法包括备份、冗余、检查点和恢复等。\n崩溃停止、崩溃恢复和拜占庭故障是分布式系统中常见的故障类型和处理方法。\n\n崩溃停止：指节点因为硬件故障、软件故障等原因而停止工作，无法处理请求和发送响应。在这种情况下，通常的做法是通过备份或者冗余机制来保证系统的可用性。\n崩溃恢复：指节点在崩溃之后能够恢复正常工作。在分布式系统中，崩溃恢复通常通过检查点和恢复机制实现。检查点是指在节点正常工作的过程中定期保存系统状态的快照，当节点崩溃之后，可以通过恢复最近一次的检查点来恢复系统状态。\n拜占庭故障：指节点在分布式系统中出现不可预测的错误或者故障，例如节点发送错误的消息、故意不发送消息、篡改消息等。这种故障在分布式系统中比较常见，因此需要采取特殊的处理方式。在拜占庭故障中，通常使用多数投票算法或者拜占庭容错算法来解决。多数投票算法是指节点之间通过投票来决定最终的结果，只有得到多数节点的认可才被认为是有效的。拜占庭容错算法则是一种更加复杂的算法，可以在少数节点出现故障或者恶意行为的情况下仍然保证系统的正确性。\n\n在实际应用中，分布式系统需要根据不同的故障类型和处理方式来设计和实现，提高系统的容错性和可靠性。\n2.3.3 按时间划分模型同步模型、异步模型和部分同步模型是分布式系统中常见的通信模型。\n\n同步模型：指进程之间的通信是基于同步的，即发送方发送消息后需要等待接收方确认收到消息后才能继续执行。这种模型具有简单、可靠、易于实现的优点，但同时也存在效率低、容易死锁等问题。\n异步模型：指进程之间的通信是基于异步的，即发送方发送消息后不需要等待接收方确认，可以直接继续执行。这种模型具有效率高、并行度高等优点，但同时也存在可靠性低、容易产生乱序等问题。\n部分同步模型：指进程之间的通信既包括同步模型的特点，又包括异步模型的特点。具体来说，部分同步模型中既存在同步消息，也存在异步消息。这种模型可以在保证可靠性的同时，又能充分发挥系统的并行性能，因此在分布式系统中得到广泛应用。\n\n在实际应用中，需要根据具体的场景来选择不同的通信模型。例如，在需要保证数据一致性和可靠性的场景中，可以选择同步模型或者部分同步模型；而在需要高效并行处理的场景中，可以选择异步模型或者部分同步模型。\n2.4 消息语义传递消息语义传递指的是在分布式系统中，如何确保消息的正确传递和语义的一致性。在分布式系统中，消息的传递是通过网络进行的，网络通信可能会受到各种因素的干扰和影响，例如网络延迟、丢包、重复等问题。因此，在消息的传递过程中需要保证消息的正确性和语义的一致性。\n在实际应用中，通常使用一些技术来保证消息的正确性和语义的一致性，例如：\n\n消息确认机制：发送方在发送消息后，需要等待接收方的确认消息，以确保消息被正确地接收。如果发送方在一定时间内没有收到确认消息，就会重新发送消息，以保证消息的可靠传递。\n消息重复检测：接收方在接收到消息后，会对消息进行唯一性检测，以避免重复处理消息，从而保证消息语义的一致性。\n事务机制：在涉及到多个操作的场景中，可以使用事务机制来保证操作的原子性、一致性和持久性。例如，数据库中的事务机制可以保证一组数据库操作要么全部执行成功，要么全部执行失败，从而确保数据的一致性和可靠性。\n消息序列化和反序列化：在消息的传递过程中，需要将消息转换成网络传输格式进行传输。因此，需要对消息进行序列化和反序列化，以保证消息的正确性和可靠性。\n\n综上所述，消息语义传递是分布式系统中非常重要的一环，需要采取各种技术手段来确保消息的正确性和语义的一致性，从而保证分布式系统的稳定运行。\n幂等性指的是在进行多次相同操作时，最终的结果与只执行一次操作时的结果是一致的。在分布式系统中，由于网络通信等因素的影响，可能会导致消息被重复传递，因此，需要考虑如何保证消息的幂等性。\n具体来说，消息幂等性通常可以通过以下几种方式来实现：\n\n去重：对于已经处理过的消息，可以进行去重操作，避免重复处理相同的消息。\n乐观锁：使用乐观锁机制可以避免多次修改同一资源导致的数据不一致问题。\n版本号：在对资源进行修改时，可以使用版本号来确保修改的原子性和一致性。\n业务逻辑实现：在实现业务逻辑时，可以通过设计合理的业务逻辑来确保多次执行相同操作时的结果是一致的。\n\n综上所述，消息语义和幂等性在分布式系统中都是非常重要的概念。消息语义保证了消息的正确性和语义的一致性，而幂等性则保证了操作的原子性和一致性，从而确保分布式系统的稳定运行。 \n","categories":["分布式系统"],"tags":["分布式系统","深入理解分布式系统"]},{"title":"深入理解分布式系统（五）分布式事务","url":"/2024/06/26/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%EF%BC%88%E4%BA%94%EF%BC%89%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/","content":"分布式事务5.1 什么是分布式事务ACID:\n\n原子性（Atomicity）：一个事务被视为一个不可分割的最小工作单位，事务中的所有操作要么全部完成，要么全部撤销回滚，不允许出现部分完成的情况。\n一致性（Consistency）：事务开始前和结束后，数据库必须处于一致的状态，即事务执行后所得的结果必须符合预期的规定的结构和约束条件。\n隔离性（Isolation）：多个事务相互隔离不受干扰，每个事务只能“看到”其所执行的数据和其他事务已提交的数据，而看不到其他事务未提交的数据。\n持久性（Durability）：一个事务提交后，它对数据库的改变必须被永久保存到数据库中，即使出现断电等故障，其对数据库的改变也不能丢失。\n\n分布式事务两种变体：\n\n同一份数据需要在多个副本上更新，一个分布式事务需要更新所有的副本，如果有的节点提交了事务，有的节点回滚了事务，那么这样的结果对于用户来说是无法接受的。（可利用单主复制解决）\n数据进行了分区，事务跨越多个节点，还要同时保证整体数据一致和事务的ACID属性。（常见且重点）\n\n分布式事务通常不讨论ACID中的一致性。\n想要实现持久性，只需在向客户端返回响应之前，确保将数据存储再非易失性存储设备即可，通常还会包括一些WAL或其他日志文件，虽然非易失性存储设备可能会损坏，但不考虑极端的情况，通过备份就可以解决该问题。、\n原子性：原子提交（Atomic Commit）\n隔离性：并发控制（Concurrency Control）(锁和MVCC)\n5.2 原子提交原子性的保证在分布式和单机系统中都很难。\n方法：日志&#x2F;WAL，可以回滚，撤销\n分布式的原子性的实现：\n\n原子提交协议（Atomic Commit Protocol）\n协定性：所有的都同意一个值，那么所有进程要么一起提交事务，要么一起终止事务\n有效性：如果所有进程都没问题，就提交，但凡有一个有问题，就终止\n终止性：\n弱终止条件：如果没有任何故障发生，那么所有进程最终都会作出决议\n强终止条件：没有发生故障的进程最终会做出决议\n\n\n\n\n\n5.2.1 两阶段提交协议\n(443条消息) 两阶段提交协议（two phase commit protocol，2PC）详解_两阶段协议_延迟满足的博客-CSDN博客\n两阶段协议存在的问题：\n\n同步阻塞问题\n单点故障问题\n数据不一致问题\n提交阶段不确定问题\n\n基于 2PC 存在的问题，后来有人提出了三阶段提交协议，在其中引入超时的机制，将阶段 1 分解为两个阶段：在超时发生以前，系统处于不确定阶段；在超时发生以后，系统则转入确定阶段。\n还有解决方法：Parallel Commits，第一阶段的结果已知（写入全局日志中），返回给客户端，异步执行第二阶段，该方法要跟共识算法一起工作。\n5.2.2 三阶段提交非阻塞协议，可以在协调者寄了的时候选出新的协调者推进事务执行\n(443条消息) 三阶段提交协议(3PC)_愿好的博客-CSDN博客\n缺点：并没有解决所有的问题。\n\n可用性以正确性为代价，同时很容易收到网络分区的影响（导致脑裂选出多个协调者）\n至少三轮往返消息，增加了事务的完成时间\n\n满足强终止性\n二阶段提交依然是\n5.2.3 Paxos提交算法\n5.2.4 基于Quorum的提交协议每个节点有一票，总共V票：\n\nVc：最小提交票数，要提交必须达到这个票数，0&lt;Vc&lt;&#x3D;V\nVa：最小中止票数，要中止必须达到这个票数，0&lt;Va&lt;&#x3D;V\n\nVc+Va&gt;V\n三个子协议：\n\n提交协议：事务开始时使用（类似三阶段中的pre commit，但是需要等待Vc票数）\n中止协议：网络分区时开始使用（出现网络分区，会在与协调者失联的分区中选出代理协调者，如果在失联分区中有在提交&#x2F;中止状态（哪怕一个），都推进所有参与者到该状态；如果至少有一个参与者处于预提交状态，并且至少Vc个参与者在等待提交投票的结果，则代理协调者向所有参与者发送预提交消息，如果有超过Vc个参与者恢复响应，那么代理协调者就会发送真正的提交消息;如果没有处于准备提交状态的参与者，并且至少Va个参与者在等待中止事务的投票结果，那么代理协调者就会发送真正的中止消息）\n合并协议：当系统从网络分区中恢复过来的时候使用\n\n5.2.5 Saga事务用来处理长活事务（Long-Lived Transaction，LLT）\n(443条消息) 分布式事务系列：Saga_saga事务_码出钞能力的博客-CSDN博客\n5.3 并发控制悲观并发控制（Pessimistic Concurrency Control）：假设多个事务之间会相互干扰，因此在任何时候都将资源加锁，避免其他事务修改该资源。悲观并发控制的主要优点是简单易懂，但由于频繁加锁导致效率低下，不适合高并发场景。\n乐观并发控制（Optimistic Concurrency Control）：假设多个事务之间不会相互干扰，并行访问数据，而在提交时进行冲突检测。如果两个事务的修改发生冲突，则其中一个事务必须回滚并重试。乐观并发控制可以最大程度地提高并发性，但需要开发人员自己实现数据版本控制，相对较为复杂。\n多版本并发控制（Multi-Version Concurrency Control）：每当一个事务对数据库进行更新操作时，会将当前数据的快照存储为新的版本，并使用版本号进行标识。在读取数据时，事务不会阻塞其他事务的读写操作，同时也不会锁定当前版本的数据。如果发现其他事务已经更新了数据，则会从前一个版本中获取数据。多版本并发控制的主要优点是高效、可扩展性好，但需要占用更多的磁盘空间。\n5.3.1 两阶段锁两阶段锁（Two-Phase Locking）是一种常用于并发控制的技术，旨在解决并发操作下出现的数据一致性问题。\n在两阶段锁策略中，事务必须分为两个阶段：增长阶段和收缩阶段。\n\n增长阶段：当事务请求资源时，该事务会先申请锁定所需资源。在此阶段中，锁可以被占用但不能被释放，每个事务只能逐渐获得锁，不能释放锁。\n\n收缩阶段：当事务完成所需工作时，它将释放所有已经锁定的资源，并且这些锁不再被使用。在此阶段中，锁可以被释放但不能被继续占用，每个事务只能逐渐释放锁。\n\n\n在这个过程中，锁的状态保持不变。所有的事务都必须遵循这些规则，以确保并发操作的正确性和一致性。\n两阶段锁的优点是可以避免死锁的发生，但是也有一些缺点，例如可能会导致事务等待时间较长，从而影响系统的响应速度。此外，还有许多其他的并发控制技术，如乐观并发控制、基于时间戳的并发控制等，可以用于替代或补充两阶段锁。\n三种方法避免死锁：\n死锁是一种并发控制问题，指两个或多个事务或进程相互等待释放已经占用的资源，导致所有事务或进程都无法继续执行。为了避免死锁，可以采取以下几种方法：\n\n死锁预防（破坏死锁条件）：通过约定加锁顺序、引入超时机制、限制某些进程对资源的访问等方式，在程序设计时直接避免死锁发生。\n死锁避免（银行家算法）：通过安全序列算法对每个事务或进程的资源请求进行安全性检查，只有当该事务或进程的资源请求不会导致死锁时才会被允许。\n等待-死亡：该方案是基于非剥夺方法。当进程Pi请求的资源正被进程Pj占有时，只有当Pi的时间戳比进程Pj的时间戳小时，Pi才能等待。否则Pi被卷回（roll-back），即死亡。\n伤害-等待：它是一种基于剥夺的方法。当进程Pi请求的资源正被进程Pj占有时，只有当进程Pi的时间戳比进程Pj的时间戳大时，Pi才能等待。否则Pj被卷回（roll-back），即死亡。\n\n\n死锁检测与恢复：在程序运行过程中，周期性地监测系统中是否发生了死锁，一旦检测到死锁，就采取资源抢夺或事务回滚等方式，进行死锁恢复。\n\n以上三种方法可以单独或组合使用，以达到更好的死锁预防效果。同时，在程序设计时，应注意不要通过不合理的代码逻辑、数据库设计等导致死锁现象的出现。\n5.3.2 乐观并发控制（不要锁）两类，基于检查的并发控制和基于时间戳的并发控制。\n\n基于检查的并发控制\n\n读取：创建副本，放到私有空间，读是读的副本，写操作被记录到私有空间的临时文件中。\n校验：没有冲突就提交，有冲突就中止。\n写入：校验没问题，就把私有空间的数据持久化存储。\n\n\n基于时间戳的并发控制\n每个数据项有两个时间戳\n\n写时间戳： W-TS(X)\n\n读时间戳：R-TS(X)\n#1.读操作if TS(T_i) &lt; W-TS(X)&#123;\tabort(R_i(X))&#125;else&#123;\taccept(R_i(X))\tR-TS(X)=TS(T_i)&#125;#2.写操作TS(T_i)必须大于R-TS(X)和W-TS(X)，否则丢弃if TS(T_i)&lt;R-TS(X)||TS(T_i)&lt;W-TS(X)&#123;\tabort(W_i(X))&#125;else &#123;\taccept(W_i(X))\tW-TS(X)=TS(T_i)&#125;\n\n难点：\n\n时间戳的精确性\n可能产生不可恢复的操作（后面的读事务基于前面的写事务，但前面的写事务回滚）\n\n看起来没有锁，但是实际上在修改时间戳的时候，仍可能要获取锁\n\n\n\n\n5.3.3 多版本并发控制（很像celldb啊）可以看作在乐观并发控制的基础上增加了多个版本，为每个数据项存储多个版本\n读到的是某个版本的数据，写是增加版本而并非覆盖\n衍生出三种主流多版本并发控制：\n\n多版本两阶段锁\n多版本乐观并发控制\n多版本时间戳排序\n\n元数据（Tuple存储到数据项头部）：\n\nTid：唯一单调递增的时间戳（事务开始的时间戳）\n\ntxn-id：获得当前写锁的事务的Tid，如果没有事务持有该数据的写锁，则为0，可通过CAS来修改此字段，避免使用锁\n\nCAS，即 Compare-And-Swap，是一种原子操作，用于实现并发控制。在多线程编程中，CAS可以保证对共享变量的操作在多线程情况下能够正确地执行。\nCAS操作需要三个参数：内存地址 V、旧的预期值 A 和新值 B。当且仅当当前内存地址的值等于旧的预期值 A 时，才会将该内存地址的值更新为新值 B。否则，不做任何操作。\nCAS操作的基本流程如下：\n\n线程读取内存地址 V 的当前值；\n线程比较内存地址 V 的当前值与旧的预期值 A 是否相等；\n如果相等，线程将新值 B 写入内存地址 V，并返回操作成功；\n如果不相等，线程不做任何操作，并返回操作失败。\n\n通过CAS操作，可以避免传统并发控制方法（如锁定）的一些问题，例如死锁和竞争条件。但同时，也存在一些限制。例如，CAS只能应用于单个变量的操作；如果需要对多个变量进行联合操作，则需要使用其他并发控制方式。\n\n\n\nbegin-ts: 创建该版本的数据项的事务提交的时间戳（开始肯定是提交了才有嘛）,Tcommit\n\nend-ts：最新版本的话，则为无限大，否则该数据项等于上一个或下一个版本数据项的begin-ts\n\n\n\n多版本两阶段锁(这里的锁，是根据对于数据的元数据的版本来进行判断来实现的)：\n代表MySQL,Oracle,Postgres\n\ntxn-id\n\nread-cnt：当前数据的读锁的数量。可以将read-cnt和txn-id组合成一个64位整型值，用CAS来更新两个\n\nbegin-ts\n\nend-ts\n#对于读操作Ti Xv为版本find Xv where begin-ts(Xv) &lt;= Ti &lt;end-ts(Xv)if txn-id(Xv)==0 || txn-id(Xv)==Ti&#123;\tread-cnt(Xv)+=1\taccept(Read(Xv))&#125;else&#123;\tabort()and rollback(T)&#125;#对于写操作 找到最新版本Xvfinx Xv where end-ts(Xv) ==INFif txn-id(Xv)==0||txn-id(Xv)==Ti&#123;\ttxn-id(Xv)=Ti\tnew(Xv+1)\ttxn-id(Xv+1)=Ti\taccept(Write(Xv+1))&#125;else&#123;\tabort() and rollback(T)&#125;#善后#for writefor all write data item&#123;\ttxn-id(Xv+1)=0\tbegin-ts(Xv+1)=Tcommit\tend-ts(Xv+1)=INF\ttxn-id(Xv)=0\tend-ts(Xv)=Tcommit&#125;#for readfor all read data item&#123;\tread-cnt(Xv) -=1&#125;\n\n\n多版本乐观并发控制\nMemSQL用这个\nMetadata:\n\ntxn-id\nbegin-ts\nend-ts\n\n#读find Xv where begin-ts(Xv)&lt;= Ti &lt; end-ts(Xv)if txn-id(Xv)==0 || txn-id(Xv)==Ti&#123;\taccept(Read(Xv))&#125;else&#123;\tabort()and rollback(T)&#125;#写find Xv where end-ts(Xv) == INF //确保最新if txn-id(Xv) == 0 ||\ttxn-id(Xv)==Ti&#123;\ttxn-id(Xv) = Ti\tnew(Xv+1)\ttxn-id(Xv+1) = Ti\tbegin-ts(Xv+1) = INF\taccept(Write(Xv+1))&#125;else&#123;\tabort() and rollback(T)&#125;#提交事务for all read data item&#123;\tif begin-ts(Xv) &gt;Ti&#123;\t //数据项被其他事务修改过，读到了过期的数据\t abort() and rollback(T)\t&#125;&#125;for all write data item&#123;\ttxn-id(Xv+1) = 0\tbegin-ts(Xv+1) = Tcommit\tend-ts(Xv+1) = INF\ttxn-id(Xv) = 0\tend-ts(Xv) = Tcommit&#125;\n\n多版本时间戳排序\n\ntxn-id\n\nread-ts(最大的读过的事务的Tid)\n\nbegin-ts\n\nend-ts\n#读find Xv where begin-ts(Xv)&lt;=Ti&lt;end-ts(Xv)if txn-id(Xv) == 0 || txn-id(Xv) == Ti&#123;\taccept(read(Xv))\tread-ts(Xv)=max(Ti,read-ts(xV))&#125;else&#123; abort() rollback(T)&#125;#写find Xv where end-ts(Xv) ==INFif txn-id(Xv)=0&amp;&amp;Ti &gt; read-ts(Xv)&#123;\ttxn-id(Xv) = Ti\tnew(Xv+1)\ttxn-id(Xv+1) =Ti\tread-ts(Xv+1) = 0\taccept(Write(Xv+1))&#125;else &#123;\tabort() and rollback(T)&#125;#善后for all write data item&#123;\ttxn-id(Xv+1) = 0\tbegin-ts(Xv+1) = Ti\tend-ts(Xv+1) = INF\ttxn-id(Xv) = 0\tend-ts(Xv) = Ti&#125;\n\n\n版本存储和垃圾回收\n版本存储：\n\n仅追加存储（Append-Only Storage）\n有指针\n如果说恰好有很大数据的一个属性，在新版本中又不发生改变，则很占空间（所以要复用）\nMemSQL、PG\n\n\n时间旅行存储（Time-Travel Storage）\n单独用一个时间旅行表来存储历史版本\n最新版本的数据存储到主表\n\n\n增量存储（Delta Storage）\n只将发生变化的字段信息存储到增量存储中\n增量存储在MySQL和Oracle中被称为回滚段\n对于更新频繁的工作负载，可以减少内存分配，对于读操作频繁的工作负载，需要访问回滚段才能重新拼出需要的信息，开销会更高\n\n\n\n垃圾回收：\n\n元组级别（Tuple-Level Garbage Collection) ：\n后台清理（Background Vaccuuming, VAC）:后台线程周期性清理:star2:\n协同清理 (Cooperative Cleaning, COOP)：遍历最老到最新，事务执行时清理\n\n\n事务级别垃圾回收（Transaction-Level Garbage Collection）:\n如果一个事务创建的版本不被任何活跃事务访问，意味着该事务已经过期。\n系统会根据该事务读写的数据集合（Read&#x2F;Write Sets）清理相对应的版本\n\n\n\n\n\n5.4 Percolator分布式事务解决方案：Percolator\n构建于Bigtable的基础上，主要用于网页搜索索引等服务\n支持多行事务\n依赖一个单点授时，单时间源的授时服务（TSO，Timestamp Oracle）\n使用多版本时间戳排序来实现快照隔离\n利用如下元数据实现快照隔离：\n\nlock:锁信息\nwrite：事务提交时间戳\ndata：数据\n\n事务处理步骤：\n\n分配事务开始时间戳:\nstart_ts=oracle.GetTimestamp()\n\n\n\n将所有写操作缓冲起来，直到提交时再一并写入\nvoid set(Write w)&#123;\twrites_.push_back(w)&#125;\n\npreWrite:\n\n所有写操作挑选一个作为主锁（随意挑选，固定使用第一个写操作作为主锁）：锁住事务中写操作涉及的所有数据\n\n其他写操作作为次锁\nbool preWrite(Write w,Write primary)&#123; Column c = w.col; bigtable::Txn T = bigtable::StartRowTransaction(w.row); //如果事务开始后该数据被修改，则中止事务 if (T.Read(w.row,c+&quot;write&quot;,[start_ts,INF]))return false; //尝试获取锁 if (T.Read(w.row,c+&quot;lock&quot;,[0,INF]))return fasle;   T.Write(w.row,c+&quot;data&quot;,start_ts,w.value); T.Write(w.row,c+&quot;lock&quot;,start_ts,&#123;primary.row,primary.col&#125;); return T.Commit();&#125;\n\n\n提交事务\n#写bool Commit()&#123;\tWrite Primary = writes_[0];\tvector&lt;Write&gt; secondaries(writes_.begin()+1,wirtes_.end());\tif (!PreWrite(primary,primary))return false;\tfor (Write w:secondaries)\t\tif (!PreWrite(w,parimary)) return false;\t\tint commit_ts = oracle.GetTimestamp();\t//先提交主锁的写操作\tWrite p = primary;\tbigtable::Txn T= bigtable::StartRowTransaction(p.row);\tif (!T.Read(p.row,p.col+&quot;lock&quot;,[start_ts,start_ts]))\t\treturn false;\tT.Write(p.row,p.col+&quot;write&quot;,commit_ts,start_ts);\tT.Erase(p.row,p.col+&quot;lock&quot;,commit_ts);\tif (!T.commit())return false;\t//第二阶段，更新所有次(secondary)锁的写操作\tfor (Write w:secondaries)&#123;\t\tbigtable::Write(w.row,w.rol+&quot;write&quot;,commit_ts,start_ts);\t\tbigtable::Erase(w.row,w.rol+&quot;lock&quot;,commit_ts);\t&#125;\treturn true;&#125;#读bool Get(Row row,Column c,string *value)&#123;\twhile(true)&#123;\t\tbigtable::Txn T = bigtable::StartRowTransaction(row);\t\t//检查是否有并发写入的锁\t\tif (T.Read(row,c+&quot;lock&quot;,[0,start_ts]))&#123;\t\t\t//存在锁，尝试清理并等待锁释放\t\t\tBackoffAndMaybeCleanupLock(row,c);\t\t\tContinue;\t\t&#125;\t\t//找到小于开始时间戳的最新写入版本\t\tlatest_write=T.Read(row,c+&quot;write&quot;,[0,start_ts]);\t\tif (!latest_write.found()) return false; //没有找到\t\tint data_ts =latest_write.start_timestamp();\t\t*value = T.Read(row,c+&quot;data&quot;,[data_ts,data_ts]);\t\treturn true;\t\t\t&#125;&#125;\n\n","categories":["分布式系统"],"tags":["分布式系统","深入理解分布式系统"]},{"title":"深入理解分布式系统（六）时间和事件顺序","url":"/2024/06/26/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%EF%BC%88%E5%85%AD%EF%BC%89%E6%97%B6%E9%97%B4%E5%92%8C%E4%BA%8B%E4%BB%B6%E9%A1%BA%E5%BA%8F/","content":"时间和事件顺序6.1 物理时钟\n机械时钟\n石英时钟\n原子钟：原子共振频率标准来计算\nGPS\n\n6.2 时钟同步NTP:(430条消息) NTP详解(网络时间协议)_127.127.1.0 ntp含义_思福迪小白的博客-CSDN博客\n针对NTP同步导致时间回退甚至是负数的情况–单调时钟，保证返回的时间严格单调增长\nCloudflare没用单调时钟，而是在发现时间差为负数或者0时变为一个默认值（golang没暴露单调时钟）\n单调时钟的局限性：以自身所在的计算机的某个时间为起点，也就是说，来自同一个节点的单调时钟才有意义。\n如何发明分布式系统中的单调时钟？\n6.3 逻辑时钟Lamport Clock\nHappens-Before:\n​\tif a-&gt;b\n\nif a and b are in the same process, and a is before b, then a-&gt;b\nif a is the event that sends a message , b is the event that receives the message, then a-&gt;b.\nif a-&gt;b and b-&gt;c, then a-&gt;c; if a &#x2F;-&gt;b or b&#x2F;-&gt;a, then a and b are in concurrency(a||b).\n\na-&gt;b, then C(a)&lt;C(b)\nC(a)&lt;C(b), a&#x2F;-&gt;b\n\n每个进程都有自己的逻辑时钟，初始值为0\n如果进程i内部发生一个新的事件，那么将其逻辑时钟加一，即Ci&#x3D; Ci+1\nif process i sends a message to process j , and the logic clock in process i is C(i), then, firstly, C(i)&#x3D;C(i)+1, and then, i sends Ci and the message to process j, and then, process j updates its logic clock Cj&#x3D; max(Ci,Cj)+1\n\n根据离散数学的关系而言，逻辑时钟和物理时钟的区别在于，物理时钟的先后关系是一种total ordering，是全局可见的一种关系，谁先谁后一目了然；然而逻辑时钟 is a kind of partial ordering，只有部分元素的先后关系（本质原因是，我们不能根据逻辑时间的先后去判定逻辑业务的先后）\n如何使逻辑时钟也具有全序关系？给进程加上优先级，但是赋予进程不同的优先级排序会有不同的全序关系\nRAFT的任期、选举算法、日志和状态机的思想等都出自这篇论文（Lamport,Leslie.”Time,clocks,and the ordering of events in a distributed system.”Concurrency: the Works of Leslie Lamport. 2019.179-196）：\n\n一个去中心化的算法，通过逻辑时钟实现分布式资源互斥来分配资源\n每个进程维护一个消息队列，消息的格式为Tm: Pi, 即为第i个进程在Tm的逻辑时钟下发送的消息\n进程维护自己的消息，也接收别人的消息，决定自己是否能够获取资源的条件\n消息队列中除开自己的消息之外的消息的逻辑时间，均大于自己的消息\n排在队头的消息是自己的消息（这里消息的插入可以是对头队尾，也可以是中间）\n\n\n\n6.4 向量时钟跟逻辑时钟很类似，只不过逻辑时钟只考虑了本地的逻辑时间，而向量时钟的维度为节点数，维护全局的时间。\n向量时钟（Vector Clock）是一种在分布式系统中用于记录事件发生顺序的机制。它通过给每个节点分配一个独特的向量来跟踪每个节点上的事件发生次数，这个向量被称为向量时钟。\n向量时钟的大小等于节点数，每个元素代表了一个节点的时间戳。当一个事件发生时，对应节点的时间戳会自增1。如果两个事件发生在不同的节点上，那么它们的时间戳是相互独立的，无法比较先后顺序；但如果它们发生在同一个节点上，就可以用向量时钟来比较它们的先后顺序。比如说，设有A,B,C三个节点，此时在A节点上发生了一个事件，那么其向量时钟会变为[1,0,0]，因为这是A节点上第一个事件。如果随后在C节点上发生了一个事件，那么其向量时钟会变为[0,0,1]，因为这是C节点上第一个事件。如果再在B节点上发生了一个事件，那么其向量时钟会变为[0,1,0]，因为这是B节点上第一个事件。这样，在整个分布式系统中，我们得到了A为[1,0,0]，B为[0,1,0]，C为[0,0,1]的向量时钟。\n当一条消息从一个节点传递到另一个节点时，消息中会包含发送方的向量时钟。接收方在收到消息后，将它自己的向量时钟和接收到的消息中的向量时钟进行比较，取每个位置上较大的值作为新的时间戳。然后将接收到的消息的时间戳同步到本地，再加上1，表示接收到了这条消息。这样，接收方就可以知道这条消息是在哪个节点上发送的，以及这条消息的先后顺序。\n向量时钟不仅能够帮助我们比较事件间的先后关系，还能检测出并发事件。比如说，如果两个事件A和B同时发生，那么它们对各自持有的向量时钟都会影响到相应的位置上，导致这两个节点上的向量时钟不一致。这样，我们就可以检测出这两个事件的并发性。\n缺点在于，向量的维度与节点数正相关，随着节点增多，向量时钟越大，向量时钟需要大量的磁盘和内存空间，同时需要更长的时间来计算和比较。\n","categories":["分布式系统"],"tags":["分布式系统","深入理解分布式系统"]},{"title":"深入理解分布式系统（四）分布式共识","url":"/2024/06/26/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%EF%BC%88%E5%9B%9B%EF%BC%89%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%B1%E8%AF%86/","content":"分布式共识4.1 分布式共识简介分布式共识（Distributed Consensus）是指在分布式系统中，多个节点（或进程）协同完成某个任务或达成某个决策的过程。在这个过程中，每个节点需要就该任务或决策达成一致，并且能够互相通信、协调、协作。\n分布式共识的一个重要应用是在区块链技术中，用于解决双花问题（Double-spending problem）和确定哪些交易会被写入区块链。比特币等加密货币就是通过共识算法来实现去中心化的交易记录。\n常见的分布式共识算法包括拜占庭将军问题（Byzantine fault tolerance, BFT）、Raft、Paxos、Proof of Work（PoW）、Proof of Stake（PoS）等。这些算法都有各自的优缺点，适用于不同的场景。例如，PoW 算法被应用在比特币等加密货币中，而 PoS 算法则被用在以太坊等区块链平台中。\n4.1.1 什么是分布式共识分布式共识是指在一个分布式系统中，多个节点之间需要就某些决策达成一致意见的过程。在这个过程中，各个节点通过相互通信和协作来达成共识，以保证系统能够正常运作并避免出现错误或冲突。\n在分布式系统中，由于节点之间的网络延迟、节点故障等原因，不同节点的状态可能存在不一致的情况。因此，需要通过分布式共识算法来解决这些问题。常用的分布式共识算法包括 Paxos、Raft、Byzantine Fault Tolerance 等。\n分布式共识算法的基本思路是，通过节点之间的通信和协作，选出一个“领导者”节点来负责提出某个决策，其他节点通过投票和确认的方式来达成共识，以保证系统在多个节点之间的一致性和可靠性。这种算法在分布式数据库、区块链等系统中都得到了广泛应用。\n4.1.2 为什么要达成共识在分布式系统中，节点之间的状态可能存在不一致的情况，如果不对这些状态进行协调，就可能导致系统出现错误或冲突。为了避免这种情况的发生，需要在分布式系统中实现共识机制，保证各个节点之间的状态达成一致，从而保证系统的正确性和可靠性。\n具体来说，如果在一个分布式系统中，某些节点的状态发生了变化，但其他节点还没有收到这个变化的通知，那么这些节点就会基于过期的状态进行操作，从而导致数据不一致或操作冲突。通过分布式共识算法，可以确保所有节点在进行操作前都已经达成了共识，从而保证了数据的一致性和操作的正确性。\n另外，分布式共识还能够防止拜占庭错误的发生。拜占庭错误是指分布式系统中存在恶意节点或网络攻击，导致节点之间的通信受到干扰或伪造。通过分布式共识算法，可以检测和排除这些恶意行为，确保系统的安全性和可靠性。\n4.2 异步系统中的共识4.2.1 FLP不可能定理FLP不可能定理是指，在一个异步的分布式系统中，不存在一个算法能够保证在存在至少一个节点故障的情况下，仍然能够保证所有节点能够在有限时间内达成共识。\n该定理由Fischer、Lynch和Paterson在1985年提出，是分布式共识领域的一个重要理论。其基本思想是，由于节点之间的通信存在延迟和不可靠性，因此在存在故障节点的情况下，无法确定某个节点是否已经停止工作或者只是延迟。这种不确定性会导致共识过程无法完成。\nFLP不可能定理的证明使用了卡慕尔异步通信模型，即假设节点之间的消息传输可以无限制地延迟，但必须保证每个节点最终能够收到所有消息。基于这种通信模型，可以证明在存在至少一个节点故障的情况下，无法保证所有节点能够在有限时间内达成共识。\n虽然FLP不可能定理指出了分布式共识问题的困难性，但是在实际应用中，往往会使用一些近似算法来解决共识问题。例如，Paxos算法、Raft算法等就是通过一些特殊的约束条件来实现了共识，从而在实际应用中得到了广泛的应用。\n\n安全性: 在一个任期内只会确定一个值（something wrong not happen）\n活性：分布式系统最终会认同某一个值(something right must happen)\n容错性\n\n分布式系统中的 safety 和 liveness — 源代码 (lrita.github.io)\n和CAP一样，三选二\n证明：\nFLP不可能定理的证明是基于卡慕尔异步通信模型的，该模型假设节点之间的消息传输可以无限制地延迟，但必须保证每个节点最终能够收到所有消息。在这种通信模型下，证明FLP不可能定理的基本思路是，通过构造一个反例来说明在异步通信模型下，不存在一个算法能够保证在存在至少一个节点故障的情况下，仍然能够保证所有节点能够在有限时间内达成共识。\n具体来说，假设有一个分布式系统，其中包含n个节点，节点之间通过消息传递来达成共识。为了方便起见，假设系统中只有两种状态：0和1。初始状态下，每个节点的状态都是不确定的。节点之间的通信是异步的，消息传输可以无限制地延迟，且无法保证消息的可靠性。\n接下来，假设有一个算法A，可以在存在至少一个节点故障的情况下，仍然能够保证所有节点能够在有限时间内达成共识。为了证明FLP不可能定理，需要构造一个反例来说明这个算法是不可行的。\n具体来说，假设存在两个节点p和q，它们的状态初始时均为不确定状态。为了达成共识，节点p发送一个消息m给节点q，告诉节点q它当前的状态是0。但由于通信是异步的，消息m可能会被延迟或者丢失，导致节点q无法知道节点p的状态。因此，节点q可以选择继续等待消息m，或者猜测节点p的状态是1。如果节点q猜测节点p的状态是1，那么节点q会发送一个消息n给节点p，告诉节点p它当前的状态是1。由于节点p也无法确定节点q的状态，节点p也有可能会猜测节点q的状态是0，从而发送一个消息k给节点q，告诉节点q它当前的状态是0。这样，就形成了一个死锁状态，导致节点p和q无法达成共识。\n从上述分析可以看出，由于异步通信模型的存在，无法保证消息的可靠性和节点状态的一致性，从而导致FLP不可能定理的存在。虽然该定理证明了在异步通信模型下，不存在一个算法能够保证在存在至少一个节点故障的情况下，仍然能够保证所有节点能够在有限时间内达成共识，但在实际应用中，可以采用一些近似算法来解决共识问题。\n\n故障屏蔽\n使用故障检测器\n使用随机性算法\n\n这三种方法可以绕开FLP不可能定理\n4.2.2 故障屏蔽故障屏蔽（Fault tolerance）和故障检测器（Fault detection）是分布式系统中常用的技术，用于提高系统的可靠性和鲁棒性。使用随机性算法是实现这些技术的一种常用方法。\n故障屏蔽是一种技术，可以在系统中发生故障时保证系统的正常运行。一种常见的故障屏蔽技术是冗余备份（Redundancy），即在系统中增加多个备份，当一个节点发生故障时，备份节点可以接管其任务，保证系统的正常运行。在实现冗余备份时，常常使用随机性算法，如随机化选举（Randomized election）和随机化复制（Randomized replication）等技术，来提高系统的可靠性和鲁棒性。\n4.2.3 使用故障检测器故障检测器是一种技术，用于检测分布式系统中的故障节点。一种常见的故障检测器是心跳检测（Heartbeat detection），即每个节点定期向其他节点发送心跳消息，检测是否有节点故障。在实现心跳检测时，常常使用随机性算法，如随机化时间间隔（Randomized interval）和随机化路线（Randomized routing）等技术，来避免故障检测过程中的死锁和瓶颈等问题，提高检测的准确性和效率。\n虽然完美的故障检测器具备以下条件：\n\n完全性：每一个故障的进程都会被每一个正确的进程怀疑\n精确性：每一个正确的进程都不会被其他进程怀疑\n\n但实际上，实现困难。而论文证明，即使使用”不完美”的故障检测器，只要通信可靠，失效进程不超过一半，依然可以用来解决共识问题。因此实现最终弱故障检测器：\n\n最终弱完全性：每一个故障的进程最终都会被一些正确的进程检测到。\n最终弱精确性：经过一段时间后，一个正确的进程不会被其他正确的进程怀疑。\n\n4.2.4 使用随机性算法随机性算法是指在算法设计和实现中引入随机性的一种技术，可以用于解决一些分布式系统中的复杂问题，如分布式计算、分布式存储、分布式共识等问题。随机性算法具有一些优点，如简单、快速、容易实现和分布式化等特点，可以提高分布式系统的性能和效率。\n区块链：\nProof of Work（PoW）和Proof of Stake（PoS）是两种常见的区块链共识机制，用于保证区块链的安全性和去中心化特性。它们的主要区别在于如何选举出下一个区块的记账节点。\nPoW机制是通过计算一定难度的工作量来选举出下一个区块的记账节点。矿工需要通过计算一个随机数，使得计算结果符合一定的规则，以此获得记账权。这种机制需要大量的计算能力和电力消耗，因此存在能源浪费和环境污染等问题。\nPoS机制则是通过拥有一定数量的代币来选举出下一个区块的记账节点。持有更多代币的用户会有更大的概率被选中作为记账节点。这种机制可以避免计算资源和能源的浪费，但需要考虑如何避免寡头垄断和激励机制的问题。\n以下是PoW和PoS机制的一些优缺点：\nProof of Work（PoW）:\n\n优点：安全性高，攻击成本高，可预测性好。\n缺点：能源浪费，环境污染，效率低，中心化问题。\n\nProof of Stake（PoS）:\n\n优点：节省能源，环保，效率高，可扩展性好，分散化程度高。\n缺点：可能导致寡头垄断，激励机制难以设计，安全性有待验证。\n\n[(459条消息) [区块链]共识算法（POW,POS,DPOS,PBFT）介绍和心得_dpos共识机制_乐扣老师lekkoliu的博客-CSDN博客](https://blog.csdn.net/lsttoy/article/details/61624287?ops_request_misc=%7B%22request%5Fid%22%3A%22168594614916800186538613%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=168594614916800186538613&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~baidu_landing_v2~default-2-61624287-null-null.142^v88^control_2,239^v2^insert_chatgpt&amp;utm_term=pow pos&amp;spm&#x3D;1018.2226.3001.4187)\n[(459条消息) 区块链必知基础知识、POS、POW、DPOS、公有链、私有链、联盟链_区块链pos_yida&amp;yueda的博客-CSDN博客](https://blog.csdn.net/qq_40585384/article/details/124678390?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=pow pos&amp;utm_medium&#x3D;distribute.pc_search_result.none-task-blog-2allsobaiduweb~default-0-124678390.142^v88^control_2,239^v2^insert_chatgpt&amp;spm&#x3D;1018.2226.3001.4187)\n4.3 同步系统中的共识Dolev-Strong算法是一种用于解决密码学中的安全多方计算（Secure Multiparty Computation，SMC）问题的算法。该算法由Danny Dolev和Hadas Shachnai-Strong于1991年提出。\n安全多方计算是一种加密技术，允许多个参与者在不泄露私有信息的情况下共同计算出一个结果。在安全多方计算中，每个参与者需要负责保护自己的私有信息，同时协调计算过程以达到预期的结果。Dolev-Strong算法就是一种用于实现安全多方计算的算法之一。\nDolev-Strong算法基于一种名为交互式验证协议（Interactive Verification Protocol，IVP）的技术，通过多轮的通信和验证来确保计算的正确性和安全性。该算法可以在不需要信任第三方的情况下完成安全计算，因此具有很好的去中心化特性。\nDolev-Strong算法的主要思想是，将计算任务分解成多个子任务，每个参与者只负责计算其中的一部分，并将计算结果加密后传递给下一个参与者。在每个子任务之间，参与者需要进行验证，以确保计算的正确性和安全性。通过多轮的交互和验证，参与者最终可以得到正确的计算结果，同时保护自己的私有信息不被泄露。\n总的来说，Dolev-Strong算法是一种基于交互式验证协议的安全多方计算算法，可以在不需要信任第三方的情况下实现安全计算，具有很好的去中心化特性，被广泛应用于密码学、区块链和分布式系统等领域。\n4.4 Paxos(443条消息) 分布式共识算法——Paxos算法（图解）_杨 戬的博客-CSDN博客\nPaxos算法是一种用于解决分布式系统中达成一致性的算法，由Leslie Lamport于1998年提出。Paxos算法的目的是保证分布式系统中各个节点之间的状态一致性，即在不可靠的网络环境下，保证不同节点对共享资源的操作具有相同的效果。\nPaxos算法的核心思想是通过一个协调者（coordinator）和多个参与者（acceptor）之间的协作来达成共识。在Paxos算法中，协调者的主要任务是向参与者发起提案（proposal），而参与者的主要任务是接受并决策是否通过提案，进而达成一致性。\n具体来说，Paxos算法分为三个阶段：\n\n准备阶段（prepare phase）：协调者向参与者发起提案，并请求参与者发送自己曾经接受的最大提案编号（proposal number），以便协调者了解当前的提案状态。\n接受阶段（accept phase）：如果协调者获得了大多数参与者的反馈，并且没有其他提案正在进行，那么协调者就可以向参与者发起新的提案，并请求参与者接受该提案。\n学习阶段（learn phase）：一旦协调者成功地向大多数参与者发送了新的提案，并得到了反馈，那么协调者就可以通知所有参与者接受该提案，从而完成一致性达成的过程。\n\n总的来说，Paxos算法是一种用于解决分布式系统中达成一致性的算法，通过协调者和参与者之间的协作来实现共识。该算法被广泛应用于分布式存储、分布式计算、分布式数据库和区块链等领域。\nPaxos算法是一种非常复杂的算法，实现和理解上有一些细节需要注意：\n\n提案编号（proposal number）的生成方式需要确保唯一性和可比较性，一般使用时间戳和节点编号等信息组合而成。\n在准备阶段，参与者需要检查当前提案的编号是否比自己之前接受的所有提案编号都要大。如果有更大的提案编号，参与者就需要返回该提案的编号和对应的值，以便协调者做出决策。\n在接受阶段，协调者需要确保至少有半数的参与者接受了新的提案，并将其值写入日志。如果无法达成一致，协调者需要回退并重新发起提案。\n在学习阶段，协调者需要通知所有参与者已经达成共识，并将提案值写入共享存储中。\nPaxos算法还需要考虑一些异常情况，例如节点宕机、网络延迟和网络分区等，需要通过复杂的协议来保证系统的可用性和一致性。\n\n需要注意的是，Paxos算法是一种非常复杂的算法，对于初学者来说理解起来比较困难。因此，建议在实践中结合阅读相关文献和代码实现，逐步理解其细节和原理。\n为什么要提案编号？\n\n分布式系统使用时间戳之类的物理时间可能并不准确\n轮次+服务器id\n\n4.5 Go实现Paxos4.6 Multi-PaxosMulti-Paxos是Paxos算法的一个变种，用于优化Paxos算法在多次提案的情况下的性能。在Paxos算法中，每次提案都需要执行一次完整的Paxos流程，包括准备、接受和学习三个阶段，这会导致Paxos算法的性能比较低。\nMulti-Paxos通过引入领导者（leader）的概念来优化Paxos算法的性能。在Multi-Paxos中，领导者负责向参与者发起提案，而参与者则只需要根据领导者的指示来决策是否接受提案。因此，领导者可以在一段时间内发起多个提案，从而避免了每次提案都需要执行完整的Paxos流程的问题。\n具体来说，Multi-Paxos的流程如下：\n\n领导者向参与者发起一个提案，包括提案编号和提案值。\n参与者根据提案编号进行决策：如果当前的提案编号比之前接受的所有提案编号都要大，那么参与者就接受该提案，并向领导者发送接受消息；否则，参与者就拒绝该提案，并向领导者发送拒绝消息。\n如果领导者收到了大多数参与者的接受消息，那么该提案就被确定，并向所有参与者发送确定消息，完成该提案的学习阶段。\n如果领导者收到了大多数参与者的拒绝消息，那么领导者就需要重新选择一个提案编号，并重新发起提案。\n\n需要注意的是，Multi-Paxos仍然需要保证Paxos算法的正确性和一致性，但通过引入领导者来优化性能，使得Multi-Paxos在实际应用中更加高效。\n4.8 Raft算法要持久化存储的信息：\n\ncurrentTerm：当前任期，用于恢复\nvotefor:向谁投票，只投个第一个发送RequestVote RPC的人而拒绝其他发送RequestVote RPC的人\n日志：包含索引位置，任期号，命令本身，如果日志在半数节点上被存储，则该记录可提交。注意，领导者先将日志持久化存储到本地，再并行用AppendEntries RPC发送到其他节点上。这时，如果收到超过半数的响应，则领导者将命令应用于自己的状态机，提交该日志，然后向客户端返回响应。后续的日志复制RPC中还包含LeaderCommit表明领导者已经提交的日志的最大索引，跟随者收到此RPC时也会提交所有小于该索引的日志\n\n两个RPC：\n\nRequestVote RPC ：用于领导者选举，包含term,id,lastLogIndex,lastLogTerm，同样在用于领导者选举中，最后两个属性若term&gt;跟随者的term或者term相等但index大于跟随者最后一条日志的index，则跟随者才会投票，同理也需要一半投票才行，这确保了领导者在超过半数给他投票的节点中拥有最完整的日志。\nAppendEntries RPC ： 用于复制日志&#x2F;发送心跳信息，后续的日志复制RPC中还包含LeaderCommit表明领导者已经提交的日志的最大索引，跟随者收到此RPC时也会提交所有小于该索引的日志\n\n节点转换流程：\n\n\n\n只有发生以下三种情况之一才更新自己的状态\n\nRequestVote RPC收到超过半数的选票，变为领导者\n收到来自其他领导者的AppendEntries，退化为跟随者\n没发生上述两种情况，任期++，投自己一票\n\n\n\n\n保证两个特性：\n\n安全性：一个任期内最多只有一个领导者被选出来\n活性：系统最终能选出一个领导者\n\n解决活锁问题（没人可以获得超过一半选票）：\n\n节点随机选择超时时间（T-2T期间，T越大于网络传播时间效果越加，但同时不能太大，否则性能会受到影响）\n\n两个特性：\n\n如果任期和索引相同，则日志条目完全相同，日志内容相同，且之前的日志也完全相同（数学归纳法？）\nRAFT不允许出现日志空洞，必须连续提交日志\n为了维护这两个特性，在AppendEntries中还有之前一个日志的prevLogIndex和任期prevLogTerm，跟随者收到后，会检查自己最后一条日志的index和term是否匹配，若匹配，则接受，否则拒绝。（一致性检查）\n\n延迟提交：\n\n为什么需要延迟提交？\n若出现网络分区，导致B分区中的一个服务器拥有更新任期的日志（比如3），而A分区中的领导者（此时在任期4，而最新的日志任期为2），若提交后宕机（而A分区中其他服务器的日志任期也为2，但未提交），而B分区中的服务器此时恰好又成为新的领导者（任期5），此时则会覆盖掉A分区中未提交任期为日志2的服务器的日志，而实际上，A分区之前的领导者实际上已经提交了该日志，这不符合已提交日志不能被修改的需求\n\n\n怎么延迟提交\n日志必须存储在超过半数节点上\n领导者必须看到超过半数节点上还存储着至少一条自己任期内的记录\n领导者只能提交自己任期的日志，从而间接提交之前任期的日志\nno-op日志：只有索引和日期，保持领导者的权威\n在领导者刚选举成功时，就本地追加no-op日志（只包含任期），同时appendEntries到其他的节点，显然，no-op日志的任期就是领导者当前的任期，当然能提交，从而间接提交之前的任期的日志\n\n\n\n\n\n清理不一样的日志：\n\n两种不一样的日志，缺失&#x2F;多出来的\n前者直接AppendEntries来补齐（也要用到nextIndex）\n后者，领导者为每个跟随者保存nextIndex[]变量，存储领导者最后一条日志的索引+1\n\n\n流程\n针对缺失的：领导者检查自己的日志，最新index为10，然后比如对于跟随者1，nextIndex[1]&#x3D;11,带上前一个日志条目的唯一标识（10，任期6），跟随者1索引为10处没有日志，递减nextIndex[1],直到nextIndex[1]&#x3D;5,索引4且任期4的日志匹配，补齐索引5-10\n针对多出来的，跟上面一样，直到找到匹配的index，而之后的全部删除即可\n\n\n\n处理旧领导者：\n\nRPC请求有自己的任期，如果发生网络分区，老的领导者还以为自己是领导者，他的RPC在被其他Follower接收到的时候，但凡Follower已知的任期比他新，都会返回拒绝消息，但凡接收到拒绝消息，老的领导者就跟咽了气的皮球似的变为跟随者。\n\n配置变更：\n\n使用 Joint Consensus（联合共识）完成两阶段协议\n第一阶段,Cold+new，多数派，提交\n第二阶段,Cnew，多数派，提交，提交后后续配置都基于Cnew（不在Cnew的领导者下台）\n不在Cnew的领导者下台会导致一个问题就是，不在Cnew的跟随者将不再收到心跳，因此其会参与领导者选举（尽管会因为日志不够新而导致竞选失败，但是还是会影响竞选过程导致可用性变差）\n解决：Pre-Vote阶段，就还是发送Pre-Vote请求询问整个系统“我到底有没有资格参与竞选”（这个资格还是根据任期以及日志Index来判断的）。但这样会有个问题就是，如果在Cnew集群中的领导者还没有把Cnew的日志发到其跟随者上，也就是说，跟随者的日志还不够新，那么就算有Pre-Vote，可能还是会影响选举，导致不在Cnew的服务节点竞选成功\n增强Pre-Vote判断条件：\n任期更大，或者任期相同索引更大\n至少一次选举时间内没有收到领导者心跳\n\n\n注意到在Pre-Vote阶段不会增加自己的任期，所以Pre-Vote不仅可以解决配置更改干扰领导者的问题，还能解决网络分区脑裂和任期爆炸增长的问题\n示例：etcd，将候选者细分为预候选者和候选者，前者发送Pre-Vote，不增加日期，后者发送RequestVote，会增加任期\n\n\n\n\n\n\n\n日志压缩：\n\n关注最终状态\n压缩后得到快照，持久化存储\n每个服务器独立地压缩其已提交的日志\n保存最后一条被丢弃的日志的索引和任期，用AppendEntries进行日志一致性的检查\n一旦丢弃了前面部分的日志，领导者要承担两个责任：\n如果服务器重启了，则需要将最新的快照加载到状态机后再接收日志\n向较慢的跟随着发送一致的状态快照(InstrallSnapshot RPC)\n\n\nLastIncludeIndex和LastIncludeTerm，记录状态，之前的日志全部丢弃\n在正常运行期间通过写时复制技术（COW）生成快照（开源LogCabin）\n\n4.9 Raft和PaxosRaft和Paxos都是分布式一致性算法，它们都被广泛应用于构建高可用性、高可靠性的分布式系统。\nPaxos是最早提出的分布式一致性算法之一，由Leslie Lamport在1990年代初期提出。Paxos算法包含了两个主要的组件：leader选举和状态复制。它的核心思想是通过在节点之间达成共识来实现状态的复制和一致性。\nRaft是一种新近出现的分布式一致性算法，由Diego Ongaro和John Ousterhout于2013年提出。Raft算法也包含了leader选举和状态复制两个主要部分，它强化了容错机制和可读性，使得它更容易被理解和实现。\n相比而言，Raft与Paxos相比较具有以下优势：\n\n理解和实现容易：Raft算法把分布式一致性问题分成了几个独立的子问题，分别处理，每个子问题都比较容易理解和实现，使得整个算法更加容易理解和实现。\n更好的可读性：Raft的算法描述更接近日常使用中的术语，更容易理解，在阅读和修改代码时更加方便。\n更好的性能：Raft算法的性能比Paxos算法更好，特别是在网络不稳定或者出现网络分区的情况下，Raft算法的表现更加优秀。\n\n总之，虽然Raft和Paxos都是用于实现分布式一致性的算法，但是它们有着不同的设计思路和实现方式。Raft算法在易用性和可读性方面，相对Paxos算法更胜一筹，但在实际的应用场景中，不同的问题需要选择最适合的算法来解决。\n4.10 拜占庭容错和PBFT算法Raft和Paxos，都是非常高效的算法，他们只支持CFT（Crash fault tolerance），只允许系统内节点宕机（crash），并不考虑系统内有作恶节点。\n共识算法系列：PBFT算法关键点综述、优缺点总结 - 知乎 (zhihu.com)\n共识算法系列之一：raft和pbft算法 - 知乎 (zhihu.com)\n\n","categories":["分布式系统"],"tags":["分布式系统","深入理解分布式系统"]},{"title":"自然辩证法课程知识点","url":"/2024/09/24/%E8%87%AA%E7%84%B6%E8%BE%A9%E8%AF%81%E6%B3%95/","content":"😀自然辩证法课程知识点总结同步连接：网页版\n世界科技体制的形成和中国科技体制的变革定义：\n\n科技体制：\n组织结构和运行机制：\n科技体制是指科学技术的组织设置及其相互之间的组织性制约关系；\n其机制是指科学技术在内外动力作用下产生动态过程的各相关因素互相制约的一般模式\n\n\n\n\n原则：\n科技体制化是科学技术产物发展的必然产物\n科技体制的形成与建设过程充分显示了社会对科技发展的或促进或制约的过程\n中国科技体制\n是移植国外的，而非内生的\n其有深刻的历史合理性与必然性\n\n\n\n\n\n1. 世界科学技术\n\n从小科学到大科学\n哥白尼天体运行论\n牛顿-自然哲学中的数学原理\n爱因斯坦-相对论\n\n\n\n近代科学体系的建立：\n两个特点：逻辑演绎+实验验证\n\n\n小科学特点：\n个体行为（个人独立完成，无经费）\n追求知识（无实际效益）\n自由探索（兴趣使然，无具体目标）\n\n\n大科学：大目标，大投入，大设备，大协作，大效益\n\n\n曼哈顿就工程（物理），阿波罗计划，国际空间站等\n中国神六，嫦娥卫星：万人一杆枪\n中国：从陈景润到王选、袁隆平\n\n2. 世界科技体制的形成古希腊：\n毕达哥拉斯，“伦理-政治学园”\n柏拉图：柏拉图学园：ACADEMY学院、研究院、学会\n亚里士多德：吕克昂学园\n亚历山大时期：谬赛昂学院，图书馆\n\n就科学而言，没有形成集体系统的研究，没有形成共同体，没有形成完整的体制\n\n科学：近代科学\n\n体制：近代科学的体制\n\n英国皇家学会、法国科学院\n\n\n意大利-世俗大学\n8世纪开始，教堂建立寺院学校\n意大利波轮首先出现世俗的法律学校\n12世纪，加上医学院和法学院，成为伯伦那大学\n15世纪，欧洲共有80所大学，意大利20所\n1603-1630，罗马成立猞狸学社\n\n\n基础教育有7科：文法、修辞、逻辑、算术、几何、天文学、音乐\n世俗大学教师出现，处于外围和业余地位，有若干专门职位\n1400年，伯伦那大学教席数目：\n科学（自然哲学、物理学、占星学）3\n医学 11人\n\n\n\n英语-皇家学会（1660）\n皇家学会前身-无形学院\n非正式小组-哲学学会\n1660.11.28:英国皇家学会成立\n1662-1669:获得皇家各种特许证，英女皇成为学会保护人，称“伦敦皇家自然知识促进学会”\n\n\n世界首个有影响的科学家组织正式开始自己的历史\n\n皇家学会宣布科学的价值与功能，规定了科学活动的规范\n\n组织定型\n章程明确\n活动记录完整\n\n标志着科学活动在英国社会中得到正式承认，宣布了科学活动的体制化\n\n\n\n\n学会宗旨是促进自然科学的发展，是世界上历史最长而又从未中断过的科学学会\n皇家学会没有政府拨款，会员定期缴纳会费，每周固定集会\n1664年专门的委员会：机械69人，手工业35人，农业32人，天文学15人\n1665年，出版物直属刊物《哲学会刊》，开辟科学团体出版社杂志的先河，成为学术共同体形成与成熟的重要标志\n\n\n\n特点与局限性：独立团体，自主性强，成员混杂，业余科学，科学体制化的初步阶段，非职业化\n\n法国-科学院（1666）\n私人赞助科学，规模较小，不稳定\n科学考察、实验、仪器、原料费用增强\n科学家提议，建立由国家支持的专门机构—自然科学院\n国王：通过科学为王权增光\n1666年，法国科学院成立\n1699年，改组学会\n法国科学院的宗旨：鼓励与保护研究精神，致力于提高教育和出版物质量并致力于维护法兰西科学用语的纯洁性及其作用\n法国科学院由院士、外国合作院士和通讯院士组成\n\n\n历史上第一个“官办”科学机构\n经费国家提供，科学家专心致力于研究\n只吸收各领域的专门学者\n吸收国外著名科学家作为院士\n\n\n特点与局限性：\n仅限于少数高级精英分子\n院士有年薪和助手配置，由国家财政支持\n承担行政与管理使命：管理公共事务、处理市政、军事、教育及工农业方面的科学问题\n是一个管理机构而非纯粹的研究组织\n\n\n影响：\n开始独立科学研究机构的先例\n德国、俄罗斯、中国先后受其影响建立自己的国家级科学院\n法国科学院成立及制度成立标志科学可以成为有经济收入的专门职业\nRS会员交会费，法国科学院拿薪水\n\n\n\n德国-研究型大学\n德国大学19世纪演变为研究型大学，大学教师必须进行科学研究\n1917，蔡元培回国，大学不是神官发财的地方，是做学问的地方\n德国大学：猞狸正教授席位；青年学者可以授课，晋升必须有独立研究成果\n私人教师成立教授后备军。德国大学发展为现代以科学研究为主体的大学\n\n教学实验室的出现\nSEMINAR的出现：科学研究不再局限于精英科学家\n科学研究与工业结合\n\n\n\n特点与局限：\n大学没有系，只有教授席位\n教授与助教、研究生关系类似于企业主与雇主的关系\n助教难以开展独立自由的研究，科研人才成长受阻\n学科体系僵硬，不利于新学科发展\n\n\n\n美国-现代大学-研究生院-工业实验室\n美国大学：系的建立，系代表大学科，容量远大于教授席位；克服教授席位等级森严僵硬等问题；科学研究以课题为基础，比席位更加灵活，人员流动性强\n研究生院出现：哈佛，耶鲁，斯坦福，康奈尔；培养大批研究生；主要方式SEMINAR；直接把研究生带到科学研究的前沿；财政资助；奖学金\n工业实验室：贝尔实验室；企业提供雄厚科研经费与优越条件；加强科学研究与企业之间的相互交流，形成工业-大学联合体\n美国国家实验室：80多个部，局，委员会有半数以上设立科学研究机构；原子能委员会5大研究基地；NASA；科学家参与国家科学事业，与大学、工业形成三足鼎立局面\n大学科体制\n科学-技术一体化（国家工程研究中心）\n科学-工业一体化（企业博士后流动站，科学园，科学孵化器）\n科学-军事一体化\n科学-工业-军事一体化\n科研全球化（国际科学学会）\n跨国公司研发机构\n\n\n\n小结两种模式：\n\n分散性：英国、美国\n集中性：法国、俄罗斯\n集中性：中国\n中科院法律地位：国家知识创新体系核心\n\n\n\n3. 中国科技体制的历史演变\n国人对科学技术认识过程：\n\n1582，利玛窦，开始接触西方技术\n1607 徐光启 《几何原理》 逻辑严密\n李鸿章：三千年未有之变局，三年前未有之强敌！\n张之洞：师夷长技以制夷，中体西用\n陈独秀、胡适等：德先生，赛先生\n1956，毛泽东：向科学进军\n周恩来：实现四个现代化\n邓小平：科学技术是第一生产力\n江泽民：科教兴国\n胡锦涛：自主创新\n\n\n\n科学团体自主发展阶段\n\n\n\n1915，中国科学社成立\n1916，地质调查所成立\n社会现代人-人的现代化-观念的现代化\n中国第一位数学博士胡明复\n\n\n\n国家科技体制初步确定阶段\n\n\n\n1928，中央研究院成立（法国体制）\n1937，成立评议会\n1948，建立院士制\n1949，科技人员满打满算5万人，机构30多个\n\n\n\n旧中国科研机构的一元化改造\n\n\n\n1949，中科院成立\n1955，成立学部\n1950，中华全国自然科学专门学会联合会成立\n1958，国防科技委员会成立\n1958，国家科学技术委员会成立\n1958，中国科学技术协会成立\n\n\n\n新中国科学研究系统五大方面军\n\n中国科学院\n高等院校\n中央产业部门科研机构\n地方研究机构\n国防科研机构\n\n集中力量，形成拳头，进行突破\n\n新中国科技制简评\n\n特点：\n科技体制建立在公有制基础上，R&amp;D机构基本为国有\n科技体制建立的基点是依靠自己的力量，自主发展科技事业\n政府直接组织科研规范、计划的制定和实施\n中央政府是国家科学机制的中心\n科技体制是在不稳定模式中发展的，科技自身发展与对经济、社会的贡献两者始终难以协调\n\n\n优点：\n好钢用在刀刃上，集中力量打击歼灭战\n在国际封锁、国内资源稀缺条件下，这一体制能够将有限资源向战略目标领域动员与集中，迅速建立比较完整的组织体系和基础设施\n在当时历史条件下这一体制基本上是成功和有效的，两弹一星一潜艇\n\n\n缺点：\n是一个自封闭的垂直结构体系，科研单位对上级领导部门负责而缺少与社会及独立单位之间的横向联系。\n缺少一种公平的科技成果有偿转让机制，不利于研究成果扩散\n国家用行政手段直接管理过多，科研单位缺乏自主权\n科研机构自成体系、条块分隔严重，科技资源严重分散，也导致人员结构与知识结构僵化\n\n\n\n\n\n4. 当前中国科技体制改革简述\n科技体制改革试点阶段：\n\n\n\n背景：军事竞赛、经济竞赛\n1978，邓小平：科学技术是生产力等，陈景润报告\n1982，赵紫阳，经济建设必须依靠科学技术\n1980，中关村走向中国硅谷的起点\n\n\n\n科技体制改革全面发展展开阶段\n\n\n\n改革拨款制度，放松科研机构把管制\n落实“面向”、“依靠”，堵死一头，网开一面\n1985，《专利法》\n1985，深圳科技工业园创办\n1986，国家自然科学基金委员会成立\n\n\n\n科技体制改革调整深化阶段\n\n\n\n稳住一头，放开一片\n科技大战三个层次：面向经济主战场，发展高科技及产业，加强基础研究\n“面向”，“依靠”，“攀高峰”\n1993，《中华人民共和国科学技术进步法》\n1995，《关于加速科学技术进步的决定》\n1996，《中华人民共和国促进科技成果转化法》\n1994，中国工程院成立\n\n\n\n建设国家创新体系阶段：\n\n\n\n1998，中科院：《迎接知识经济时代，建设国家创新体系》\n1998以后，国家部委376个技术开发型研究院\n1999，《国家科学技术奖励条例》\n\n\n5. 当前中国科技体制改革主要措施中国科技体制主要目标：使科技人员作用得到充分发挥，使科学技术成果迅速广泛用于生产，提高科技生产力，促进科学技术和社会发展。改革围绕运行机制展开措施：\n\n在经费拨款方面：对从事不同类型工作的研究机构实行不同的拨款办法和管理办法，逐步减少事业费拨款而加大对项目的资助\n在研究所体制改革方面：\n政研职责分开，直接控制转间接控制；\n扩大研究所自主权，实行所长制\n鼓励研究、教育、设计机构与生产单位相互之间的联系合作\n鼓励技术发展型科技机构进入企业\n实行课题组长负责制\n\n\n在人才制度方面：促使研究机构更加开发，加强科研机构同大学与企业之间人员的信息的交流与横向联合\n在强调为国民经济服务的同时，继续重视基础研究。\n\n6. 当前中国科技体制改革的主要成效\n科技与经济结合方面取得了一定成效，并未根本解决（经济创新与科学创新）\n资源配置改善，但未优化（课题制）\n科学产出增加，质量有待提高（SCI）\n\n在组织结构方面出现新的生长点，但研究所作用削弱\n\n1980s，重点实验室，开放实验室\n\n1990s，工程研究中心，技术开发中心\n\n博士后流动站\n\n高新技术产业开发区\n\n民间科技机构，科技中介机构\n\n外商设计的科研机构（微软亚研院）\n\n吴明翰\n\n中国科技经历三次飞跃\n\n\n1956年制定12年科技发展远景规划，中国走上现代化轨道\n1978年全国科学大会\n当今时代自主创新，建设创新型国家\n\n\n\n\n\n7. 国家重大科技计划\n国家科技攻关计划\n1982年实施\n面向国民经济建设主战场\n中国累计投资最大，人员最多\n\n\n863计划\n4位重量级科学家：应用光学王大珩，核物理王淦昌，空间自动控制杨嘉墀，无线电电子陈芳允给中共中央写信，提出跟踪世界先进技术水平；国务院批准《高技术研究发展计划（863计划）纲要》\n有限目标，突出重点\n选择生物技术，航天技术，信息技术，激光技术，自动化技术，能源技术和新材料7的领域15个主题作为研究重点\n目标：\n在几个重要高技术领域，跟踪国际水平，缩小同国外的差距\n培养新一代高水平科技人才\n通过伞型辐射，带动相关方面的科学技术进步\n为下世纪初经济发展和国防建设奠定比较先进的基础\n把阶段性研究成果同其他推广应用计划密切衔接，迅速地转化为生产力，发挥经济效益\n\n\n缺陷：高技术，产业化\n\n\n星火计划\n1986，实施第一个依靠科学技术促进农村经济发展的计划\n宗旨：把先进技术引进农村，提高农村科技水平和生产率\n1994，重新确认第一批国家星火计划基地42个\n\n\n攀登计划\n1991年实施\n为了加强基础性研究制定的计划，“稳住一头”政策的重要实施\n实现科技的纵深部署，吸引一批学术带头人形成队伍，集中力量发展优势领域突破\n46个计划先后列入\n\n\n\n8. 单元总结\n古希腊情况-ACADEMY来历\n英法的不同科学体制类型，科学职业化\n德国研究型大学出现，seminar，科学实验室出现；美国大学中系、研究生院建立，工业实验室建立\n中国科技体制：五大主力军，四大紧急措施，优势与短处，改革的目标与主要措施，重大计划（863）\n\n科普的定位和职业化问题1. 背景\n\n弗兰西斯培根：知识就是力量\n阿基米德，牛顿，斯坦因门茨\n法拉第，哈雷，罗伯特\n贺麟\n阿福莫夫\n科普角色：培养人才，争取支持-公众理解，公众参与，协商（科普定位）\n英国给理工科学生开设科学传播课程\n钱学森科普印象\n\n\n2. 科学在中国普及的简要历程-国人眼中的科学\n\n利玛窦，1582，中国开始接触西方科学技术\n洋务运动-失败\n师夷长技以制夷\n明治维新\n德国“铁血宰相”皮斯麦评价日本人与中国人留学\n中央之国，方正之邦\n1905，科举制度废除，开始逐步系统学习科学知识\n三个变化：\n知识：四书五经—科学知识\n人：传统读书人—近代知识分子\n体制：科举制度—科学教育、研究制度\n\n\n1300年科学生态\n严复回国后考举人\n留学生一代，二代区别\n杨振宁感慨\n垄育之：现在船坚炮利的技术层面上，然后进入后面的声光化电知识层面，在深度到科学思想，科学精神层面\n新文化运动\n1915年\n赛先生—赛菩萨\n北京大学科学与民主雕塑：SD定个O\n\n\n1922，梁启超：国人对于科学态度存在三点根本错误\n把科学看的太低太粗\n把科学看的太呆太窄\n把科学看的太势力太俗\n\n\n建国后，1949，普及科学知识\n1951，科普协会宗旨：普及自然科学知识，提高科学技术水平\n1958，中国科协，6项基本任务：\n积极协助有关单位开展科学技术研究和技术改革工作\n总结交流和推广科学技术的发明创造和先进经验\n大力普及科学技术知识\n采取各种业余教育办法，积极培养科学技术人才\n经常开展学术讨论和学术批判，出版学术刊物，继续进行知识分子的团结和改造工作\n加强与国际科学技术界的联系，促进国际学术交流和国际科学界的保卫和平斗争\n\n\n高士其\n改革开放，以经济建设为中心，科学技术是第一生产力\n1980s，中国《养鸡500天》，美国《宇宙》\n赛先生—–赛财神\n樊洪业：“传统科普”特点，四个方面：\n第一，科普理念，是从主流意识形态的框架中衍生出来的。\n第二，科普对象，定位于工农兵。\n第三，科普方针，须紧密结合生产实际需要\n第四，科普体制，中央集权制之下的一元化组织结构\n\n\n90年代，提升全民科学素养\n国内伪科学泛滥，国外PUS兴起，美国2061计划提出\n1992，94，96，2001，03，05，07，09-10，2015，2018科学素养调查（0.3、0.2、0.3、1.4、1.98、1.6、2.25、3.27、6.2、8%）\n1999，全民科学素质行动计划（2049计划）\n2002，《科学技术普及法》\n2003，19专题“创新文化与科学普及”\n2006，《全民科学素质行动计划纲要》方针：“政府推动，全民参与，提升素质，促进和谐”\n2015，《深化科技体制改革实施方案》，2020我国公民科学素养比例：10%\n\n\n\n中国人眼中的科学：\n政府，科学技术是第一生产力\n公众，对科技信息感兴趣程度排第一位（83.19%的被调查公众）的是“致富信息，”(2003)\n\n\n86年前，梁启超：国人对于科学的态度存在三点根本错误：太低太粗，太呆太窄，太势力太俗\n\n3. 科普的定位\n科普定义：指学校正规科学教育以外的、主要通过大众传媒以及各类宣传、展示等方式传播科学知识，提高国民科学素质的社会教育活动。\n\n科普对于提高国民科学素质的贡献或责任？\n\n科普的角色：教育背后的影子？独立性？\n\n科学教育与科学普及的关系，学校教育是科学普及的基础，科学普及是学校教育的补充和延续。\n\n联合国《2002年人类发展报告》，1998年中国公民的中学净入学率仅为50%(美、英、法相应数据分别为90%、94%和94%)\n\n与科学教育相比，科普的对象及需求更加参差多元且变化复杂，手段非强制性，内容上难以系统化、统一化、按部就班地进行普及提高全体国民科学素质中的科学数育与科学普及：“亡羊补牢”还是“亡羊找羊”？\n\n科学知识无限，公众需求多元\n\n专业之外的专家 &#x3D; 公众？\n\n科学知识的确定性？\n\n最低的科学素养标准？\n\n远离公众生活工作实际，接受？-缺失模型？\n\n公众：参差多元、具体语境、变换复杂\n\nPCST-9各国代表所采用的传播名称：“公众理解科学与工程”、“公众理解研究”、“公众参与科学”、“人民科学运动”、“公众对科学的认知”、“公众对科学的意识”、“科学普及”、“科学对话”\n\n科学技术没有国界，但是科学普及却越来越需要和世界各国的历史传统、现实情以及自身需求结合起来其形式面对各国千整万别的从日常生活，到精神文化，到民主政等不同次的多元化需求，不断现出干姿百态的模式和形态\n\n英国：讨论潜在风险：印度：解决现实生存\n中国公众，致富信息\n发达国家公众，健康、环保\n\n\n对科学技术与公众关系的新认识\n\n公众角色：被普及者（空瓶子）、纳税人\n\n技术的社会形成(SST)\n\n技术预见(TF)\n\n公众参与科学\n\n技术的社会形成\n\n(SST: Social Shaping of Technology— Donald Mackenzie. Robin Williams\n线性模式(基研-应用开发-技术创新-经济增长)不符合科学技术发展的实际情況\n技术是如何在特定的社会条件制约（组织的、政治的、经济的、文化的）下形成或定型的\n技术的后果是来自社会的协商和解释，而不是来自技术自身的逻辑发展。\n自行车，运动工具一交通工具，电话（中国，导弹，飞机-兰德公司2016年4月建议TW用导弹防御，放年飞机、军）\n公众作为技术的使用者，消费者对技术的影响\n\n\n技术预见(TF: Technology Foresight):\n\nBen R Martin,“技术预见是对科学、技术、经济环境和社会的远期未来进行有步骤的探索过程，其目的是选定产生最大经济与社会效益的战略领域和通用技术\n不仅关注未来科技的自身推动因素，而且着眼于外部市场的求拉动作用，既包括对科学技术自身在机会的选择，也包括对经济发展、社会进步相关需求的识别：不仅关注未来技术对工业和经济的影响。\n日本(1970-2006)：科技界、政府、企业、公众\n公众是技术发展的利益相关者\n\n\n丹麦的共识会议（外行公众参与的共识发展会议）\n\n步骤：选题、组建指导委员会、征集志愿者，第一次预备会、组织专家小组、第二次预备会、公众讨论会、广泛讨论征集意见\n专家提供专业背景文献资料，回答询问问题给出意见和建议，更正报告表述性错误（保留公众小组对报告内容的完整控制权）\n公众了解、咨询、提问、起草撰写报告，公众在科学技术问题或相关问题领域的评估中扮演重要角色”，“外行公民扮演关键性角色”——科学、科学家成为背景\n\n\n技术的社会形成(ssT)\n\n公众作为技术的使用者，消费者对技术的影响\n技术预见：公众作为利益相关者\n公众参与科学：公众作为政策参与者\n澳大利亚科学对话，科学家与公众6：6，丹麦的共识会议，科学、科学家成为背景\n\n\n公众角色：被普及者、纳税人有权了解（均一化、同质化）\n\n公众的角色、身份需要引入新维度：科学技术的使用者，消费者，利益相关者，决策参与者\n\n\n以公众科学需求为导向，提供公众需要的知识（针对性）\n\n\n4. 科普的职业化\n传统观点：\n\n1985年《英国：公众理解科学》：“每一个科学家的一个职业责任就是促进公众对科学的理解”，并希望科学家“真正认识到这是你义不容辞的工作”\n1986年，美国西格玛希( Sigma X)科学研究会在庆祝其成立一百周年时提出，让公众理解科学技术是今后一百年间科技界最应首先考虑的问题\n1999年，美国科学促进会主席格林伍德在美国科学年会上呼吁美国科学家“到美国各级学校兼职，直接参与加强科学教育和促进公众了解科学的工作\n2000年，在中国际科普论坛上，中国科协主席同光召指出：“广大科技工作者是开展科普工作的主要力量。坚持不懈地开展科普工作，是科技工作者义不容辞的责任。”\n\n\n学者观点\n\n2010，PCST-11（印度）后续研讨会主题目：“培训科学家与媒介对话”\n高士其：“科学普及是科学工作者的重要任务之一，只有把科学研究和科学普及相互结合才是一个完整的科学工作者。”\n作为科学传播链中“第一发球员”的科学家们应当承担起科学普及的主体责任，多次发出了“科学普及太重要了，不能单由科普作家来担当”的呼吁\n钱学森建议，研究生、博士生学位论文加一个副篇，用通俗语言对行外人讲清楚自己的研究题目\n\n\n大众传播学理论中有一个基本的信息传播模经过传播模型，包括信息传播者，信息，传播渠道，信息接受者四个基本要素：即模型1:\n\n信息传播者→信息→传播渠道→信息接受者\n信息生产者等于信息传播者\n\n\n科学家→科学知识→传播渠道→公众\n\n三下乡：“文化、科技、卫生”进多村\n\n四进社区：“科教、文体、卫生、法律”进社区\n\n科学家科普非常态化、追求科学家名声、追求新闻效应，科普工作形式化、脉冲式的运动式的\n\n科普内容、方式的变化\n\n媒体，“科学”成为文字游戏的对象，通俗性（可读性）、时效性、新闻性等都高于科学性\n\n\n信息传播者→信息→传播道→信息接受者\n\n信息传播者：科学家？编辑记者？作家？\n信息：科研论文？科技新闻（科普创作）？\n2000,“通常认为科普创作者是主要的科学普及工作者，现在看来科学传播的主体可能主要是媒体科学传播工作者”\n2002,“当前科学传播系统中有5个主体，即科学共同体、政府、媒体、公众以及非政府组织”\n\n\n模型2:\n\n科学知识生产者&lt;-&gt;信息①&lt;-&gt;科学知识传播者&lt;-&gt;信息②&lt;-&gt;传播渠道&lt;-&gt;科学知识接受者\n“科学知识生产者”和“科学知识传播者”的区别\n信息①和信息②的区别\n传统的科学家（科学知识生产者）与公众（科学知识接受者）之间的直接交流渠道仍然存在\n\n\n\n\n(1)科学家不应是当今科普的职业主体。在科普主体中，“科学知识传播者”应属于其主要的职业化队伍，包括科技传媒、科普创作、科技展览、科普活动等\n\n(2)科普作品应建立自己的评价体系，不应作为科学界的科研成果来评价。由于两者在语言规范、评价标准，交流对象等方面在在着诸多差异，因而科学界也始终难以认同科普类作品作为传统的科研成果\n\n(3)科普不应当作为科学家的硬性的职业要求。由于科学普及正逐渐发展成为一个独立的职业，其规范和评价与科学家科研工作会有本质不同。\n\n当代科学家的科普责任：\n\n把“科学家”作进一步的区分：科学家个人和科学家组织，分别探讨二者的科普责任有助于认清并进而缓解当前存在的尴尬局面。\n科学家个人即指作为个体的科研工作者，\n科学家组织则小到科学研究的课题组、实验室，大到科研院所、科技协会，直至整个科学共同体\n就科学家个人而言，针对每一位科学家在科普方面提出，职业上的工作要求、甚至量化的考核指标是不现实的，但作为一种观念倡导和一份责任上的提醒，注意提高其自身的科普意识和能力是必要的。\n科学家组织，除科研经费庞大、资源丰富、设施齐外，还有复杂程度不同的人员层次结构，除科学家(竺可桢、华罗、苏步青、张开逊，三人行)外，包括相当比例的如学术秘书、各级科研助手、研究生、各类科研期刊编辑、网络、管理、学会组织人员等，教育、人事、宣传、综合服务、工会等部门行政人员（也具有科研或科学教育背景，甚至由一线科学家兼任)\n相对而言，由于科学家团体在经费、人力、设施等方面都有较为充分的资源保障和更大的选择空间，因而其科普责任可以比较明确的进行量化规定和评估\n\n\n\n5. 单元总结\n科学家是科学知识的最初供给者：提高国民科学素质水平的主阵地在于学校科学教育，面向社会公众的科学普及的主渠道在于大众传媒：而科教的改革实践、科普的深入开展都离不开科学家的积极参与。科普需要协调与科研、教育、大众传媒相互之间的关系，建立密切的交流协作机制，进一步明确自己的角色定位。\n在提高全体国民科学素质的目标下，只谈科学普及是远远不够的：再科学规划中，只谈科学家的责任和作用也是远远不够的。\n相对于科学教育，科普更应以公众的各类科学需求为导向，建立高效的响应机制，提高国民科学素质的目标对于科普并不合适。\n当前科普的职业化应体现在两个方面，一是科学共同体外部的科普职业队伍建设（主要部分），二是科学共同体内部的科普职业队伍建设。\n从科学传播的角度看二者既有相互独立的地方，更有在传播链条上的依存合作关系。\n职业化的科学普及无疑将为促进科学的传播以及科技与社会的和谐发展带来一个全新的局面，也将更加需要科学家的积极投入和配合，而绝不意味着科学家退出科普领域。\n1897，“科学”一词由康有为译自日语，1905废除科举制度\nPUS:公众理解科学（Public Understanding of Science）\n《全民科学素质行动计划纲要(2006 2010-2020)》方针：“政府推动，全民参与，提升素质，促进和谐”\n丹麦“共识会议”的全称：外行公众参与的共识发展会议\n三下乡：“文化、科技、卫生”进乡村\n四进社区：“科教、文体、卫生、法律”进社区\n我国当前公众科学素质水平：8%\n\n科学共同体：分层与奖励1. 科学共同体与范式\n共同体( COMMUNITY)定义：通常译为“社区”，是社会学中的一个重要概念，一般指若干社会群体(民族、家庭等)或社会组织(机关、团体等)聚集在某一区域里，形成一个在生活上相互关联的大集体\n\n科学共同体( SCIENTIFIC COMMUNITY)定义：\n\n英国学者坡兰依，1942，“科学的自主性”：把全社会从事科学研究的科学家作为个具有共同信念、共同价值、共同规范的和群体，以区别于一般的社会群体组织。\n库恩、普赖斯、默顿\n库恩，1960S-70S《科学革命的结构》，《必要的张力》：“科学共同体是由一些学有专长的实际工作者所组成。他们由所受教育和训练中的共同因素结合在一起，他们自认为也被认为专门探素一些共同的目标，也包括培养自己的接班人。”\n科学共同体是科学认识的主体：科学家个人→科学家集体\n“科学研究尽管是由个人进行的，而科学知识本质上是集团的产物，如不考虑创造这种知识的集团特殊性，那就无法理解知识的特有效能，也无法理解它的发展方式。从这一点说，我的书是属于社会学的，但也绝不允许这个问题离开认识论。”\n通过科学共同体的研究把科学的认识论方面与社会学方面有机的结合了起来，使科学社会学发生了重要变化\n\n\n\n\n科学共同体特点：\n\n由从事实际工作的科学家组成。\n共同体组成分层次的：学科，专业，方向，研究领域\n专业一致的根本基础：专业教育相同，对专业问题的看法相似\n有共同的社会关系\n有共同的范式\n\n\n范式(PARADIGM)：\n\n有20多种不同的提法\n主要是指科学的认识标准以及科学活动。\n世界观：免子变成狐狸？\n科学成果、概念、原理、方法\n实验程序、实验仪器\n学科模式、活动规则、行为方式\n一种科学的传统\n\n\n前范式阶段：\n\n观点林立、众说纷纭\n同一域的科学家没有共同信念，没有公认的学科研究方法和评价标准，没有主导的理论学说\n同一领域科学家无法相互协作、相互交流，从而形成不了共同体\n\n\n常规科学阶段：\n\n某一范式对一定时期的科学研究确立了支配的地位时，科学发展进入常规阶段。\n科学家主要从事说明、完善、捍卫范式的研究，不再发明新理论。\n判定重大事实：使事实更精确化\n理论与事实更加相符\n理论的细化、形式化、完美化。\n科学发展进入高度累积的阶段\n\n\n后范式阶段：\n\n反常的情况不断出现，难以用常规的理论和方法解决\n既不能排除，也不能同化。微粒说不能解释光的衍射现象。\n反常影响到范式的基本原则时，常规科学陷入危机之中。\n科学共同体内部开始出现不同的意见和声音，理论修改越来越缺乏一致意见。\n新理论、新方法、新标准开始建立，旧的范式逐渐瓦解。\n\n\n新范式出现：\n\n住往由学科领域里的新手提出标新立异的观点，并常常遭到旧范式的抵制，\n可能同时出现多个新的范式，相互之间形成竞争，最后或者统一、或者并存，形成几个科学共同体——产生不同的学派\n新的范式经受住挑战，解决新的问题，包容旧的范式的内容，最后获得胜利\n\n\n范式与科学共同体：“粘合剂”\n\n范式为共同体的成员提供理论和方法上的信念\n范式给出新理论、方法的标准，成为共同体的进入门槛\n范式为科学共同体的交流提供了共同语言。为共同体下一代培养提供了内容标准\n为共同体研究提供新的起点的平台，推进科学持续发展范式使得科学共同体独立于外部，其自主性得以保护\n\n\n\n2. 科学共同体的形式形式：\n\n内在形式：学派，无形学院\n外在形式：学会，研究所，大学\n\n学派( SCHOOL)：\n\n是科学家的一种特殊的创造性联合，往往由一代甚至几代具有很高学术水平和技能的科学家团结在一个或者几个科学大师周围，在某一研究方向上进行创造性的科研工作。\n日心说、地心说\n水成论、火成论、突变论\n微粒说、波动说\n燃素说、氧化说\n\n学派形成的条件\n\n以共同的范式为基础\n学派是不同范式在竞争中的科学社会组织的表现形式。\n当科学理论内部显现危机时，不同学派的出现为科学理论的发展进步提供了新的生长点，扩展了理论领域和理论方法。\n\n\n以学术权威为核心\n学术权威为学派范式的理论基础做出了根本性贡献。\n(1)与传统理论、观点、方法有明显的区别\n(2)贡献是奠基性的，在此新方向上后来者可以有大量值得探讨的问题，从而形成共同的学术团体一学派\n\n\n以学派创始人为核心的创新集体\n学派内部有结构，学术权威为核心，周围有追随者、合作者、拥护者。\n师生关系是学派的基本结构\n形成学术图层：\n(1)核心是学派大师、领袖；\n(2)学派大师直接领导下的科学家、学生；\n(3)在学派基地外，但认同学派的观点和范式\n\n\n\n\n\n学派的功能\n\n培育科学新生长点的基地\n学派是新思想的孵化器、庇护所：如罗瓦的群论、孟德尔的遗传理论？\n学派为新理论提供了生存空间，造成适宜的学术小气候\n学派成员相互激励、交流，形成群体竟争优势，可与传统学派抗衡。\n\n\n是培养新一代科学家的摇篮\n“大科学家是大科学家挑选和培养出来的”\n在研究风格和研究方法上的影响一隐性知识，“渔”非鱼也\n卢瑟福指导过的科学家有11人获得诺奖，玻尔手下有7人获奖。\n美国1901-1972,92位获奖者中有一半以上(48)其导师也是诺奖获得者\n名师一高徒\n\n\n不同学派的存在是科学发展的组织保障\n不同学派的出现为科学发展创造了一个良性竞争的环境。\n为不同的学术观点提供了发表的机会\n保障了学术研究的自由。\n\n\n\n学派领袖和学派风格：\n\n卢瑟福：独立思考、首创精神、个性（博士生）\n\n尼尔斯玻尔：“哥本哈根精神”\n\n学派领袖的阻碍作用：马太效应\n\n科学学派的特征\n\n(1)科学带头人一大科学家\n(2)科学带头人的教育技能，鉴定才能的能力\n(3)特殊的科学气氛\n(4)科学带头人的高品质，个人感召力\n(5)学生的独立思考与首创力\n(6)研究方法与解释现象的观点\n(7)学生与科学带头人的经常交住与密切联系\n(8)存在大批有才能的学生\n(9)课题的统一\n(10)独特的思维方式\n(11)具有新奇的科学思想\n(12)创立新的科学方向\n\n\n无形学院( INVISIBLE COLLEGE)\n\n17世纪波义耳，“看不见的学院”（自发的、非正式的科学团体）。\n普赖斯，将“无形学院”概念从科学史移植到科学社会学。认为科学共同体中有两类组织，一是正式的、有组织的科学家集团，一是非正式的、非组织化的科学家群体，后者主要通过科学交流、信息网络连接在一起，被称为无形学院。\n默顿，“从社会学意义上，可以把“无形学院解释为地理上分散的科学家集簇，这些科学家处在较大的科学共同体中，但是，他们彼此之间在认识上的相互作用比其他科学家的相互影响更加频繁。”\n克兰，“社会子”，重视科学中心的非正式社会组织在科学进步中的作用。\n\n\n现代科学知识发展的两种反向趋势：\n\n高度专门化：走向封闭性，科学共同体之间交流困难。\n接受外部的学术思想：不同学科相互交叉和渗透，走向开放\n开放性的表现即是无形学院\n\n\n无形学院特征\n\n具有共同的专业研究领域。\n具有趋同的学术思想和理论倾向\n地域上存在空间跨度\n社会结构是松散的、非正式的。\n科学家之间主要通过信息媒介、交流网络来沟通，形成复杂的网络系统。\n通过无形学院网络更容易了解研究前沿。（正式系统往往有滞后效应）\n\n\n无形学院与科学交流：\n\n普赖斯：无形学院是科学家（作为信息传递者）通过信息交流形成的看不见的集体。\n无形学院作为科学共同体的另一种社会形态，其重要指标是：无形学院有独特的、富有个性化的科学交流的信息网络。\n科学家只进入正式的科学交流网络是不够的：学生要与导师打成一片。\n\n\n外在形式：学会、研究所、大学\n\n学会\n\n科学共同体最为广泛的社会外在组织形式。\n基本覆盖各国的科学共同体成员。\n主要任务是学术交流。\n各种学会常常是各国政府领导科学事业的思想库和咨询库。\n\n\n大学\n\n传统功能是教书育人。\n现代大学还有科学研究功能一研究型大学\n教师通过科学研究，发展新知识、传播新知识\n服务社会、国家利益\n\n\n国家科研组织系统\n\n国立科研机构：侧重于关系国计民生、国家安全的综合应用研究及其相关基础研究。\n企业研发中心：侧重于开发研究及相关的应用研究\n大学：侧重基础研究\n非政府、非营利科研机构：对上述各部分进行补充\n\n\n\n3. 科学共同体的社会分层\n分层定义：\n\n分层概念源于地质学，在地质剖面中可以看到地质发展史上不同时代的岩石具有不同的形状，形成若干岩层。\n分层即是根据地质学知识对岩层进行鉴定以判定生成年代的过程。\n\n\n社会分层定义：\n\n由于社会成员之间有差异，可以根据差异程度把社会成员划分为若干不同的等级，形成社会的等级结构。处于不同等级地位上的社会成员就自然形成了不同的社会层次\n社会分层就是对人进行分类，依据一定的标准去衡量人们在整个社会生活和社会关系中的不同位置，从而把社会中的人划分为不同的阶层。\n\n\n社会分层的标准\n\n(1)根据人的自然属性：年龄、性别、种族、肤色等。\n(2)根据人的社会属性：地位、教育程度、收入水平、权力、声望、行业、单位等。\n北大学费：30万-150万\n\n\n\n\n现代社会的分层结构：\n\n梨状体：处于最高层的人是极少数，但处于最低层的人也是少数，相当大部分的人处于中间位置。这在农业社会也是如此。\n社会越发达，处于中间位置的人（中产阶级）就越多，处于下层的人就越少\nBNU英语老师：只要有工作就是中产阶级\n鲁迅：社会三种人，维护传统-维持现状-改革创新\n\n\n朱克曼统计\n\n金字塔模型\n\n1,美国诺贝尔奖获得者\n13,美国科学院院士\n2400,获得过博士学位的科学家\n2600,载入《美国男女科学家》词典的科学家\n4300,载入《科技人员登记册》的科学家\n6800,自称的科学工作者\n处于顶端的科学界超级精英于底层科学家比例：1：486\n底层科学家通过高层道路极为艰难，机会很小\n\n\n年龄：\n\n1.科学是年轻人的事业。\n科研人员中25-44岁所占比例远高于一般职业雇员的相应比例。\n\n\n2.条理化程度高的学科年轻人出成果早，成名早\n3.角色顺序\n科学家的4种角色：A研究，B教学，C行政管理，D鉴定和评审（守门员）\n科学家的科学生涯早期主要从事研究、教学工作，晚期渐渐从事行政管理和评审工作\n科学的特征之一是老年人进行管理一科学中的“老人政治”。\n\n\n\n\n性别：\n\n妇女进入科学界人数较少\n不同学科比例有所不同\n科学高层次中男女比例差异显著\n智商调查显示：博士学位获得者中女博士智商平均值稍高于男博士\n\n\n女性科研生产率低有社会因素\n流动性差\n动力问题\n性别歧视\n\n\n\n\n学术声望（知名度）：\n\n1.是一种无形的社会承认，是科学家们自愿作出，受非科学因素影响小。\n国奖部奖不如学人的“心奖”（心服）\n金杯银杯不如学界的“口碑”（口服）\n\n\n2.科学家发表论文数及被引证次数是知名度的经验测量指标\n科学家论文生产率的逆二次幂规律（洛特卡定律）：发表N篇论文作者人数与1&#x2F;N平方成比例：相应发表一篇论文100人，2-25，3-11……\n高水平科学家论文被大量引用，大多数论文被忽略\n\n\n\n\n学术背景\n\n1.名师出高徒：约一半美国诺贝尔获得者导师也是诺贝尔奖获得者\n2.著名机构的的优势积累，倍增效应\n\n\n\n4. 科学的奖励制度：优先权\n\n近300年的科学史上充满了大大小小的关于科学发现和发明的优先权争论。\n17世纪，伽利略：《对巴兰德卡帕的谁谤和款诈的答辩》《试金者》\n17世纪，牛顿\n与胡克，光学、天体力学领域\n与莱布尼兹，微积分发明（利用皇家学会会长权力中止相关调查委员会工作）\n胡克与惠更斯，螺旋弹簧天平的发明权\n18世纪，卡文迪许，普利斯特列，拉瓦锡：水的成分的组成\n亚当斯，勒维列：海王星\n琴纳，皮尔逊，拉包特：接种牛痘\n19世纪，法拉弟，武拉斯顿，戴维：电磁感应现象\n拉格朗日，高斯，伯努利家族，柯西等数学领域\n20世纪，新特点：优先权之争出现在科研过程中了。\nDNA发现过程：1953-1962\n克里克、沃森；维尔金斯，弗兰克林；泡林\n\n\n\n优先权之争原因：\n同时发现必然导致优先权争议？\n能量守恒定律：焦耳，迈尔，禁尔母霍，格罗夫，柯尔丁，卡诺，法拉弟，李比希，(相互谦让，达尔文华菜士)\n默顿，科学体制本身的规范要求所致\n创新是科学界的最高价值\n原因不在于人类本性和个人品质，这仅只增加一些色彩和音调\n科学体制内在要求使得科学家为维护自己的发明而斗争\n对优先权的承认导致奖励制度的出现\n\n\n定义：科学共同体对于科学家所作贡献的肯定和承认的体系。包括各种名目的，奖励和报酬制度。\n牛顿时代，达尔文时期，爱因斯坦世纪\n哥白尼体系，胡克定律，哈雷彗星，普朗克常数\n古生物学之父一居维叶，电工学之父ー法拉弟，实验心理学之父一冯特\n\n\n金钱：在科学报酬制度是不重要的，“科学王国基本的硬通货是承认“\n退却主义：孟德尔，迈尔\n\n\n科学体制承认：主要是在科学的正式交流渠道中实现的。\n三个方面：论文和著作发表，被引证率，荣誉奖励\n两个类别：实际职位，名誉承认\n承认与科学的生产率正相关：大科学家一般是高产的\n研究工作的质量比单纯的数量要重要的多\n\n\n学院科学：纯科学\n规范： CUDOS&#x3D; kudos\nCommunalism 公有主义\nUniversalism 普遍主义\nDisinterestedness 无私利性\nOriginality 独创性\nOrganized skepticism 有条理的怀疑主义\n\n\n后学院科学：产业科学\n规范： PLACE\nProprietary 所有人的(专利的、所有权的)\nLocal 局部的，地方的\nAuthoritarian 权威的\nCommissioned 定向的，任务导向的\nExpert 专门的\n\n\n学院科学的奖励：精神性、荣誉性\n同行承认\n命名\n称号\n荣誉\n精神\n\n\n后学院科学的奖励：多元、多样、广泛\n多元：国家、企事、NGO、个人（饶毅个人放弃院士评选）\n多样：荣誉、实物、金钱、股权、职位\n广泛：基研、应用、开发\n物质为主\n精神为辅\n\n\n国家最高科学技术奖\n国家自然科学奖\n国家技术发明奖\n国家科学技术进步奖\n中华人民共和国国际科学技术合作奖\n最高科学技术奖、国际科学技术合作奖不分等级\n自然科学奖、技术发明奖、科学技术进步奖分一等奖、二等奖\n自然科学奖、技术发明奖、科学技术进步奖每年奖励项目总数不细过400项。\n\n\n\n\n国家最高科学技术奖(2000—)\n(1)在当代科学技术前沿取得重大突破或者在科学技术发展中有卓越建树的\n(2)在科学技术创新、科学技术成果转化和高技术产业化中，创造巨大经济效益或者社会效益的。\n2000年度吴文俊、袁隆平\n2001年度王选、黄昆。\n2002年度金怡濂。\n2003年度刘东生、王永志。\n2004年首次空缺\n2005年度叶笃正、吴孟超\n2006年度李振声\n2007年度闵恩泽、吴征镒\n2008年度王忠诚、徐光宪\n2009年度谷超豪、孙家栋\n2010年度师昌绪、王振义\n2011年度谢家麟、吴良镛\n2012年度郑哲敏、王小谟\n2013年度张存浩、陈开甲\n2014年度于敏一氢弹\n2016年度屠呦呦一三无科学家-2015诺奖\n\n\n\n\n国家自然科学奖\n在基础研究和应用基础研究中阐明自然现象、特征和规律，做出重大科学发现。\n重大科学发现：\n(1)前人尚未发现或者尚未明\n(2)具有重大科学价值\n(3)得到国内外自然科学界公认\n\n\n\n\n国家技术发明奖\n运用科学技术知识做出产品、工艺、材料及其系统等重大技术发明。\n重大技术发明：\n(1)前人尚未发明或者尚未公开\n(2)具有先进性和创造性\n(3)经实施，创造显著经济效益或者社会效益。\n\n\n\n\n国家科学技术进步奖\n科学奖励的问题：“第四十一席位”\n朱克曼，《科学界的精英》\n评议人的重要性：守门员\n\n\n\n5. 科学的奖励机制：马太效应\n马太效应\n马太效应的基础\n棘轮效应一科学家一旦做出了某种成就，获得了某种声望，他以后就不会再跌回原来的水平和位置，如同棘轮装置一样\n诺贝奖获得者将终生带有这份荣誉，其光辉只可能由更光辉的新星出现而相对逊色，但其本人决不会倒回去。\n棘轮效应引导科学家不断继续努力，获得更大的成就。\n科学荣越高，科学共同体的期望值也越高，形成压力和动力。\n\n\n荣誉背景增强\n能见度\n\n\n荣誉背景的反溯增强作用：\n无名科学家经过不断努力，一且成名，人们会去回溯他以前的工作，其早期微不足道的工作也可能会受到重视和追捧、赞誉。\n成名较晚的科学家，在早期其成就被低估了，在后期其成就又被高估了。\n\n\n马太效应的正面作用：\n促进交流，提高能见度\n阅读有声望的科学家的论文\n新手最好先与名家合作发表研究成果，否则其成果可能永不见天日\n\n\n单位优势积累，群体效应\n进入优秀单位，加入先进群体\n自我实现\n运动队的冠军效应：信心一北大，哈佛的驴\n\n\n\n\n\n\n\n6. 单元总结\n科学共同体、学派、无形学院\n科学社会分层：金字塔模型\n科学家的职业顺序\n科学家论文生产率的逆二次幂规律\n科学界的最高奖励是承认\n国家最高科学技术奖\n\n科技政策与创新1. 科技政策与创新定义\n定义\n在英文文献里，科技政策最早主要是指科学政策( Science Policy),原因是在市场经济发达的国家，技术发展基本上是私人企业的行为，政府本身并不直接支持企业，政府的科技政策也因而主要集中在科学发展方面。但在实际用法中，科学和技术常常连在一起科学政策常常包含着应用科学以及技术发展，也就变成了科技政策。\n科技政策有时用 Science and Technology Policy全称表示，有时用 Science Policy表示。\n法国学者让·雅克・萨洛蒙（Jean- Jacques Salmon)：“政府采取的集中性的措施，一方面为了鼓励科学和技术研究的发展，另一方面为了利用这些研究的结果实现所期望的一般的社会、经济和政治目标\n”为科技的政策“和”利用科技的政策“\n将科技活动与政治、军事、经济和社会发进行系统整合\n美国科技政策研究领军人物布鲁克斯（ Harvey Brooks)：科技政策议题分为两类：1.“为了科学发展的政策”，如支持和管理国家科学事业的政策、计划等；2.“包含科学因素的政策”，如非常依赖于科技因素的国家政治于管理议题\n科技政策的功能不仅涉及科学技术自身的发展，而且涉及科技的应用，从而势必覆盖非常宽广的领域(科研机构、大学、工业等)需要一个开阔的视野。\n科技政策议题不仅包括传统的国家安全、经济发展、社会进步、人民健康领域，而且包括环境保护、全球变化、电子商务、电子货币等新的、紧迫的问题\n科技政策与经济政策、社会发展政策、教育政策等一起构成国家政策的不可缺少的一部分。\n\n\n科技政策的涵义：\n科技政策是为促进科学技术发展以及通过利用科学技术为国家目标（国防安全、经济增长、社会发展、环境、健康等）服务而采取的集中性和协调性的政策，是科学技术与国家发展的有机整合，通常在国家层面上使用。包括：对科技活动进行指导和管理的法律、法规、措施\n\n\n科技政策两个相互补充的部分：\n为了科学的政策(Policy for Science);\n通过科学的政策(Policy through science)\n(1)为了科学技术本身发展的科技政策\n(2)通过利用科学技术研究的成果为国家目标服务的科技政策\n\n\n科技政策的核心问题\n(1)科学技术政策的制定\n三个层次：国家战略层次，发展计划层次，管理实施层次\n\n\n(2)科学技术资源的分配：科学技术资源及分配的基本原理和依据\n(3)对科学技术的规范和控制\n科学技术的奖励制度\n2020,国家科技最高奖500-800万\n但是，科学共同体硬通货，助教工资\n\n\n\n\n当前全球性科技政策议题\n越来越多的科技政策议题包含科技与社会互动的内容，涉及到广泛的公众利益。\n(1)国家安全领域：大规模杀伤武器核查：信息安全，个人信息安全\n(2)经济发展领域：电子商务和网络经济，国际贸易，知识产权，电子货币\n(3)卫生健康领域：食品安全，流行病研究，动物实验，风险控制\n(4)环境一生态领域：全球变暖，化学品污染，核辐射，国地区环境争端\n\n\n\n起源\n\n第一次世界大战，科学与国家开始紧密连接起来\n1915年，英国建立了科学与工业研究部，开始了公共支持基础研究工作。\n1936年，法国政府设立负责科研事务的国务次长职位。\n第二次世界大战，科学技术与国家关系变化的分水岭\n科技在国家发展中地位上升\n二战后：\n美国需要什么样的科技政策？主要争论的议题有三个：\n(1)需要决定科学家在国家政策中的适当位置(总统科学顾间，863)\n(2)需要发展关于基础研究的政策\n(3)需要解决与国家安全政策相关的难题，特别与核武器相关的难题\n\n\n军方主张应该在军事相关的研究中起决定作用\n新政派议员主张需要有一个强有力的联邦机构管理技术定向的研究。\n基础研究被视为是附属函、次要的从属地位\n美国科学研究发展局(OSRD)主任万尼瓦布什及一些科学家为代表的科学共同体提出了新的富有生命力的思想路线：支持基础研究：控制原子能；把科学家放在国家决策中的重要位置\n\n\n1944-11-20，总统的问题：\n罗斯福总统要求布什就如何把战时的成功经验广泛用于即将到来的和平时期的问题提出意见，特别是针对以下四个问题：\n(1)在维护国家安全的限度内，为了把战时工作中科学知识所作的贡献尽快公之于世，应该做些什么？\n(2)特别是关于科学向疾病作斗争，国家如何组织研究，把战时取得的进展继续下去？\n(3)政府怎样促进和帮助公立与私立机构的研究活动？\n(4)国家如何更好地发现和培养美国青年人的科学才能，以确保将来的科学研究水平及得上战争期间达到的水平？\n\n\n\n\n1945-7-5，万尼瓦尔・布什：Science-the Endless Frontier\n国家安全、人民健康、公共福利需要新的科学知识需要科学进步\n联邦政府应承担责任，对科学进行强有力的投资，促进产生新的科学知识，培训青年人的科学才能\n建立一种维护科学自由探家( freedom of inquiry)保障长期稳定支持的新的机构-国家科学基金会-1950-NSF( peer review，中国-NSFC-1986稳住头）\n提出基础研究是人民健康、公众福利和国家安全的源泉，保证科学的自主性和自由就会带来繁荣和利益，赋于了科学自主性新的含义。这种自主性模式兼自主性和责任，被称为“为繁荣的自主”(autonomy-for-prosperity）\n\n\n万尼瓦尔・布什：《科学：没有止境的前沿》\n奠定了国家支持科学和教育发展的思想基础\n标志着国家科技政策的正式出现，对美国及大多数发达国家科技政策的影响达半个世纪(1994 Science for National Interests)。——现在则是各领风骚二三年，专家—体系\n1945-9-6，美总统杜鲁门在国会演讲：“今天，如果不充分发展其科学技术资源，没有一个国家能保持界的领位。\n1988，邓小平“科学技术是第一生产力”\n\n\n二战以前，联邦政府基本上没有支持基础研究的专门计划\n布什思想的成功，其自由探索的思想是与自主性原则联系在一起的，与研究活动的在内质量控制，研究与教育和培训的结合联系再一起，这些原则不仅被NSF，而且也被NIH及其他一些资助机构采用，成为科学健康发展的保证\n缺点：线性发展模式\n\n\n\n\n历史\n\n1945-1957，科技政策的体制化时期\n标志是二战后所有工业化国家都接受了政府应当积极介入科学技术的研究和发展的思想\n战期间在雷达、原子弹、电子学等领域建立起来的大规模、多学科的严格的研究计划组织模式对战后各国科技发展产生深远影响\n美国加强国立实验室建设：橡树岭国家实验室、阿拉贡国家实验室、劳伦斯回家实验室等\n\n\n1950，NSF建立，经费不多，意义重大—科学究相对独立、自由，政治、军事干扰少；至今已经有170多项NSF资助的研究项目获得了诺贝尔奖\n1957-1969，军事化模式的新阶段\n1957-10-4，前苏联 SPUTNIK 一 洲际导弹\n1958-1-31，美国卫星上天，1957-1958，NASA成立，国防部成立高级研究计划：1958-11,《家家防卫教育法案》通过：NSF加强—多元化科技体制确立\n欧洲，1957欧洲经济共同体成立，欧洲原子能共同体成立。\n1963经济合作与发展组织(OECD)发表首篇科技政策报告，《科学和政府的政策》（ Science and the Policies of Governments)，第一次明确阐明了科学和技术政策的内容：基础研究，应用研究和试验发展三分法（基础研究 应用研究 开发研究）\n1969-7-12，阿波罗登月(美科学家担心？)\n1970-8，社会反思时期\n科技发展与核威胁、战争机器、环境污染等联系到了一起，科学技术受到各方面指责和攻击一科学技术至高无上的信条开始消退\n\n\n1971，OECD报告《科学、增长与社会：新的方向》强调需要对科技进行社会控制，把科技政策拓宽到整个政府政策部门。\n1971，美国癌症计划启动(民用科技计划)\n1972，国会技术评估办公室：否定登陆火星\n1972，联合国首次人类环境会议，罗马俱乐部《增长的极限》\n1980S，经济竞争时代\n欧洲、日本恢复并崛起（第二次珍珠港事件）\n日本注重技术预见\n军事技术向军民两用转移，政府开始介入民用技术的发展\n“竞争力”成为科技与经济政策的关键词\n企业竞争日益成为国家的竞争\n1985，欧洲元里卡计划(“我发现了！”)\n1980S末，国家创新系统(NIS)提出\n\n\n1990s以来，全球化与创新时代\n前苏联倒台，冷战结束\n1994，美国《为了国家利益的科学》，把国家利益和安全的概念从回防扩展到经社会、健康各个方面\n创新可出现在研究、设计、生产及营销的任何环节\n知识经济：直接建立在知识的生产、分配和使用之上的经济\n在生物、信息、纳米关键技术领域启动国家R&amp;D计划，基研、应用、技术日益交叉和网络化\n官—产—学加强合作。\n公众理解科学(PUS)、公众参与科学\n\n\n\n\n前沿\n科技政策研究是一个不同专业群体“诸侯制据”的领域\n科技政策研究是个学科交叉领域，又是一个实际性很强的领域。\n多学科交叉，实践性很强\n主要理论基础是经济学，政治学和社会学\n\n\n国家创新系统(NIS)的理论，揭示出科学、技术和创新之间存在着系统性的联系，说明创新是许多不同的行为主体(企业、大学、研究机构、政府、学会等)相互作用的系统行为，创新不仅依赖于具体行为者的表现，而且依赖于他们与创新系统中其他行为者之间的相互作用，包括科学、技术、组织、商业、金融和法律等一系列活动。\nNIS理论为科技政策提供新的视野和理论工具。如科技政策的传统理论依据是市场失效原理，即指单靠市场机制不能解决某些科技领域的最优资源配置，必须由政府来调控与支持\n还有“系统失效”，小布什的常春顾问一希拉里，一家两个“总统”\n\n\n官产学合作。创新成为经济可持续增长和响应社会需要的关键推动力。实践表明，创新常常需要官产学多方合作。一方面，许多商业上取得成功的高技术和根本性创新并不是来源于竞争的市场，而是公共资金对基础研究长期支持的结果，例如互联网的发明（美国海军司令部）：另一方面，要促进技术在社会上得到广泛的应用和扩散，需要私营企业的参与。因此，创新要公共部门、科研部门和私营部门或产学多方相互补充的能力，相互间需要建立伙伴关系\n三螺旋模型：政府、学术界（大学和科研院所）与产业界以经济发展的需求为纽带而联接起来，形成三种力量交叉影响、抱成一团又螺旋上升的“三重螺旋”的新关系\n技术预见。通过系统研究科学技术趋势和经济社会长远未来的需求，选择和确定可能产生最大经济和社会回报的新兴通用技术和战略研究领域的活动。\n需要深入研究的政策议题：\n(1)科技人才的需求与供给。不同行业、部门人オ求的环境分析，科技人才供给面临挑战。\n(2)改进科技劳动力市场，包括雇佣和薪制度改革、促进科技人才流动、全球人才竞争的压力和机遇等。\n(3)组织中的人才激励与管理\n(4)教育和培训计划改革，提高科学教育质量、改革高等教育课程、建立新的博士和博士后计划、促进研究人员流动\n\n\n科学与治理\n共识会议，科学沙龙\n\n\n国际科技合作-欧盟框架计划\n1984年启动\n设立科技目标，有限领域，主要活动方针，必须的责任，参与规划，资金分配等\n\n\n国际科技合作，中医药国际科技合作计划\n2006年\n中国科学技术发展自主创新战略的重要体现\n中医药有2000多年的历史\n目前使用人口最多、保存最完整，影响力最大的传统医药体系，共有12807种中药，8000余种中医药典籍，60000余处方。\n中医药学是以自然科学知识为主体，同时受中国古代哲学思想的深刻影响，并与人文社会科学知识相交融的医学科学\n中医药2个基本原则：整体观念+辨证论治\n中医药4个特点：简、便、廉、验\n现代化，国际化，文化传播\n基于现有韩方典籍的中药制剂品目许可规定，中药制剂根据11种现有韩方典籍中记录的韩方进行品目许可。\n中医药英文译名：\nTraditional Medicine\nTraditional Chinese Medicine\nOriental Medicine：中医药，韩国东医，日本汉方医学，越南医学\n\n\n2007-10,WHO《中医药学名词术语国际标准》：中韩、日等国学者共同努力4年编而成，共收词3543个。并用繁体字，为中医药走向全球标准化迈出重要一步\n\n\n回际科技合作-中医药国际科技合作计划\n中医药资源，挖掘、保护、开发、利用、推广、国际化\n中医药研发，科研、生产、敦育、培训\n中医药交流，人才交流、信息共享、文化交流\n政府间含作\n民间合作\n\n\n\n2. 中国科技政策\n\n建国以来，我国制定的若干中长期科技规划：\n“1956-1967年科学技术发展远景规划”\n“1963-1972年科学技术发展规划”\n“1978-1985年全国科学技术发展规划”\n“1986-2000年国家中长期科学技术发展规划”\n“1991-1995-2000年科学技术发展十年规划和“八五”计划”\n“全固科技发展“九五”计划和到2010年长期规划”\n“国民经济和社会发展第十个五年计划科技数育发展专项规划”\n“2006-2020年国家中长期科学和技术发展规划”\n\n\n1956-1，采取以任务为经，以学科为纬，以任务带学科的原则\n向科学进军的思想\n57项重要科学技术任务，带有关健意义的12个科学研究重点\n\n\n\n\n\n四大紧急措施：为发展无线电电子学，自动化，半导体和计算机技术这四个现代科学技术发展中关键作用的新学科领域，短时间内改变现状，接近国际水平。\n\n\n\n总体来说，规划所涉及的内容全面：规划的编制以科学家和科技人员为主：规划涉及的部门多：编制程序简单\n邓小平：没有两弹一星，中国就不能叫做大国\n陈毅，没有原子弹，说话不算数，把裤子当了\n川藏公路\n三线建设\n奠定大国基础\n\n\n《国家中长期科学和技术发展规划纲要（2006-2020)》\n到2020年，我国科学技术发展的总体目标是：自主创新能力显著增强，科技促进经济社会发展和保障国家安全的能力显著增强，为全面建设小康社会提供强有力的支撑：基础科学和前沿技术研究综合实力显著增强，取得一批在世界具有重大影响的科学技术成果，进入创新型国家行列，为在本世纪中叶成为世界科技强奠定基础。\n指导方针：自主创新，重点跨越，支撑发展，引领未来\n11个重点领域技术\n\n\n国家中长期科学和技术发展规划战略研究\n国家中长期科学和技术发展规划战略研究20个专题\n\n\n3. 科技政策与创新\n创新的含义\n今天的创新是一个更广泛的概念，可以涉及科学发现、技术发明、技术创新、市场创新、管理创新、组织创新、制度创新、思想和观念创新等\n创新的基本涵义是指技术创新：“是一个从新产品或新工艺设想的产生，经过研究、开发、工程化、商业化生产，到市场应用的完整过程的一系列活动的总和“\n创新活动本质上是一个经济过程。\n技术发明仅仅是创新的其中一个环节。\n创新的落脚点是创造效益\n\n\n创新过程的五代模式\n(1)基于R&amp;D的技术推动过程\n(2)市场需求拉动的过程（贝尔实验室）\n(3)整合了R&amp;D推动和市场需求拉动的结合模式\n(4)基于较强用户-厂商联系的一体化、平行模式\n(5)系统一体化和网络化模式（三螺旋）\n越来越将创新过程视为一个复杂的相互作用过程，简言之，创新不是一个独立事件，而是由许多事件组合在一起以螺旋式不断发展的，很难判断是哪一环节产生的创新结果或哪个因素造就了创新成功\n\n\n政府干预技术创新的合理性\n主要是因为在技术创新过程中存在“市场失效”问题，竞争的市场不是投资基研和最佳机制，必须由政府来支持。\n“系统失效”的问题，创新体系中各要素的不匹配或是过窄的专业化所形成的制度刚性、信息不对称以及要素流动等问题所形成的系统失灵。\n需要由政府对技术创新的方向、规模以及速度进行干预，使之朝社会收益最大化的方向发展。\n科技政策在创新中的角色：提高创新效率和增强创新能方，促进创新活动的大规模涌现。\n\n\n\n\n\n历史\n建设国家创新体系-1998年以后\n1998，中科院：《迎接知识经济时代，建设国家创新体系》\n1998年以后，国家部委所属376个技术开发型研究院\n1999,《国家科学技术奖励条例》\n1999,《关于加强技术创新、发展高科技、实现产业化的决定》\n\n\n现状\n在经费拨款方面：对从事不同类型工作的研究机构施行不同的拨款办法和管理办法，逐步减少事业费拨款而加大对项目的资助\n在研究所体制改革方面：\n政研职责分开，直接控制转间接控制；\n扩大研究所自主权，实行所长制\n鼓励研究、教育、设计机构与生产单位相互之间的联系合作\n鼓励技术发展型科技机构进入企业\n实行课题组长负责制\n\n\n在人才制度方面：促使研究机构更加开发，加强科研机构同大学与企业之间人员的信息的交流与横向联合\n在强调为国民经济服务的同时，继续重视基础研究。\n\n\n主要成绩：\n促进了科学技术与经济的结合：政策体系、项目合同制、技术市场\n科研组织结构出现了新的生长点：高新技术产业开发区、工程研究中心、企业技术研发中心、博士后流动站\n科技产出大增加：科研成果、论文、专利增加\n科技资源配置有明显改善：R&amp;D投入、基础-应用-开发研究比例\n\n\n主要问题：\n各方面科技力量比较分散，自成体系\n企业自主创新能力弱，创新意识差，远未成为技术创新的主体\n科技评价制度、激励人才成长、鼓励创新创业的机制不完善\n\n\n未来：\n在创新活动全球化背景下：\n参加游戏活动\n利用游戏规则\n修改游戏规则\n制定新的游戏规则\n\n\n1.加强自主创新，自主创新3种类型：\n(1)加大基础研究投入，加强原始性创新，努力获得更多的科学发现和技术发明，从源头上占据主动地位\n(2)促进各创新环节的密切合作，加强集成创新，使各种相关技术有机融合，形成具有市场竞争力的产业和产品\n(3)引进国外先进技术后，重点放在引进消化吸收和再次创新上\n\n\n2.鼓励企业成为技术创新主体\n发挥经济、科技政策的导向作用，使企业成为研究开发投入的主体。\n改革科技计划支持方式，支持企业承担国家研究开发任务，使企业成为创新活动的主体。\n完善技术转移机制，促进企业的技术集成与应用，使企业成为创新成果应用的主体。\n\n\n3.重建国家创新体系创新型国家\n统筹协调科技体制与经济体制、育体制的改革进程，重建国家创新体系。\n把建设以企业为主体、产学研结合作为全面推进国家创新体系建设的突破口，坚持市场导向，打通创新产业链，盘活国家创新资源。\n建设科学研究与高等数育有机结合的知识创新体系，培养创新人才。\n提高全民族科学文化素质，营造有利于创新的社会环境。\n最终形成以政府为主导、充分发挥市场配置资源的基础性作用、各类科技创新主体紧密联系和有效互动的国家创新体系。\n\n\n\n\n中国的科技发展思路要有大的转变。\n在发展路径上，从跟踪模仿为主向加强自主创新转变。\n在创新方式上，从注重单项技术的研究开发向加强以重大产品和新兴产业为中心的集成创新转变。\n在创新体制上，从以科研院所改革为突破口向整体推进国家创新体系建设转变；\n在发展部署上，从以研究开发为主向科技创新与科学普及并重转变\n在国际合作上，从一般性科技交流向全方位，主动利用全球科技资源转变\n\n\n需要说明的几点：\n国家创新体系是一个全国一盘棋的系统工程。\n科学技术是第一生产力，但中间还需要跨越许多创新环节\n科技政策是其中的一个政策工具，还需要金融政策、财税政策、知识产权保护政策等等手段。\n\n\n反思：\n在国家创新体系中企业一家独大是中国科技创新的出路吗？没有跳出长期以来中国科技体制改革“体”为“用”服务模式\n\n\n保障美国21世纪繁荣的4大科技政策《迎接风暴：振兴美国经济、创造就业机会、建设美好未来》\n1.提升基础科学教育水平\n2.加大基础科学研究投入\n3.培养科学创新人才\n4.改善创新投资环境\n\n\n\n\n4. 单元总结\n科技政策分为两个部分，三个核心问题\n《科学：没有止境的前沿》主要观点\n1963，OECD发表《科学和政府的政策》提出科学活动的三种类型：基础研究，应用研究和试验发展\n“市场失效”、“系统失效”\n三螺旋模型：政府、学术界与产业界\n1956四大紧急措施\n自主创新三种类型\n《国家中长期科学和技术发展规划纲要(2006-2020)》指导方针：自主创新，重点跨越，支撑发展，引领未来\n中医药4个特点：简、便、廉、验\n\n科学家角色、行为规范与不端行为1. 前言\n角色定义：与一定的社会位置和地位相联系的行为。\n社会角色是一个与社会体制、社会规范和价值体系相联系的概念。\n美国社会心理学家米德首先将角色一词引入社会学：个人在社会中总要扮演一定的角色，表示对具有一定社会地位的人所期望的行为。个人是各种角色的总和。\n\n\n角色差距：一个人不能顺利地扮演自己的角色时，产生角色差距。\n角色丛：一个人需要在社会生活中扮演多种角色（不同方面扮演不同角色），构成角色丛。\n角色冲突：一个人不能同时扮演好几种角色时就会产生角色冲突，就需要进行调整。\n科学家角色：“科学家要有科学家的行为。”\n科学家是一个独立的社会群体，其行为已经明显有别于其他一些社会群体的行为特征。\n科学家角色的出现和形成与科学的体制化进程是密切相关的。\n\n\n\n2. 科学家角色形成\n古代社会\n从事相关科学研究的人有哲学家，对自然（科学）发生兴趣–自然哲学家，如毕达哥拉斯、泰勒斯。\n神职人员，观察天象等\n技术人员，如工匠、医生、工程师、建筑师、占星术士、炼金术士等。阿基米德、希波克拉底。\n只有做出科学贡献的不同的人物，没有具有独立身份的科学家\n没有专门化的科学家角色，没有把科学本身当作目的来对待\n科学活动是在没有固定的社会角色以及特定的社会圈子中进行的。\n在古代社会，即使在某个时期科学活动可能比较繁荣，但不可能持久。所以，古代科学往往出现中断、停滞、倒退等种种现象。\n\n\n中世纪晚期\n克拉伯僧侣学院，埃及埃兹哈尔寺院(公元9世纪)\n欧洲大学，波伦那大学(12AD)、巴黎大学、牛津大学、剑桥大学\n大学科学教育开始出现，开始有部分教师通过专门讲授自然科学课程而得到工资，但处于外围和边缘的地位。\n\n\n近代早期英国\n17世纪科学逐渐成为上层精英人士的兴趣爱好\n在英国上层精英人物中逐步出现了以科学为中心的定期聚会和组织-1660年皇家学会诞生。\n\n\n近代早期法国\n法国科学院：科学家的研究工作得到政府的资助。\n科学家获得科学研究的固定职业（法国科学院院士、年薪、助手、管理职能）\n拿破仑对科学和教育采取“强制饲养”的政策，使法国职业科学家、工程师大量增加——”百余年中头一个有科学教育的、也是唯一重要的统治者“（贝尔纳）\n专业化、职业化的科学家开始出现。\n\n\n大学科学教师出现\n19世纪，德国研究型大学形成\n大学科学教师：教学、研究\n教授领导实验室（教学实验室）\n美国研究生培养体制化（研究生院），研究生导师\n科学研究与大学教学的结合对于科学家社会角色的形成具有重要意义：职位稳定化（课题不稳定）、研究梯队化（金字塔≠橄榄模式）、人才培养持续化。\n\n\n科学家进入企业和政府\n科学家兼企业家\n工业实验室提供大批科学研究职位，成为现代科学力量的重要组成部分（美国，40%)，科学-产业共同体\n国家实验室和政府部门科学家队伍：研究、管理、决策咨询(美国20%)，科学-政治-军事共同体，官-产-学一体化\n\n\n普赖斯统计：\n1903-1960年间，美国科学家人数增长了24倍，科学家在总人口中的密度增加了8倍\n17世纪中叶，全世界科学家屈指可数(皇家学会100，法国科学院15)，20世纪中叶，仅美国有科学技术学位的人就数以百万计\n90%的科学家生活在当代\n\n\n小结\n近代科学活动以及科学家的社会角色是经过几个世纪的发展才出现在西欧若干国家。\n现代科学知识的积累、发展、进步（根本原因在于科学家角色的形成，以及在此角色下开展的科学活动。\n近代科学家在世界其他地方的出现是西方科学传播的结果，不是本地传统知识分子的直接演变\n这也可以解释古代科学的停滞、倒退、甚至多次毁灭，其原因在于：\n古代传统社会的科学活动由其他的、非科学家角色完成\n取得这些科学成果的人并没有形成独立的科学家社会角色以及相应的社会圈子\n科学研究是在没有固定的社会角色和社会体制下进行的，不可能持久、稳定、连续的发展。\n\n\n\n\n\n3. 科学家的行为规范\n行为规范：在同一领域从事相近或者相同活动的人的行为准则。\n\n科学家的行为规范：\n(1)认识规范（技术规范）\nA一般科学方法论：逻辑一致、实践检验\nB各学科的特有范式\n\n\n(2)社会规范\n\n\n默顿《17世纪英国的科学技术与社会》：\n\n科学的精神气质( ETHOS)的出现\n新教清教主义对培育科学精神有重要意义\n(1)理性主义：宗教真理可以通过理性手段达到，而不是靠神启\n(2)经验主义：通过观察和系统研究自然来认识、证明上帝的业绩。\n(3)禁俗主义：勤奋工作，不计结果，不主张享乐\n(4)功利主义：求知和工作对人类有利，减轻人类生活的负担\n\n\n\n\n科学家精神气质\n\n科学包括：(1)知识、方法：(2)支配科学活动的文化价值。\n科学家活动的共同精神气质和伦理规范，即规则、指令、惯例、信念、价值这些具有感情色彩的东西形成的综合体。\n这种精神气质将从事科学活动的人联系在一起，进而合法化为体制的价值，内化为科学家的科学良心，形成科学家的行为规范。\n\n\n默顿提出四条科学的基本规范：\n\n普遍主文\n公有主义\n无私利性\n有条理的怀疑主义\n\n\n普遍主义( UNIVERSALISM)\n\n科学的标准依据科学自身的固有价值，是普遍一致的，与国家、种族、阶级、宗教、年龄等无关。\n非个人特性：科学与个人品质无关（高兰克林避雷针）\n开放性，自由职业：学习、研究科学的机会均等\n国际主义，科学没有国界\n实践要求民主的社会环境。\n\n\n公有主义( COMMUNISN)\n\n所有科学重大发现都是社会合作产物，其成果归属整个科学共同体\n科学家对其发现的定律、定理等只享有优先权，没有占有权、支配权\n科学成果是公共财高，应当公开，获得承认是硬通货\n与专利冲突\n\n\n无私利性( DISINTERESTEDNESS)\n\n从事科学活动的人不应该以科学谋取私利，应该为科学而科学。\n科学家不能因个人原因接受或拒绝某种科学思想或观点。\n从事科学源自内在的科学兴趣\n纯洁性也使科学处于严格的监督之下：“每一项科学技术都为科学家的正直诚实提供证据”，公众调查-科学家排名靠前( lawyer)\n比较理想主义\n\n\n有条理的怀疑主义（ORGANIZED SKEPTICISM）\n\n科学对自己的成果、理论呈现出批判的态度\n科学不承认神圣的、不能批判的东西。\n崇尚合理的怀疑和批判精神，并推而广之\n与宗教、意识形态多有冲突\n托马斯-阿奎那：不是因为理解才信仰，而是因为信仰才能理解\n\n\n补充和修正：\n\n默顿：创新性，谦应。\n巴伯：理性精神，感情中立\n斯托勒：客观性，概括性\n齐曼：怀疑精神一创新精神\n一同一个范式的补充和修正：基本规范\n\n\n质疑：\n\n专利\n保密制度\n市场竞争\n\n\n否定：\n\n无私利性原则是一个神话。\n每一条规范都存在着一个对立的规范\n科学规范并不是现实地存在着，当违反它们时才表现出来。\n科学规范并没有证据表明已经体制化了。\n\n\n主流观点\n\n默顿的科学规范仍是最基本的\n规范原则主要局限在科学的纯学术研究\n是学院科学的理想模式\n对科学家有潜移默化的作用\n一定程度上维护了科学的自主性\n\n\n小结\n\n学院科学：由科学家在大学和实验室中发展起来的纯粹科学，直接目的是发展知识，为科学而科学，不关心科学知识的应用。\n爱因斯坦：科学庙堂里的三种人：(1)科学能带来快乐，智力上的快感；(2)追求科学的功利目的；(3)修身养性，领悟世界：爱因斯坦，普朗克一以激情来工作（ You need talent to be good，and passion to be great)\n但是，学院科学很难被公众理解，科学得到社会支持的重要途径是科学成果的实际应用。\n公众根据科学的技术应用来评价科学、理解科学(身体的科学、身边的科学)。\n在现代社会，经济、军事、政治是决定科学应用方向的强大力量，进而影响科学的发展。\n没有功利应用，学院科学也难以为继——科学已经变得“太大、太昂贵”了。\n\n\n后学院科学（齐曼）：\n科学组织、管理、实施方式的变革。\n科学高度职业化(高度综合、高度分化)\n科学是科学家的谋生手段\n“与实践之网紧密联系在一起”\n“根据市场规则来组织”\n\n\n后学院科学的六大特征：\n(1)集体化，大课题，大设备，集体协作\n(2)极限化，经费、人员、资源限制\n(3)效用化，商用价值被突出\n(4)政策化，政府操纵，控制，科学政策成为政府政策的重要部分\n(5)产业化，与产业一体化\n(6)官僚化，层层申批，程序化，官样文章化\n\n\n保持必要的张力：\n科学的自主性是科学发展的内在、原始动力\n科学不能也无法回避社会的发展需求\n科学的基本规范仍需要尊重和维护（普遍主义、公有主义、无私利性、有条理地怀疑、创新性等）\n在需求与自主之间保持必要的张力\n\n\n\n\n\n4. 为什么要制定科研规范\n二战以前\n\n社会对科研资助非常少，对科研的期望值也比较低。\n科研人员基本上独立处理自己的事务。\n科学的目标主要是追求知识，其对新知识的认同和检验有相对比较严谨的程序，如重复，可检验性\n科学家诚信度高，公众认可。\n\n\n二战后：\n\n公共财政开始大规模支持科学研究，政府、社会对科研成果以及科研方式越来越感兴趣。\n\n逐渐地开始扩展到科研某些行为层面：\n\n先是对实验中的人和动物的关注，\n再是对科研资金运用的关注，\n再是对科研不端行为的关注，\n关注科研的风险、信任问题-PX、GM\n\n\n客观上：\n\n科研探索有其局限性，也会犯错误，如材料、数据、仪器、环境、人的观测能力。\n科研的前沿，信号与噪音分不清，测不准原理。\n\n\n\n\n科学技术与社会：\n\n有利益交织与冲突：求知-第一生产力\n\n科研成本急剧上升，2-4%GDP，是政府的重要财政投入，科学成为庞大的社会事业\n\n科学研究的不确定性和潜在风险増加：疯牛病、转基因作物、核电站。\n\n科学界不断出现严重的不端行为，黄禹锡，”越来越多的科学家，越来越多的骗子”\n\n公众民主、主体意识上升，要求科研增加透明度，利益相关者\n\n科学界需要建立于公众的新关系：科普，公众理解科学，科学对话\n\n科学不仅仅是科学界的事情，政府管理科学事业的需要\n\n阿西莫夫：科学太重要了，不能只让科学家来作主。\n\n\n\n\n5. 科研活动中的错误\n三种类型\n\n非道德错误\n疏忽造成的错误\n不端行为\n\n\n非道德错误\n\n数据的可靠性、方法的可错性、实验的不可控性、价值观的影响等\n默顿：自我实现的预言\n美国动物实验心理学家的动物\n德国动物实验心理学家的动物\n\n\n疏忽造成的错误\n\n非故意\n草率，急于求成，\n漫不经心，粗心大意\n责任心问题，缺乏严谨的科研态度和耐心\n毛选校对20遍。\n研究生论文3&#x2F;10000:\n原子弹数据1&#x2F;200000\n需要在第一时间更正错误，同样危害科学家信誉。\n\n\n\n\n不端行为(FFP)\n\n伪造( FABRICATION)：拼数据或结果，并记录和报告它们\n篡改( FALSIFICATION)：改动科研材料、设备或过程，改变和省略数据或结果，使研究不能在科研记录中准确表现\n剽窃( PLAGIARISM)：在未给予适当名誉的情况下，盗用别人的思想、方法、结果表述。\n\n\n\n6. 利益冲突\n经济利益冲突：个人利益与经济收入与科学研究之间的矛盾。\n\n职责冲突\n\n时间上的冲突，工作时间，挣外快时间一大科学家“不在会场上，就在去往会场的路上”\n资源使用冲突，公共设备与私人研究\n师生冲突，培养还是打工？——“院士都是由学生培养的”\n从属关系，在政府、大学、科研机构的与公司之间任职\n\n\n个人冲突：在评议、申报、选拔过程中\n\n个人关系亲密一利益共同体，互为评委\n个人关系紧张一互相压制\n存在个人科研竞争关系一山头主义\n\n\n\n7. 合作和荣誉分配\n科研合作：\n\n意向阶段：同心同德\n申请阶段：同舟共济\n研究进行时：同甘共苦\n研究结果出现和使用：同床异梦\n研究结果利益分配：同室操戈\n\n\n荣誉分配三种方式：\n\n(1)作者列表\n(2)致谢\n(3)参考文献和引文列表\n\n\n荣誉分配：\n\n论文作者是在研究的概念构思、设计规划或数据收集和解释过程中作出过重要贡献的人，以及在论文草稿据写和发表物最终稿审定中发挥重要作用的。\n署名原则三条同时满足：\n(1)对概念的构思和设计、数据获得、数据分析和解释等作出了实质性贡献\n(2)起草或修订过论文中的重要知识内容\n(3)审定待发表的最终稿。\n\n\n单单是争取到科研资助、收集了数据、对研究小组进行了一般监督，不具备署名权\n在论文设计、撰写过程中起作用较小的人可以放在文章后面致谢里，不能作为作者署名。\n\n\n作者署名的排名先后，即表明了荣誉也表明需要承担相应的责任\n\n案例：夏腾与黄禹锡\n\n\n应当避免的行为：\n\n荣誉署名。如项目主管、研究资助者、著名学者、导师等。\n“腊肠式”发表。将重要研究分成若干篇论文，数量影响质量。SCI\n重复发表。不告知首次发表的情况下重复同一内容的行为。“自我抄装”\n不成熟的公开发表。在研究工作接受学术评审前不发布不成熟的公开报告，除非有紧急情况，如重大危害、早期预警等。\n\n\n\n8. 科研中的不端行为防治\n同行评议：由具有相似学术水平、知识和经验的同事对科研工作进行评估。\n\n科学家的4种角色：A研究，B教学，C行政管理，D鉴定和评审（守门员）\n是科学研究和科研职业自我约束的一个基本要素\n资助评审—资助哪些项目\n论文评审—哪些研究发现可以发表\n人员评审—雇佣和提升哪些科研人员\n文献评审（专家证词）—哪些研究是可靠的\n\n\n一般没有报酬，荣誉性质。\n\n匿名评审。\n\n双盲( DOUBLE- BLIND)原则，评审方与被评审方互相不知道。\n\n陈平原：同行评议国内无法保密。\n透明原则，公开评审者\n\n\n\n9. 单元总结\n科学家职业化：法国\n科学共同体结构：金字塔模式\n科研基本规范：默顿4条\n不端行为：FFP，伪造，篡改，剽窃\n荣誉分配：三种方式：作者列表，致谢，参考文献与引文列表\n同行评议双盲原则\n科学家的4种角色\n\n科技的社会应用与技术预见1. 科学技术的社会应用前言\n科学技术的社会应用：\n\n第一次工业革命至今250年了，世界发生了翻天覆地的变化：\n马克思：蒸汽机诞生以来的100年所创造的财富比过去3000年创造的财富总和还要多，科学技术是最高意义上的革命力量\n科学技术是第一生产力，80%的贡献来自于科学技术的进步\n社会科学技术化，生产、生活、环境、文化\n但工业化至今250年，达到高生活水平的世界人口只占总人口的1&#x2F;3（发达国家），大部分(2&#x2F;3)仍生活在贫穷国家一发展中国家。\n发展中国家对发达国家科学技术的兴趣和需求非常强烈！希望尽快引进（科学技术是非本土的资源，需要大量、持续地进行移植）\n希望利用科学技术解决贫穷问题、营养不良问题、健康卫生问题、生产效益低下问题，以及其它社会诸多问题\n\n\n一个预设：科学技术因素在发达国家的工业化进程中起到了至关重要的作用。那么，科学技术因素在发展中国家向工业化转型的过程中也将起到至关重要的作用\n\n对“发展”的认识？\n\n等于经济增长\n生存发展权是第一位的\n经济发展了，就有了解决其他问题的资本\n基本无视科技发展、工业化过程带来的些负面后果：环境污染、气候变暖、资源匮乏、能源危机、物种灭绝、消费主义猖獗、城市化问题\n\n\n\n对科技应用的乐观态度\n科学技术促进发展\n发展中国家在刚独立时基本上不具备自主创新的能力，只能从发达国家那里寻求技术来源\n二战后，许多新独立国家走上了集中资源发展大型工业企业的道路，如中国、印度，其工业化进程大大快于发达国家曾经的过程\n乐观主义情绪：发展中国家的工业化将比早先的工业化国家如英国、法国、德国的发展步伐更快，社会成本也将会更低\n\n\n有利条件(1)：后发优势\n发展中国家不必凡事从头做起，没有必要去重新发明灯泡、发电机、汽车、计算机等\n现存技术的R&amp;D投资成本已经得到了补偿，收益远远大于成本，今天获得这些技术的成本已经大幅度下降了\n发展中国家可以轻易地获得这些方面的技术资源\n\n\n有利条件(2)：选择优势\n目前已经形成了竞争激烈的国际技术市场。\n发展中国家可以从琳琅满目的充满技术、产品和服务的“国际技术超市”中选择自己需要的东西，甚至成为“砍价”的主动方\n中国“高速铁路”项目，选择性价比高的日本、德国、法国的技术，轻松打市场牌(波音-空客)\n\n\n有利条件(3)：国际援助\n发展中国家可以从发达国家那里获得由政府、民间组织设立的支援贫穷国家经济、科技发展的援助项目，得到直接的帮助。\n联合国1963年成立“运用科学技术促进发展咨询委员会”(ACAST)，认为运用科学技术促进欠发达国家的发展，是联合国义不容辞的责任。\n\n\n但是，联合国“运用科学技术促进发展咨询委员会”( ACAST，1970s)调查报告显示，发展中国家R&amp;D投入只占全世界R&amp;D经费投入的2%，到了微不足道的地步\n\n科技应用实践中出现的问题\n相关分析(1)：教育与科研导向问题\n发展中国家的科学家，尤其是优秀科学家往往接受的是西方传统的科学、科研的教育和培养，衡量科研成果的主要指标是是否作出了高水平的基础研究，发表科研论文——SCI\n科学精英与发展中国家的经济、社会、文化背景相脱离，甚至毫无关系，本地的科学共同体被边缘化、被异化\n斯里兰卡：教育西化、科研西化、精英西化\n\n\n相关分析(2)：科技与本地需求相脱节\n本地的需求和问题被忽视，引进的先进的科学技术往往是西方的成熟技术，变成“交钥匙工程”，无法促进科技进步，其发展与本地的需求关系不大\n发展中国家的经济结构也并不鼓励高水平的科研活动，如农业、矿业不是技术密集型产业农林牧业常常靠的不是持续创新，反而对地方性知识依赖较多\n发展中国家人才流失，海龟变海带、海怪，最后技术移民，变成反向的向发达国家的人才援助\n\n\n相关分析(3)：引进技术不便宜\n进口设备、工艺、原料、技术等，其专利被发达国家跨国公司所垄断，满天要价的情况严重\n跨国公司将专利技术转移到发展中国家的子公司时，经常蓄意把价格定的过高，有时甚至高出几十倍，形成有组织的“转移定价”。导致西方技术的隐性成本很高。\n中国的计算机技术引进，卫星技术引进\n\n\n相关分析(4)：产生新的问题\n发展中国家引进的技术往往是资本密集型、技术密集型的，这些技术并没有创造出更多的就业机会，而且对传统农业工业已有的工作岗位造成严重破坏。\n对西方技术的依赖，需要付出高昂的代价，发展中国家的小规模经营个体的经济能力承受不起创新的成本。\n\n\n相关分析(5)：案例\n“绿色革命”带来粮食大丰收的同时，造成新的贫困问题，菲律宾、印度\n增产的途径是实施系统的、太规模的种植改良计划，需要不断使用化肥以及人工灌溉\n最终受益的是大型农场主\n\n\n\n若干解决策略与思路分析\n中间技术：\n一方面传统本土技术效率低下，难以脱贫致富，一方面发达国家的技术过于先进和昂贵，生产者负担不起，引进后不能创造更多就业机会\n需要介于西方技术和本土技术之间的中间技术，既能创造就业机会，也能提高经济收入\n砖瓦厂：小规模、低成本、低价格\n加纳、冈比亚、苏丹成功案例\n\n\n适用技术：\n不同于西方发展模式，结合本地需求和自身条件，适合自身发展的技术路线，能独立自主、保护本地生态平衡、对传统生活方式和价值观的影响和损害降到最小的限度\n沼气技术：替代西方能源和肥料体系，成本低，简单适用，容易推广\n\n\n技术融合：\n把先进技术与传统技术、新技术和旧技术有机地调合起来，而不是让新技术取代旧技术，以满足穷人的不断增长的各种需要\n摆脱对西方技术的依赖\n提高本土技术能力和研发水平\n产生本土的技术创新，甚至出口\n\n\n技术融合的方式：\n(1)新技术嫁接到旧技术上\n(2)新技术应用于市场导向的、小规模的生产活动上，而不是让新技术取代旧技术\n(3)新技术应用到公共物品和公共服务上，如公共卫生、农村电信等\n\n\n案例：\n古巴：运用先进技术解决社会经济生产中的实际问题，而不是从事生物技术的前沿进行基础研究，利用新技术改造制糖业，提高本土技术水平\n印度：生物公司科研与世界同步，与本地发展严重脱节，大量人才外流\n\n\n讨论\n对“发展”重新认识：经济增长，环境代价，资源代价，生产模式的代价，消费模式的代价\n可持续发展的理念：\n(1)满足当代人的需要：代内公平\n(2)不损害后代人的发展需要：代际公平\n\n\n科技、经济全球化：\n日本人用中国人生产的筷子，吃泰国人生产的大米，穿印尼人生产的衣服，喝巴西的橘子汁，买哥伦比亚的鲜花，尝墨西哥的草莓\n生产、消费、文化价值均一化，丧失多样性\n美国的汉堡包全球消费：改变所在地的农业体系和饮食体系\n成都之行，回锅肉\n\n\n适用技术的问题：\n印度沼气技术：富人更富，穷人失去原有资源\n中国沼气技术：集体收益？\n\n\n科学技术不是万能的；不是独立自主发展的：受到社会的影响和塑造\n谁想发展某种技术？\n谁能拥有和控制这种技术？\n谁能从这种技术中获得收益？\n\n\n\n\n\n2. 技术预见背景\n技术预测( Technology forecast)\n始于1930S-美国，美国军方通过对技术发展的过去进行推演来判断未来，为制定科技政策服务。\n早期的技术预测多是探索性预测，即对已有技术发展轨迹的外推，而没有考虑未来可能的发展方向和突破\n高潮：二战前后，上世纪50-60年代（航空航天、电子、通讯、计算机技术等新领域出现）\n技术预见，Technology foresight\n上世纪90年代出现又一次高潮\n\n\n日本，1970年日本运用德尔菲方法进行了一次大规模的“30年技术遇见”调查活动\n美国技术预见的时间跨度为5-10年，每隔两年就公布次《国家关键技术报告》。1995年美国国家科学技术委员会发布第3本《国家关键技术报告》，公布了未来5-10年内重点发展的27类关键技术\n德国技术预见的时间跨度为30年，每隔5年组织一次大规模预见活动。1998年的技术预见“ Delphi98”涉及12个领域，1070项技术\n英国技术预见的时间跨度为20年，通常每5年组织一次大规模预见活动。1999年英国政府实施了第二次技术预见活动，参与预见活动的专家分为10个学科小组和3个主题小组及2个支撑小组\n上世纪90年代以来技术预见日受关注，渐成朝多国家都相继开展了基于德尔菲调查的国家技术预见活动\n一个主要原因是技术预见适应了当今时代社会、经济和科技发展的大趋势，提供了一种应对未来挑战的新的认识手段，创造了一种选择未来方向的新的识别机制\n时至今日，技术预见已成为一些国家科技发展规划的重要基础，技术预见遴选出的关键技术及其领域成为政府科学技术发展规划的重要内容\n\n3. 什么是技术预见？\n按照英国学者本・马丁( Ben R Martin)给出的一个较为公认的定义：\n“技术预见是对科学、技术、经济、环境和社会的远期未来进行有步骤的探索过程，其目的是选定可能产生最大经济与社会效益的战略研究领域和通用新技术”\n可见，技术预见不仅关注未来科技的自身推动因素而且着眼于外部市场的需求拉动作用，也就是说预见既包括对科学技术自身潜在机会的选择也包括对经济发展、社会进步相关需求的识别、不仅关注未来技术对工业和经济的影响，也关注其可能产生的社会效益（包括对环境的影响）。不仅是面对未来，而且要主动地通过选择“塑造”未来\n\n\n技术干预是一项极其复杂繁琐的工作，主要方法有：\n德尔菲法\n情景分析法\n相关树法\n其实际操作都需要耗费大量的时间、人力和经费。\n\n\n预见调查结果作为国家科技政策制定的基础数据，对于日本科技政策调整和相关领域的科技资源配置有着重要的影响\n情景分析法：设定未来发展的多种情景，分析各种可能的需求\n相关树法：建立技术关联树，综合考虑相关环节和每一种结果\n**德尔菲法( DELPHI)**：德尔菲（Delphi）—古希腊神话阿波罗神谕( ORACLE)的发布地点\n通过问卷调查的方式，让专家对事先拟定的问题自由发表意见\n统计汇总后反馈给咨询专家\n专家再次回答同样的问题\n再汇总一再反馈一可反复操作\n问题答案得到一定程度的逐渐集中，从而获得比较科学性和权威性的判断\n\n\n德尔菲法(DELPHI)特点：\n专家背对背答复咨询意见，可以充分自由地根据自己的判断和认识回答问题，提出意见\n调查结果以统计方式给出不同观点的评价，并反馈给专家，从而达到信息交流和意见凝聚的作用\n集思广益，民主与集中相结合，政策决策的有效手段\n德尔菲法是系统分析方法在意见和价值判断领域内的一种有效方法。它突破了传统的数量分析限制，为更合理地制订政策开阔思路\n\n\n技术预见过程一一材料技术领域（中科院“中国未来20年技术预见”项目）\n首先，由国内一流专家组成材料领域专家组\n其次，将材料技术领域划分为若干子领域（高分子材料、金属材料、无机和陶瓷材料、功能材料、光电子材料、纳米材料）；\n再次，由材料技术领域专家分别组成6个子领域专家组；\n通过专家研讨会（领域层面-子领域层面一多次）\n筛选出86项德尔菲调查课题；\n大型德尔菲调查（两轮）等主要方法\n对86项材料技术课题（两轮德尔菲调查数目数一致）进行了重要程度的排序\n\n\n\n4. 材料技术预见\n会聚技术是21世纪初提出的最新技术。它是指把纳米科学和技术、生物技术、信息技术、认知科学四个科学技术领域会聚在一起而组合起来的技术(简写为NBIC)\n\n美国国家科学基金会主持编写的《提升人类能力的会聚技术》报告中所说：“如果认知科学家能够想到它，纳米科学家就能够制造它，生物科学家就能够使用它，信息科学家就能够监视和控制它。\n会聚技术给我们描绘了这样一个前景：人类将在纳米的物质层面上重新认识和改造世界以及人类本身\n\n\n德尔菲调查\n\n在材料技术预见的首轮德尔菲调查中，回收的210份专家问卷共反馈了230多条建议。根据这些建议，材料技术领域专家和部分子领域专家对总共86项材料技术中的近30条课题描述进行了修改和调整，其中合并了两项技术课题，增加了一项技术课题（因而前后两轮调查的课题总数没有变化）\n在第二轮调查中，有效回复的187份问卷反馈，建议约有110多条\n第二轮德尔菲调查，主要针对\n(1)对促进经济增长\n(2)提高人们生活质量\n(3)保障国家安全的重要程度\n请专家进行判断，综合考虑上述3个因素，在此基础上得出材料技术领域最重要的10个技术课题。\n\n\n\n\n技术课题预期实现时间\n\n\n\n\n当前中国的研究开发水平\n\n\n\n技术领先国家\n\n\n\n关于技术发展的制约因素\n最大制约因素是“研发投入”(70%）\n其次是“技术可能性”(54%)\n再次是“人力资源”、“商业可行性”和“基础设施”，这3者入选率相近(25%左右)\n“政策法规”入选率最低，不到9%。\n\n\n\n\n\n技术预见结论\n材料技术预见两轮德尔菲调查法综合结果排名表明：前10项技术课题有7项相同，且排名变化都在前15位，说明两轮调查结果集中度非常高\n整体来看，材料技术各领域对社会发展重要性受到高度关注与普遍重视\n与综合排名的前10项材料技术课题相比，“经济增长”单项排名的前10项技术课题中有8项是重合的，显示出各领域专家对材料技术在经济增长方面的重要性共识较多，也说明经济主战场的需求是我国材料技术发展的最主要动力源\n就预期实现时间，表现比较乐观的预见态度\n就中国当前研发水平来看，各个子领域研发水平普遍落后国际水平，个别优势项目希望突破\n技术领先国家方面，我国上升空间很大\n制约技术发展因素，首位因素是研发投入，其次是技术可能性，再其次是商业可能性等；基础研发投入不足\n\n\n技术预见讨论\n市场唯一不变的就是变化\n武侠：要练神功，勇气、平静、智慧\n最好的防御是进攻\n最好的预见是主动改变- Shape Future\n行到水穷处，坐看云起时\n自然、随缘也是开放、包容，君子豹变\n\n\n\n5. 单元总结\n可持续发展：代内公平、代际公平\n什么是技术预见？\n什么是德尔菲法？\n会聚技术：NBIC\n\n© 北京大学 JackHCC\n","categories":["自然辩证法"],"tags":["自然辩证法"]}]