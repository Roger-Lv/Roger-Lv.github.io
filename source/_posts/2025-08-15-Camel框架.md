---
title: Camel框架
date: 2025-08-18
updated:
tags: [人工智能,Agent,LLM]
categories: Agent
keywords:
description:
top_img: /img/default_top_img.jpg
comments:
cover: /img/cover/camel.png
toc:
toc_number:
toc_style_simple:
copyright:
copyright_author:
copyright_author_href:
copyright_url:
copyright_info:
mathjax:
katex:
aplayer:
highlight_shrink:
aside:
abcjs:


---



# NeurIPS 2023｜AI Agents先行者CAMEL:第一个基于大模型的多智能体框架

转自：https://zhuanlan.zhihu.com/p/671093582

AI Agents是当下大模型领域备受关注的话题，用户可以引入多个扮演不同角色的LLM Agents参与到实际的任务中，Agents之间会进行竞争和协作等多种形式的动态交互，进而产生惊人的群体智能效果。本文介绍了来自[KAUST研究团队](https://zhida.zhihu.com/search?content_id=237261967&content_type=Article&match_order=1&q=KAUST研究团队&zhida_source=entity)的大模型心智交互[CAMEL框架](https://zhida.zhihu.com/search?content_id=237261967&content_type=Article&match_order=1&q=CAMEL框架&zhida_source=entity)（“骆驼”），CAMEL框架是最早基于[ChatGPT](https://zhida.zhihu.com/search?content_id=237261967&content_type=Article&match_order=1&q=ChatGPT&zhida_source=entity)的autonomous agents知名项目，目前已被顶级人工智能会议NeurIPS 2023录用。



![img](https://pic3.zhimg.com/v2-8b8618126f0a2ed74a344da3d67b98b8_1440w.jpg)

1777dbe9073c4bcd8ab59365481bcafc.png



> 论文题目： CAMEL: Communicative Agents for “Mind” Exploration of Large Scale Language Model Society 论文链接： [https://ghli.org/camel.pdf](https://link.zhihu.com/?target=https%3A//ghli.org/camel.pdf)
> 代码链接： [https://github.com/camel-ai/camel](https://link.zhihu.com/?target=https%3A//github.com/camel-ai/camel)
> 项目主页： [https://www.camel-ai.org/](https://link.zhihu.com/?target=https%3A//www.camel-ai.org/)

*“什么神奇的技巧让我们变得智能？ 窍门就是没有窍门。智慧的力量源于我们巨大的多样性，而不是任何单一的、完美的原则。”*
*——人工智能先驱 马文·明斯基（[Marvin Minsky](https://zhida.zhihu.com/search?content_id=237261967&content_type=Article&match_order=1&q=Marvin+Minsky&zhida_source=entity)）[1]*

目前来看，在机器通向高级智能的道路上，以ChatGPT为代表的大模型（LLMs）应该是必须经过的里程碑之一，它们以聊天对话的人机交互方式在多个领域的复杂任务解决方面取得了非常耀眼的成就。随着LLMs的发展，**AI Agents（AI智能体）之间的交互框架也逐渐兴起**，尤其是在一些复杂的专业领域，以角色扮演等模式预置的智能体完全有能力代替人类用户在任务中扮演的角色，同时，**智能体之间通过以协作和竞争形式的动态交互**往往能够带来意想不到的效果，这就是**被[OpenAI](https://zhida.zhihu.com/search?content_id=237261967&content_type=Article&match_order=1&q=OpenAI&zhida_source=entity)人工智能专家[Andrej Karpathy](https://zhida.zhihu.com/search?content_id=237261967&content_type=Article&match_order=1&q=Andrej+Karpathy&zhida_source=entity)等人看作是“通向AGI最重要的前沿研究方向”的AI Agents**。

今年3-4月份一些基于ChatGPT的Autonomous Agent项目[2]：

- “CAMEL”（骆驼：大模型心智交互框架）- 发布于2023.3.21
- “[AutoGPT](https://zhida.zhihu.com/search?content_id=237261967&content_type=Article&match_order=1&q=AutoGPT&zhida_source=entity)” - 发布于2023.3.30
- “[BabyGPT](https://zhida.zhihu.com/search?content_id=237261967&content_type=Article&match_order=1&q=BabyGPT&zhida_source=entity)” - 发布于2023.4.3
- “Westworld” simulation（斯坦福西部世界小镇） — 发布于2023.4.7

**作为最早基于ChatGPT的autonomous agents知名项目**，CAMEL重点探索了一种**称为角色扮演（role-playing）的新型合作代理框架**，该框架可以有效缓解智能体对话过程中出现的错误现象，从而有效引导智能体完成各种复杂的任务，人类用户只需要输入一个初步的想法就可以启动整个过程。**目前，CAMEL已经被国际人工智能顶级会议NeurIPS 2023录用**。



![img](https://pica.zhimg.com/v2-113f13f599524f392c3d372269e96274_1440w.jpg)

demos



**作者对CAMEL框架设计了灵活的模块化功能，包括不同代理的实现、各种专业领域的提示示例和AI数据探索框架等**，因此CAMEL可以作为一个基础的Agents后端，支持AI研究者和开发者更加轻松地开发有关于多智能体系统、合作人工智能、博弈论模拟、社会分析、人工智能伦理等方面的应用。**具体的，作者通过涉及两种角色扮演的合作场景，生成了两个大型的指令数据集AI Society和AI Code，以及两个单轮问答数据集AI Math和AI Science，用于探索[LLM涌现能力](https://zhida.zhihu.com/search?content_id=237261967&content_type=Article&match_order=1&q=LLM涌现能力&zhida_source=entity)的研究**。

### 01. CAMEL框架

下图展示了CAMEL中的role-playing框架，人类用户需要首先制定一个想要实现的想法或目标，**例如：开发一个用于股票市场的交易机器人。这项任务涉及的角色是AI助理智能体（使其扮演Python程序员角色）和AI用户智能体（使其扮演股票交易员角色）**。



![img](https://pic4.zhimg.com/v2-0d07166cff60e3655f3aa7cb0854c839_1440w.jpg)

camel role-playing framework

作者首先为CAMEL设置了一个任务细化器（Task Specifier），该细化器会根据输入的想法来制定一个较为详细的实现步骤，**随后AI助理智能体（AI Assistant）和AI用户智能体（AI User）通过聊天的方式来进行协作通信**，各自一步步完成指定的任务。其中协作通信通过系统级的消息传递机制来实现，令 $\mathcal{P}*A$ 为传递给AI助理智能体的系统消息，$\mathcal{P}_U$ 为传递给AI用户智能体的系统消息。随后为AI助理智能体和AI用户智能体分别实例化为两个ChatGPT模型 $\mathcal{F}_1$ 和 $\mathcal{F}_2$ ，相应得到AI助理智能体 $\mathcal{A}\leftarrow\mathcal{F}*{1}^{\mathcal{P}*{A}}$ 和AI用户智能体 $\mathcal{U}\leftarrow\mathcal{F}*{2}^{\mathcal{P}_{U}}$ 。

角色分配完成后，**AI助理智能体和AI用户智能体会按照指令跟随的方式协作完成任务**，令 $\mathcal{I}_t$ 为时间 $t$ 时刻获得的用户指令消息，$\mathcal{S}_t$ 为AI助理智能体给出的解决方案，因而 $t$ 时刻得到的对话消息集为：



在下一个时刻 $t+1$ ，AI用户智能体 $\mathcal{U}$ 会根据历史对话消息集 $\mathcal{M}*t$ ，来生成新的指令 $\mathcal{I}*{t+1}$ 。然后再将新指令消息与历史对话消息集一起传递给AI助理智能体 $\mathcal{A}$ 来生成新一时刻的解决方案：





更多技术细节，可以参考我们先前对[CAMEL的报道](https://link.zhihu.com/?target=https%3A//www.techbeat.net/article-info%3Fid%3D4821)。

### 02. CAMEL使用示例

### 2.1 协作角色扮演（cooperate role-playing）

CAMEL内置的协作式role-playing框架可以在人类用户不具备专业知识的情况下，通过Agents之间的协作方式完成复杂任务，下图展示了CAMEL开发股票市场交易机器人的例子，其中AI助理智能体的扮演的角色是一名Python程序员，而AI用户智能体扮演的角色为一名股票交易员。



![img](https://pic2.zhimg.com/v2-61d1edb7f86e0e120ea5b7fe1bb320a7_1440w.jpg)

image.png



在role-playing框架中，AI智能体都具有特定领域的专业知识，此时我们只需要指定一个原始想法的Prompt，随后两个AI智能体就会围绕着这一想法展开工作，在上图中，**用户智能体提出交易机器人需要有对股票评论的情绪分析功能**，随后助理智能体直接给出了安装情绪分析和股票交易所需的python库的脚本。



![img](https://pic1.zhimg.com/v2-d6737f9518e5dc1db9b06e0d00a3d338_1440w.jpg)

image.png



随着任务的进行，用户智能体给出的指示也会越来越明确，上图中的指示为：定义一个函数以使用Yahoo Finance API获取特定股票的最新股价。助理智能体会根据该指示直接生成一段代码来解决需求。

### 2.2 具身智能体（embodied agent）

在先前的研究中，**AI Agents可以理解为在模拟一些操作，而没有与现实世界交互或使用外部工具执行操作**，目前的LLMs已经具备与互联网或其他工具API交互的能力，**CAMEL也提供了能够在物理世界中执行各种操作的具身智能体（embodied agent），它们可以浏览互联网、阅读文档、创建图像、音频和视频等内容**，甚至可以直接执行代码。



![img](https://pica.zhimg.com/v2-70ead7d682e0e80fac2bfc081290cdc0_1440w.jpg)

embodied agent



上图展示了CAMEL通过使用embodied agent调用HuggingFace提供的Stable Diffusion工具链生成骆驼科图像的样例，在这一过程中，embodied agent首先会推理出骆驼科所包含的所有动物，随后调用扩散模型生成图像并进行保存。

### 2.3 critic在环（critic-in-the-loop）

为了增强role-playing框架的可控性，**作者团队还为CAMEL设计了一种critic-in-the-loop，这种机制受到了蒙特卡洛树搜索（MTCS）方法的启发**，它可以结合人类偏好实现树搜索的决策逻辑来解决任务，CAMEL可以设置一个**中间评价智能体（critic）来根据用户智能体和助理智能体出的各种观点进行决策来完成最终任务**，整体流程如下图所示。



![img](https://picx.zhimg.com/v2-814690e0a00b40bc9db82117d54c7c01_1440w.jpg)

critic-in-the-loop



考虑这样一个场景，我们让CAMEL主持一场很具体的科研项目讨论会，而科研项目的主题“大型语言模型”，**CAMEL可以将用户智能体的角色设置为一个博士后，将助理智能体的角色设置为博士生，而中间评价智能体的角色设置为教授**。任务指示博士生来帮助博士后制定研究计划，需要围绕大模型的伦理展开研究。



![img](https://pic3.zhimg.com/v2-49337c8d858ff8cb942f6d966fa94a84_1440w.jpg)

cd45d7eff8544cb489c608ec4132c1c6.png



在接到任务后，博士后智能体首先抛出了关于这一项目的三个观点，表明项目应该首先从调研大模型伦理方面的相关工作着手。随后教授智能体会根据这三个观点给出自己的看法。并且认为观点2最为合理的，即研究大模型歧视性算法。**同时还会给出另外两个观点的缺陷，例如观点1缺乏更加清晰的结构，观点3的研究范围太窄等等**。



![img](https://pic2.zhimg.com/v2-9539bf3da7b8fe4186525e94ba803883_1440w.jpg)

952ec02136994d82bdcdeb0b2af87426.png



在教授发言之后，**博士生智能体会进行更加具体的项目规划，例如直接列出一些大模型伦理安全方向的相关文献**，并且讨论如何开展具体的研究。

### 03. 实验效果

本文的性能评估主要从三个方面进行，并且采用两个gpt-3.5-turbo作为实验智能体，实验的数据集使用CAMEL框架生成的四个AI数据集，其中AI Society和AI Code侧重于智能体的对话效果，而AI Math和AI Science侧重于智能体的问题解决能力。

### 3.1 Agent评估

在这一部分，作者从AI Society和AI Code数据集中分别随机选择 100 个任务进行评估，然后使用CAMEL框架和单个gpt-3.5-turbo进行对比实验，结果评估方面分为两部分，**一方面由人类受试者对两种方法给出的解决方案给出453份投票数据，来决定哪种方案更加可行。另一方面，作者提示GPT4模型对两种方案直接给出评分**，具体的对比数据如下表所示。



![img](https://pic2.zhimg.com/v2-bdecee4deb9e6441bea34ce52b2b718d_1440w.jpg)

aadbbd5162ef4fbea0d82563fa8937e0.png



从上表中可以看出，**CAMEL框架给出的解决方案在人类评估和GPT4评估中均大幅优于gpt-3.5-turbo给出的解决方案，其中人类评估和GPT4评估的总体趋势高度一致**。

### 3.2 使用GPT-4对ChatBot评估

在这一部分，**作者在CAMEL生成的四个数据集上对LLaMA-7B模型进行了逐步的微调**，通过向LLM中不断注入来自社会、代码、数学和科学等不同领域的知识，来观察模型对知识发现的接受效果。作者首先从AI Society数据集开始，**让模型了解人类的互动常识和社会动态，随后AI Code和其他数据集的注入，模型获得了编程逻辑和语法的知识，同时拓宽了模型对科学理论、经验观察和实验方法的理解**。



![img](https://pic3.zhimg.com/v2-37e90314213b4164b6102a926544ca00_1440w.jpg)

b3ff76f0086e45dcb957cf4945bc6516.png

上表展示了模型在**20个Society任务、20个代码编写任务、20个数学任务和60个科学任务上**的测试效果，可以看到在每次添加数据集时，模型在已训练过的任务域上都会表现得更好。

### 3.3 HumanEval

为了进一步评估CAMEL框架的代码编写任务解决能力，**作者在HumanEval和HumanEval+两个评估基准上进行了实验**，实验结果如下表所示。



![img](https://pic4.zhimg.com/v2-6532884b7bb1268d69a3d6d23e4fcb13_1440w.jpg)

49fd4c645a9d498ebd0afdf37cba37fe.png



上表中清楚地证明了CAMEL框架的卓越性能，它不仅远远超过了LLaMA-7B模型，而且还大大超过了Vicuna-7B模型，这表明使用CAMEL生成的数据集在增强LLM处理编码相关任务方面有独特的效果。

### 04.CAMEL AI开源社区

![img](https://picx.zhimg.com/v2-23d65082a8ae64ffb00bbd0accc950f3_1440w.jpg)