---
title: 现有GUI Agent的训练数据、训练方法及实例分析
date: 2025-08-27
updated:
tags: [LLM,Agent]
categories: Agent
keywords:
description:
top_img: /img/default_top_img.jpg
comments:
cover: /img/cover/agent.png
toc:
toc_number:
toc_style_simple:
copyright:
copyright_author:
copyright_author_href:
copyright_url:
copyright_info:
mathjax:
katex:
aplayer:
highlight_shrink:
aside:
abcjs:




---

# 现有GUI Agent的训练数据、训练方法及实例分析

## 一、主要训练数据来源

### 1. 公开可用数据集
- **CogAgent**的预训练数据全部来源于公开可用的数据集，包括文本识别、视觉定位(visual grounding)等多方面数据。https://openaccess.thecvf.com/content/CVPR2024/papers/Hong_CogAgent_A_Visual_Language_Model_for_GUI_Agents_CVPR_2024_paper.pdf
- 具体数据包括：(1)文本识别数据，用于处理GUI中的文字内容；(2)视觉定位数据，帮助模型理解界面元素的位置和关系。
- CogAgent的训练策略综合了多种数据源，专门针对GUI特有的挑战进行了优化设计。

### 2. 用户交互轨迹数据
- **MobileA3gent**框架使用从用户日常手机交互中自动收集的数据来训练移动代理，采用去中心化的自源数据收集方法。https://arxiv.org/html/2502.02982v2
- **Mobile-Agent-v3**的训练数据直接来源于高质量离线交互轨迹中的各个步骤，通过分析用户与GUI的实际交互过程来学习操作模式。

### 3. 合成数据与专家演示
- 部分GUI Agent使用专家演示数据，即由人类专家执行任务并记录操作步骤，作为训练样本。
- 有些系统会生成合成GUI交互数据，通过模拟用户行为创建大规模训练集。

## 二、主要训练方法

### 1. 监督微调(Supervised Fine-Tuning, SFT)
- 大多数GUI Agent主要采用监督微调方法，在预训练的多模态大模型基础上进行针对性训练。
- 训练任务通常包括：视觉问答(VQA)、界面元素定位、操作步骤预测等。
- 微调过程使用标注好的"状态-动作"对，即特定GUI界面状态下应执行的操作。

### 2. 强化学习(Reinforcement Learning)
- 部分高级GUI Agent框架结合了强化学习，通过奖励机制优化长期任务完成能力。
- **Mobile-Agent-v3**在监督微调阶段后，还使用强化学习进一步优化代理性能。

### 3. 多阶段训练策略
- **CogAgent**采用了全面的训练策略，包括预训练和针对GUI特定任务的微调阶段。
- 预训练阶段关注基础的视觉语言理解能力，微调阶段则专注于GUI交互的特殊需求。

## 三、典型GUI Agent实例分析

### 1. CogAgent
- **特点**：专门训练的视觉语言模型，专为GUI理解和导航设计。
- **训练数据**：
  - 文本识别数据：处理GUI中的各种文本元素
  - 视觉定位数据：理解界面元素的位置和关系
  - 任务执行数据：GUI操作与结果的映射关系 
- **训练方法**：采用多阶段训练，首先在大规模数据上预训练，然后在GUI特定任务上进行监督微调。
- **优势**：相比直接使用通用VLM(如GPT-4V)，CogAgent在GUI任务上表现更专业、更高效。

### 2. MobileAgent/AppAgent
- **特点**：基于GPT-4V的移动设备GUI交互代理，能够自主完成手机上的用户请求。
- **训练数据**：
  - 来自真实用户交互的轨迹数据
  - 高质量的离线交互步骤序列 
- **训练方法**：
  - 监督微调：在标注的交互轨迹上训练
  - 协作学习框架：多个代理共同学习，共享经验 
- **实例**：AppAgent能够基于手机截图理解界面，并执行点击、输入等操作完成任务，如"在微信中发送表情"等。

### 3. UFO (Windows GUI Agent)
- **特点**：专为Windows操作系统设计的UI聚焦代理，采用双智能体架构。
- **训练方法**：
  - 不直接训练新模型，而是利用预训练的GPT-Vision作为基础
  - 通过精心设计的框架(HostAgent+AppAgent)和控制交互模块实现GUI操作
  - 采用计划反思(Plan Reflection)机制提高适应性 [[3.5.4]]
- **特殊设计**：包括控制过滤、安全卫士等机制，增强在复杂Windows环境中的可靠性。

## 四、发展趋势

1. **专业化训练**：从通用VLM转向针对GUI任务专门优化的模型，如CogAgent所示。

2. **数据多样性**：结合真实用户交互数据、合成数据和专家演示，构建更全面的训练集。

3. **安全机制**：现代GUI Agent越来越重视安全机制，如UFO中的"安全卫士"功能，对敏感操作请求用户确认。

4. **跨应用能力**：新一代GUI Agent(如UFO)开始支持跨应用任务执行，能够处理更复杂的用户请求。

总体而言，GUI Agent的训练正从简单地应用现有VLM转向专门设计的训练策略和数据集，以更好地理解和操作图形用户界面，实现更可靠、更安全的自动化交互。